<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xi="http://www.w3.org/2001/XInclude" xml:id="automated-downloading-with-wget" type="original" xml:base="automated-downloading-with-wget/automated-downloading-with-wget.xml">
    <teiHeader>
        <fileDesc>
            <titleStmt>
                <title>Automated Downloading with Wget</title>
                <author role="original_author">Ian Milligan</author>
                <editor role="reviewers">Aurélien Berra</editor>
                <editor role="editors">Adam Crymble</editor>
            </titleStmt>
            <publicationStmt>
                <distributor>Programming Historian</distributor>
                <idno type="doi">10.46430/phen0001</idno>
                <date type="published">06/27/2012</date>
            </publicationStmt>
            <sourceDesc>
                <p>Born digital, in a markdown format. This lesson is original. Available translations are the following:<ref type="translations" target="#descarga-automatizada-con-wget"/>
                </p>
            </sourceDesc>
        </fileDesc>
        <profileDesc>
            <abstract>
                <p>Wget is a useful program, run through your computer's command line, for retrieving online material.</p>
            </abstract>
            <textClass>
                <keywords>
                    <term xml:lang="en">web-scraping</term>
                </keywords>
            </textClass>
        </profileDesc>
    </teiHeader>
    <text xml:lang="en">
        <body>
            <div type="2" n="1">
                <head>Editor's Note</head>
                <p>This lesson requires you to use the command line. If you have no
previous experience using the command line you may find it helpful to
work through the <emph>Programming Historian’s</emph>
                    <ref target="/lessons/intro-to-bash">Introduction to the Bash Programming Language</ref>.</p>
            </div>
            <div type="2" n="2">
                <head>Lesson Goals</head>
                <p>This is a lesson designed for intermediate users, although beginner
users should be able to follow along.</p>
                <p>Wget is a useful program, run through your computer's command line, for
retrieving online material.</p>
                <figure>
                    <desc>The Mac Command Line, Terminal</desc>
                    <graphic url="Terminal-on-mac2.png"/>
                </figure>
                <p>It can be useful in the following situations:</p>
                <list type="unordered">
                    <item>Retrieving or mirroring (creating an exact copy of) an entire
website. This website might contain historical documents, or it may
simply be your own personal website that you want to back up. One
command can download the entire site onto your computer.</item>
                    <item>Downloading specific files in a website's hierarchy (all websites
within a certain part of a website, such as every page that is
contained within the <code rend="inline">/papers/</code> directory of a website).</item>
                </list>
                <p>In this lesson, we will work through three quick examples of how you
might use wget in your own work. At the end of the lesson, you will be
able to quickly download large amounts of information from the Internet
in an automated fashion. If you find a repository of online historical
information, instead of right-clicking on every file and saving it to
build your dataset, you will have the skills to craft a single command
to do so.</p>
                <p>First, a caution is in order. You need to be careful about how you use
wget. If you consult the manual when in doubt, and work through the
lessons here, you should be okay. You should always build a delay into
your commands so that you do not overload the servers, and should also
always put a limit on the speed to which you download. This is all part
of being a good Internet citizen, and can be seen as analogous to
sipping from a firehose rather than turning it on all at once (it's not
good for you, or the water company).</p>
                <p>Be as specific as possible when formulating your download. One joke
suggests that you can accidentally download the entire Internet with
wget. While that's a bit of an exaggeration, it isn't too far off!</p>
                <p>Let's begin.</p>
            </div>
            <div type="2" n="3">
                <head>Step One: Installation</head>
                <div type="3" n="3.1">
                    <head>Linux Instructions</head>
                    <p>If you are using a Linux system, you should already have wget installed.
To check if you have it, open up your command line. Type <code rend="inline">'wget'</code> and
press enter. If you have wget installed the system will respond with:</p>
                    <ab>
                        <code xml:id="code_automated-downloading-with-wget_0" corresp="code_automated-downloading-with-wget_0.txt" rend="block"/>
                    </ab>
                    <p>If you do not have wget installed, it will respond with</p>
                    <ab>
                        <code xml:id="code_automated-downloading-with-wget_1" corresp="code_automated-downloading-with-wget_1.txt" rend="block"/>
                    </ab>
                    <p>If you are on OS X or Windows, you will need to download the program. If
on Linux, you receive the error message indicating that you do not have
wget installed, follow the OS X instructions below.</p>
                </div>
                <div type="3" n="3.2">
                    <head>OS X Instructions</head>
                    <div type="4" n="3.2.1">
                        <head>OS X Option One: The Preferred Method</head>
                        <p>On OS X, there are two ways to get wget and install it. The easiest is
to install a package manager and use it to automatically install wget.
There is a second method, discussed below, that involves compiling it.</p>
                        <p>Both, however, require that you install Apple's 'Command Line Tools' to
use properly. This requires downloading XCode. If you have the 'App
Store', you should be able to just <ref target="https://itunes.apple.com/us/app/xcode/id497799835?mt=12">download XCode via this link</ref>.  If
not, the following instructions will work.</p>
                        <p>To download this, go to the <ref target="https://developer.apple.com/xcode/">Apple Developer website</ref>, register as a
developer, and then in the <ref target="https://developer.apple.com/xcode/">downloads for Apple developers</ref> section you will need to find the correct version. If
you are on the most recent version, Lion as of July 2012, you can use
the main link. If not, you will need to click on the link: "Looking for
additional developer tools? <ref target="https://developer.apple.com/downloads/">View Downloads</ref>."</p>
                        <p>After logging in with your free developer credentials, you will see a
long list. Type xcode in the search bar and find a version that is
compatible with your operating system version. This may take some
clicking around to find the right version for you. For example, Xcode
3.2 is the version for OS X 10.6 Snow Leopard, 3.0 is the version for OS
X 10.5 Leopard, etc.</p>
                        <p>It is a big download, and will take some time. Once you have the file,
install it.</p>
                        <p>You will need to install the '<hi rend="bold">Command Line Tools</hi>' kit in XCode. Open
up the 'Preferences' tab, click on 'Downloads,' and then click 'Install'
next to Command Line Tools. We are now ready to install a package
manager.</p>
                        <p>The easiest package manager to install is <emph>Homebrew</emph>. Go to
<ref target="https://brew.sh">https://brew.sh</ref> and review the instructions. There are
many important commands, like wget, that are not included by default in
OS X. This program facilitates the downloading and installation of all
required files.</p>
                        <p>To install <emph>Homebrew</emph>, open up your terminal window and type the
following:</p>
                        <ab>
                            <code lang="language-bash" xml:id="code_automated-downloading-with-wget_2" corresp="code_automated-downloading-with-wget_2.txt" rend="block"/>
                        </ab>
                        <p>This uses the ruby programming language, built into OS X, to install
Homebrew. To see if the installation worked, type the following into
your terminal window:</p>
                        <ab>
                            <code lang="language-bash" xml:id="code_automated-downloading-with-wget_3" corresp="code_automated-downloading-with-wget_3.txt" rend="block"/>
                        </ab>
                        <p>A list of documentation options should appear if it has been installed.
We have one more command to run to make sure everything is working,
which is:</p>
                        <ab>
                            <code lang="language-bash" xml:id="code_automated-downloading-with-wget_4" corresp="code_automated-downloading-with-wget_4.txt" rend="block"/>
                        </ab>
                        <p>With <emph>Homebrew</emph> installed, we now have to install wget. This is now an
easy step.</p>
                        <ab>
                            <code lang="language-bash" xml:id="code_automated-downloading-with-wget_5" corresp="code_automated-downloading-with-wget_5.txt" rend="block"/>
                        </ab>
                        <p>It will proceed to download the most recent version of wget, which is
wget 1.14. After the script stops running, and you are back to your main
window, enter the following command into the terminal:</p>
                        <ab>
                            <code lang="language-bash" xml:id="code_automated-downloading-with-wget_6" corresp="code_automated-downloading-with-wget_6.txt" rend="block"/>
                        </ab>
                        <p>If you have installed it, you will see:</p>
                        <ab>
                            <code xml:id="code_automated-downloading-with-wget_7" corresp="code_automated-downloading-with-wget_7.txt" rend="block"/>
                        </ab>
                        <p>If not, you will see:</p>
                        <ab>
                            <code xml:id="code_automated-downloading-with-wget_8" corresp="code_automated-downloading-with-wget_8.txt" rend="block"/>
                        </ab>
                        <p>At this point, you should have installed wget successfully. We are now
ready to keep going!</p>
                    </div>
                    <div type="4" n="3.2.2">
                        <head>OS X Option Two</head>
                        <p>If for some reason you do not want to install a package manager, you are
able to simply download wget alone. This will be applicable if you are
using a different packet manager (such as Mac Ports) or if you want to
keep your infrastructure to a minimum. Follow the same instructions
again to install xcode and the Command Line Tools set.</p>
                        <p>Then you can subsequently download an uncompiled version of wget from
the <ref target="http://www.gnu.org/software/wget/">GNU website</ref> (I chose to download the file 'wget-1.13.tar.gz',
which you can find by following the link to either the <ref target="http://ftp.gnu.org/gnu/wget/">HTTP</ref> or
<ref target="ftp://ftp.gnu.org/gnu/wget/">FTP</ref> download pages), unzip it (by double-clicking on it) into your
home directory (on a Mac, this will be your <code rend="inline">/user/</code> directory – for
example, my user name is ianmilligan and it appears next to a house icon
in my Finder), and then open up Terminal. For this tutorial, we have
downloaded <code rend="inline">wget-1.13</code>.</p>
                        <p>First, we will need to navigate to the directory that the wget files are
in. At the terminal, type:</p>
                        <ab>
                            <code lang="language-bash" xml:id="code_automated-downloading-with-wget_9" corresp="code_automated-downloading-with-wget_9.txt" rend="block"/>
                        </ab>
                        <p>Note that if you have downloaded a different version of wget, the
following steps will work but you may have to replace the above version
number (i.e. <code rend="inline">1.13</code>) with your own.</p>
                        <p>We now need to generate the instructions, or makefile, for the file.
This is sort of a blueprint for what the final file is going to look
like. Accordingly, type:</p>
                        <ab>
                            <code lang="language-bash" xml:id="code_automated-downloading-with-wget_10" corresp="code_automated-downloading-with-wget_10.txt" rend="block"/>
                        </ab>
                        <p>Now that we have the blueprints, let's tell our computer to follow
them. Type:</p>
                        <ab>
                            <code lang="language-bash" xml:id="code_automated-downloading-with-wget_11" corresp="code_automated-downloading-with-wget_11.txt" rend="block"/>
                        </ab>
                        <p>Then, you need to make the final file. By pre-pending the command sudo,
you are running the command with highest security privileges. This lets
you actually install the file into your system.</p>
                        <ab>
                            <code lang="language-bash" xml:id="code_automated-downloading-with-wget_12" corresp="code_automated-downloading-with-wget_12.txt" rend="block"/>
                        </ab>
                        <p>At this point, you will be prompted for your computer's password. Type
it.</p>
                        <p>You should now have wget installed.</p>
                    </div>
                </div>
                <div type="3" n="3.3">
                    <head>Windows Instructions</head>
                    <p>The easiest way is to download a working version. To do so, visit
<ref target="https://eternallybored.org/misc/wget/">this website</ref> and download <code rend="inline">wget.exe</code> using the installation files appropriate to your computer. You can find out if you need the 32-bit or 64-bit binary by checking your device specifications, or performing an online search.</p>
                    <p>If you place <code rend="inline">wget.exe</code> in
your <code rend="inline">C:\Windows</code> directory, you can then use wget from anywhere on your
computer. This will make your life easier as you will not have to worry
about always running wget from only one place on your system. If it is
in this directory, Windows will know that the command can be used
anywhere in your terminal window.</p>
                </div>
            </div>
            <div type="2" n="4">
                <head>Step Two: Learning about the Structure of Wget – Downloading a Specific Set of Files</head>
                <p>At this point, users of all three platforms should be on the same page.
We use wget through our operating system's command line interface
(introduced previously as <code rend="inline">Terminal</code> for Mac and Linux users, where you
have been playing around with some Python commands). You need to use
your command line, instead of the Komodo Edit client you may have used
in other lessons.</p>
                <p>The comprehensive documentation for wget can be found on the <ref target="http://www.gnu.org/software/wget/manual/wget.html">GNU wget
manual</ref> page.</p>
                <p>Let's take an example dataset. Say you wanted to download all of the
papers hosted on the website ActiveHistory.ca. They are all located at:
<ref target="http://activehistory.ca/papers/">http://activehistory.ca/papers/</ref>; in the sense that they are all
contained within the <code rend="inline">/papers/</code> directory: for example, the 9th paper
published on the website
is <ref target="http://activehistory.ca/papers/historypaper-9/">http://activehistory.ca/papers/historypaper-9/</ref>. Think of this
structure in the same way as directories on your own computer: if you
have a folder labeled <code rend="inline">/History/</code>, it likely contains several files
within it. The same structure holds true for websites, and we are using
this logic to tell our computer what files we want to download.</p>
                <p>If you wanted to download them all manually, you would either need to
write a custom program, or right-click every single paper to do so. If
the files are organized in a way that fits your research needs, wget is
the quickest approach.</p>
                <p>To make sure wget is working, try the following.</p>
                <p>In your working directory, make a new directory. Let's call it
<code rend="inline">wget-activehistory</code>. You can make this using your Finder/Windows, or if
you are at a Terminal window at that path, you can type:</p>
                <ab>
                    <code lang="language-bash" xml:id="code_automated-downloading-with-wget_13" corresp="code_automated-downloading-with-wget_13.txt" rend="block"/>
                </ab>
                <p>Either way, you now have a directory that we will be working in. Now
open up your command line interface and navigate to
the <code rend="inline">wget-activehistory</code> directory. As a reminder, you can type:</p>
                <ab>
                    <code lang="language-bash" xml:id="code_automated-downloading-with-wget_14" corresp="code_automated-downloading-with-wget_14.txt" rend="block"/>
                </ab>
                <p>to navigate to a given directory. If you've made this directory in your
home directory, you should be able to type <code rend="inline">cd wget-activehistory</code> to
move to your new directory.</p>
                <p>Enter the following command:</p>
                <ab>
                    <code lang="language-bash" xml:id="code_automated-downloading-with-wget_15" corresp="code_automated-downloading-with-wget_15.txt" rend="block"/>
                </ab>
                <p>After some initial messages, you should see the following (figures,
dates and some details will be different, however):</p>
                <ab>
                    <code xml:id="code_automated-downloading-with-wget_16" corresp="code_automated-downloading-with-wget_16.txt" rend="block"/>
                </ab>
                <p>What you have done is downloaded just the first page of
<ref target="http://activehistory.ca/papers/">http://activehistory.ca/papers/</ref>, the index page for the papers to your
new directory. If you open it, you'll see the main text on the home page
of ActiveHistory.ca. So at a glance, we have already quickly downloaded
something.</p>
                <p>What we want to do now, however, is to download every paper. So we need
to add a few commands to wget.</p>
                <p>Wget operates on the following general basis:</p>
                <ab>
                    <code lang="language-bash" xml:id="code_automated-downloading-with-wget_17" corresp="code_automated-downloading-with-wget_17.txt" rend="block"/>
                </ab>
                <p>We have just learned about the [URL] component in the previous example,
as it tells the program where to go. Options, however, give the program
a bit more information about what exactly we want to do. The program
knows that an option is an option by the presence of a dash before the
variable. This lets it know the difference between the URL and the
options. So let's learn a few commands now:</p>
                <ab>
                    <code xml:id="code_automated-downloading-with-wget_18" corresp="code_automated-downloading-with-wget_18.txt" rend="block"/>
                </ab>
                <p>Recursive retrieval is the most important part of wget. What this means
is that the program begins following links from the website and
downloading them too. So for example, the
<ref target="http://activehistory.ca/papers/">http://activehistory.ca/papers/</ref> has a link to
<ref target="http://activehistory.ca/papers/historypaper-9/">http://activehistory.ca/papers/historypaper-9/</ref>, so it will download
that too if we use recursive retrieval. However, it will also follow any
other links: if there was a link to <ref target="http://uwo.ca">http://uwo.ca</ref> somewhere on that
page, it would follow that and download it as well. By default, -r sends
wget to a depth of five sites after the first one. This is following
links, to a limit of five clicks after the first website. At this point,
it will be quite indiscriminate. So we need more commands:</p>
                <ab>
                    <code lang="language-bash" xml:id="code_automated-downloading-with-wget_19" corresp="code_automated-downloading-with-wget_19.txt" rend="block"/>
                </ab>
                <p>(The double-dash indicates the full-text of a command. All commands also
have a short version, this could be initiated using -np).</p>
                <p>This is an important one. What this means is that wget should follow
links, but not beyond the last parent directory. In our case, that means
that it won't go anywhere that is not part of the
<ref target="http://activehistory.ca/papers/">http://activehistory.ca/papers/</ref> hierarchy. If it was a long path such as
<ref target="http://niche-canada.org/projects/events/new-events/not-yet-happened-events/">http://niche-canada.org/projects/events/new-events/not-yet-happened-events/</ref>,
it would only find files in the <code rend="inline">/not-yet-happened-events/</code> folder. It
is a critical command for delineating your search.</p>
                <p>Here is a graphical representation:</p>
                <figure>
                    <desc>A graphical representation of how 'no-parent' works with wget</desc>
                    <graphic url="active-history-chart_edited-1.jpg"/>
                </figure>
                <p>Finally, if you do want to go outside of a hierarchy, it is best to be
specific about how far you want to go. The default is to follow each
link and carry on to a limit of five pages away from the first page you
provide. However, perhaps you just want to follow one link and stop
there? In that case, you could input <code rend="inline">-l 2</code>, which takes us to a depth
of two web-pages. Note this is a lower-case 'L', not a number 1.</p>
                <ab>
                    <code lang="language-bash" xml:id="code_automated-downloading-with-wget_20" corresp="code_automated-downloading-with-wget_20.txt" rend="block"/>
                </ab>
                <p>If these commands help direct wget, we also need to add a few more to be
nice to servers and to stop any automated countermeasures from thinking
the server is under attack! To that end, we have two additional
essential commands:</p>
                <ab>
                    <code lang="language-bash" xml:id="code_automated-downloading-with-wget_21" corresp="code_automated-downloading-with-wget_21.txt" rend="block"/>
                </ab>
                <p>It is not polite to ask for too much at once from a web server. There
are other people waiting for information, too, and it is thus important
to share the load. The command -<code rend="inline">w 10</code>, then, adds a ten second wait in
between server requests. You can shorten this, as ten seconds is quite
long. In my own searches, I often use a 2 second wait. On rare
occasions, you may come across a site that blocks automated downloading
altogether. The website's terms of service, which you should consult,
may not mention a policy on automated downloading, but steps to prohibit
it may be built into their website's architecture nonetheless. In such
rare cases, you can use the command <code rend="inline">––random-wait</code> which will vary the
wait by 0.5 and 1.5 times the value you provide here.</p>
                <p>Another critical comment is to limit the bandwidth you will be using in
the download:</p>
                <ab>
                    <code lang="language-bash" xml:id="code_automated-downloading-with-wget_22" corresp="code_automated-downloading-with-wget_22.txt" rend="block"/>
                </ab>
                <p>This is another important, polite command. You don't want to use up too
much of the servers' bandwidth. So this command will limit the maximum
download speed to 20kb/s. Opinion varies on what a good limit rate is,
but you are probably good up to about 200kb/s for small files – however,
not to tax the server, let us keep it at 20k. This will also keep us at
<code rend="inline">ActiveHistory.ca</code> happy!</p>
                <div type="3" n="4.1">
                    <head>Step Three: Mirror an Entire Website</head>
                    <p>Ok, with all of this, let's finally download all of the ActiveHistory.ca
papers. Note that the trailing slash on the URL is critical – if you
omit it, wget will think that papers is a file rather than a directory.
Directories end in slashes. Files do not. The command will then download
the entire ActiveHistory.ca page. The order of the options does not
matter.</p>
                    <ab>
                        <code lang="language-bash" xml:id="code_automated-downloading-with-wget_23" corresp="code_automated-downloading-with-wget_23.txt" rend="block"/>
                    </ab>
                    <p>It will be slower than before, but your terminal will begin downloading
all of the ActiveHistory.ca papers. When it is done, you should have a
directory labeled <code rend="inline">ActiveHistory.ca</code> that contains the <code rend="inline">/papers/</code>
sub-directory – perfectly mirrored on your system. This directory will
appear in the location that you ran the command from in your command
line, so likely is in your <code rend="inline">USER</code> directory. Links will be replaced with
internal links to the other pages you've downloaded, so you can actually
have a fully working ActiveHistory.ca site on your computer. This lets
you start to play with it without worrying about your internet speed.</p>
                    <p>To see if the download was a success, you will also have a log in your
command screen. Take a look over it to make sure that all files were
downloaded successfully. If it did not download, it will let you know
that it failed.</p>
                    <p>If you want to mirror an entire website, there is a built-in command to
wget.</p>
                    <ab>
                        <code xml:id="code_automated-downloading-with-wget_24" corresp="code_automated-downloading-with-wget_24.txt" rend="block"/>
                    </ab>
                    <p>This command means 'mirror,' and is especially useful for backing up an
entire website. It introduces the following set of commands:
time-stamping, which looks at the date of the site and doesn't replace
it if you already have that version on your system (useful for repeated
downloads), as well as infinite recursion (it will go as many layers
into the site as necessary). The command for mirroring ActiveHistory.ca
would be:</p>
                    <ab>
                        <code lang="language-bash" xml:id="code_automated-downloading-with-wget_25" corresp="code_automated-downloading-with-wget_25.txt" rend="block"/>
                    </ab>
                </div>
            </div>
            <div type="2" n="5">
                <head>A Flexible Tool for Downloading Internet Sources</head>
                <p>As you become increasingly comfortable with the command line, you'll
find wget a helpful addition to your digital toolkit. If there is an
entire set of archival documents that you want to download for text
mining, if they're arranged in a directory and are all together (which
is not as common as one might think), a quick wget command will be
quicker than scraping the links with Python. Similarly, you can then
begin downloading things directly from your command line: programs,
files, backups, etc.</p>
                <div type="3" n="5.1">
                    <head>Further Reading</head>
                    <p>I've only given a snapshot of some of wget's functionalities. For more,
please visit the <ref target="http://www.gnu.org/software/wget/manual/wget.html">wget manual</ref>.</p>
                </div>
            </div>
        </body>
    </text>
</TEI>
