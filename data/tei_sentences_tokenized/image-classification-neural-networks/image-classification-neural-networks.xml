<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xi="http://www.w3.org/2001/XInclude" xml:id="image-classification-neural-networks" type="original" xml:base="image-classification-neural-networks/image-classification-neural-networks/image-classification-neural-networks.xml">
    <teiHeader>
        <fileDesc>
            <titleStmt>
                <title>Creating Deep Convolutional Neural Networks for Image Classification</title>
                <author role="original_author">Nabeel Siddiqui</author>
                <editor role="reviewers">
                    <persName>Fabian Offert</persName>
                    <persName>Melvin Wevers</persName>
                </editor>
                <editor role="editors">Scott Kleinman</editor>
            </titleStmt>
            <publicationStmt>
                <distributor>Programming Historian</distributor>
                <idno type="doi">10.46430/phen0108</idno>
                <date type="published">03/23/2023</date>
            </publicationStmt>
            <sourceDesc>
                <p>Born digital, in a markdown format. This lesson is original.</p>
            </sourceDesc>
        </fileDesc>
        <profileDesc>
            <abstract>
                <p>This lesson provides a beginner-friendly introduction to convolutional neural networks (CNNs) for image classification. The tutorial provides a conceptual understanding of how neural networks work by using Google's Teachable Machine to train a model on paintings from the ArtUK database. This lesson also demonstrates how to use Javascript to embed the model in a live website.</p>
            </abstract>
            <textClass>
                <keywords>
                    <term xml:lang="en">machine-learning</term>
                </keywords>
            </textClass>
        </profileDesc>
    </teiHeader>
    <text xml:lang="en">
        <body><div type="2" n="1"><head><w>Introduction</w></head><p><w>In</w><w>the</w><w>last</w><w>few</w><w>years</w><w>,</w><ref target="https://perma.cc/Q4J7-5CAG"><w>machine</w><w>learning</w></ref><w>has</w><w>transformed</w><ref target="https://perma.cc/T9EZ-KZUZ"><w>computer</w><w>vision</w></ref><w>and</w><w>impacted</w><w>a</w><w>myriad</w><w>of</w><w>industries</w><w>and</w><w>disciplines</w><pc>.</pc><w>These</w><w>innovations</w><w>have</w><w>enabled</w><w>scholars</w><w>to</w><w>conduct</w><w>large-scale</w><w>explorations</w><w>of</w><w>cultural</w><w>datasets</w><w>previously</w><w>requiring</w><w>manual</w><w>interpretation</w><w>,</w><w>but</w><w>also</w><w>bring</w><w>their</w><w>own</w><w>set</w><w>of</w><w>challenges</w><pc>.</pc><w>Bias</w><w>is</w><w>rampant</w><w>,</w><w>and</w><w>many</w><w>machine</w><w>learning</w><w>techniques</w><w>disproportionately</w><w>damage</w><w>women</w><w>and</w><w>communities</w><w>of</w><w>color</w><pc>.</pc><w>Humanities</w><w>scholars</w><w>with</w><w>expertise</w><w>in</w><w>issues</w><w>of</w><w>identity</w><w>and</w><w>power</w><w>can</w><w>serve</w><w>as</w><w>important</w><w>bulwarks</w><w>against</w><w>growing</w><w>digital</w><w>inequality</w><pc>.</pc><w>Yet</w><w>,</w><w>the</w><w>high</w><w>level</w><w>of</w><w>statistics</w><w>and</w><w>computer</w><w>science</w><w>knowledge</w><w>required</w><w>to</w><w>comprehend</w><w>machine</w><w>learning</w><w>algorithms</w><w>has</w><w>resulted</w><w>in</w><w>critical</w><w>analysis</w><w>often</w><w>failing</w><w>to</w><w>look</w><w>inside</w><w>the</w><w>'black</w><w>box</w><w>'</w><pc>.</pc></p><p><w>This</w><w>lesson</w><w>provides</w><w>a</w><w>beginner-friendly</w><w>introduction</w><w>to</w><ref target="https://perma.cc/JU7X-TJSG"><w>convolutional</w><w>neural</w><w>networks</w></ref><w>,</w><w>which</w><w>along</w><w>with</w><ref target="https://perma.cc/VF62-JVB4"><w>transformers</w></ref><w>,</w><w>are</w><w>frequently-used</w><w>machine</w><w>learning</w><w>models</w><w>for</w><w>image</w><w>classification</w><pc>.</pc><w>Neural</w><w>networks</w><w>develop</w><w>their</w><w>own</w><w>idiosyncratic</w><w>ways</w><w>of</w><w>seeing</w><w>and</w><w>often</w><w>fail</w><w>to</w><w>separate</w><w>features</w><w>in</w><w>the</w><w>ways</w><w>we</w><w>might</w><w>expect</w><pc>.</pc><w>Understanding</w><w>how</w><w>these</w><w>networks</w><w>operate</w><w>provides</w><w>us</w><w>with</w><w>a</w><w>way</w><w>to</w><w>explore</w><w>their</w><w>limitations</w><w>when</w><w>programmed</w><w>to</w><w>identify</w><w>images</w><w>they</w><w>have</w><w>not</w><w>been</w><w>trained</w><w>to</w><w>recognize</w><pc>.</pc></p><p><w>In</w><w>this</w><w>tutorial</w><w>,</w><w>we</w><w>will</w><w>train</w><w>a</w><w>convolutional</w><w>neural</w><w>network</w><w>to</w><w>classify</w><w>paintings</w><pc>.</pc><w>As</w><w>historians</w><w>,</w><w>we</w><w>can</w><w>use</w><w>these</w><w>models</w><w>to</w><w>analyze</w><w>which</w><w>topics</w><w>recur</w><w>most</w><w>often</w><w>over</w><w>time</w><w>,</w><w>or</w><w>automate</w><w>the</w><w>creation</w><w>of</w><w>metadata</w><w>for</w><w>a</w><w>database</w><pc>.</pc><w>In</w><w>contrast</w><w>to</w><w>other</w><w>resources</w><w>that</w><w>focus</w><w>on</w><w>developing</w><w>the</w><w>most</w><w>accurate</w><w>model</w><w>,</w><w>the</w><w>goal</w><w>of</w><w>this</w><w>lesson</w><w>is</w><w>more</w><w>modest</w><pc>.</pc><w>It</w><w>is</w><w>aimed</w><w>at</w><w>those</w><w>wanting</w><w>to</w><w>gain</w><w>an</w><w>understanding</w><w>of</w><w>the</w><w>basic</w><w>terminology</w><w>and</w><w>makeup</w><w>of</w><w>neural</w><w>networks</w><w>so</w><w>that</w><w>they</w><w>can</w><w>expand</w><w>their</w><w>knowledge</w><w>later</w><w>,</w><w>rather</w><w>than</w><w>those</w><w>seeking</w><w>to</w><w>create</w><w>production-level</w><w>models</w><w>from</w><w>the</w><w>outset</w><pc>.</pc></p><div type="3" n="1.1"><head><w>Audience</w><w>and</w><w>Requirements</w></head><p><w>Neural</w><w>networks</w><w>are</w><w>a</w><w>fascinating</w><w>topic</w><w>,</w><w>and</w><w>I</w><w>have</w><w>done</w><w>my</w><w>best</w><w>to</w><w>simplify</w><w>my</w><w>explaination</w><w>of</w><w>them</w><pc>.</pc><w>Although</w><w>this</w><w>removes</w><w>some</w><w>nuance</w><w>,</w><w>it</w><w>also</w><w>allows</w><w>us</w><w>to</w><w>more</w><w>easily</w><w>gain</w><w>an</w><w>understanding</w><w>of</w><w>the</w><w>general</w><w>concept</w><w>and</w><w>how</w><w>neural</w><w>networks</w><w>operate</w><pc>.</pc><w>Nonetheless</w><w>,</w><w>because</w><w>of</w><w>the</w><w>issue</w><w>'s</w><w>complexity</w><w>,</w><w>this</w><w>tutorial</w><w>provides</w><w>more</w><w>background</w><w>information</w><w>than</w><w>other</w><w>tutorials</w><w>focused</w><w>on</w><w>advanced</w><w>coding</w><pc>.</pc></p><p><w>We</w><w>will</w><w>be</w><w>using</w><w>Google</w><w>'s</w><ref target="https://teachablemachine.withgoogle.com/"><w>Teachable</w><w>Machine</w></ref><w>to</w><w>train</w><w>our</w><w>model</w><w>—</w><w>do</w><w>n't</w><w>worry</w><w>if</w><w>you</w><w>do</w><w>n't</w><w>know</w><w>what</w><w>``</w><w>training</w><w>''</w><w>a</w><w>model</w><w>is</w><w>right</w><w>now</w><pc>.</pc><w>Teachable</w><w>Machine</w><w>contains</w><w>a</w><w>drag</w><w>and</w><w>drop</w><w>interface</w><w>that</w><w>permits</w><w>even</w><w>those</w><w>without</w><w>coding</w><w>experience</w><w>to</w><w>train</w><w>a</w><w>model</w><pc>.</pc><w>While</w><w>the</w><w>default</w><w>model</w><w>we</w><w>create</w><w>in</w><w>Teachable</w><w>Machine</w><w>will</w><w>be</w><w>biased</w><w>towards</w><w>our</w><w>training</w><w>data</w><w>,</w><w>it</w><w>will</w><w>suffice</w><w>for</w><w>pedagogical</w><w>purposes</w><w>and</w><w>make</w><w>apparent</w><w>machine</w><w>learning</w><w>'s</w><w>limitations</w><pc>.</pc></p><p><w>The</w><w>latter</w><w>half</w><w>of</w><w>the</w><w>tutorial</w><w>will</w><w>take</w><w>the</w><w>neural</w><w>network</w><w>we</w><w>train</w><w>in</w><w>Teachable</w><w>Machine</w><w>and</w><w>embed</w><w>it</w><w>into</w><w>a</w><w>live</w><w>website</w><pc>.</pc><w>To</w><w>follow</w><w>along</w><w>with</w><w>this</w><w>section</w><w>,</w><w>you</w><w>will</w><w>need</w><w>to</w><w>have</w><w>some</w><w>familiarity</w><w>with</w><w>coding</w><w>JavaScript</w><pc>.</pc><w>We</w><w>will</w><w>be</w><w>using</w><w>the</w><ref target="https://perma.cc/3GBE-NVER"><w>ml5.js</w></ref><w>JavaScript</w><w>library</w><w>built</w><w>on</w><w>top</w><w>of</w><w>Tensorflow.js</w><pc>.</pc><w>This</w><w>library</w><w>takes</w><w>its</w><w>inspiration</w><w>from</w><ref target="https://perma.cc/TH4U-WCL7"><w>Processing</w></ref><w>and</w><ref target="https://perma.cc/5DXT-UR72"><w>p5.js</w></ref><w>created</w><w>by</w><w>The</w><w>Processing</w><w>Foundation</w><w>whose</w><w>goal</w><w>is</w><w>``</w><w>to</w><w>promote</w><w>software</w><w>literacy</w><w>within</w><w>the</w><w>visual</w><w>arts</w><w>,</w><w>and</w><w>visual</w><w>literacy</w><w>within</w><w>technology-related</w><w>fields</w><w>—</w><w>and</w><w>to</w><w>make</w><w>these</w><w>fields</w><w>accessible</w><w>to</w><w>diverse</w><w>communities</w><pc>.</pc><w>``</w><w>[</w><w>1^</w><w>]</w><w>For</w><w>those</w><w>needing</w><w>a</w><w>JavaScript</w><w>refresher</w><w>,</w><ref target="https://www.freecodecamp.org/learn/javascript-algorithms-and-data-structures/"><w>FreeCodeCamp</w></ref><w>has</w><w>excellent</w><w>and</w><w>free</w><w>interactive</w><w>tutorials</w><pc>.</pc><w>I</w><w>also</w><w>recommend</w><w>Jon</w><w>Duckett</w><w>'s</w><w>book</w><emph><w>JavaScript</w><w>and</w><w>jQuery</w><w>:</w><w>Interactive</w><w>Front</w><w>End</w><w>Development</w></emph><ref type="footnotemark" target="#en_note_2"/><pc>.</pc><w>If</w><w>neither</w><w>of</w><w>these</w><w>resources</w><w>appeal</w><w>to</w><w>you</w><w>,</w><w>there</w><w>are</w><w>hundreds</w><w>of</w><w>additional</w><w>tutorials</w><w>and</w><w>videos</w><w>you</w><w>can</w><w>access</w><w>online</w><w>through</w><w>a</w><w>quick</w><w>search</w><pc>.</pc></p><p><w>Along</w><w>with</w><w>JavaScript</w><w>,</w><w>you</w><w>should</w><w>have</w><w>some</w><w>familiarity</w><w>with</w><w>your</w><w>browser</w><w>'s</w><w>developer</w><w>tools</w><w>and</w><w>know</w><w>how</w><w>to</w><w>use</w><w>load</w><w>up</w><w>the</w><w>JavaScript</w><w>console</w><pc>.</pc><w>If</w><w>you</w><w>need</w><w>help</w><w>,</w><w>there</w><w>are</w><w>instructions</w><w>for</w><ref target="https://perma.cc/F5DC-NDDW"><w>Chrome</w></ref><w>,</w><ref target="https://perma.cc/EUD2-5LTL"><w>Firefox</w></ref><w>,</w><ref target="https://perma.cc/BLA9-VNWS"><w>Edge</w></ref><w>,</w><w>and</w><ref target="https://perma.cc/S5A9-XAHH"><w>Safari</w></ref><w>available</w><pc>.</pc><w>Many</w><w>browsers</w><w>limit</w><w>access</w><w>to</w><w>local</w><w>files</w><w>through</w><w>JavaScript</w><w>for</w><w>security</w><w>reasons</w><pc>.</pc><w>Consequently</w><w>,</w><w>you</w><w>will</w><w>be</w><w>likely</w><w>to</w><w>need</w><w>to</w><w>launch</w><w>a</w><w>live</w><w>server</w><w>on</w><w>your</w><w>machine</w><pc>.</pc><w>I</w><w>recommend</w><w>that</w><w>you</w><w>either</w><w>use</w><w>an</w><w>extension</w><w>for</w><w>your</w><w>code</w><w>editor</w><w>,</w><w>such</w><w>as</w><ref target="https://perma.cc/6PP4-52VR"><w>Live</w><w>Server</w></ref><w>for</w><ref target="https://perma.cc/7LQR-AK96"><w>Visual</w><w>Studio</w><w>Code</w></ref><w>,</w><w>or</w><ref target="https://perma.cc/6476-MNFC"><w>run</w><w>a</w><w>server</w><w>through</w><w>Python</w></ref><pc>.</pc></p><p><w>Hopefully</w><w>,</w><w>the</w><w>choice</w><w>of</w><w>the</w><w>tools</w><w>in</w><w>this</w><w>tutorial</w><w>will</w><w>allow</w><w>you</w><w>to</w><w>focus</w><w>on</w><w>the</w><w>broader</w><w>concepts</w><w>surrounding</w><w>neural</w><w>networks</w><w>without</w><w>worrying</w><w>as</w><w>much</w><w>about</w><w>coding</w><pc>.</pc><w>It</w><w>'s</w><w>worth</w><w>mentioning</w><w>,</w><w>however</w><w>,</w><w>that</w><w>Python</w><w>and</w><w>R</w><w>are</w><w>vastly</w><w>more</w><w>popular</w><w>at</w><w>the</w><w>production</w><w>level</w><w>,</w><w>and</w><w>much</w><w>of</w><w>the</w><w>cutting-edge</w><w>work</w><w>in</w><w>machine</w><w>learning</w><w>relies</w><w>on</w><w>these</w><w>two</w><w>languages</w><w>rather</w><w>than</w><w>the</w><w>toolset</w><w>shown</w><w>in</w><w>this</w><w>tutorial</w><pc>.</pc><w>If</w><w>you</w><w>are</w><w>interested</w><w>in</w><w>expanding</w><w>your</w><w>knowledge</w><w>of</w><w>neural</w><w>networks</w><w>,</w><w>see</w><emph><w>Programming</w><w>Historian</w><w>'s</w></emph><w>excellent</w><w>articles</w><w>on</w><ref target="/en/lessons/computer-vision-deep-learning-pt1"><w>Computer</w><w>Vision</w><w>for</w><w>the</w><w>Humanities</w></ref><w>and</w><ref target="/en/lessons/interrogating-national-narrative-gpt"><w>Interrogating</w><w>a</w><w>National</w><w>Narrative</w><w>with</w><w>Recurrent</w><w>Neural</w><w>Networks</w></ref><pc>.</pc></p></div></div><div type="2" n="2"><head><w>Setup</w><w>and</w><w>Dataset</w></head><p><w>To</w><w>begin</w><w>,</w><w>create</w><w>a</w><w>new</w><w>folder</w><w>called</w><code rend="inline"><w>projects</w></code><pc>.</pc><w>This</w><w>folder</w><w>will</w><w>hold</w><w>all</w><w>relevant</w><w>files</w><w>and</w><w>images</w><pc>.</pc><w>To</w><w>train</w><w>the</w><w>neural</w><w>network</w><w>in</w><ref target="https://teachablemachine.withgoogle.com/"><w>Google</w><w>'s</w><w>Teachable</w><w>Machine</w></ref><w>,</w><w>you</w><w>will</w><w>need</w><w>a</w><w>collection</w><w>of</w><w>labeled</w><w>images</w><w>as</w><w>most</w><w>neural</w><w>networks</w><w>are</w><w>geared</w><w>towards</w><w>what</w><w>is</w><w>known</w><w>as</w><w>'supervised</w><w>learning</w><w>'</w><pc>.</pc></p><p><w>Machine</w><w>learning</w><w>can</w><w>be</w><w>divided</w><w>into</w><w>two</w><w>forms</w><w>:</w><w>supervised</w><w>and</w><w>unsupervised</w><w>learning</w><pc>.</pc><w>Supervised</w><w>learning</w><w>involves</w><w>data</w><w>that</w><w>is</w><w>already</w><w>labeled</w><pc>.</pc><w>Unsupervised</w><w>learning</w><w>,</w><w>on</w><w>the</w><w>other</w><w>hand</w><w>,</w><w>involves</w><w>identifying</w><w>patterns</w><w>and</w><w>grouping</w><w>data</w><w>that</w><w>is</w><w>alike</w><w>together</w><pc>.</pc><w>You</w><w>may</w><w>have</w><w>seen</w><w>the</w><w>use</w><w>of</w><w>some</w><w>unsupervised</w><w>machine</w><w>learning</w><w>algorithms</w><w>such</w><w>as</w><ref target="https://perma.cc/39XM-PBAS"><w>K-Means</w><w>Clustering</w></ref><w>and</w><ref target="https://perma.cc/JM3P-BZWN"><w>Latent</w><w>Dirichlet</w><w>Allocation</w></ref><w>in</w><w>digital</w><w>humanities</w><w>research</w><pc>.</pc></p><p><w>For</w><w>this</w><w>tutorial</w><w>,</w><w>we</w><w>will</w><w>download</w><w>a</w><w>dataset</w><w>of</w><w>paintings</w><w>from</w><ref target="https://artuk.org/"><w>ArtUK</w></ref><w>,</w><w>which</w><w>provides</w><w>access</w><w>to</w><w>works</w><w>that</w><w>meet</w><w>the</w><w>UK</w><w>'s</w><w>requirements</w><w>for</w><w>``</w><ref target="https://artuk.org/footer/faq"><w>public</w><w>ownership</w></ref><pc>.</pc><w>''</w><w>Approximately</w><w>,</w><ref target="https://artuk.org/about/provide-free-digital-access-to-the-uks-art"><w>80</w><w>%</w><w>of</w><w>the</w><w>UK</w><w>'s</w><w>publicly</w><w>owned</w><w>art</w><w>is</w><w>not</w><w>on</w><w>display</w></ref><pc>.</pc><w>ArtUK</w><w>combats</w><w>this</w><w>by</w><w>providing</w><w>the</w><w>general</w><w>public</w><w>access</w><w>to</w><w>these</w><w>materials</w><pc>.</pc></p><p><w>The</w><w>ArtUK</w><w>website</w><w>allows</w><w>you</w><w>to</w><w>view</w><w>artworks</w><w>by</w><ref target="https://artuk.org/discover/topics"><w>topic</w></ref><w>,</w><w>and</w><w>we</w><w>will</w><w>use</w><w>these</w><w>topics</w><w>to</w><w>train</w><w>our</w><w>image</w><w>classifier</w><pc>.</pc><w>You</w><w>can</w><ref target="/assets/image-classification-neural-networks/dataset.zip"><w>download</w><w>a</w><code rend="inline"><w>.zip</w></code><w>file</w><w>containing</w><w>the</w><w>images</w><w>here</w></ref><pc>.</pc><w>Save</w><w>the</w><code rend="inline"><w>.zip</w></code><w>file</w><w>in</w><w>your</w><code rend="inline"><w>projects</w></code><w>folder</w><w>and</w><w>unzip</w><w>it</w><pc>.</pc><w>Inside</w><w>,</w><w>you</w><w>will</w><w>find</w><w>a</w><w>folder</w><w>called</w><w>``</w><w>dataset</w><w>''</w><w>with</w><w>two</w><w>additional</w><w>folders</w><w>:</w><code rend="inline"><w>training</w></code><w>and</w><code rend="inline"><w>testing</w></code><pc>.</pc><w>Once</w><w>you</w><w>have</w><w>downloaded</w><w>all</w><w>the</w><w>files</w><w>,</w><w>go</w><w>ahead</w><w>and</w><w>launch</w><w>a</w><w>live</w><w>server</w><w>on</w><w>the</w><code rend="inline"><w>projects</w></code><w>folder</w><pc>.</pc><w>In</w><w>most</w><w>cases</w><w>,</w><w>you</w><w>can</w><w>view</w><w>the</w><w>server</w><w>using</w><w>the</w><w>localhost</w><w>address</w><w>of</w><w>``</w><w>http</w><w>:</w><w>//127.0.0.1</w><w>''</w><pc>.</pc></p></div><div type="2" n="3"><head><w>Understanding</w><w>Neural</w><w>Networks</w></head><p><w>How</w><w>exactly</w><w>do</w><w>artificial</w><w>neurons</w><w>work</w><pc>?</pc><w>Rather</w><w>than</w><w>diving</w><w>directly</w><w>into</w><w>training</w><w>them</w><w>,</w><w>it</w><w>is</w><w>helpful</w><w>to</w><w>first</w><w>gain</w><w>a</w><w>broader</w><w>understanding</w><w>of</w><w>their</w><w>infrastructure</w><pc>.</pc></p><p><w>Let</w><w>'s</w><w>say</w><w>we</w><w>are</w><w>interested</w><w>in</w><w>a</w><w>simple</w><w>task</w><w>,</w><w>such</w><w>as</w><w>determining</w><w>if</w><w>an</w><w>image</w><w>is</w><w>a</w><w>picture</w><w>of</w><w>a</w><w>square</w><w>or</w><w>triangle</w><pc>.</pc><w>If</w><w>you</w><w>have</w><w>done</w><w>any</w><w>kind</w><w>of</w><w>coding</w><w>,</w><w>you</w><w>will</w><w>know</w><w>that</w><w>most</w><w>programs</w><w>solve</w><w>this</w><w>by</w><w>processing</w><w>a</w><w>sequence</w><w>of</w><w>steps</w><pc>.</pc><w>Loops</w><w>and</w><w>statements</w><w>(</w><w>such</w><w>as</w><code rend="inline"><w>for</w></code><w>,</w><code rend="inline"><w>while</w></code><w>and</w><code rend="inline"><w>if</w></code><w>)</w><w>allow</w><w>our</w><w>program</w><w>to</w><w>have</w><w>branches</w><w>that</w><w>simulate</w><w>logical</w><w>thinking</w><pc>.</pc><w>In</w><w>the</w><w>case</w><w>of</w><w>determining</w><w>whether</w><w>an</w><w>image</w><w>contains</w><w>a</w><w>shape</w><w>,</w><w>we</w><w>could</w><w>code</w><w>our</w><w>program</w><w>to</w><w>count</w><w>the</w><w>number</w><w>of</w><w>sides</w><w>and</w><w>display</w><w>``</w><w>square</w><w>''</w><w>if</w><w>it</w><w>finds</w><w>four</w><w>,</w><w>or</w><w>``</w><w>triangle</w><w>''</w><w>if</w><w>it</w><w>finds</w><w>three</w><pc>.</pc><w>Distinguishing</w><w>between</w><w>geometric</w><w>objects</w><w>may</w><w>seem</w><w>like</w><w>a</w><w>relatively</w><w>simple</w><w>task</w><w>,</w><w>but</w><w>it</w><w>requires</w><w>a</w><w>programmer</w><w>to</w><w>not</w><w>only</w><w>define</w><w>a</w><w>shape</w><w>'s</w><w>characteristics</w><w>but</w><w>also</w><w>implement</w><w>logic</w><w>that</w><w>discerns</w><w>those</w><w>characteristics</w><pc>.</pc><w>This</w><w>becomes</w><w>increasingly</w><w>difficult</w><w>as</w><w>we</w><w>run</w><w>into</w><w>scenarios</w><w>where</w><w>distinctions</w><w>between</w><w>images</w><w>are</w><w>more</w><w>complex</w><pc>.</pc><w>For</w><w>instance</w><w>,</w><w>look</w><w>at</w><w>the</w><w>following</w><w>images</w><w>:</w></p><figure><desc><w>Figure</w><w>1</w><pc>.</pc><w>A</w><w>picture</w><w>of</w><w>a</w><w>cat</w></desc><figDesc><w>An</w><w>image</w><w>of</w><w>a</w><w>small</w><w>cat</w><w>at</w><w>the</w><w>bottom</w><w>of</w><w>a</w><w>set</w><w>of</w><w>stairs</w><w>looking</w><w>directly</w><w>at</w><w>the</w><w>camera</w></figDesc><graphic url="cat.jpeg"/></figure><figure><desc><w>Figure</w><w>2</w><pc>.</pc><w>A</w><w>picture</w><w>of</w><w>a</w><w>dog</w></desc><figDesc><w>A</w><w>picture</w><w>of</w><w>a</w><w>dog</w><w>outside</w><w>holding</w><w>a</w><w>rose</w><w>in</w><w>its</w><w>mouth</w><w>staring</w><w>directly</w><w>at</w><w>the</w><w>camera</w></figDesc><graphic url="dog.jpeg"/></figure><p><w>As</w><w>humans</w><w>,</w><w>we</w><w>can</w><w>easily</w><w>determine</w><w>which</w><w>one</w><w>is</w><w>a</w><w>dog</w><w>and</w><w>which</w><w>one</w><w>is</w><w>a</w><w>cat</w><pc>.</pc><w>However</w><w>,</w><w>outlining</w><w>the</w><w>exact</w><w>differences</w><w>proves</w><w>challenging</w><pc>.</pc><w>It</w><w>turns</w><w>out</w><w>that</w><w>humans</w><w>are</w><w>usually</w><w>a</w><w>lot</w><w>better</w><w>at</w><w>handling</w><w>the</w><w>nuances</w><w>of</w><w>vision</w><w>than</w><w>computers</w><pc>.</pc><w>What</w><w>if</w><w>we</w><w>could</w><w>get</w><w>a</w><w>computer</w><w>to</w><w>process</w><w>images</w><w>the</w><w>way</w><w>our</w><w>brains</w><w>do</w><pc>?</pc><w>This</w><w>question</w><w>and</w><w>insight</w><w>forms</w><w>the</w><w>basis</w><w>of</w><w>artificial</w><w>neurons</w><pc>.</pc></p><p><w>As</w><w>the</w><w>name</w><w>implies</w><w>,</w><w>artificial</w><w>neurons</w><w>take</w><w>their</w><w>inspiration</w><w>from</w><w>neurons</w><w>in</w><w>the</w><w>brain</w><pc>.</pc><w>The</w><w>following</w><w>is</w><w>a</w><w>simplified</w><w>diagram</w><ref type="footnotemark" target="#en_note_3"/><w>of</w><w>how</w><w>a</w><w>biological</w><w>and</w><w>artificial</w><w>neuron</w><w>work</w><w>:</w></p><figure><desc><w>Figure</w><w>3</w><pc>.</pc><w>A</w><w>diagram</w><w>of</w><w>a</w><w>biological</w><w>and</w><w>an</w><w>artificial</w><w>neuron</w><pc>.</pc></desc><figDesc><w>There</w><w>is</w><w>a</w><w>picture</w><w>at</w><w>the</w><w>top</w><w>of</w><w>an</w><w>image</w><w>showing</w><w>a</w><w>biological</w><w>neuron</w><w>with</w><w>the</w><w>dendrites</w><w>,</w><w>nucleus</w><w>,</w><w>axon</w><w>,</w><w>and</w><w>axon</w><w>terminals</w><w>labeled</w><pc>.</pc><w>At</w><w>the</w><w>bottom</w><w>,</w><w>there</w><w>is</w><w>a</w><w>picture</w><w>of</w><w>a</w><w>geometric</w><w>rendition</w><w>of</w><w>the</w><w>neuron</w><w>with</w><w>the</w><w>dendrites</w><w>labeled</w><w>as</w><w>input</w><w>and</w><w>axon</w><w>labeled</w><w>as</w><w>output</w><pc>.</pc></figDesc><graphic url="neuron.png"/></figure><p><w>Biological</w><w>neurons</w><w>have</w><w>dendrites</w><w>,</w><w>which</w><w>are</w><w>branch-like</w><w>appendages</w><w>that</w><w>receive</w><w>electrical</w><w>inputs</w><w>from</w><w>other</w><w>neurons</w><w>and</w><w>send</w><w>those</w><w>to</w><w>the</w><w>cell</w><w>body</w><pc>.</pc><w>If</w><w>stimulated</w><w>enough</w><w>,</w><w>the</w><w>cell</w><w>body</w><w>will</w><w>send</w><w>signals</w><w>down</w><w>the</w><w>axon</w><w>to</w><w>the</w><w>axon</w><w>terminals</w><w>which</w><w>will</w><w>then</w><w>output</w><w>them</w><w>to</w><w>other</w><w>neurons</w><pc>.</pc></p><p><w>In</w><w>what</w><w>ways</w><w>does</w><w>an</w><w>artificial</w><w>neuron</w><w>mimic</w><w>a</w><w>biological</w><w>one</w><pc>?</pc><w>In</w><w>1943</w><w>,</w><w>Warren</w><w>MuCulloch</w><w>and</w><w>Walter</w><w>Pitts</w><w>laid</w><w>the</w><w>foundation</w><w>for</w><w>creating</w><w>artificial</w><w>neurons</w><w>in</w><w>their</w><w>paper</w><w>``</w><w>A</w><w>Logical</w><w>Calculus</w><w>of</w><w>Ideas</w><w>Immanent</w><w>in</w><w>Nervous</w><w>Activity</w><pc>.</pc><w>''</w><ref type="footnotemark" target="#en_note_4"/><w>In</w><w>contrast</w><w>to</w><w>biological</w><w>neurons</w><w>that</w><w>receive</w><w>their</w><w>electricity</w><w>from</w><w>other</w><w>neurons</w><w>,</w><w>they</w><w>posited</w><w>that</w><w>an</w><w>artificial</w><w>neuron</w><w>receives</w><w>an</w><w>arbitrary</w><w>number</w><w>of</w><w>numerical</w><w>values</w><pc>.</pc><w>It</w><w>then</w><w>outputs</w><w>their</w><w>sum</w><w>to</w><w>another</w><w>neuron</w><pc>.</pc><w>This</w><w>,</w><w>however</w><w>,</w><w>presents</w><w>a</w><w>problem</w><w>:</w><w>if</w><w>the</w><w>neuron</w><w>automatically</w><w>outputs</w><w>these</w><w>sums</w><w>,</w><w>all</w><w>neurons</w><w>would</w><w>fire</w><w>simultaneously</w><w>rather</w><w>than</w><w>when</w><w>sufficiently</w><w>stimulated</w><pc>.</pc><w>To</w><w>counter</w><w>this</w><w>,</w><w>artificial</w><w>neurons</w><w>determine</w><w>if</w><w>the</w><w>sum</w><w>of</w><w>the</w><w>inputs</w><w>they</w><w>receive</w><w>exceed</w><w>a</w><w>particular</w><w>threshold</w><w>before</w><w>outputting</w><w>the</w><w>results</w><pc>.</pc><w>Think</w><w>of</w><w>it</w><w>as</w><w>a</w><w>cup</w><w>that</w><w>can</w><w>hold</w><w>a</w><w>certain</w><w>amount</w><w>of</w><w>liquid</w><w>before</w><w>it</w><w>starts</w><w>overflowing</w><pc>.</pc><w>Likewise</w><w>,</w><w>a</w><w>neuron</w><w>may</w><w>take</w><w>in</w><w>electricity</w><w>but</w><w>only</w><w>``</w><w>fire</w><w>''</w><w>when</w><w>it</w><w>reaches</w><w>a</w><w>critical</w><w>mass</w><pc>.</pc><w>The</w><w>exact</w><w>way</w><w>that</w><w>this</w><w>threshold</w><w>outputs</w><w>to</w><w>other</w><w>neurons</w><w>is</w><w>determined</w><w>through</w><w>activation</w><w>functions</w><w>,</w><w>which</w><w>we</w><w>will</w><w>look</w><w>at</w><w>in</w><w>more</w><w>depth</w><ref target="#a-basic-neural-network"><w>in</w><w>the</w><w>next</w><w>section</w></ref><pc>.</pc></p><p><w>It</w><w>should</w><w>be</w><w>noted</w><w>that</w><w>biological</w><w>neurons</w><w>are</w><w>vastly</w><w>more</w><w>complex</w><w>entities</w><w>than</w><w>artificial</w><w>neurons</w><pc>.</pc><w>Andrew</w><w>Glassner</w><w>sums</w><w>up</w><w>the</w><w>gulf</w><w>between</w><w>the</w><w>two</w><w>in</w><emph><w>Deep</w><w>Learning</w><w>a</w><w>Visual</w><w>Approach</w></emph><w>by</w><w>noting</w><w>:</w></p><quote><p><w>The</w><w>``</w><w>neurons</w><w>''</w><w>we</w><w>use</w><w>in</w><w>machine</w><w>learning</w><w>are</w><w>inspired</w><w>by</w><w>real</w><w>neurons</w><w>in</w><w>the</w><w>same</w><w>way</w><w>that</w><w>a</w><w>stick</w><w>figure</w><w>drawing</w><w>is</w><w>inspired</w><w>by</w><w>a</w><w>human</w><w>body</w><pc>.</pc><w>There</w><w>'s</w><w>a</w><w>resemblance</w><w>,</w><w>but</w><w>only</w><w>in</w><w>the</w><w>most</w><w>general</w><w>sense</w><pc>.</pc><w>Almost</w><w>all</w><w>of</w><w>the</w><w>details</w><w>are</w><w>lost</w><w>along</w><w>the</w><w>way</w><w>,</w><w>and</w><w>we</w><w>'re</w><w>left</w><w>with</w><w>something</w><w>that</w><w>'s</w><w>more</w><w>of</w><w>a</w><w>reminder</w><w>of</w><w>the</w><w>original</w><w>,</w><w>rather</w><w>than</w><w>even</w><w>a</w><w>simplified</w><w>copy</w><pc>.</pc><ref type="footnotemark" target="#en_note_5"/></p></quote><p><w>What</w><w>is</w><w>important</w><w>to</w><w>understand</w><w>is</w><w>not</w><w>the</w><w>exact</w><w>relationship</w><w>between</w><w>artificial</w><w>and</w><w>biological</w><w>neurons</w><w>,</w><w>but</w><w>the</w><w>spatial</w><w>language</w><w>and</w><w>metaphors</w><w>used</w><w>in</w><w>the</w><w>literature</w><w>which</w><w>can</w><w>make</w><w>it</w><w>much</w><w>easier</w><w>to</w><w>figure</w><w>out</w><w>what</w><w>exactly</w><w>is</w><w>going</w><w>on</w><w>in</w><w>a</w><w>basic</w><w>neural</w><w>network</w><pc>.</pc></p><div type="3" n="3.1"><head><w>A</w><w>Basic</w><w>Neural</w><w>Network</w></head><p><w>A</w><w>neural</w><w>network</w><w>is</w><w>simply</w><w>a</w><w>web</w><w>of</w><w>interconnected</w><w>artificial</w><w>neurons</w><pc>.</pc><w>Those</w><w>we</w><w>will</w><w>examine</w><w>here</w><w>are</w><w>'feed-forward</w><w>'</w><w>,</w><w>which</w><w>means</w><w>that</w><w>data</w><w>only</w><w>passes</w><w>through</w><w>them</w><w>in</w><w>one</w><w>direction</w><pc>.</pc><w>These</w><w>are</w><w>particularly</w><w>popular</w><w>for</w><w>completing</w><w>classification</w><w>tasks</w><pc>.</pc><w>In</w><w>contrast</w><w>,</w><w>recurrent</w><w>neural</w><w>networks</w><w>have</w><w>loops</w><w>where</w><w>data</w><w>from</w><w>one</w><w>part</w><w>of</w><w>the</w><w>neural</w><w>network</w><w>is</w><w>passed</w><w>back</w><w>to</w><w>another</w><pc>.</pc><w>Although</w><w>they</w><w>are</w><w>usually</w><w>drawn</w><w>from</w><w>left</w><w>to</w><w>right</w><w>,</w><w>it</w><w>is</w><w>easier</w><w>to</w><w>think</w><w>of</w><w>a</w><w>neural</w><w>network</w><w>as</w><w>a</w><w>series</w><w>of</w><w>steps</w><w>where</w><w>each</w><w>neuron</w><w>does</w><w>some</w><w>sort</w><w>of</w><w>calculation</w><pc>.</pc><w>They</w><w>almost</w><w>always</w><w>consist</w><w>of</w><w>an</w><w>input</w><w>layer</w><w>,</w><w>a</w><w>series</w><w>of</w><w>hidden</w><w>layers</w><w>,</w><w>and</w><w>an</w><w>output</w><w>layer</w><pc>.</pc></p><p><w>As</w><w>the</w><w>name</w><w>implies</w><w>,</w><w>the</w><w>input</w><w>layer</w><w>holds</w><w>the</w><w>inputs</w><w>for</w><w>the</w><w>data</w><w>to</w><w>be</w><w>analyzed</w><pc>.</pc><w>Regardless</w><w>of</w><w>the</w><w>data</w><w>'s</w><w>original</w><w>form</w><w>,</w><w>it</w><w>must</w><w>first</w><w>be</w><w>converted</w><w>into</w><w>a</w><w>numerical</w><w>representation</w><w>to</w><w>go</w><w>through</w><w>the</w><w>network</w><pc>.</pc><w>Let</w><w>'s</w><w>consider</w><w>how</w><w>neurons</w><w>convert</w><w>digital</w><w>images</w><w>to</w><w>numbers</w><pc>.</pc><w>Digital</w><w>images</w><w>are</w><w>made</w><w>up</w><w>of</w><w>a</w><w>series</w><w>of</w><w>pixels</w><pc>.</pc><w>We</w><w>can</w><w>represent</w><w>these</w><w>images</w><w>numerically</w><w>as</w><w>multi-dimensional</w><w>arrays</w><w>with</w><w>dimensions</w><w>representing</w><w>height</w><w>,</w><w>width</w><w>,</w><w>and</w><w>the</w><w>number</w><w>of</w><w>channels</w><pc>.</pc><w>The</w><w>channels</w><w>correspond</w><w>to</w><w>the</w><w>color</w><w>depth</w><w>for</w><w>each</w><w>pixel</w><pc>.</pc><w>For</w><w>instance</w><w>,</w><w>the</w><w>color</w><w>depth</w><w>for</w><w>a</w><w>grayscale</w><w>image</w><w>will</w><w>have</w><w>a</w><w>single</w><w>value</w><w>representing</w><w>the</w><w>intensity</w><w>of</w><w>light</w><w>,</w><w>while</w><w>a</w><w>color</w><w>image</w><w>will</w><w>have</w><w>a</w><w>series</w><w>of</w><w>values</w><w>for</w><w>red</w><w>,</w><w>green</w><w>,</w><w>and</w><w>blue</w><pc>.</pc></p><p><w>From</w><w>the</w><w>input</w><w>layer</w><w>,</w><w>the</w><w>neural</w><w>network</w><w>usually</w><w>passes</w><w>data</w><w>into</w><w>a</w><w>series</w><w>of</w><w>``</w><w>hidden</w><w>layers</w><pc>.</pc><w>''</w><w>Hidden</w><w>layers</w><w>are</w><w>those</w><w>after</w><w>the</w><w>input</w><w>layer</w><w>and</w><w>before</w><w>the</w><w>output</w><w>layer</w><pc>.</pc><w>Depending</w><w>on</w><w>the</w><w>type</w><w>of</w><w>network</w><w>,</w><w>the</w><w>number</w><w>of</w><w>hidden</w><w>layers</w><w>and</w><w>their</w><w>function</w><w>will</w><w>vary</w><pc>.</pc><w>Any</w><w>network</w><w>with</w><w>more</w><w>than</w><w>one</w><w>hidden</w><w>layer</w><w>is</w><w>referred</w><w>to</w><w>as</w><w>a</w><w>``</w><w>deep</w><w>neural</w><w>network</w><pc>.</pc><w>''</w></p><p><w>In</w><w>most</w><w>hidden</w><w>layers</w><w>,</w><w>the</w><w>neural</w><w>network</w><w>takes</w><w>the</w><w>values</w><w>from</w><w>previous</w><w>layers</w><w>,</w><w>does</w><w>a</w><w>mathematical</w><w>calculation</w><w>on</w><w>them</w><w>(</w><w>usually</w><w>summation</w><w>)</w><w>,</w><w>and</w><w>multiplies</w><w>the</w><w>sum</w><w>by</w><w>a</w><w>particular</w><w>'weight</w><w>'</w><w>before</w><w>sending</w><w>it</w><w>to</w><w>the</w><w>neurons</w><w>in</w><w>the</w><w>next</w><w>layer</w><pc>.</pc><w>Each</w><w>neuron</w><w>then</w><w>takes</w><w>its</w><w>input</w><w>and</w><w>turns</w><w>it</w><w>into</w><w>a</w><w>single</w><w>output</w><w>—</w><w>normally</w><w>by</w><w>adding</w><w>up</w><w>the</w><w>values</w><pc>.</pc></p><p><w>How</w><w>do</w><w>the</w><w>neurons</w><w>in</w><w>hidden</w><w>layers</w><w>help</w><w>solve</w><w>mathematical</w><w>problems</w><w>and</w><w>classification</w><w>tasks</w><pc>?</pc><w>Let</w><w>'s</w><w>go</w><w>through</w><w>a</w><w>simple</w><w>example</w><pc>.</pc><w>Let</w><w>'s</w><w>assume</w><w>that</w><w>we</w><w>are</w><w>interested</w><w>in</w><w>solving</w><w>the</w><w>following</w><w>equation</w><w>:</w><code rend="inline"><w>x+y=7.5</w></code><pc>.</pc><w>In</w><w>this</w><w>scenario</w><w>,</w><w>we</w><w>know</w><w>that</w><w>the</w><w>output</w><w>should</w><w>be</w><w>7.5</w><w>,</w><w>but</w><w>we</w><w>do</w><w>not</w><w>know</w><w>the</w><w>inputs</w><pc>.</pc><w>We</w><w>can</w><w>begin</w><w>by</w><w>simply</w><w>guessing</w><w>numbers</w><w>such</w><w>as</w><w>3</w><w>and</w><w>2</w><pc>.</pc><w>Putting</w><w>them</w><w>into</w><w>our</w><w>equation</w><w>gives</w><w>us</w><w>an</w><w>answer</w><w>of</w><w>5</w><pc>.</pc><w>However</w><w>,</w><w>we</w><w>know</w><w>that</w><w>we</w><w>need</w><w>to</w><w>get</w><w>an</w><w>answer</w><w>of</w><w>7.5</w><w>so</w><w>one</w><w>of</w><w>the</w><w>things</w><w>that</w><w>we</w><w>can</w><w>do</w><w>is</w><w>multiply</w><w>the</w><w>inputs</w><w>by</w><w>a</w><w>number</w><pc>.</pc><w>We</w><w>can</w><w>start</w><w>by</w><w>multiplying</w><w>our</w><w>original</w><w>guesses</w><w>by</w><w>2</w><pc>.</pc><w>The</w><w>amount</w><w>that</w><w>we</w><w>multiply</w><w>each</w><w>number</w><w>is</w><w>known</w><w>as</w><w>a</w><w>weight</w><w>:</w><code rend="inline"><w>(</w><w>3x2</w><w>)</w><w>+</w><w>(</w><w>2x2</w><w>)</w><w>=10</w></code><pc>.</pc><w>Now</w><w>we</w><w>have</w><w>overshot</w><w>our</w><w>output</w><w>,</w><w>so</w><w>we</w><w>need</w><w>to</w><w>adjust</w><w>the</w><w>weights</w><w>down</w><pc>.</pc><w>A</w><w>neural</w><w>network</w><w>uses</w><w>the</w><w>``</w><w>error</w><w>''</w><w>value</w><w>to</w><w>adjust</w><w>the</w><w>weights</w><w>of</w><w>our</w><w>network</w><w>accordingly</w><w>,</w><w>in</w><w>a</w><w>process</w><w>called</w><w>``</w><w>back</w><w>propagation</w><pc>.</pc><w>''</w><w>Let</w><w>'s</w><w>try</w><w>1.5</w><w>:</w><code rend="inline"><w>(</w><w>3x1.5</w><w>)</w><w>+</w><w>(</w><w>2x1.5</w><w>)</w><w>=7.5</w></code><pc>.</pc><w>We</w><w>now</w><w>have</w><w>the</w><w>correct</w><w>result</w><w>despite</w><w>not</w><w>knowing</w><w>the</w><w>original</w><w>inputs</w><w>and</w><w>simply</w><w>choosing</w><w>two</w><w>random</w><w>values</w><pc>.</pc><w>This</w><w>is</w><w>exactly</w><w>how</w><w>a</w><w>neural</w><w>network</w><w>works</w><pc>!</pc></p><p><w>One</w><w>thing</w><w>to</w><w>note</w><w>is</w><w>that</w><w>the</w><w>output</w><w>of</w><w>a</w><w>neuron</w><w>to</w><w>the</w><w>next</w><w>layer</w><w>is</w><w>rarely</w><w>the</w><w>value</w><w>originally</w><w>calculated</w><pc>.</pc><w>Instead</w><w>,</w><w>it</w><w>is</w><w>sent</w><w>to</w><w>an</w><w>activation</w><w>function</w><w>to</w><w>prevent</w><w>network</w><w>collapse</w><pc>.</pc><w>Recall</w><w>from</w><ref target="#understanding-artificial-neurons"><w>earlier</w></ref><w>that</w><w>an</w><w>activation</w><w>function</w><w>in</w><w>a</w><w>biological</w><w>neuron</w><w>has</w><w>a</w><w>threshold</w><w>that</w><w>stops</w><w>all</w><w>neurons</w><w>from</w><w>firing</w><w>at</w><w>the</w><w>same</w><w>time</w><pc>.</pc><w>You</w><w>can</w><w>think</w><w>of</w><w>network</w><w>collapse</w><w>as</w><w>removing</w><w>any</w><w>redundancy</w><w>in</w><w>neurons</w><pc>.</pc><w>For</w><w>instance</w><w>,</w><w>if</w><w>a</w><w>neuron</w><w>adds</w><w>two</w><w>different</w><w>input</w><w>values</w><w>then</w><w>outputs</w><w>them</w><w>to</w><w>another</w><w>neuron</w><w>which</w><w>,</w><w>in</w><w>turn</w><w>,</w><w>adds</w><w>up</w><w>the</w><w>first</w><w>neuron</w><w>'s</w><w>output</w><w>,</w><w>we</w><w>can</w><w>reduce</w><w>the</w><w>number</w><w>of</w><w>neurons</w><w>by</w><w>programming</w><w>the</w><w>first</w><w>to</w><w>perform</w><w>the</w><w>whole</w><w>calculation</w><pc>.</pc><w>While</w><w>this</w><w>may</w><w>seem</w><w>more</w><w>efficient</w><w>,</w><w>it</w><w>diminishes</w><w>our</w><w>network</w><w>'s</w><w>flexibility</w><pc>.</pc></p><p><w>The</w><w>activation</w><w>function</w><w>in</w><w>an</w><w>artificial</w><w>neuron</w><w>stops</w><w>network</w><w>collapse</w><w>by</w><w>introducing</w><w>non-linearity</w><pc>.</pc><w>There</w><w>are</w><w>numerous</w><w>types</w><w>of</w><w>activation</w><w>functions</w><pc>.</pc><w>The</w><w>simplest</w><w>non-linear</w><w>functions</w><w>are</w><w>``</w><w>step</w><w>functions</w><pc>.</pc><w>''</w><w>In</w><w>these</w><w>functions</w><w>,</w><w>a</w><w>certain</w><w>threshold</w><w>(</w><w>sometimes</w><w>a</w><w>group</w><w>of</w><w>thresholds</w><w>)</w><w>is</w><w>chosen</w><w>and</w><w>the</w><w>values</w><w>to</w><w>the</w><w>left</w><w>of</w><w>the</w><w>threshold</w><w>output</w><w>a</w><w>single</w><w>value</w><w>,</w><w>while</w><w>the</w><w>values</w><w>to</w><w>the</w><w>right</w><w>of</w><w>the</w><w>threshold</w><w>output</w><w>several</w><w>values</w><pc>.</pc><w>The</w><w>most</w><w>popular</w><w>activation</w><w>functions</w><w>are</w><w>variations</w><w>of</w><ref target="https://perma.cc/BT2H-UDG2"><w>rectified</w><w>linear</w><w>unit</w></ref><w>(</w><w>ReLU</w><w>)</w><pc>.</pc><w>In</w><w>its</w><w>simplest</w><w>form</w><w>,</w><w>a</w><w>ReLU</w><w>activation</w><w>function</w><w>outputs</w><code rend="inline"><w>0</w></code><w>for</w><w>values</w><w>that</w><w>are</w><w>less</w><w>than</w><w>zero</w><w>,</w><w>and</w><w>the</w><w>input</w><w>value</w><w>itself</w><w>if</w><w>it</w><w>'s</w><w>higher</w><w>than</w><w>zero</w><pc>.</pc></p><p><w>Activation</w><w>functions</w><w>are</w><w>particularly</w><w>important</w><w>in</w><w>the</w><w>final</w><w>layer</w><w>as</w><w>they</w><w>constrain</w><w>the</w><w>output</w><w>to</w><w>within</w><w>a</w><w>certain</w><w>range</w><pc>.</pc><w>If</w><w>you</w><w>are</w><w>familiar</w><w>with</w><ref target="/en/lessons/logistic-regression"><w>logistic</w><w>regression</w></ref><w>,</w><w>you</w><w>may</w><w>be</w><w>familiar</w><w>with</w><w>the</w><ref target="https://perma.cc/3J3M-FPJQ"><w>sigmoid</w><w>function</w></ref><w>which</w><w>is</w><w>used</w><w>in</w><w>binary</w><w>classification</w><pc>.</pc><w>We</w><w>can</w><w>use</w><w>this</w><w>same</w><w>function</w><w>as</w><w>an</w><w>activation</w><w>function</w><w>for</w><w>a</w><w>neural</w><w>network</w><w>to</w><w>constrain</w><w>our</w><w>values</w><w>set</w><w>to</w><code rend="inline"><w>0</w></code><w>or</w><code rend="inline"><w>1</w></code><pc>.</pc><w>However</w><w>,</w><w>because</w><w>we</w><w>normally</w><w>have</w><w>more</w><w>than</w><w>two</w><w>categories</w><w>,</w><w>the</w><ref target="https://perma.cc/VRE3-9SNN"><w>ArgMax</w></ref><w>and</w><ref target="https://perma.cc/PRB9-JKYW"><w>SoftMax</w></ref><w>functions</w><w>are</w><w>more</w><w>common</w><pc>.</pc><w>The</w><w>former</w><w>outputs</w><w>the</w><w>category</w><w>with</w><w>the</w><w>maximum</w><w>probability</w><w>to</w><w>1</w><w>and</w><w>the</w><w>remainder</w><w>to</w><w>zero</w><pc>.</pc><w>The</w><w>latter</w><w>provides</w><w>values</w><w>for</w><w>each</w><w>category</w><w>between</w><code rend="inline"><w>0</w></code><w>and</w><code rend="inline"><w>1</w></code><w>with</w><w>the</w><w>highest</w><w>value</w><w>indicating</w><w>the</w><w>most</w><w>likely</w><w>classification</w><w>and</w><w>the</w><w>lowest</w><w>value</w><w>indicating</w><w>the</w><w>least</w><w>likely</w><w>classification</w><pc>.</pc></p></div><div type="3" n="3.2"><head><w>Convolutional</w><w>Neural</w><w>Networks</w></head><p><w>Hopefully</w><w>,</w><w>you</w><w>now</w><w>have</w><w>a</w><w>good</w><w>understanding</w><w>of</w><w>how</w><w>a</w><w>basic</w><w>neural</w><w>network</w><w>works</w><pc>.</pc><w>Convolutional</w><w>neural</w><w>networks</w><w>draw</w><w>on</w><w>this</w><w>same</w><w>foundation</w><pc>.</pc><w>These</w><w>networks</w><w>are</w><w>particularly</w><w>good</w><w>at</w><w>detecting</w><w>image</w><w>features</w><w>and</w><w>get</w><w>their</w><w>name</w><w>from</w><w>their</w><w>``</w><w>convolutional</w><w>layers</w><pc>.</pc><w>''</w></p><p><w>Think</w><w>about</w><w>what</w><w>makes</w><w>up</w><w>an</w><w>image</w><pc>.</pc><w>If</w><w>you</w><w>have</w><w>ever</w><w>taken</w><w>a</w><w>drawing</w><w>class</w><w>,</w><w>you</w><w>may</w><w>have</w><w>learned</w><w>to</w><w>divide</w><w>a</w><w>sketch</w><w>into</w><w>simple</w><w>shapes</w><w>,</w><w>such</w><w>as</w><w>circles</w><w>and</w><w>squares</w><pc>.</pc><w>Later</w><w>,</w><w>you</w><w>took</w><w>these</w><w>shapes</w><w>and</w><w>drew</w><w>more</w><w>complex</w><w>images</w><w>on</w><w>top</w><w>of</w><w>them</w><pc>.</pc><w>A</w><w>convolutional</w><w>neural</w><w>network</w><w>essentially</w><w>does</w><w>the</w><w>same</w><w>thing</w><pc>.</pc><w>As</w><w>we</w><w>stack</w><w>convolution</w><w>layers</w><w>on</w><w>top</w><w>of</w><w>one</w><w>another</w><w>,</w><w>each</w><w>learns</w><w>to</w><w>identify</w><w>different</w><w>parts</w><w>of</w><w>a</w><w>growingly</w><w>complex</w><w>shape</w><pc>.</pc><w>The</w><w>first</w><w>layer</w><w>detects</w><w>basic</w><w>features</w><w>such</w><w>as</w><w>corners</w><w>and</w><w>edges</w><pc>.</pc><w>The</w><w>middle</w><w>layers</w><w>detect</w><w>shapes</w><w>and</w><w>segment</w><w>them</w><w>into</w><w>object</w><w>parts</w><pc>.</pc><w>The</w><w>last</w><w>layers</w><w>will</w><w>be</w><w>able</w><w>to</w><w>recognize</w><w>the</w><w>objects</w><w>themselves</w><w>,</w><w>before</w><w>sending</w><w>them</w><w>to</w><w>the</w><w>output</w><w>layer</w><w>for</w><w>classification</w><pc>.</pc><w>For</w><w>more</w><w>information</w><w>about</w><w>how</w><w>the</w><w>layers</w><w>of</w><w>a</w><w>convolution</w><w>network</w><w>work</w><w>,</w><w>I</w><w>recommend</w><w>Erik</w><w>Reppel</w><w>'s</w><w>excellent</w><w>blog</w><w>post</w><emph><w>Visualizing</w><w>parts</w><w>of</w><w>Convolutional</w><w>Neural</w><w>Networks</w><w>using</w><w>Keras</w><w>and</w><w>Cats</w></emph><pc>.</pc><ref type="footnotemark" target="#en_note_6"/></p><p><w>What</w><w>exactly</w><w>is</w><w>a</w><w>convolution</w><w>though</w><pc>?</pc><w>At</w><w>its</w><w>most</w><w>basic</w><w>,</w><w>a</w><w>convolution</w><w>is</w><w>a</w><w>mathematical</w><w>function</w><w>resulting</w><w>in</w><w>two</w><w>sets</w><w>of</w><w>information</w><w>becoming</w><w>converged</w><pc>.</pc><w>If</w><w>you</w><w>have</w><w>used</w><w>filters</w><w>,</w><w>such</w><w>as</w><w>blurs</w><w>,</w><w>in</w><w>common</w><w>image</w><w>editing</w><w>applications</w><w>,</w><w>you</w><w>have</w><w>used</w><w>convolutions</w><pc>.</pc><w>Convolutions</w><w>for</w><w>images</w><w>work</w><w>by</w><w>taking</w><w>a</w><w>filter</w><w>(</w><w>also</w><w>known</w><w>as</w><w>a</w><w>kernel</w><w>)</w><w>consisting</w><w>of</w><w>a</w><w>grid</w><w>of</w><w>numbers</w><w>;</w><w>usually</w><w>3x3</w><w>or</w><w>5x5</w><w>,</w><w>and</w><w>moving</w><w>it</w><w>over</w><w>each</w><w>pixel</w><w>in</w><w>the</w><w>image</w><pc>.</pc><w>As</w><w>the</w><w>filter</w><w>moves</w><w>,</w><w>the</w><w>values</w><w>in</w><w>each</w><w>overlapping</w><w>pixel</w><w>are</w><w>multiplied</w><w>by</w><w>the</w><w>values</w><w>in</w><w>the</w><w>filter</w><pc>.</pc><w>Finally</w><w>,</w><w>the</w><w>values</w><w>for</w><w>all</w><w>the</w><w>numbers</w><w>in</w><w>the</w><w>grid</w><w>are</w><w>added</w><w>together</w><w>to</w><w>create</w><w>a</w><w>single</w><w>output</w><pc>.</pc></p><p><w>Because</w><w>the</w><w>neural</w><w>network</w><w>takes</w><w>the</w><w>values</w><w>from</w><w>each</w><w>grid</w><w>and</w><w>adds</w><w>them</w><w>together</w><w>,</w><w>the</w><w>values</w><w>given</w><w>to</w><w>the</w><w>next</w><w>layer</w><w>are</w><w>smaller</w><w>than</w><w>the</w><w>original</w><w>image</w><pc>.</pc><w>This</w><w>new</w><w>array</w><w>of</w><w>numbers</w><w>is</w><w>referred</w><w>to</w><w>as</w><w>a</w><w>``</w><w>feature</w><w>map</w><w>''</w><w>and</w><w>makes</w><w>training</w><w>the</w><w>neural</w><w>network</w><w>less</w><w>computationally</w><w>intensive</w><pc>.</pc><w>An</w><w>activation</w><w>function</w><w>,</w><w>such</w><w>as</w><w>ReLU</w><w>,</w><w>is</w><w>also</w><w>commonly</w><w>used</w><w>to</w><w>transform</w><w>all</w><w>negative</w><w>values</w><w>to</w><w>zero</w><pc>.</pc></p><p><w>Finally</w><w>,</w><w>a</w><w>``</w><w>pooling</w><w>layer</w><w>''</w><w>is</w><w>utilized</w><pc>.</pc><w>A</w><w>pooling</w><w>layer</w><w>works</w><w>similarly</w><w>to</w><w>a</w><w>convolutional</w><w>layer</w><w>in</w><w>that</w><w>it</w><w>takes</w><w>a</w><w>grid</w><w>;</w><w>usually</w><w>2x2</w><w>,</w><w>and</w><w>passes</w><w>it</w><w>over</w><w>each</w><w>value</w><w>in</w><w>the</w><w>feature</w><w>map</w><pc>.</pc><w>In</w><w>contrast</w><w>with</w><w>the</w><w>convolution</w><w>layer</w><w>,</w><w>however</w><w>,</w><w>the</w><w>pooling</w><w>layer</w><w>simply</w><w>takes</w><w>the</w><w>maximum</w><w>or</w><w>average</w><w>value</w><w>(</w><w>depending</w><w>on</w><w>which</w><w>convolutional</w><w>neural</w><w>network</w><w>you</w><w>are</w><w>using</w><w>)</w><w>of</w><w>the</w><w>numbers</w><w>in</w><w>the</w><w>grid</w><pc>.</pc><w>This</w><w>creates</w><w>a</w><w>smaller</w><w>feature</w><w>map</w><pc>.</pc><w>Together</w><w>,</w><w>convolutions</w><w>and</w><w>pooling</w><w>allow</w><w>neural</w><w>networks</w><w>to</w><w>perform</w><w>image</w><w>classification</w><w>even</w><w>if</w><w>the</w><w>spatial</w><w>arrangement</w><w>of</w><w>the</w><w>pixels</w><w>is</w><w>different</w><w>,</w><w>and</w><w>without</w><w>having</w><w>to</w><w>do</w><w>as</w><w>many</w><w>calculations</w><pc>.</pc></p></div><div type="3" n="3.3"><head><w>Transfer</w><w>Learning</w><w>and</w><w>Convolutional</w><w>Neural</w><w>Networks</w></head><p><w>Now</w><w>,</w><w>we</w><w>are</w><w>going</w><w>to</w><w>begin</w><w>using</w><w>Google</w><w>'s</w><ref target="https://teachablemachine.withgoogle.com/"><w>Teachable</w><w>Machine</w></ref><w>to</w><w>train</w><w>our</w><w>model</w><pc>.</pc><w>Teachable</w><w>Machine</w><w>provides</w><w>a</w><w>simple</w><w>interface</w><w>we</w><w>can</w><w>use</w><w>without</w><w>initially</w><w>having</w><w>to</w><w>worry</w><w>about</w><w>code</w><pc>.</pc><w>When</w><w>you</w><w>load</w><w>it</w><w>,</w><w>you</w><w>will</w><w>find</w><w>that</w><w>you</w><w>have</w><w>the</w><w>option</w><w>to</w><w>train</w><w>three</w><w>different</w><w>types</w><w>of</w><w>models</w><pc>.</pc><w>For</w><w>this</w><w>tutorial</w><w>,</w><w>we</w><w>will</w><w>be</w><w>creating</w><w>what</w><w>Teachable</w><w>Machine</w><w>calls</w><w>a</w><w>``</w><w>Standard</w><w>image</w><w>model</w><pc>.</pc><w>''</w></p><p><w>Training</w><w>an</w><w>image</w><w>classifier</w><w>from</w><w>scratch</w><w>can</w><w>be</w><w>difficult</w><pc>.</pc><w>We</w><w>would</w><w>need</w><w>to</w><w>provide</w><w>numerous</w><w>images</w><w>along</w><w>with</w><w>their</w><w>corresponding</w><w>labels</w><pc>.</pc><w>Instead</w><w>,</w><w>Teachable</w><w>Machine</w><w>relies</w><w>on</w><w>transfer</w><w>learning</w><pc>.</pc></p><p><w>Transfer</w><w>learning</w><w>expands</w><w>on</w><w>a</w><w>model</w><w>that</w><w>has</w><w>already</w><w>been</w><w>trained</w><w>on</w><w>a</w><w>separate</w><w>group</w><w>of</w><w>images</w><pc>.</pc><w>Teachable</w><w>Machine</w><w>relies</w><w>on</w><ref target="https://perma.cc/8FWJ-NDXH"><w>MobileNet</w></ref><w>as</w><w>the</w><w>basis</w><w>for</w><w>its</w><w>transfer</w><w>learning</w><pc>.</pc><w>MobileNet</w><w>is</w><w>a</w><w>lightweight</w><w>neural</w><w>network</w><w>designed</w><w>to</w><w>run</w><w>on</w><w>small</w><w>devices</w><w>with</w><w>low-latency</w><pc>.</pc><w>Its</w><w>training</w><w>times</w><w>are</w><w>relatively</w><w>quick</w><w>,</w><w>and</w><w>we</w><w>can</w><w>start</w><w>with</w><w>fewer</w><w>images</w><pc>.</pc><w>Of</w><w>course</w><w>,</w><w>MobileNet</w><w>was</w><w>not</w><w>trained</w><w>on</w><w>the</w><w>images</w><w>that</w><w>we</w><w>are</w><w>interested</w><w>in</w><w>,</w><w>so</w><w>how</w><w>exactly</w><w>can</w><w>we</w><w>use</w><w>it</w><pc>?</pc><w>This</w><w>is</w><w>where</w><w>transfer</w><w>learning</w><w>kicks</w><w>in</w><pc>.</pc></p><p><w>You</w><w>can</w><w>think</w><w>of</w><w>transfer</w><w>learning</w><w>as</w><w>a</w><w>process</w><w>of</w><w>modifying</w><w>the</w><w>final</w><w>layer</w><w>of</w><w>a</w><w>preexisting</w><w>model</w><w>to</w><w>discern</w><w>our</w><w>images</w><w>'</w><w>``</w><w>features</w><pc>.</pc><w>''</w><w>At</w><w>first</w><w>,</w><w>these</w><w>features</w><w>are</w><w>mapped</w><w>to</w><w>the</w><w>categories</w><w>that</w><w>MobileNet</w><w>was</w><w>trained</w><w>on</w><w>,</w><w>but</w><w>through</w><w>transfer</w><w>learning</w><w>,</w><w>we</w><w>can</w><w>overwrite</w><w>this</w><w>mapping</w><w>to</w><w>reflect</w><w>our</w><w>own</w><w>categories</w><pc>.</pc><w>Thus</w><w>,</w><w>we</w><w>can</w><w>rely</w><w>on</w><w>the</w><w>earlier</w><w>layers</w><w>to</w><w>do</w><w>most</w><w>of</w><w>the</w><w>heavy</w><w>lifting</w><w>—detecting</w><w>basic</w><w>features</w><w>and</w><w>shapes—</w><w>while</w><w>still</w><w>having</w><w>the</w><w>benefit</w><w>of</w><w>using</w><w>the</w><w>final</w><w>layers</w><w>to</w><w>recognize</w><w>specific</w><w>objects</w><w>and</w><w>perform</w><w>classification</w><pc>.</pc></p></div></div><div type="2" n="4"><head><w>Creating</w><w>Your</w><w>Own</w><w>Model</w></head><p><w>On</w><w>the</w><w>Teachable</w><w>Machine</w><w>home</w><w>page</w><w>,</w><w>go</w><w>ahead</w><w>and</w><w>click</w><w>the</w><w>``</w><w>Get</w><w>Started</w><w>''</w><w>button</w><pc>.</pc><w>Then</w><w>,</w><w>click</w><w>``</w><w>Image</w><w>Project</w><w>''</w><w>and</w><w>select</w><w>``</w><w>Standard</w><w>image</w><w>model</w><pc>.</pc><w>''</w></p><p><w>Now</w><w>,</w><w>we</w><w>can</w><w>begin</w><w>uploading</w><w>image</w><w>samples</w><w>for</w><w>each</w><w>class</w><pc>.</pc><w>You</w><w>will</w><w>find</w><w>that</w><w>you</w><w>can</w><w>either</w><w>``</w><w>Upload</w><w>''</w><w>images</w><w>or</w><w>use</w><w>your</w><w>webcam</w><w>to</w><w>create</w><w>new</w><w>ones</w><pc>.</pc><w>We</w><w>will</w><w>be</w><w>uploading</w><w>all</w><w>the</w><w>images</w><w>for</w><w>each</w><w>of</w><w>our</w><w>categories</w><w>to</w><w>the</w><w>training</w><w>folder</w><pc>.</pc></p><p><w>Under</w><w>``</w><w>Class</w><w>1</w><w>''</w><w>,</w><w>click</w><w>``</w><w>Choose</w><w>images</w><w>from</w><w>your</w><w>files</w><w>,</w><w>or</w><w>drag</w><w>&amp;</w><w>drop</w><w>here</w><pc>.</pc><w>''</w><w>Select</w><w>the</w><w>``</w><w>aircraft</w><w>''</w><w>folder</w><w>from</w><w>inside</w><w>the</w><w>dataset</w><w>``</w><w>training</w><w>''</w><w>folder</w><w>and</w><w>drag</w><w>it</w><w>into</w><w>the</w><w>Teachable</w><w>Machine</w><w>window</w><pc>.</pc><w>Click</w><w>the</w><w>pencil</w><w>icon</w><w>next</w><w>to</w><w>``</w><w>Class</w><w>1</w><w>''</w><w>and</w><w>change</w><w>the</w><w>name</w><w>to</w><w>``</w><w>aircraft</w><w>''</w><pc>.</pc></p><p><w>Repeat</w><w>this</w><w>process</w><w>for</w><w>the</w><w>other</w><w>folders</w><w>in</w><w>the</w><w>dataset</w><pc>.</pc><w>After</w><w>the</w><w>second</w><w>time</w><w>,</w><w>you</w><w>will</w><w>need</w><w>to</w><w>click</w><w>``</w><w>+</w><w>Add</w><w>a</w><w>class</w><w>''</w><w>for</w><w>each</w><w>new</w><w>folder</w><pc>.</pc></p><p><w>{</w><w>%</w><w>include</w><w>figure.html</w><w>filename=</w><w>''</w><w>add_classes.png</w><w>''</w><w>alt=</w><w>''</w><w>An</w><w>image</w><w>showcasing</w><w>the</w><w>Google</w><w>Teachable</w><w>Machine</w><w>interface</w><pc>.</pc><w>On</w><w>the</w><w>left</w><w>,</w><w>there</w><w>is</w><w>an</w><w>option</w><w>to</w><w>upload</w><w>files</w><w>and</w><w>on</w><w>the</w><w>right</w><w>are</w><w>all</w><w>the</w><w>images</w><w>of</w><w>aircraft</w><w>currently</w><w>being</w><w>loaded</w><pc>.</pc><w>The</w><w>label</w><w>has</w><w>been</w><w>changed</w><w>to</w><w>aircraft</w><pc>.</pc><w>''</w><w>caption=</w><w>''</w><w>Figure</w><w>4</w><pc>.</pc><w>Adding</w><w>classes</w><w>to</w><w>Google</w><w>Teachable</w><w>Machine</w><pc>.</pc><w>''</w><w>%</w><w>}</w></p><p><w>Once</w><w>you</w><w>have</w><w>finished</w><w>uploading</w><w>the</w><w>images</w><w>,</w><w>you</w><w>can</w><w>adjust</w><w>various</w><w>parameters</w><w>for</w><w>how</w><w>the</w><w>model</w><w>should</w><w>be</w><w>trained</w><w>by</w><w>clicking</w><w>on</w><w>``</w><w>Advanced</w><w>''</w><w>under</w><w>Training</w><pc>.</pc><w>Here</w><w>you</w><w>will</w><w>see</w><w>options</w><w>for</w><w>epochs</w><w>,</w><w>batch</w><w>size</w><w>,</w><w>and</w><w>learning</w><w>rate</w><pc>.</pc></p><figure><desc><w>Figure</w><w>5</w><pc>.</pc><w>Advanced</w><w>settings</w><w>in</w><w>Google</w><w>Teachable</w><w>Machine</w><pc>.</pc></desc><figDesc><w>Showcases</w><w>the</w><w>advanced</w><w>settings</w><w>tab</w><pc>.</pc><w>There</w><w>are</w><w>options</w><w>that</w><w>the</w><w>user</w><w>can</w><w>set</w><w>through</w><w>a</w><w>drop</w><w>down</w><w>menu</w><w>for</w><w>epochs</w><w>,</w><w>batch</w><w>size</w><w>,</w><w>and</w><w>learning</w><w>rate</w></figDesc><graphic url="advanced_settings.png"/></figure><p><w>An</w><w>epoch</w><w>refers</w><w>to</w><w>the</w><w>number</w><w>of</w><w>times</w><w>that</w><w>each</w><w>image</w><w>is</w><w>fed</w><w>through</w><w>the</w><w>neural</w><w>network</w><w>during</w><w>training</w><pc>.</pc><w>Because</w><w>each</w><w>image</w><w>is</w><w>fed</w><w>through</w><w>multiple</w><w>times</w><w>,</w><w>we</w><w>do</w><w>n't</w><w>actually</w><w>need</w><w>a</w><w>large</w><w>number</w><w>of</w><w>sample</w><w>images</w><pc>.</pc><w>You</w><w>may</w><w>be</w><w>wondering</w><w>why</w><w>we</w><w>do</w><w>n't</w><w>just</w><w>set</w><w>the</w><w>epoch</w><w>ridiculously</w><w>high</w><w>so</w><w>that</w><w>our</w><w>model</w><w>works</w><w>through</w><w>the</w><w>dataset</w><w>a</w><w>greater</w><w>number</w><w>of</w><w>times</w><pc>.</pc><w>The</w><w>chief</w><w>reason</w><w>is</w><w>``</w><w>overfitting</w><pc>.</pc><w>''</w></p><p><w>Overfitting</w><w>is</w><w>when</w><w>our</w><w>neural</w><w>network</w><w>gets</w><w>really</w><w>proficient</w><w>at</w><w>working</w><w>with</w><w>our</w><w>training</w><w>set</w><w>but</w><w>fails</w><w>on</w><w>new</w><w>data</w><pc>.</pc><w>This</w><w>is</w><w>a</w><w>result</w><w>of</w><w>the</w><ref target="https://perma.cc/7DGT-SLED"><w>bias-variance</w><w>tradeoff</w></ref><pc>.</pc><w>If</w><w>a</w><w>model</w><w>has</w><w>high</w><w>bias</w><w>,</w><w>it</w><w>performs</w><w>well</w><w>on</w><w>our</w><w>training</w><w>data</w><w>set</w><w>but</w><w>not</w><w>as</w><w>well</w><w>on</w><w>a</w><w>new</w><w>one</w><pc>.</pc><w>In</w><w>contrast</w><w>,</w><w>if</w><w>it</w><w>has</w><w>high</w><w>variance</w><w>,</w><w>it</w><w>may</w><w>not</w><w>work</w><w>as</w><w>well</w><w>on</w><w>our</w><w>training</w><w>data</w><w>but</w><w>could</w><w>have</w><w>more</w><w>flexibility</w><w>when</w><w>it</w><w>comes</w><w>to</w><w>new</w><w>data</w><pc>.</pc><w>How</w><w>to</w><w>determine</w><w>the</w><w>exact</w><w>relationship</w><w>between</w><w>variance</w><w>and</w><w>bias</w><w>is</w><w>a</w><w>complex</w><w>topic</w><pc>.</pc><w>One</w><w>common</w><w>method</w><w>is</w><w>to</w><w>save</w><w>a</w><w>bit</w><w>of</w><w>the</w><w>original</w><w>data</w><w>by</w><w>splitting</w><w>it</w><w>into</w><w>a</w><w>``</w><w>testing</w><w>''</w><w>set</w><pc>.</pc><w>Rather</w><w>than</w><w>using</w><w>this</w><w>data</w><w>to</w><w>build</w><w>the</w><w>original</w><w>model</w><w>,</w><w>the</w><w>testing</w><w>set</w><w>is</w><w>used</w><w>to</w><w>provide</w><w>statistical</w><w>summaries</w><w>of</w><w>how</w><w>well</w><w>the</w><w>model</w><w>will</w><w>work</w><w>on</w><w>new</w><w>data</w><pc>.</pc><w>Teachable</w><w>Machine</w><w>does</w><w>this</w><w>'under</w><w>the</w><w>hood</w><w>'</w><w>,</w><w>but</w><w>when</w><w>you</w><w>build</w><w>more</w><w>elaborate</w><w>models</w><w>,</w><w>you</w><w>will</w><w>need</w><w>to</w><w>determine</w><w>how</w><w>much</w><w>of</w><w>the</w><w>original</w><w>data</w><w>should</w><w>be</w><w>preserved</w><w>yourself</w><pc>.</pc></p><p><w>Batch</w><w>size</w><w>refers</w><w>to</w><w>the</w><w>number</w><w>of</w><w>images</w><w>used</w><w>for</w><w>training</w><w>per</w><w>iteration</w><pc>.</pc><w>If</w><w>you</w><w>have</w><w>80</w><w>images</w><w>and</w><w>a</w><w>batch</w><w>size</w><w>of</w><w>16</w><w>,</w><w>this</w><w>means</w><w>that</w><w>it</w><w>will</w><w>take</w><w>5</w><w>iterations</w><w>to</w><w>make</w><w>up</w><w>one</w><w>epoch</w><pc>.</pc><w>A</w><w>key</w><w>advantage</w><w>to</w><w>using</w><w>a</w><w>smaller</w><w>batch</w><w>size</w><w>is</w><w>that</w><w>it</w><w>is</w><w>much</w><w>more</w><w>efficient</w><w>on</w><w>memory</w><pc>.</pc><w>Because</w><w>we</w><w>are</w><w>updating</w><w>the</w><w>model</w><w>after</w><w>each</w><w>batch</w><w>,</w><w>the</w><w>network</w><w>tends</w><w>to</w><w>be</w><w>trained</w><w>faster</w><pc>.</pc><w>Nonethless</w><w>,</w><w>batch</w><w>sizes</w><w>make</w><w>an</w><w>impact</w><w>on</w><w>the</w><w>generalization</w><w>and</w><w>convergence</w><w>on</w><w>our</w><w>model</w><w>,</w><w>so</w><w>we</w><w>need</w><w>to</w><w>be</w><w>careful</w><w>with</w><w>this</w><w>setting</w><pc>.</pc></p><p><w>The</w><w>learning</w><w>rate</w><w>refers</w><w>to</w><w>how</w><w>much</w><w>we</w><w>should</w><w>change</w><w>our</w><w>model</w><w>based</w><w>on</w><w>the</w><w>estimated</w><w>error</w><pc>.</pc><w>This</w><w>impacts</w><w>how</w><w>well</w><w>your</w><w>neural</w><w>network</w><w>performs</w><pc>.</pc></p><p><w>We</w><w>will</w><w>stick</w><w>with</w><w>the</w><w>default</w><w>settings</w><w>for</w><w>now</w><pc>.</pc><w>Click</w><w>on</w><w>the</w><w>``</w><w>Train</w><w>''</w><w>button</w><w>to</w><w>begin</w><w>training</w><w>your</w><w>model</w><pc>.</pc></p><p style="alert alert-warning"><w>Please</w><w>note</w><w>that</w><w>immediately</w><w>upon</w><w>finishing</w><w>the</w><w>training</w><w>,</w><w>Teachable</w><w>Machine</w><w>will</w><w>begin</w><w>to</w><w>test</w><w>the</w><w>video</w><w>feed</w><w>from</w><w>your</w><w>webcam</w><pc>.</pc><w>You</w><w>need</w><w>to</w><w>select</w><w>``</w><w>File</w><w>''</w><w>in</w><w>the</w><w>dropdown</w><w>menu</w><w>next</w><w>to</w><w>Input</w><w>rather</w><w>than</w><w>Webcam</w><w>to</w><w>stop</w><w>this</w><pc>.</pc></p><p><w>A</w><w>bar</w><w>will</w><w>display</w><w>the</w><w>progress</w><pc>.</pc><w>Be</w><w>sure</w><w>not</w><w>to</w><w>close</w><w>your</w><w>browser</w><w>or</w><w>switch</w><w>tabs</w><w>during</w><w>this</w><w>time</w><pc>.</pc><w>The</w><w>pop-up</w><w>displayed</w><w>below</w><w>will</w><w>remind</w><w>you</w><w>of</w><w>this</w><pc>.</pc></p><figure><desc><w>Figure</w><w>6</w><pc>.</pc><w>Pop-up</w><w>Showing</w><w>Not</w><w>to</w><w>Switch</w><w>Tabs</w></desc><figDesc><w>Pop-up</w><w>browser</w><w>notification</w><w>is</w><w>displayed</w><w>stating</w><w>not</w><w>to</w><w>switch</w><w>tabs</w><pc>.</pc><w>There</w><w>is</w><w>an</w><w>option</w><w>to</w><w>click</w><w>OK</w><w>or</w><w>not</w><w>show</w><w>message</w><w>again</w></figDesc><graphic url="donotswitch.png"/></figure><p><w>After</w><w>training</w><w>is</w><w>complete</w><w>,</w><w>you</w><w>will</w><w>want</w><w>to</w><w>test</w><w>your</w><w>model</w><pc>.</pc><w>There</w><w>are</w><w>various</w><w>measures</w><w>we</w><w>can</w><w>use</w><w>to</w><w>determine</w><w>how</w><w>well</w><w>a</w><w>model</w><w>works</w><pc>.</pc><w>If</w><w>you</w><w>click</w><w>on</w><w>``</w><w>Under</w><w>the</w><w>hood</w><w>''</w><w>in</w><w>the</w><w>Advanced</w><w>settings</w><w>,</w><w>the</w><w>Loss</w><w>and</w><w>Accuracy</w><w>per</w><w>Epoch</w><w>is</w><w>displayed</w><pc>.</pc><w>The</w><w>closer</w><w>the</w><w>loss</w><w>is</w><w>to</w><w>0</w><w>and</w><w>the</w><w>accuracy</w><w>is</w><w>to</w><w>1</w><w>,</w><w>the</w><w>better</w><w>our</w><w>model</w><w>is</w><w>at</w><w>understanding</w><w>our</w><w>images</w><pc>.</pc></p><p><w>One</w><w>of</w><w>the</w><w>benefits</w><w>of</w><w>Teachable</w><w>Machine</w><w>is</w><w>that</w><w>we</w><w>can</w><w>immediately</w><w>begin</w><w>testing</w><w>our</w><w>model</w><pc>.</pc><w>The</w><w>default</w><w>input</w><w>for</w><w>new</w><w>images</w><w>is</w><w>to</w><w>use</w><w>your</w><w>webcam</w><w>so</w><w>we</w><w>will</w><w>switch</w><w>it</w><w>to</w><w>file</w><pc>.</pc><w>Go</w><w>ahead</w><w>and</w><w>upload</w><w>one</w><w>of</w><w>the</w><w>images</w><w>in</w><w>the</w><code rend="inline"><w>testing</w></code><w>folder</w><w>and</w><w>see</w><w>the</w><w>results</w><pc>.</pc><w>Normally</w><w>we</w><w>would</w><w>want</w><w>to</w><w>test</w><w>our</w><w>model</w><w>with</w><w>many</w><w>images</w><w>at</w><w>once</w><w>,</w><w>but</w><w>Teachable</w><w>Machine</w><w>only</w><w>lets</w><w>us</w><w>test</w><w>one</w><w>image</w><w>at</w><w>a</w><w>time</w><pc>.</pc><w>In</w><w>the</w><code rend="inline"><w>testing</w></code><w>folder</w><w>,</w><w>there</w><w>are</w><w>ten</w><w>images</w><w>for</w><w>testing</w><w>the</w><w>classification</w><pc>.</pc><w>Go</w><w>ahead</w><w>and</w><w>compare</w><w>how</w><w>you</w><w>would</w><w>classify</w><w>them</w><w>yourself</w><w>with</w><w>the</w><w>output</w><w>Teachable</w><w>Machine</w><w>provided</w><pc>.</pc></p><div type="3" n="4.1"><head><w>Export</w><w>the</w><w>Model</w></head><p><w>Let</w><w>'s</w><w>export</w><w>and</w><w>download</w><w>our</w><w>model</w><w>to</w><w>see</w><w>how</w><w>we</w><w>can</w><w>reuse</w><w>it</w><w>in</w><w>new</w><w>circumstances</w><pc>.</pc><w>Click</w><w>the</w><w>``</w><w>Export</w><w>Model</w><w>''</w><w>button</w><w>,</w><w>and</w><w>you</w><w>will</w><w>see</w><w>three</w><w>options</w><w>:</w><w>Tensorflow.js</w><w>,</w><w>Tensorflow</w><w>,</w><w>and</w><w>Tensorflow</w><w>Light</w><pc>.</pc><ref target="https://perma.cc/8WVM-Z7QF"><w>Tensorflow</w></ref><w>is</w><w>a</w><w>library</w><w>developed</w><w>by</w><w>Google</w><w>focused</w><w>on</w><w>machine</w><w>learning</w><w>and</w><w>artificial</w><w>intelligence</w><pc>.</pc><w>We</w><w>will</w><w>choose</w><w>Tensorflow.js</w><w>,</w><w>which</w><w>is</w><w>simply</w><w>a</w><w>JavaScript</w><w>implementation</w><w>of</w><w>the</w><w>library</w><pc>.</pc><ref target="https://perma.cc/3GBE-NVER"><w>Ml5.js</w></ref><w>and</w><ref target="https://perma.cc/5DXT-UR72"><w>p5.js</w></ref><w>,</w><w>which</w><w>we</w><w>will</w><w>use</w><w>to</w><w>later</w><w>embed</w><w>our</w><w>model</w><w>on</w><w>our</w><w>website</w><w>,</w><w>rely</w><w>on</w><w>Tensorflow.js</w><w>at</w><w>a</w><w>lower</w><w>level</w><pc>.</pc></p><p><w>Once</w><w>you</w><w>have</w><w>selected</w><w>Tensorflow.js</w><w>,</w><w>you</w><w>will</w><w>be</w><w>given</w><w>a</w><code rend="inline"><w>.zip</w></code><w>file</w><w>containing</w><w>three</w><w>files</w><w>:</w></p><list type="unordered"><item><code rend="inline"><w>model.json</w></code><w>containing</w><w>data</w><w>about</w><w>the</w><w>different</w><w>layers</w><w>for</w><w>the</w><w>neural</w><w>network</w><w>itself</w></item><item><code rend="inline"><w>weights.bin</w></code><w>containing</w><w>information</w><w>about</w><w>the</w><w>weights</w><w>for</w><w>each</w><w>of</w><w>the</w><w>neurons</w></item><item><code rend="inline"><w>metadata.json</w></code><w>containing</w><w>information</w><w>about</w><w>which</w><w>Tensorflow</w><w>version</w><w>is</w><w>being</w><w>used</w><w>for</w><w>the</w><w>network</w><w>along</w><w>with</w><w>the</w><w>class</w><w>labels</w></item></list><p><w>Unzip</w><w>this</w><w>folder</w><w>,</w><w>and</w><w>place</w><w>the</w><w>files</w><w>inside</w><w>of</w><w>your</w><code rend="inline"><w>projects</w></code><w>folder</w><w>:</w></p><figure><desc><w>Figure</w><w>7</w><pc>.</pc><w>Projects</w><w>Folder</w><w>with</w><w>Tensorflow.js</w><w>Files</w></desc><figDesc><w>An</w><w>image</w><w>of</w><w>a</w><w>directory</w><w>in</w><w>macOS</w><w>Finder</w><w>showing</w><w>the</w><w>following</w><w>files</w><w>:</w><w>metadata.json</w><w>,</w><w>weights.bin</w><w>,</w><w>and</w><w>model.json</w><pc>.</pc><w>A</w><w>directory</w><w>entitled</w><w>dataset</w><w>is</w><w>also</w><w>available</w></figDesc><graphic url="project1.png"/></figure></div><div type="3" n="4.2"><head><w>Import</w><w>the</w><w>Model</w><w>with</w><w>ml5.js</w></head><p><w>Teachable</w><w>Machine</w><w>is</w><w>a</w><w>great</w><w>resource</w><w>for</w><w>familiarizing</w><w>yourself</w><w>with</w><w>how</w><w>neural</w><w>networks</w><w>—and</w><w>machine</w><w>learning</w><w>more</w><w>broadly—</w><w>work</w><pc>.</pc><w>However</w><w>,</w><w>it</w><w>is</w><w>limited</w><w>in</w><w>what</w><w>it</w><w>can</w><w>do</w><pc>.</pc><w>For</w><w>instance</w><w>,</w><w>maybe</w><w>we</w><w>would</w><w>like</w><w>to</w><w>create</w><w>some</w><w>sort</w><w>of</w><w>graph</w><w>that</w><w>displays</w><w>information</w><w>about</w><w>the</w><w>classification</w><pc>.</pc><w>Or</w><w>,</w><w>maybe</w><w>we</w><w>want</w><w>to</w><w>allow</w><w>others</w><w>to</w><w>use</w><w>our</w><w>model</w><w>for</w><w>classification</w><pc>.</pc><w>For</w><w>that</w><w>,</w><w>we</w><w>will</w><w>need</w><w>to</w><w>import</w><w>our</w><w>model</w><w>to</w><w>a</w><w>system</w><w>that</w><w>allows</w><w>more</w><w>flexibility</w><pc>.</pc><w>Although</w><w>there</w><w>are</w><w>many</w><w>possible</w><w>tools</w><w>to</w><w>choose</w><w>from</w><w>,</w><w>for</w><w>this</w><w>tutorial</w><w>we</w><w>will</w><w>be</w><w>using</w><code rend="inline"><w>ml5.js</w></code><w>and</w><code rend="inline"><w>p5.js</w></code><pc>.</pc></p><p><ref target="https://ml5js.org/"><w>Ml5.js</w></ref><w>is</w><w>a</w><w>JavaScript</w><w>library</w><w>built</w><w>on</w><w>top</w><w>of</w><w>Tensorflow.js</w><pc>.</pc><w>As</w><w>mentioned</w><w>earlier</w><w>,</w><w>machine</w><w>learning</w><w>libraries</w><w>often</w><w>require</w><w>users</w><w>to</w><w>have</w><w>significant</w><w>background</w><w>knowledge</w><w>of</w><w>programming</w><w>and/or</w><w>statistics</w><pc>.</pc><w>For</w><w>most</w><w>neural</w><w>network</w><w>libraries</w><w>,</w><w>you</w><w>must</w><w>specify</w><w>properties</w><w>for</w><w>each</w><w>layer</w><w>of</w><w>the</w><w>neural</w><w>network</w><w>such</w><w>as</w><w>its</w><w>inputs</w><w>,</w><w>outputs</w><w>,</w><w>and</w><w>activation</w><w>functions</w><pc>.</pc><w>Ml5.js</w><w>takes</w><w>care</w><w>of</w><w>this</w><w>for</w><w>you</w><w>,</w><w>making</w><w>it</w><w>easier</w><w>for</w><w>beginners</w><w>to</w><w>start</w><pc>.</pc></p><p><w>To</w><w>begin</w><w>,</w><w>let</w><w>'s</w><w>go</w><w>ahead</w><w>and</w><w>create</w><w>some</w><w>files</w><w>in</w><w>our</w><code rend="inline"><w>projects</w></code><w>folder</w><pc>.</pc><w>Inside</w><w>the</w><w>folder</w><w>,</w><w>we</w><w>will</w><w>create</w><w>an</w><code rend="inline"><w>index.html</w></code><w>page</w><w>that</w><w>will</w><w>call</w><w>the</w><w>rest</w><w>of</w><w>our</w><w>JavaScript</w><w>libraries</w><pc>.</pc><w>This</w><w>allows</w><w>us</w><w>to</w><w>examine</w><w>the</w><w>model</w><w>'s</w><w>output</w><w>without</w><w>having</w><w>to</w><w>look</w><w>directly</w><w>at</w><w>the</w><w>browser</w><w>'s</w><w>developer</w><w>console</w><w>—</w><w>although</w><w>we</w><w>will</w><w>do</w><w>that</w><w>as</w><w>well</w><pc>.</pc><w>We</w><w>also</w><w>need</w><w>to</w><w>create</w><w>a</w><w>file</w><w>called</w><code rend="inline"><w>sketch.js</w></code><w>in</w><w>the</w><w>same</w><w>directory</w><w>as</w><code rend="inline"><w>index.html</w></code><pc>.</pc></p><p><w>In</w><w>the</w><w>discussion</w><w>below</w><w>,</w><w>we</w><w>will</w><w>add</w><w>the</w><w>contents</w><w>of</w><w>this</w><w>file</w><w>step</w><w>by</w><w>step</w><pc>.</pc><w>If</w><w>you</w><w>get</w><w>lost</w><w>at</w><w>any</w><w>point</w><w>,</w><w>you</w><w>can</w><w>download</w><w>the</w><w>full</w><w>code</w><ref target="/assets/image-classification-neural-networks/sketch.js"><w>here</w></ref><pc>.</pc></p><p><w>Finally</w><w>,</w><w>we</w><w>will</w><w>take</w><w>an</w><w>image</w><w>from</w><w>the</w><code rend="inline"><w>testing</w></code><w>folder</w><w>and</w><w>place</w><w>it</w><w>in</w><w>our</w><w>project</w><w>'s</w><w>root</w><w>folder</w><w>to</w><w>assure</w><w>our</w><w>code</w><w>is</w><w>working</w><pc>.</pc><w>You</w><w>can</w><w>use</w><w>any</w><w>image</w><w>you</w><w>like</w><w>,</w><w>but</w><w>I</w><w>am</w><w>going</w><w>to</w><w>use</w><w>the</w><w>first</w><w>one</w><w>for</w><w>this</w><w>example</w><pc>.</pc><w>Your</w><code rend="inline"><w>projects</w></code><w>folder</w><w>should</w><w>now</w><w>look</w><w>like</w><w>this</w><w>:</w></p><figure><desc><w>Figure</w><w>8</w><pc>.</pc><w>Projects</w><w>Folder</w><w>with</w><w>'script.js</w><w>'</w><w>,</w><w>'index.html</w><w>'</w><w>,</w><w>and</w><w>test</w><w>image</w></desc><figDesc><w>Image</w><w>of</w><w>a</w><w>directory</w><w>in</w><w>macOS</w><w>Finder</w><w>with</w><w>the</w><w>following</w><w>items</w><w>:</w><w>index.html</w><w>,</w><w>metadata.json</w><w>,</w><w>model.json</w><w>,</w><w>sketch.js</w><w>,</w><w>testing0.jpg</w><w>,</w><w>and</w><w>weights.bin</w><pc>.</pc><w>There</w><w>is</w><w>also</w><w>a</w><w>folder</w><w>entitled</w><w>dataset</w></figDesc><graphic url="project2.png"/></figure><p><w>We</w><w>will</w><w>base</w><w>the</w><w>code</w><w>for</w><w>our</w><code rend="inline"><w>index.html</w></code><w>file</w><w>on</w><w>the</w><ref target="https://learn.ml5js.org/#/"><w>official</w><w>ml5.js</w><w>boilerplate</w><w>template</w></ref><pc>.</pc><w>This</w><w>template</w><w>links</w><w>to</w><w>the</w><w>latest</w><w>ml5.js</w><w>and</w><w>p5.js</w><w>libraries</w><pc>.</pc><w>While</w><w>ml5.js</w><w>does</w><w>not</w><w>require</w><w>p5.js</w><w>,</w><w>most</w><w>examples</w><w>use</w><w>both</w><w>because</w><w>the</w><w>combination</w><w>allows</w><w>us</w><w>to</w><w>quickly</w><w>code</w><w>an</w><w>interface</w><w>for</w><w>interacting</w><w>with</w><w>the</w><w>model</w><pc>.</pc><w>We</w><w>will</w><w>have</w><w>most</w><w>of</w><w>the</w><w>code</w><w>for</w><w>our</w><w>neural</w><w>network</w><w>in</w><w>a</w><w>separate</w><w>JavaScript</w><w>file</w><w>named</w><code rend="inline"><w>sketch.js</w></code><w>,</w><w>and</w><w>our</w><w>boilerplate</w><w>template</w><w>will</w><w>link</w><w>to</w><w>that</w><w>script</w><pc>.</pc></p><ab><code lang="language-html" xml:id="code_image-classification-neural-networks_0" corresp="code_image-classification-neural-networks_0.txt" rend="block"/></ab><p><w>Outside</w><w>of</w><w>this</w><w>template</w><w>,</w><w>we</w><w>do</w><w>not</w><w>have</w><w>any</w><w>additional</w><w>code</w><w>in</w><w>our</w><code rend="inline"><w>index.html</w></code><w>file</w><pc>.</pc><w>Instead</w><w>,</w><w>we</w><w>have</w><w>a</w><w>link</w><w>to</w><code rend="inline"><w>sketch.js</w></code><pc>.</pc><w>Note</w><w>that</w><w>many</w><w>p5.js</w><w>and</w><w>ml5.js</w><w>conventions</w><w>draw</w><w>on</w><w>artistic</w><w>terminology</w><w>,</w><w>and</w><w>that</w><w>is</w><w>where</w><w>we</w><w>will</w><w>do</w><w>the</w><w>majority</w><w>of</w><w>our</w><w>coding</w><pc>.</pc><w>Switch</w><w>your</w><w>editor</w><w>to</w><code rend="inline"><w>sketch.js</w></code><pc>.</pc></p><p><w>We</w><w>will</w><w>make</w><w>sure</w><w>that</w><w>everything</w><w>is</w><w>working</w><w>properly</w><w>by</w><w>printing</w><w>the</w><w>current</w><w>version</w><w>of</w><w>ml5.js</w><w>to</w><w>the</w><w>console</w><pc>.</pc><w>In</w><code rend="inline"><w>sketch.js</w></code><w>,</w><w>copy</w><w>or</w><w>type</w><w>the</w><w>following</w><w>:</w></p><ab><code lang="language-javascript" xml:id="code_image-classification-neural-networks_1" corresp="code_image-classification-neural-networks_1.txt" rend="block"/></ab><p><w>You</w><w>should</w><w>have</w><w>already</w><w>started</w><w>a</w><w>live</w><w>server</w><w>during</w><ref target="#setup-and-dataset"><w>the</w><w>setup</w><w>stage</w></ref><pc>.</pc><w>If</w><w>not</w><w>,</w><w>you</w><w>should</w><w>launch</w><w>it</w><w>now</w><w>on</w><w>the</w><code rend="inline"><w>projects</w></code><w>folder</w><pc>.</pc><w>Load</w><w>up</w><code rend="inline"><w>index.html</w></code><w>in</w><w>your</w><w>web</w><w>browser</w><w>—remember</w><w>that</w><code rend="inline"><w>index.html</w></code><w>is</w><w>just</w><w>a</w><w>boiler</w><w>plate</w><w>template</w><w>linking</w><w>to</w><code rend="inline"><w>sketch.js</w></code><w>—</w><w>and</w><w>check</w><w>the</w><w>developer</w><w>console</w><w>for</w><w>the</w><w>output</w><pc>.</pc><w>As</w><w>long</w><w>as</w><w>the</w><w>output</w><w>for</w><w>the</w><w>current</w><w>version</w><w>displays</w><w>,</w><w>you</w><w>should</w><w>n't</w><w>encounter</w><w>any</w><w>problems</w><pc>.</pc></p><p style="alert alert-warning"><w>Please</w><w>note</w><w>that</w><w>the</w><w>output</w><w>for</w><w>ml5.js</w><w>consists</w><w>of</w><w>a</w><w>large</w><w>number</w><w>of</w><w>emojis</w><w>and</w><w>favicons</w><w>that</w><w>often</w><w>fail</w><w>to</w><w>load</w><pc>.</pc></p><p><w>Because</w><w>we</w><w>are</w><w>using</w><w>p5.js</w><w>,</w><w>it</w><w>is</w><w>worth</w><w>taking</w><w>a</w><w>few</w><w>minutes</w><w>to</w><w>examine</w><w>some</w><w>of</w><w>its</w><w>peculiarities</w><pc>.</pc><w>P5.js</w><w>is</w><w>an</w><w>interpretation</w><w>of</w><ref target="https://perma.cc/TH4U-WCL7"><w>Processing</w></ref><w>in</w><w>JavaScript</w><pc>.</pc><w>Both</w><w>p5.js</w><w>and</w><w>Processing</w><w>cater</w><w>to</w><w>digital</w><w>artists</w><w>,</w><w>especially</w><w>those</w><w>interested</w><w>in</w><w>creating</w><ref target="https://perma.cc/54HM-BRQG"><w>generative</w><w>art</w></ref><pc>.</pc><w>You</w><w>will</w><w>find</w><w>that</w><w>drawing</w><w>on</w><w>artistic</w><w>terminology</w><w>is</w><w>a</w><w>common</w><w>convention</w><w>amongst</w><w>p5.js</w><w>and</w><w>ml5.js</w><w>programmers</w><pc>.</pc><w>This</w><w>is</w><w>why</w><w>we</w><w>named</w><w>our</w><w>JavaScript</w><w>file</w><code rend="inline"><w>sketch.js</w></code><pc>.</pc></p><p><w>The</w><w>two</w><w>key</w><w>functions</w><w>in</w><w>p5.js</w><w>that</w><w>draw</w><w>on</w><w>this</w><w>tradition</w><w>are</w><w>the</w><code rend="inline"><w>setup</w><w>(</w><w>)</w></code><w>and</w><code rend="inline"><w>draw</w><w>(</w><w>)</w></code><w>functions</w><pc>.</pc><w>The</w><code rend="inline"><w>setup</w><w>(</w><w>)</w></code><w>function</w><w>is</w><w>automatically</w><w>executed</w><w>when</w><w>the</w><w>program</w><w>is</w><w>run</w><pc>.</pc><w>We</w><w>will</w><w>use</w><w>it</w><w>to</w><w>create</w><w>a</w><w>blank</w><w>square</w><w>canvas</w><w>that</w><w>is</w><w>500x500</w><w>pixels</w><w>using</w><w>the</w><code rend="inline"><w>createCanvas</w><w>(</w><w>)</w></code><w>function</w><pc>.</pc><w>We</w><w>will</w><w>also</w><w>move</w><w>our</w><w>code</w><w>that</w><w>outputs</w><w>the</w><w>current</w><w>version</w><w>of</w><w>ml5.js</w><w>to</w><w>the</w><w>console</w><pc>.</pc></p><ab><code lang="language-javascript" xml:id="code_image-classification-neural-networks_2" corresp="code_image-classification-neural-networks_2.txt" rend="block"/></ab><p><w>By</w><w>executing</w><w>the</w><w>command</w><w>above</w><w>you</w><w>will</w><w>have</w><w>created</w><w>the</w><w>canvas</w><w>but</w><w>,</w><w>because</w><w>it</w><w>is</w><w>set</w><w>to</w><w>white</w><w>,</w><w>you</w><w>may</w><w>not</w><w>be</w><w>able</w><w>to</w><w>differentiate</w><w>it</w><w>from</w><w>the</w><w>rest</w><w>of</w><w>the</w><w>page</w><pc>.</pc><w>To</w><w>make</w><w>it</w><w>easier</w><w>to</w><w>see</w><w>the</w><w>boundaries</w><w>of</w><w>our</w><w>canvas</w><w>,</w><w>we</w><w>will</w><w>use</w><w>the</w><code rend="inline"><w>background</w><w>(</w><w>)</w></code><w>function</w><w>and</w><w>pass</w><w>it</w><w>the</w><w>hex</w><w>value</w><w>for</w><w>black</w><pc>.</pc></p><ab><code lang="language-javascript" xml:id="code_image-classification-neural-networks_3" corresp="code_image-classification-neural-networks_3.txt" rend="block"/></ab><p><w>If</w><w>you</w><w>load</w><code rend="inline"><w>index.html</w></code><w>again</w><w>,</w><w>you</w><w>will</w><w>see</w><w>that</w><w>we</w><w>now</w><w>have</w><w>a</w><w>black</w><w>canvas</w><w>that</w><w>is</w><w>500x500</w><w>pixels</w><pc>.</pc></p><p><w>Next</w><w>,</w><w>we</w><w>will</w><w>load</w><w>the</w><w>actual</w><w>model</w><pc>.</pc><w>In</w><w>the</w><w>past</w><w>,</w><w>this</w><w>was</w><w>commonly</w><w>done</w><w>using</w><w>a</w><w>callback</w><w>function</w><w>to</w><w>deal</w><w>with</w><w>JavaScript</w><w>'s</w><w>asynchronous</w><w>nature</w><pc>.</pc><w>If</w><w>you</w><w>are</w><w>unfamiliar</w><w>with</w><w>JavaScript</w><w>,</w><w>this</w><w>may</w><w>be</w><w>a</w><w>source</w><w>of</w><w>confusion</w><pc>.</pc><w>Basically</w><w>,</w><w>JavaScript</w><w>reads</w><w>code</w><w>from</w><w>top</w><w>to</w><w>bottom</w><w>,</w><w>but</w><w>it</w><w>does</w><w>not</w><w>stop</w><w>to</w><w>complete</w><w>any</w><w>part</w><w>of</w><w>the</w><w>code</w><w>unless</w><w>it</w><w>must</w><pc>.</pc><w>This</w><w>can</w><w>lead</w><w>to</w><w>issues</w><w>when</w><w>performing</w><w>tasks</w><w>such</w><w>as</w><w>loading</w><w>a</w><w>model</w><w>,</w><w>because</w><w>JavaScript</w><w>may</w><w>start</w><w>calling</w><w>the</w><w>model</w><w>before</w><w>it</w><w>has</w><w>finished</w><w>loading</w><pc>.</pc><w>Callback</w><w>functions</w><w>provide</w><w>a</w><w>way</w><w>around</w><w>this</w><w>as</w><w>they</w><w>are</w><w>not</w><w>called</w><w>in</w><w>JavaScript</w><w>until</w><w>other</w><w>code</w><w>has</w><w>already</w><w>completed</w><pc>.</pc></p><p><w>To</w><w>deal</w><w>with</w><w>common</w><w>errors</w><w>in</w><w>loading</w><w>images</w><w>,</w><w>models</w><w>and</w><w>the</w><w>complexity</w><w>of</w><w>callbacks</w><w>,</w><w>p5.js</w><w>introduced</w><w>a</w><w>new</w><code rend="inline"><w>preload</w><w>(</w><w>)</w></code><w>function</w><pc>.</pc><w>This</w><w>is</w><w>a</w><w>powerful</w><w>feature</w><w>of</w><w>p5.js</w><w>that</w><w>allows</w><w>us</w><w>to</w><w>be</w><w>sure</w><w>that</w><w>images</w><w>and</w><w>models</w><w>are</w><w>loaded</w><w>before</w><w>the</w><code rend="inline"><w>setup</w><w>(</w><w>)</w></code><w>function</w><w>is</w><w>called</w><pc>.</pc></p><p><w>We</w><w>will</w><w>place</w><w>the</w><w>call</w><w>for</w><w>loading</w><w>our</w><w>model</w><w>in</w><w>the</w><code rend="inline"><w>preload</w><w>(</w><w>)</w></code><w>function</w><w>and</w><w>assign</w><w>it</w><w>to</w><w>a</w><w>global</w><w>variable</w><pc>.</pc><w>Although</w><w>the</w><code rend="inline"><w>preload</w><w>(</w><w>)</w></code><w>function</w><w>allows</w><w>us</w><w>to</w><w>avoid</w><w>callbacks</w><w>in</w><w>certain</w><w>situations</w><w>,</w><w>we</w><w>probably</w><w>still</w><w>want</w><w>some</w><w>feedback</w><w>for</w><w>when</w><w>the</w><w>model</w><w>is</w><w>successfully</w><w>loaded</w><pc>.</pc><w>For</w><w>this</w><w>,</w><w>we</w><w>will</w><w>create</w><w>a</w><w>new</w><w>function</w><w>called</w><code rend="inline"><w>teachableMachineModelLoaded</w><w>(</w><w>)</w></code><w>that</w><w>will</w><w>output</w><w>a</w><w>message</w><w>to</w><w>the</w><w>console</w><pc>.</pc><w>You</w><w>only</w><w>have</w><w>to</w><w>call</w><w>the</w><code rend="inline"><w>model.json</w></code><w>file</w><w>for</w><w>this</w><w>to</w><w>work</w><pc>.</pc><w>Ml5.js</w><w>will</w><w>automatically</w><w>look</w><w>in</w><w>the</w><w>same</w><w>folder</w><w>for</w><w>the</w><w>file</w><w>containing</w><w>the</w><w>weights</w><w>and</w><w>metadata</w><pc>.</pc></p><ab><code lang="language-javascript" xml:id="code_image-classification-neural-networks_4" corresp="code_image-classification-neural-networks_4.txt" rend="block"/></ab><p><w>Now</w><w>that</w><w>we</w><w>have</w><w>loaded</w><w>the</w><w>model</w><w>,</w><w>we</w><w>need</w><w>to</w><w>add</w><w>our</w><w>testing</w><w>image</w><pc>.</pc><w>The</w><w>first</w><w>thing</w><w>that</w><w>we</w><w>will</w><w>do</w><w>is</w><w>load</w><w>our</w><w>image</w><w>using</w><w>the</w><w>p5.js</w><code rend="inline"><w>loadImage</w><w>(</w><w>)</w></code><w>function</w><pc>.</pc><w>The</w><code rend="inline"><w>loadImage</w><w>(</w><w>)</w></code><w>function</w><w>takes</w><w>a</w><w>path</w><w>to</w><w>the</w><w>image</w><w>as</w><w>a</w><w>parameter</w><w>and</w><w>returns</w><w>a</w><code rend="inline"><w>p5.Image</w></code><w>object</w><w>,</w><w>which</w><w>provides</w><w>some</w><w>additional</w><w>functions</w><w>to</w><w>manipulate</w><w>images</w><w>compared</w><w>with</w><w>plain</w><w>JavaScript</w><pc>.</pc><w>We</w><w>can</w><w>place</w><w>this</w><w>call</w><w>in</w><w>the</w><code rend="inline"><w>preload</w><w>(</w><w>)</w></code><w>function</w><pc>.</pc><w>You</w><w>can</w><w>choose</w><w>any</w><w>of</w><w>the</w><w>test</w><w>images</w><w>or</w><w>your</w><w>own</w><w>image</w><w>to</w><w>experiment</w><w>with</w><pc>.</pc><w>Just</w><w>place</w><w>them</w><w>in</w><w>the</w><w>same</w><w>folder</w><w>as</w><w>the</w><w>code</w><pc>.</pc><w>For</w><w>the</w><w>purposes</w><w>of</w><w>this</w><w>tutorial</w><w>,</w><w>we</w><w>are</w><w>just</w><w>going</w><w>to</w><w>load</w><code rend="inline"><w>testing0.jpg</w></code><w>,</w><w>which</w><w>is</w><w>an</w><w>image</w><w>of</w><w>an</w><w>aircraft</w><pc>.</pc></p><ab><code lang="language-javascript" xml:id="code_image-classification-neural-networks_5" corresp="code_image-classification-neural-networks_5.txt" rend="block"/></ab><p><w>We</w><w>can</w><w>now</w><w>use</w><w>the</w><w>p5.js</w><code rend="inline"><w>image</w><w>(</w><w>)</w></code><w>function</w><w>to</w><w>draw</w><w>the</w><w>image</w><w>to</w><w>the</w><w>screen</w><pc>.</pc><w>It</w><w>takes</w><w>three</w><w>arguments</w><pc>.</pc><w>The</w><w>first</w><w>is</w><w>the</w><w>name</w><w>of</w><w>the</w><w>variable</w><w>containing</w><w>the</w><w>image</w><pc>.</pc><w>In</w><w>this</w><w>case</w><w>,</w><w>it</w><w>is</w><w>the</w><code rend="inline"><w>testImage</w></code><w>variable</w><pc>.</pc><w>The</w><w>next</w><w>two</w><w>are</w><w>x</w><w>and</w><w>y</w><w>coordinates</w><w>for</w><w>where</w><w>to</w><w>place</w><w>the</w><w>image</w><pc>.</pc><w>We</w><w>are</w><w>going</w><w>to</w><w>put</w><w>it</w><w>in</w><w>the</w><w>center</w><w>of</w><w>our</w><w>canvas</w><pc>.</pc><w>An</w><w>easy</w><w>way</w><w>to</w><w>do</w><w>this</w><w>is</w><w>through</w><w>the</w><w>``</w><w>height</w><w>''</w><w>and</w><w>``</w><w>width</w><w>''</w><w>variables</w><w>that</w><w>contain</w><w>the</w><w>canvas</w><w>dimensions</w><pc>.</pc><w>P5.js</w><w>makes</w><w>these</w><w>available</w><w>to</w><w>us</w><w>automatically</w><w>,</w><w>and</w><w>we</w><w>can</w><w>divide</w><w>by</w><w>two</w><w>to</w><w>center</w><w>the</w><w>image</w><pc>.</pc></p><p><w>We</w><w>will</w><w>issue</w><w>this</w><w>call</w><w>inside</w><w>of</w><w>the</w><code rend="inline"><w>draw</w><w>(</w><w>)</w></code><w>function</w><w>,</w><w>which</w><w>is</w><w>called</w><w>immediately</w><w>after</w><code rend="inline"><w>setup</w><w>(</w><w>)</w></code><w>and</w><w>is</w><w>where</w><w>we</w><w>will</w><w>place</w><w>the</w><w>majority</w><w>of</w><w>our</w><w>code</w><pc>.</pc></p><ab><code lang="language-javascript" xml:id="code_image-classification-neural-networks_6" corresp="code_image-classification-neural-networks_6.txt" rend="block"/></ab><p><w>If</w><w>you</w><w>look</w><w>at</w><w>the</w><w>image</w><w>,</w><w>you</w><w>will</w><w>find</w><w>that</w><w>it</w><w>is</w><w>not</w><w>perfectly</w><w>centered</w><w>on</w><w>the</w><w>canvas</w><pc>.</pc><w>This</w><w>is</w><w>one</w><w>of</w><w>the</w><w>peculiarities</w><w>of</w><w>working</w><w>with</w><w>p5.js</w><pc>.</pc><w>It</w><w>places</w><w>the</w><w>image</w><w>on</w><w>the</w><w>canvas</w><w>using</w><w>the</w><w>top</w><w>left</w><w>corner</w><w>as</w><w>the</w><w>anchor</w><w>point</w><pc>.</pc><w>We</w><w>can</w><w>call</w><w>the</w><code rend="inline"><w>imageMode</w><w>(</w><w>)</w></code><w>function</w><w>and</w><w>pass</w><w>it</w><w>the</w><w>``</w><w>CENTER</w><w>''</w><w>argument</w><w>to</w><w>change</w><w>how</w><w>p5.js</w><w>determines</w><w>where</w><w>to</w><w>place</w><w>images</w><pc>.</pc><w>This</w><w>setting</w><w>will</w><w>stay</w><w>in</w><w>place</w><w>until</w><w>you</w><w>decide</w><w>to</w><w>change</w><w>it</w><pc>.</pc></p><p><w>If</w><w>you</w><w>run</w><w>the</w><w>following</w><w>,</w><w>you</w><w>will</w><w>now</w><w>see</w><w>that</w><w>we</w><w>have</w><w>our</w><w>image</w><w>in</w><w>the</w><w>center</w><w>of</w><w>the</w><w>canvas</w><pc>.</pc></p><ab><code lang="language-javascript" xml:id="code_image-classification-neural-networks_7" corresp="code_image-classification-neural-networks_7.txt" rend="block"/></ab><p><w>The</w><code rend="inline"><w>draw</w><w>(</w><w>)</w></code><w>function</w><w>is</w><w>unique</w><w>to</w><w>p5.js</w><w>and</w><w>loops</w><w>based</w><w>on</w><w>the</w><w>frame</w><w>rate</w><pc>.</pc><w>This</w><w>is</w><w>again</w><w>due</w><w>to</w><w>p5.js</w><w>being</w><w>originally</w><w>geared</w><w>towards</w><w>artists</w><pc>.</pc><w>Constantly</w><w>looping</w><w>the</w><w>material</w><w>inside</w><w>of</w><code rend="inline"><w>draw</w><w>(</w><w>)</w></code><w>makes</w><w>it</w><w>easier</w><w>to</w><w>make</w><w>animations</w><pc>.</pc><w>When</w><w>you</w><w>post</w><w>the</w><w>image</w><w>onto</w><w>the</w><w>canvas</w><w>,</w><w>p5.js</w><w>is</w><w>actually</w><w>continuously</w><w>running</w><w>the</w><w>code</w><w>and</w><w>placing</w><w>a</w><w>new</w><w>image</w><w>on</w><w>top</w><w>of</w><w>the</w><w>old</w><w>one</w><pc>.</pc><w>To</w><w>stop</w><w>this</w><w>,</w><w>we</w><w>can</w><w>call</w><w>the</w><code rend="inline"><w>noLoop</w><w>(</w><w>)</w></code><w>function</w><pc>.</pc></p><ab><code lang="language-javascript" xml:id="code_image-classification-neural-networks_8" corresp="code_image-classification-neural-networks_8.txt" rend="block"/></ab><p><w>We</w><w>are</w><w>now</w><w>ready</w><w>to</w><w>evaluate</w><w>our</w><w>model</w><pc>.</pc><w>We</w><w>will</w><w>call</w><w>the</w><code rend="inline"><w>classify</w><w>(</w><w>)</w></code><w>function</w><w>from</w><w>our</w><w>classifier</w><w>object</w><pc>.</pc><w>It</w><w>requires</w><w>a</w><w>single</w><w>argument</w><w>containing</w><w>the</w><w>object</w><w>that</w><w>we</w><w>are</w><w>interested</w><w>in</w><w>classifying</w><w>along</w><w>with</w><w>a</w><w>callback</w><pc>.</pc><w>We</w><w>will</w><w>use</w><code rend="inline"><w>getResults</w><w>(</w><w>)</w></code><w>as</w><w>our</w><w>callback</w><w>function</w><pc>.</pc><w>ml5.js</w><w>will</w><w>automatically</w><w>send</w><w>two</w><w>arguments</w><w>to</w><w>the</w><w>function</w><w>containing</w><w>information</w><w>about</w><w>errors</w><w>and/or</w><w>results</w><pc>.</pc><w>We</w><w>will</w><w>output</w><w>these</w><w>results</w><w>to</w><w>the</w><w>console</w><w>:</w></p><ab><code lang="language-javascript" xml:id="code_image-classification-neural-networks_9" corresp="code_image-classification-neural-networks_9.txt" rend="block"/></ab><p><w>If</w><w>everything</w><w>went</w><w>well</w><w>,</w><w>you</w><w>should</w><w>see</w><w>the</w><w>results</w><w>of</w><w>the</w><w>classification</w><w>on</w><w>the</w><w>console</w><w>as</w><w>a</w><w>JavaScript</w><w>object</w><pc>.</pc><w>Let</w><w>'s</w><w>take</w><w>a</w><w>closer</w><w>look</w><w>at</w><w>the</w><w>output</w><pc>.</pc><w>Note</w><w>that</w><w>the</w><w>exact</w><w>numbers</w><w>you</w><w>get</w><w>may</w><w>vary</w><pc>.</pc><w>This</w><w>is</w><w>the</w><w>output</w><w>from</w><w>the</w><w>first</w><w>image</w><w>:</w></p><ab><code xml:id="code_image-classification-neural-networks_10" corresp="code_image-classification-neural-networks_10.txt" rend="block"/></ab><p><w>If</w><w>you</w><w>look</w><w>inside</w><w>the</w><w>JavaScript</w><w>object</w><w>(</w><w>in</w><w>most</w><w>browsers</w><w>,</w><w>this</w><w>is</w><w>done</w><w>by</w><w>clicking</w><w>on</w><w>the</w><w>arrow</w><w>symbol</w><w>next</w><w>to</w><w>the</w><w>object</w><w>name</w><w>)</w><w>,</w><w>you</w><w>will</w><w>see</w><w>the</w><w>output</w><w>for</w><w>the</w><code rend="inline"><w>testing0.jpg</w></code><w>image</w><w>list</w><w>all</w><w>the</w><w>possible</w><w>classes</w><w>by</w><w>probability</w><w>and</w><w>confidence</w><pc>.</pc><w>We</w><w>see</w><w>that</w><code rend="inline"><w>results</w><w>[</w><w>0</w><w>]</w></code><w>contains</w><w>the</w><w>most</w><w>likely</w><w>result</w><w>with</w><w>the</w><w>label</w><w>listed</w><w>in</w><code rend="inline"><w>results</w><w>[</w><w>0</w><w>]</w><w>.label</w></code><pc>.</pc><w>There</w><w>is</w><w>also</w><w>a</w><w>confidence</w><w>score</w><w>in</w><code rend="inline"><w>results</w><w>[</w><w>0</w><w>]</w></code><pc>.</pc><w>Confidence</w><w>provides</w><w>a</w><w>percentage</w><w>value</w><w>which</w><w>indicates</w><w>how</w><w>certain</w><w>our</w><w>model</w><w>is</w><w>of</w><w>the</w><w>first</w><w>label</w><pc>.</pc></p><p><w>We</w><w>can</w><w>output</w><w>these</w><w>values</w><w>to</w><w>our</w><w>canvas</w><w>using</w><w>the</w><code rend="inline"><w>text</w><w>(</w><w>)</w></code><w>function</w><w>in</w><w>our</w><code rend="inline"><w>getResults</w><w>(</w><w>)</w></code><w>call</w><w>,</w><w>which</w><w>takes</w><w>as</w><w>arguments</w><w>our</w><w>text</w><w>and</w><w>the</w><w>x</w><w>,</w><w>y</w><w>coordinates</w><w>for</w><w>where</w><w>we</w><w>want</w><w>to</w><w>place</w><w>it</w><pc>.</pc><w>I</w><w>will</w><w>place</w><w>the</w><w>text</w><w>just</w><w>below</w><w>the</w><w>image</w><w>itself</w><pc>.</pc><w>We</w><w>will</w><w>also</w><w>need</w><w>to</w><w>call</w><w>some</w><w>functions</w><w>that</w><w>detail</w><w>how</w><w>we</w><w>want</w><w>our</w><w>text</w><w>to</w><w>be</w><w>displayed</w><pc>.</pc><w>Specifically</w><w>,</w><w>we</w><w>will</w><w>use</w><code rend="inline"><w>fill</w><w>(</w><w>)</w></code><w>with</w><w>a</w><w>hex</w><w>value</w><w>for</w><w>the</w><w>color</w><w>text</w><w>,</w><code rend="inline"><w>textSize</w><w>(</w><w>)</w></code><w>for</w><w>the</w><w>size</w><w>,</w><w>and</w><code rend="inline"><w>textAlign</w><w>(</w><w>)</w></code><w>to</w><w>use</w><w>the</w><w>center</w><w>of</w><w>our</w><w>font</w><w>as</w><w>an</w><w>anchor</w><w>point</w><pc>.</pc><w>Finally</w><w>,</w><w>we</w><w>will</w><w>round</w><w>the</w><w>confidence</w><w>to</w><w>two</w><w>decimal</w><w>points</w><w>using</w><w>the</w><code rend="inline"><w>toFixed</w><w>(</w><w>)</w></code><w>function</w><pc>.</pc></p><ab><code lang="language-javascript" xml:id="code_image-classification-neural-networks_11" corresp="code_image-classification-neural-networks_11.txt" rend="block"/></ab><p><w>Run</w><w>the</w><w>code</w><w>above</w><w>to</w><w>see</w><w>a</w><w>result</w><w>of</w><w>what</w><w>the</w><w>image</w><w>represents</w><w>along</w><w>with</w><w>a</w><w>confidence</w><w>score</w><pc>.</pc><w>If</w><w>the</w><w>code</w><w>ran</w><w>successfully</w><w>,</w><w>you</w><w>should</w><w>see</w><w>the</w><w>following</w><w>result</w><w>(</w><w>although</w><w>please</w><w>note</w><w>that</w><w>your</w><w>confidence</w><w>score</w><w>is</w><w>likely</w><w>to</w><w>differ</w><w>)</w><w>:</w></p><figure><desc><w>Figure</w><w>9</w><pc>.</pc><w>Example</w><w>result</w><pc>.</pc></desc><figDesc><w>A</w><w>picture</w><w>of</w><w>a</w><w>series</w><w>of</w><w>planes</w><w>engaging</w><w>in</w><w>battle</w><w>is</w><w>shown</w><pc>.</pc><w>Underneath</w><w>the</w><w>confidence</w><w>of</w><w>the</w><w>image</w><w>is</w><w>displayed</w><w>as</w><w>65.37</w><w>%</w><w>and</w><w>the</w><w>words</w><w>'Most</w><w>Likely</w><w>Aircraft</w><w>'</w></figDesc><graphic url="final_output.png"/></figure></div></div><div type="2" n="5"><head><w>Conclusion</w></head><p><w>This</w><w>lesson</w><w>has</w><w>provided</w><w>you</w><w>with</w><w>an</w><w>introduction</w><w>to</w><w>how</w><w>neural</w><w>networks</w><w>function</w><w>,</w><w>and</w><w>explained</w><w>how</w><w>you</w><w>can</w><w>use</w><w>them</w><w>to</w><w>perform</w><w>image</w><w>classification</w><pc>.</pc><w>I</w><w>have</w><w>purposefully</w><w>kept</w><w>the</w><w>code</w><w>and</w><w>examples</w><w>simple</w><w>,</w><w>but</w><w>I</w><w>encourage</w><w>you</w><w>to</w><w>expand</w><w>upon</w><w>the</w><w>code</w><w>that</w><w>you</w><w>have</w><w>used</w><w>here</w><pc>.</pc><w>For</w><w>instance</w><w>,</w><w>you</w><w>could</w><w>add</w><w>loops</w><w>that</w><w>instruct</w><w>a</w><w>model</w><w>to</w><w>go</w><w>through</w><w>a</w><w>folder</w><w>of</w><w>images</w><w>and</w><w>output</w><w>the</w><w>results</w><w>into</w><w>a</w><w>CSV</w><w>file</w><w>which</w><w>contains</w><w>topics</w><w>,</w><w>or</w><w>charts</w><w>the</w><w>themes</w><w>of</w><w>larger</w><w>corpora</w><pc>.</pc><w>You</w><w>could</w><w>also</w><w>investigate</w><w>the</w><w>limitations</w><w>of</w><w>the</w><w>neural</w><w>network</w><w>to</w><w>identify</w><w>areas</w><w>where</w><w>it</w><w>does</w><w>not</w><w>work</w><pc>.</pc><w>For</w><w>example</w><w>,</w><w>what</w><w>happens</w><w>when</w><w>you</w><w>upload</w><w>an</w><w>abstract</w><w>painting</w><w>or</w><w>something</w><w>that</w><w>is</w><w>n't</w><w>a</w><w>painting</w><w>at</w><w>all</w><pc>?</pc><w>Exploring</w><w>these</w><w>weak</w><w>points</w><w>can</w><w>lead</w><w>to</w><w>inspiration</w><w>not</w><w>only</w><w>for</w><w>academic</w><w>but</w><w>also</w><w>creative</w><w>work</w><pc>.</pc></p><p><w>One</w><w>thing</w><w>to</w><w>keep</w><w>in</w><w>mind</w><w>is</w><w>that</w><w>our</w><w>model</w><w>is</w><w>biased</w><w>towards</w><w>our</w><w>training</w><w>data</w><pc>.</pc><w>In</w><w>other</w><w>words</w><w>,</w><w>while</w><w>it</w><w>may</w><w>be</w><w>helpful</w><w>for</w><w>categorizing</w><w>the</w><w>ArtUK</w><w>images</w><w>,</w><w>it</w><w>may</w><w>not</w><w>function</w><w>as</w><w>well</w><w>when</w><w>it</w><w>comes</w><w>to</w><w>new</w><w>data</w><pc>.</pc></p></div><div type="2" n="6"><head><w>References</w></head><p><w>While</w><w>Teachable</w><w>Machine</w><w>and</w><w>ml5.js</w><w>provide</w><w>a</w><w>good</w><w>starting</w><w>point</w><w>,</w><w>this</w><w>simplicity</w><w>comes</w><w>with</w><w>a</w><w>loss</w><w>of</w><w>flexibility</w><pc>.</pc><w>As</w><w>mentioned</w><w>earlier</w><w>,</w><w>you</w><w>will</w><w>likely</w><w>want</w><w>to</w><w>switch</w><w>to</w><w>Python</w><w>or</w><w>R</w><w>to</w><w>do</w><w>production-level</w><w>machine</w><w>learning</w><pc>.</pc><w>I</w><w>recommend</w><w>the</w><emph><w>Programming</w><w>Historian</w></emph><w>'s</w><w>tutorials</w><w>on</w><ref target="/en/lessons/computer-vision-deep-learning-pt1"><w>Computer</w><w>Vision</w><w>for</w><w>the</w><w>Humanities</w></ref><w>and</w><ref target="/en/lessons/interrogating-national-narrative-gpt"><w>Interrogating</w><w>a</w><w>National</w><w>Narrative</w><w>with</w><w>Recurrent</w><w>Neural</w><w>Networks</w></ref><pc>.</pc><w>Both</w><w>include</w><w>links</w><w>to</w><w>further</w><w>resources</w><w>which</w><w>will</w><w>help</w><w>you</w><w>to</w><w>expand</w><w>your</w><w>knowledge</w><pc>.</pc></p><p><w>If</w><w>you</w><w>are</w><w>interested</w><w>in</w><w>developing</w><w>broader</w><w>knowledge</w><w>of</w><w>ml5.js</w><w>,</w><w>or</w><w>learning</w><w>more</w><w>about</w><w>the</w><w>concepts</w><w>that</w><w>underpin</w><w>neural</w><w>networks</w><w>,</w><w>I</w><w>also</w><w>recommend</w><w>the</w><w>following</w><w>:</w></p><list type="unordered"><item><p><w>3Blue1Brown</w><w>has</w><w>some</w><w>wonderful</w><w>videos</w><w>that</w><w>delve</w><w>into</w><w>the</w><w>math</w><w>of</w><w>neural</w><w>networks</w><pc>.</pc><w>3Blue1Brown</w><w>,</w><emph><w>Neural</w><w>Networks</w></emph><w>,</w><ref target="https://perma.cc/W9RL-4QQG"><w>https</w><w>:</w><w>//www.3blue1brown.com/topics/neural-networks</w></ref><pc>.</pc></p></item><item><p><w>Dan</w><w>Shiffman</w><w>provides</w><w>a</w><w>good</w><w>overview</w><w>of</w><w>using</w><w>ml5.js</w><w>and</w><w>p5.js</w><w>for</w><w>machine</w><w>learning</w><w>on</w><w>his</w><w>YouTube</w><w>channel</w><pc>.</pc><w>The</w><w>Coding</w><w>Train</w><w>,</w><emph><w>Beginner</w><w>'s</w><w>Guide</w><w>to</w><w>Machine</w><w>Learning</w><w>in</w><w>JavaScript</w><w>with</w><w>ml5.js</w></emph><w>,</w><w>YouTube</w><w>video</w><w>,</w><w>1:30</w><w>,</w><w>March</w><w>4</w><w>2022</w><w>,</w><ref target="https://youtu.be/26uABexmOX4"><w>https</w><w>:</w><w>//youtu.be/26uABexmOX4</w></ref><pc>.</pc></p></item><item><p><w>He</w><w>also</w><w>has</w><w>a</w><w>series</w><w>of</w><w>videos</w><w>on</w><w>building</w><w>a</w><w>neural</w><w>network</w><w>from</w><w>scratch</w><w>that</w><w>covers</w><w>the</w><w>mathematical</w><w>foundations</w><w>for</w><w>machine</w><w>learning</w><pc>.</pc><w>The</w><w>Coding</w><w>Train</w><w>,</w><emph><w>10.1</w><w>:</w><w>Introduction</w><w>to</w><w>Neural</w><w>Networks</w><w>-</w><w>The</w><w>Nature</w><w>of</w><w>Code</w></emph><w>,</w><w>YouTube</w><w>video</w><w>,</w><w>7:31</w><w>,</w><w>26</w><w>June</w><w>,</w><w>2017</w><w>,</w><ref target="https://youtu.be/XJ7HLz9VYz0"><w>https</w><w>:</w><w>//youtu.be/XJ7HLz9VYz0</w></ref><pc>.</pc></p></item><item><p><w>The</w><w>official</w><w>ml5.js</w><w>reference</w><w>provides</w><w>a</w><w>comprehensive</w><w>overview</w><w>of</w><w>how</w><w>to</w><w>perform</w><w>image</w><w>classification</w><w>alongside</w><w>other</w><w>machine</w><w>learning</w><w>tasks</w><pc>.</pc><w>Ml5.js</w><w>,</w><emph><w>Reference</w></emph><w>,</w><ref target="https://perma.cc/2MNK-J3J3"><w>https</w><w>:</w><w>//learn.ml5js.org/</w><w>#</w><w>/reference/index</w></ref><pc>.</pc></p></item><item><p><w>Tariq</w><w>Rashid</w><w>'s</w><w>book</w><emph><w>Make</w><w>Your</w><w>Own</w><w>Neural</w><w>Network</w></emph><w>provides</w><w>an</w><w>excellent</w><w>and</w><w>clear</w><w>introduction</w><w>for</w><w>those</w><w>interested</w><w>in</w><w>developing</w><w>knowledge</w><w>of</w><w>machine</w><w>learning</w><pc>.</pc><w>Tariq</w><w>Rashid</w><pc>.</pc><emph><w>Make</w><w>Your</w><w>Own</w><w>Neural</w><w>Network</w></emph><pc>.</pc><w>CreateSpace</w><w>Independent</w><w>Publishing</w><w>Platform</w><w>,</w><w>2016</w><pc>.</pc></p></item><item><p><w>Tijmen</w><w>Schep</w><w>'s</w><w>interactive</w><w>documentary</w><w>is</w><w>an</w><w>excellent</w><w>introduction</w><w>to</w><w>the</w><w>dangers</w><w>of</w><w>machine</w><w>learning</w><w>and</w><w>AI</w><pc>.</pc><w>Tijmen</w><w>Schep‌</w><w>,</w><emph><w>How</w><w>Normal</w><w>Am</w><w>I</w><pc>?</pc></emph><w>,</w><ref target="https://www.hownormalami.eu/"><w>https</w><w>:</w><w>//www.hownormalami.eu/</w></ref><pc>.</pc></p></item><item><p><w>Jeremy</w><w>Howard</w><w>and</w><w>Sylvain</w><w>Gugger</w><w>'s</w><w>book</w><emph><w>Deep</w><w>Learning</w><w>for</w><w>Coders</w><w>with</w><w>fastai</w><w>and</w><w>PyTorch</w><w>:</w><w>AI</w><w>Applications</w><w>Without</w><w>a</w><w>PhD</w></emph><w>provides</w><w>a</w><w>great</w><w>introduction</w><w>machine</w><w>learning</w><pc>.</pc><w>Although</w><w>it</w><w>utilizes</w><w>Python</w><w>,</w><w>the</w><w>examples</w><w>are</w><w>straight-forward</w><w>enough</w><w>for</w><w>most</w><w>beginners</w><w>to</w><w>follow</w><w>,</w><w>and</w><w>are</w><w>relatively</w><w>simple</w><w>to</w><w>recreate</w><w>in</w><w>other</w><w>languages</w><pc>.</pc><w>Jeremy</w><w>Howard</w><w>and</w><w>Sylvain</w><w>Gugger</w><pc>.</pc><emph><w>Deep</w><w>Learning</w><w>for</w><w>Coders</w><w>with</w><w>fastai</w><w>and</w><w>PyTorch</w><w>:</w><w>AI</w><w>Applications</w><w>Without</w><w>a</w><w>PhD</w></emph><pc>.</pc><w>O</w><w>’</w><w>Reilly</w><w>Media</w><w>,</w><w>Inc.</w><w>,</w><w>2020</w><pc>.</pc></p></item><item><p><w>They</w><w>also</w><w>have</w><w>a</w><w>free</w><w>companion</w><w>video</w><w>series</w><w>that</w><w>covers</w><w>much</w><w>of</w><w>the</w><w>material</w><w>in</w><w>the</w><w>book</w><pc>.</pc><w>freeCodeCamp.org</w><w>,</w><emph><w>Practical</w><w>Deep</w><w>Learning</w><w>for</w><w>Coders</w><w>-</w><w>Full</w><w>Course</w><w>from</w><w>fast.ai</w><w>and</w><w>Jeremy</w><w>Howard</w></emph><w>,</w><w>YouTube</w><w>video</w><w>series</w><w>,</w><w>2020</w><w>,</w><ref target="https://youtu.be/0oyCUWLL_fU"><w>https</w><w>:</w><w>//youtu.be/0oyCUWLL_fU</w></ref><pc>.</pc></p></item><item><p><w>Grokking</w><w>Deep</w><w>Learning</w><w>by</w><w>Andrew</w><w>Task</w><w>is</w><w>a</w><w>wonderful</w><w>book</w><w>that</w><w>provides</w><w>a</w><w>gentle</w><w>introduction</w><w>to</w><w>some</w><w>of</w><w>the</w><w>more</w><w>advanced</w><w>mathematical</w><w>concepts</w><w>in</w><w>machine</w><w>learning</w><pc>.</pc><w>Andrew</w><w>Task</w><pc>.</pc><emph><w>Grokking</w><w>Deep</w><w>Learning</w></emph><pc>.</pc><w>Manning</w><w>Publications</w><w>,</w><w>2019</w><pc>.</pc></p></item><item><p><w>David</w><w>Dao</w><w>curates</w><w>a</w><w>list</w><w>of</w><w>current</w><w>of</w><w>some</w><w>of</w><w>the</w><w>dangerous</w><w>ways</w><w>that</w><w>AI</w><w>has</w><w>been</w><w>utilized</w><w>and</w><w>perpetuates</w><w>inequality</w><pc>.</pc><w>David</w><w>Dao</w><w>,</w><emph><w>Awful</w><w>AI</w></emph><w>,</w><ref target="https://perma.cc/P2GW-FPE7"><w>https</w><w>:</w><w>//github.com/daviddao/awful-ai</w></ref><pc>.</pc></p></item></list></div><div type="2" n="7"><head><w>Endnotes</w></head><p><ref type="footnotemark" target="#en_note_1"/><w>:</w><w>The</w><w>Processing</w><w>Foundation</w><w>,</w><w>``</w><w>Our</w><w>Mission</w><w>''</w><w>,</w><w>Accessed</w><w>December</w><w>23</w><w>,</w><w>2022</w><pc>.</pc><ref target="https://perma.cc/JRR5-CGGD"><w>https</w><w>:</w><w>//processingfoundation.org/</w></ref><pc>.</pc><ref type="footnotemark" target="#en_note_2"/><w>:</w><w>Jon</w><w>Duckett</w><w>,</w><emph><w>JavaScript</w><w>and</w><w>jQuery</w><w>:</w><w>Interactive</w><w>Front</w><w>End</w><w>Development</w></emph><w>,</w><w>(</w><w>Wiley</w><w>,</w><w>2014</w><w>)</w><pc>.</pc><ref type="footnotemark" target="#en_note_3"/><w>:</w><w>Karthikeyan</w><w>NG</w><w>,</w><w>Arun</w><w>Padmanabhan</w><w>,</w><w>Matt</w><w>R.</w><w>Cole</w><w>,</w><emph><w>Mobile</w><w>Artificial</w><w>Intelligence</w><w>Projects</w></emph><w>,</w><w>(</w><w>Packt</w><w>Publishing</w><pc>.</pc><w>2019</w><w>)</w><pc>.</pc><ref type="footnotemark" target="#en_note_4"/><w>:</w><w>McCulloch</w><w>,</w><w>W.S.</w><w>,</w><w>Pitts</w><w>,</w><w>W</w><pc>.</pc><emph><w>A</w><w>logical</w><w>calculus</w><w>of</w><w>the</w><w>ideas</w><w>immanent</w><w>in</w><w>nervous</w><w>activity</w></emph><pc>.</pc><w>Bulletin</w><w>of</w><w>Mathematical</w><w>Biophysics</w><w>5</w><w>,</w><w>115–133</w><w>(</w><w>1943</w><w>)</w><pc>.</pc><ref target="https://doi.org/10.1007/BF02478259"><w>https</w><w>:</w><w>//doi.org/10.1007/BF02478259</w></ref><ref type="footnotemark" target="#en_note_5"/><w>:</w><w>Andrew</w><w>Glassner</w><w>,</w><emph><w>Deep</w><w>Learning</w><w>a</w><w>Visual</w><w>Approach</w></emph><w>,</w><w>(</w><w>No</w><w>Starch</w><w>Press</w><w>,</w><w>2021</w><w>)</w><w>,</w><w>315</w><pc>.</pc><ref type="footnotemark" target="#en_note_6"/><w>:</w><w>Erik</w><w>Reppel</w><w>,</w><w>``</w><w>Visualizing</w><w>parts</w><w>of</w><w>Convolutional</w><w>Neural</w><w>Networks</w><w>using</w><w>Keras</w><w>and</w><w>Cats</w><w>''</w><w>,</w><emph><w>Hackernoon</w></emph><w>,</w><w>Accessed</w><w>December</w><w>23</w><w>,</w><w>2022</w><w>,</w><ref target="https://perma.cc/2LSA-DCLR"><w>https</w><w>:</w><w>//hackernoon.com/visualizing-parts-of-convolutional-neural-networks-using-keras-and-cats-5cc01b214e59</w></ref><pc>.</pc></p></div></body>
    </text>
</TEI>
