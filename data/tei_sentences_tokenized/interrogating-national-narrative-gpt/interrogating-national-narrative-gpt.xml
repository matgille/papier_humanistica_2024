<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xi="http://www.w3.org/2001/XInclude" xml:id="interrogating-national-narrative-gpt" type="original" xml:base="interrogating-national-narrative-gpt/interrogating-national-narrative-gpt/interrogating-national-narrative-gpt.xml">
    <teiHeader>
        <fileDesc>
            <titleStmt>
                <title>Interrogating a National Narrative with GPT-2</title>
                <author role="original_author">Chantal Brousseau</author>
                <editor role="reviewers">
                    <persName>Katie McDonough</persName>
                    <persName>Lorella Viola</persName>
                </editor>
                <editor role="editors">
                    <persName>John R. Ladd</persName>
                    <persName>Tiago Sousa Garcia</persName>
                </editor>
            </titleStmt>
            <publicationStmt>
                <distributor>Programming Historian</distributor>
                <idno type="doi">10.46430/phen0104</idno>
                <date type="published">10/03/2022</date>
            </publicationStmt>
            <sourceDesc>
                <p>Born digital, in a markdown format. This lesson is original.</p>
            </sourceDesc>
        </fileDesc>
        <profileDesc>
            <abstract>
                <p>In this lesson, you will learn how to apply a Generative Pre-trained Transformer language model to a large-scale corpus so that you can locate broad themes and trends within written text.</p>
            </abstract>
            <textClass>
                <keywords>
                    <term xml:lang="en">python</term>
                    <term xml:lang="en">data-manipulation</term>
                </keywords>
            </textClass>
        </profileDesc>
    </teiHeader>
    <text xml:lang="en">
        <body><div type="2" n="1"><head><w>Overview</w></head><p><w>This</w><w>lesson</w><w>is</w><w>intended</w><w>to</w><w>teach</w><w>you</w><w>how</w><w>to</w><w>apply</w><w>Generative</w><w>Pre-trained</w><w>Transformer</w><w>2</w><w>(</w><w>GPT-2</w><w>)</w><w>,</w><w>one</w><w>of</w><w>the</w><w>largest</w><w>existing</w><w>open-source</w><w>language</w><w>models</w><w>,</w><w>to</w><w>a</w><w>large-scale</w><w>text</w><w>corpus</w><w>in</w><w>order</w><w>to</w><w>produce</w><w>automatically-written</w><w>responses</w><w>to</w><w>prompts</w><w>based</w><w>on</w><w>the</w><w>contents</w><w>of</w><w>the</w><w>corpora</w><w>,</w><w>aiding</w><w>in</w><w>the</w><w>task</w><w>of</w><w>locating</w><w>the</w><w>broader</w><w>themes</w><w>and</w><w>trends</w><w>that</w><w>emerge</w><w>from</w><w>within</w><w>your</w><w>body</w><w>of</w><w>work</w><pc>.</pc><w>This</w><w>method</w><w>of</w><w>analysis</w><w>is</w><w>useful</w><w>for</w><w>historical</w><w>inquiry</w><w>as</w><w>it</w><w>allows</w><w>for</w><w>a</w><w>narrative</w><w>crafted</w><w>over</w><w>years</w><w>and</w><w>thousands</w><w>of</w><w>texts</w><w>to</w><w>be</w><w>aggregated</w><w>and</w><w>condensed</w><w>,</w><w>then</w><w>analyzed</w><w>through</w><w>direct</w><w>inquiry</w><pc>.</pc><w>In</w><w>essence</w><w>,</w><w>it</w><w>allows</w><w>you</w><w>to</w><w>``</w><w>talk</w><w>''</w><w>to</w><w>your</w><w>sources</w><pc>.</pc></p><p><w>To</w><w>do</w><w>this</w><w>,</w><w>we</w><w>will</w><w>use</w><w>an</w><w>implementation</w><w>of</w><w>GPT-2</w><w>that</w><w>is</w><w>wrapped</w><w>in</w><w>a</w><w>Python</w><w>package</w><w>to</w><w>simplify</w><w>the</w><w>finetuning</w><w>of</w><w>an</w><w>existing</w><w>machine</w><w>learning</w><w>model</w><pc>.</pc><w>Although</w><w>the</w><w>code</w><w>itself</w><w>in</w><w>this</w><w>tutorial</w><w>is</w><w>not</w><w>complex</w><w>,</w><w>in</w><w>the</w><w>process</w><w>of</w><w>learning</w><w>this</w><w>method</w><w>for</w><w>exploratory</w><w>data</w><w>analysis</w><w>you</w><w>will</w><w>gain</w><w>insight</w><w>into</w><w>common</w><w>machine</w><w>learning</w><w>terminology</w><w>and</w><w>concepts</w><w>which</w><w>can</w><w>be</w><w>applied</w><w>to</w><w>other</w><w>branches</w><w>of</w><w>machine</w><w>learning</w><pc>.</pc><w>Beyond</w><w>just</w><w>interrogating</w><w>history</w><w>,</w><w>we</w><w>will</w><w>also</w><w>interrogate</w><w>the</w><w>ethics</w><w>of</w><w>producing</w><w>this</w><w>form</w><w>of</w><w>research</w><w>,</w><w>from</w><w>its</w><w>greater</w><w>impact</w><w>on</w><w>the</w><w>environment</w><w>to</w><w>how</w><w>even</w><w>one</w><w>passage</w><w>from</w><w>the</w><w>text</w><w>generated</w><w>can</w><w>be</w><w>misinterpreted</w><w>and</w><w>recontextualized</w><pc>.</pc></p><div type="3" n="1.1"><head><w>Prerequisite</w><w>Knowledge</w></head><p><w>For</w><w>this</w><w>tutorial</w><w>,</w><w>you</w><w>will</w><w>need</w><w>a</w><hi rend="bold"><w>basic</w><w>understanding</w><w>of</w><w>Python</w></hi><w>and</w><w>how</w><w>to</w><w>run</w><w>Python</w><w>code</w><w>,</w><w>whether</w><w>that</w><w>be</w><w>via</w><ref target="/en/lessons/jupyter-notebooks"><w>Jupyter</w><w>Notebooks</w></ref><w>or</w><w>using</w><w>a</w><w>text</w><w>editor</w><w>and</w><w>the</w><w>command</w><w>line</w><pc>.</pc><w>If</w><w>you</w><w>have</w><w>not</w><w>used</w><w>Python</w><w>before</w><w>,</w><w>I</w><w>suggest</w><w>going</w><w>through</w><w>one</w><w>of</w><w>the</w><w>other</w><emph><w>Programming</w><w>Historian</w></emph><w>lessons</w><w>designed</w><w>to</w><w>introduce</w><w>you</w><w>to</w><w>Python</w><w>,</w><w>such</w><w>as</w><ref target="/en/lessons/introduction-and-installation"><w>Python</w><w>Introduction</w><w>and</w><w>Installation</w></ref><pc>.</pc></p><p><w>We</w><w>will</w><w>be</w><w>using</w><w>the</w><w>Python</w><w>tool</w><ref target="https://perma.cc/C62L-MLP8"><code rend="inline"><w>aitextgen</w></code></ref><w>to</w><w>finetune</w><w>our</w><w>GPT-2</w><w>model</w><pc>.</pc><w>Produced</w><w>by</w><w>data</w><w>scientist</w><ref target="https://perma.cc/VWH7-JFP8"><w>Max</w><w>Woolf</w></ref><w>,</w><w>this</w><w>package</w><w>was</w><w>created</w><w>with</w><w>a</w><w>goal</w><w>of</w><w>making</w><w>the</w><w>training</w><w>and</w><w>generation</w><w>of</w><w>text-based</w><w>machine</w><w>learning</w><w>models</w><w>more</w><w>accessible</w><w>and</w><w>democratic</w><w>for</w><w>those</w><w>without</w><w>the</w><w>advanced</w><w>knowledge</w><w>required</w><w>to</w><w>create</w><w>their</w><w>own</w><w>models</w><w>from</w><w>scratch</w><pc>.</pc><w>This</w><w>means</w><w>that</w><w>the</w><w>code</w><w>we</w><w>'re</w><w>writing</w><w>is</w><w>quite</w><w>simple</w><w>;</w><w>the</w><w>greater</w><w>challenge</w><w>of</w><w>this</w><w>lesson</w><w>is</w><w>understanding</w><w>what</w><w>the</w><w>code</w><w>is</w><w>doing</w><w>,</w><w>which</w><w>is</w><w>what</w><w>you</w><w>are</w><w>here</w><w>to</w><w>learn</w><pc>.</pc></p></div><div type="3" n="1.2"><head><w>Introduction</w><w>to</w><w>Machine</w><w>Learning</w><w>,</w><w>Language</w><w>Models</w><w>,</w><w>and</w><w>GPT</w></head><p><w>Although</w><w>much</w><w>of</w><w>this</w><w>tutorial</w><w>will</w><w>be</w><w>dedicated</w><w>to</w><w>explaining</w><w>the</w><w>common</w><w>terminology</w><w>used</w><w>in</w><w>relation</w><w>to</w><w>machine</w><w>learning</w><w>,</w><w>it</w><w>is</w><w>beneficial</w><w>to</w><w>begin</w><w>with</w><w>some</w><w>base-level</w><w>explanations</w><w>to</w><w>introduce</w><w>you</w><w>to</w><w>the</w><w>technical</w><w>terms</w><w>being</w><w>used</w><w>in</w><w>this</w><w>lesson</w><pc>.</pc></p><p><w>The</w><w>term</w><ref target="https://perma.cc/TY5G-8DJM"><w>``</w><w>machine</w><w>learning</w><w>''</w></ref><w>has</w><w>been</w><w>mentioned</w><w>a</w><w>few</w><w>times</w><w>in</w><w>the</w><w>lesson</w><w>already</w><w>,</w><w>but</w><w>what</w><w>exactly</w><w>is</w><w>it</w><pc>?</pc><w>While</w><w>often</w><w>thought</w><w>of</w><w>as</w><w>being</w><w>separate</w><w>entities</w><w>,</w><w>machine</w><w>learning</w><w>is</w><w>actually</w><w>considered</w><w>a</w><w>branch</w><w>of</w><ref target="https://perma.cc/3325-TKU6"><w>artificial</w><w>intelligence</w></ref><w>concerned</w><w>with</w><w>creating</w><w>computer</w><w>algorithms</w><w>that</w><w>``</w><w>learn</w><w>''</w><w>and</w><w>thus</w><w>improve</w><w>automatically</w><w>through</w><w>exposure</w><w>to</w><w>data</w><pc>.</pc><w>In</w><w>this</w><w>lesson</w><w>,</w><w>we</w><w>are</w><w>working</w><w>with</w><w>language</w><w>models</w><w>which</w><w>take</w><ref target="https://perma.cc/R862-YRMX"><w>word</w><w>vectors</w></ref><w>(</w><w>in</w><w>essence</w><w>,</w><w>words</w><w>mapped</w><w>to</w><w>and</w><w>represented</w><w>by</w><w>real</w><w>numbers</w><w>)</w><w>and</w><w>output</w><w>the</w><w>estimated</w><w>probability</w><w>of</w><w>the</w><w>word</w><w>that</w><w>will</w><w>follow</w><pc>.</pc><w>To</w><w>put</w><w>simply</w><w>,</w><w>machine</w><w>learning</w><w>language</w><w>models</w><w>look</w><w>at</w><w>part</w><w>of</w><w>a</w><w>sentence</w><w>(</w><w>i.e.</w><w>,</w><w>a</w><w>word</w><w>)</w><w>and</w><w>predict</w><w>what</w><w>the</w><w>following</w><w>part</w><w>may</w><w>be</w><pc>.</pc><w>The</w><w>most</w><w>widely-known</w><w>example</w><w>of</w><w>this</w><w>being</w><w>Google</w><w>'s</w><w>search</w><w>engine</w><w>,</w><w>which</w><w>predicts</w><w>your</w><w>search</w><w>as</w><w>you</w><w>type</w><pc>.</pc></p><p><w>As</w><w>indicated</w><w>in</w><w>the</w><w>title</w><w>of</w><w>this</w><w>lesson</w><w>,</w><w>you</w><w>are</w><w>going</w><w>to</w><w>use</w><w>GPT-2</w><w>for</w><w>our</w><w>experiment</w><w>with</w><w>machine</w><w>learning</w><w>and</w><w>language</w><w>models</w><w>today</w><pc>.</pc><w>``</w><w>GPT</w><w>''</w><w>stands</w><w>for</w><hi rend="bold"><w>G</w></hi><w>enerative</w><hi rend="bold"><w>P</w></hi><w>re-trained</w><hi rend="bold"><w>T</w></hi><w>ransformer</w><w>,</w><w>with</w><w>the</w><w>most</w><w>important</w><w>part</w><w>of</w><w>this</w><w>initialism</w><w>being</w><w>the</w><w>last</w><w>word</w><pc>.</pc><w>GPT-2</w><w>is</w><w>a</w><w>transformer-based</w><w>language</w><w>model</w><w>,</w><w>which</w><w>means</w><w>that</w><w>it</w><w>has</w><w>an</w><ref target="https://perma.cc/QG6K-H442"><w>attention</w><w>mechanism</w></ref><w>that</w><w>allows</w><w>for</w><w>predictions</w><w>to</w><w>be</w><w>made</w><w>by</w><w>looking</w><w>at</w><w>the</w><w>entirety</w><w>of</w><w>what</w><w>was</w><w>inputted</w><w>to</w><w>determine</w><w>each</w><w>word</w><w>'s</w><w>relevance</w><w>selectively</w><w>,</w><w>rather</w><w>than</w><w>sequentially</w><w>by</w><w>looking</w><w>at</w><w>the</w><w>most</w><w>recent</w><w>segment</w><w>of</w><w>input</w><w>as</w><w>is</w><w>the</w><w>case</w><w>in</w><w>language</w><w>models</w><w>based</w><w>on</w><ref target="https://perma.cc/57DY-P5J2"><w>recurrent</w><w>neural</w><w>networks</w></ref><pc>.</pc><w>The</w><w>ability</w><w>of</w><w>transformer-based</w><w>models</w><w>to</w><w>read</w><w>all</w><w>inputted</w><w>words</w><w>at</w><w>once</w><w>allows</w><w>for</w><w>the</w><w>machine</w><w>to</w><w>learn</w><w>faster</w><w>,</w><w>and</w><w>thus</w><w>the</w><w>datasets</w><w>used</w><w>for</w><w>training</w><w>can</w><w>be</w><w>made</w><w>larger</w><w>which</w><w>in</w><w>turn</w><w>improves</w><w>the</w><w>accuracy</w><w>of</w><w>the</w><w>predictions</w><w>which</w><w>the</w><w>model</w><w>outputs</w><pc>.</pc><w>Initially</w><w>developed</w><w>to</w><w>advance</w><w>research</w><w>in</w><w>generating</w><w>text</w><w>without</w><w>explicitly</w><w>labelled</w><w>training</w><w>data</w><w>,</w><w>GPT</w><w>'s</w><w>level</w><w>of</w><w>success</w><w>at</w><w>this</w><w>task</w><w>has</w><w>allowed</w><w>it</w><w>to</w><w>be</w><w>utilised</w><w>for</w><w>a</w><w>number</w><w>of</w><w>more</w><w>creative</w><w>challenges</w><w>,</w><w>from</w><ref target="https://perma.cc/JBX3-B9FC"><w>being</w><w>a</w><w>co-writer</w><w>for</w><w>your</w><w>fantasy</w><w>novel</w><w>through</w><w>platforms</w><w>such</w><w>as</w><w>NovelAI</w></ref><w>to</w><ref target="https://perma.cc/PG9M-SG9J"><w>generating</w><w>side-quests</w><w>for</w><w>adventure</w><w>games</w></ref><pc>.</pc></p></div><div type="3" n="1.3"><head><w>Case</w><w>Study</w><w>:</w><w>Brexit</w><w>in</w><w>the</w><w>Media</w></head><p><w>GPT-2</w><w>is</w><w>a</w><w>pre-trained</w><w>model</w><w>designed</w><w>to</w><w>generate</w><w>unique</w><w>text</w><w>based</w><w>on</w><w>a</w><w>given</w><w>prompt</w><pc>.</pc><w>It</w><w>already</w><w>has</w><w>a</w><w>vast</w><w>vocabulary</w><w>having</w><w>been</w><w>trained</w><w>using</w><w>a</w><w>dataset</w><w>called</w><ref target="https://perma.cc/24C9-9LB2"><w>WebText</w></ref><w>,</w><w>which</w><w>was</w><w>created</w><w>by</w><ref target="https://perma.cc/EKH4-GBZT"><w>crawling</w></ref><w>the</w><w>social</w><w>media</w><w>platform</w><w>Reddit</w><w>for</w><w>outbound</w><w>links</w><w>and</w><w>grabbing</w><w>the</w><w>text</w><w>from</w><w>these</w><w>web</w><w>pages</w><pc>.</pc><w>This</w><w>method</w><w>resulted</w><w>in</w><w>a</w><w>40GB</w><w>dataset</w><w>which</w><w>consisted</w><w>of</w><w>approximately</w><w>8</w><w>million</w><w>web</w><w>pages</w><w>,</w><w>resulting</w><w>in</w><w>1.5</w><w>billion</w><w>parameters</w><w>(</w><w>to</w><w>put</w><w>simply</w><w>,</w><w>words</w><w>and</w><w>their</w><w>weights</w><w>—</w><w>the</w><w>strength</w><w>of</w><w>their</w><w>connections</w><w>with</w><w>other</w><w>words</w><w>)</w><pc>.</pc><w>Through</w><w>a</w><w>process</w><w>known</w><w>as</w><emph><w>finetuning</w></emph><w>,</w><w>you</w><w>can</w><w>harness</w><w>the</w><w>power</w><w>of</w><w>this</w><w>model</w><w>and</w><w>retrain</w><w>GPT-2</w><w>with</w><w>your</w><w>own</w><w>smaller</w><w>corpus</w><w>,</w><w>resulting</w><w>in</w><w>a</w><w>``</w><w>specialized</w><w>''</w><w>model</w><w>that</w><w>now</w><w>has</w><w>the</w><w>vocabulary</w><w>of</w><w>your</w><w>corpus</w><w>and</w><w>can</w><w>produce</w><w>text</w><w>on</w><w>the</w><w>topic</w><w>which</w><w>your</w><w>corpus</w><w>discusses</w><pc>.</pc></p><p><w>In</w><w>this</w><w>lesson</w><w>,</w><w>we</w><w>will</w><w>be</w><w>looking</w><w>at</w><w>the</w><w>phenomenon</w><w>of</w><ref target="https://perma.cc/5P7B-7P8R"><w>Brexit</w></ref><pc>.</pc><w>This</w><w>portmanteau</w><w>of</w><w>``</w><w>British</w><w>''</w><w>and</w><w>``</w><w>exit</w><w>''</w><w>refers</w><w>to</w><w>the</w><w>referendum</w><w>held</w><w>in</w><w>2016</w><w>to</w><w>decide</w><w>whether</w><w>or</w><w>not</w><w>the</w><w>United</w><w>Kingdom</w><w>would</w><w>remain</w><w>a</w><w>member</w><w>of</w><w>the</w><ref target="https://perma.cc/D9JC-2FR4"><w>European</w><w>Union</w><w>(</w><w>EU</w><w>)</w></ref><w>,</w><w>and</w><w>subsequent</w><w>related</w><w>events</w><w>which</w><w>occurred</w><w>following</w><w>the</w><w>ultimate</w><w>decision</w><w>to</w><w>withdraw</w><w>membership</w><pc>.</pc><w>The</w><w>EU</w><w>is</w><w>a</w><w>political</w><w>and</w><w>economic</w><w>union</w><w>of</w><w>nations</w><w>which</w><w>aims</w><w>to</w><w>reduce</w><w>barriers</w><w>surrounding</w><w>trade</w><w>and</w><w>movement</w><w>across</w><w>borders</w><w>through</w><w>common</w><w>legal</w><w>,</w><w>social</w><w>,</w><w>and</w><w>economic</w><w>policies</w><pc>.</pc><w>Britain</w><w>had</w><w>historically</w><w>been</w><w>a</w><w>part</w><w>of</w><w>this</w><w>union</w><w>since</w><w>its</w><w>foundation</w><w>in</w><w>1993</w><w>with</w><w>the</w><w>enactment</w><w>of</w><w>the</w><ref target="https://perma.cc/MS43-SRM6"><w>Maastricht</w><w>Treaty</w></ref><pc>.</pc><w>This</w><w>was</w><w>the</w><w>first-ever</w><w>instance</w><w>of</w><w>a</w><w>member</w><w>state</w><w>leaving</w><w>the</w><w>EU</w><w>,</w><w>and</w><w>the</w><w>decision</w><w>would</w><w>hugely</w><w>affect</w><w>the</w><w>policies</w><w>which</w><w>had</w><w>previously</w><w>governed</w><w>the</w><w>UK</w><w>,</w><w>thus</w><w>this</w><w>topic</w><w>has</w><w>garnered</w><w>significant</w><w>media</w><w>coverage</w><w>both</w><w>nationally</w><w>and</w><w>internationally</w><w>from</w><w>the</w><w>year</w><w>of</w><w>the</w><w>referendum</w><w>up</w><w>until</w><w>the</w><w>point</w><w>when</w><w>this</w><w>lesson</w><w>is</w><w>being</w><w>written</w><w>in</w><w>2022</w><w>,</w><w>two</w><w>years</w><w>after</w><w>the</w><w>UK</w><w>officially</w><w>left</w><w>the</w><w>EU</w><w>in</w><w>2020</w><pc>.</pc><w>Beyond</w><w>issues</w><w>pertaining</w><w>strictly</w><w>to</w><w>politics</w><w>and</w><w>economics</w><w>,</w><w>the</w><w>polarising</w><w>nature</w><w>of</w><w>the</w><w>vote</w><w>for</w><w>Brexit</w><w>brought</w><w>to</w><w>light</w><w>a</w><w>number</w><w>of</w><w>societal</w><w>issues</w><w>related</w><w>to</w><w>immigration</w><w>,</w><w>race</w><w>,</w><w>and</w><w>gender</w><w>present</w><w>in</w><w>Britain</w><pc>.</pc><w>These</w><w>broader</w><w>issues</w><w>were</w><w>reflected</w><w>in</w><w>the</w><w>publications</w><w>covering</w><w>not</w><w>only</w><w>the</w><w>events</w><w>occurring</w><w>,</w><w>but</w><w>also</w><w>the</w><w>perspectives</w><w>of</w><w>voters</w><w>,</w><w>and</w><w>the</w><w>individual</w><w>actors</w><w>involved</w><w>in</w><w>the</w><w>referendum</w><w>and</w><w>subsequent</w><w>withdrawal</w><pc>.</pc></p><div type="4" n="1.3.1"><head><w>Dataset</w></head><p><w>To</w><w>interrogate</w><w>the</w><w>national</w><w>narrative</w><w>generated</w><w>and</w><w>disseminated</w><w>by</w><w>media</w><w>coverage</w><w>regarding</w><w>Brexit</w><w>,</w><w>our</w><w>input</w><w>for</w><w>this</w><w>lesson</w><w>will</w><w>be</w><ref target="/assets/interrogating-national-narrative-gpt/articles.txt"><w>a</w><w>dataset</w><w>of</w><w>4036</w><w>web-published</w><w>news</w><w>articles</w></ref><w>derived</w><w>from</w><w>popular</w><w>news</w><w>sources</w><w>in</w><w>the</w><w>UK</w><w>such</w><w>as</w><w>the</w><w>BBC</w><w>and</w><emph><w>The</w><w>Sun</w></emph><w>written</w><w>on</w><w>the</w><w>topic</w><w>of</w><w>``</w><w>Brexit</w><w>''</w><w>,</w><w>extracted</w><w>from</w><w>the</w><ref target="https://perma.cc/HR33-RF6L"><w>UK</w><w>Web</w><w>Archive</w><w>'s</w><w>curated</w><w>``</w><w>News</w><w>and</w><w>Media</w><w>''</w><w>collection</w><w>on</w><w>this</w><w>subject</w></ref><pc>.</pc><w>First</w><w>,</w><ref target="/assets/interrogating-national-narrative-gpt/scraping-links.ipynb"><w>the</w><w>links</w><w>to</w><w>each</w><w>article</w><w>were</w><w>gathered</w></ref><w>so</w><w>that</w><w>they</w><w>could</w><w>be</w><w>extracted</w><w>from</w><w>their</w><w>respective</w><w>webpages</w><w>in</w><w>bulk</w><w>via</w><w>web</w><w>scraping</w><w>through</w><w>a</w><ref target="/assets/interrogating-national-narrative-gpt/scraping-articles.ipynb"><w>Python</w><w>script</w><w>implementing</w><w>the</w><w>Beautiful</w><w>Soup</w><w>library</w></ref><pc>.</pc><w>The</w><w>articles</w><w>were</w><w>then</w><w>exported</w><w>collectively</w><w>into</w><w>a</w><w>single</w><w>,</w><w>large</w><code rend="inline"><w>.txt</w></code><w>file</w><pc>.</pc><w>The</w><w>text</w><w>was</w><w>then</w><w>cleaned</w><w>of</w><w>any</w><w>additional</w><w>HTML</w><w>tags</w><w>or</w><w>unintentionally</w><w>captured</w><w>information</w><w>,</w><w>such</w><w>as</w><w>footer</w><w>menus</w><w>,</w><w>using</w><w>regular</w><w>expressions</w><w>(</w><w>regex</w><w>)</w><pc>.</pc></p><p><w>For</w><w>a</w><w>complete</w><w>guide</w><w>on</w><w>spotting</w><w>and</w><w>removing</w><w>HTML</w><w>in</w><w>text</w><w>downloaded</w><w>from</w><w>webpages</w><w>,</w><w>you</w><w>can</w><w>follow</w><ref target="/en/lessons/from-html-to-list-of-words-1"><w>this</w><emph><w>Programming</w><w>Historian</w></emph><w>tutorial</w><w>which</w><w>walks</w><w>you</w><w>through</w><w>transforming</w><w>an</w><w>extracted</w><w>webpage</w><w>into</w><w>a</w><w>clean</w><w>list</w><w>of</w><w>words</w></ref><w>,</w><w>and</w><w>for</w><w>more</w><w>information</w><w>on</w><w>the</w><w>cleaning</w><w>with</w><w>regex</w><w>,</w><w>you</w><w>can</w><w>view</w><ref target="/en/lessons/understanding-regular-expressions"><w>this</w><emph><w>Programming</w><w>Historian</w></emph><w>tutorial</w><w>on</w><w>understanding</w><w>regular</w><w>expressions</w></ref><pc>.</pc><w>The</w><w>code</w><w>used</w><w>for</w><w>scraping</w><w>articles</w><w>comes</w><w>from</w><ref target="/en/lessons/retired/intro-to-beautiful-soup"><w>this</w><w>tutorial</w><w>that</w><w>introduces</w><w>how</w><w>Beautiful</w><w>Soup</w><w>can</w><w>be</w><w>used</w></ref><pc>.</pc><w>Although</w><w>the</w><w>Beautiful</w><w>Soup</w><w>tutorial</w><w>has</w><w>been</w><w>retired</w><w>due</w><w>to</w><w>the</w><w>underlying</w><w>website</w><w>no</w><w>longer</w><w>producing</w><w>the</w><w>referenced</w><w>HTML</w><w>,</w><w>it</w><w>is</w><w>still</w><w>useful</w><w>for</w><w>learning</w><w>about</w><w>how</w><w>the</w><w>library</w><w>interprets</w><w>and</w><w>interacts</w><w>with</w><w>a</w><w>given</w><w>web</w><w>page</w><w>;</w><w>should</w><w>you</w><w>need</w><w>more</w><w>specific</w><w>guidance</w><w>on</w><w>web</w><w>scraping</w><w>,</w><w>there</w><w>is</w><ref target="/en/lessons/automated-downloading-with-wget"><w>this</w><w>tutorial</w><w>on</w><w>downloading</w><w>via</w><w>Wget</w></ref><w>,</w><w>which</w><w>can</w><w>be</w><w>used</w><w>to</w><w>download</w><w>web</w><w>pages</w><w>containing</w><w>articles</w><w>among</w><w>other</w><w>things</w><pc>.</pc></p><p><w>With</w><w>that</w><w>being</w><w>said</w><w>,</w><w>should</w><w>you</w><w>want</w><w>to</w><w>follow</w><w>along</w><w>with</w><w>this</w><w>lesson</w><w>using</w><w>your</w><w>own</w><w>data</w><w>,</w><w>you</w><w>must</w><w>:</w></p><list type="ordered"><item><w>Ensure</w><w>that</w><w>all</w><w>of</w><w>the</w><w>text</w><w>you</w><w>would</w><w>like</w><w>to</w><w>feed</w><w>to</w><w>your</w><w>model</w><w>is</w><w>in</w><w>a</w><w>singular</w><code rend="inline"><w>.txt</w></code><w>file</w><pc>.</pc><w>If</w><w>not</w><w>scraping</w><w>your</w><w>data</w><w>from</w><w>the</w><w>web</w><w>,</w><w>you</w><w>may</w><w>need</w><w>to</w><w>convert</w><w>your</w><w>files</w><w>from</w><w>another</w><w>format</w><w>,</w><w>in</w><w>which</w><w>case</w><ref target="/en/lessons/working-with-batches-of-pdf-files"><w>this</w><w>tutorial</w><w>on</w><w>working</w><w>with</w><w>batches</w><w>of</w><w>PDFs</w></ref><w>or</w><ref target="/en/lessons/sustainable-authorship-in-plain-text-using-pandoc-and-markdown"><w>this</w><w>tutorial</w><w>introducing</w><w>Pandoc</w><w>,</w><w>a</w><w>command</w><w>line</w><w>conversion</w><w>tool</w></ref><w>may</w><w>be</w><w>helpful</w><pc>.</pc></item><item><w>Perform</w><w>some</w><w>amount</w><w>of</w><w>cleaning</w><w>so</w><w>that</w><w>your</w><w>output</w><w>is</w><w>not</w><w>hindered</w><w>by</w><w>stray</w><w>stylings</w><w>as</w><w>discussed</w><w>above</w><pc>.</pc><w>GPT-2</w><w>does</w><w>not</w><w>truly</w><w>understand</w><w>what</w><w>a</w><w>word</w><w>is</w><w>—</w><w>to</w><w>a</w><w>computer</w><w>,</w><w>words</w><w>are</w><w>just</w><w>a</w><w>series</w><w>of</w><w>numbers</w><w>that</w><w>map</w><w>to</w><w>a</w><w>representation</w><w>of</w><w>something</w><w>that</w><emph><w>we</w></emph><w>recognize</w><pc>.</pc><w>This</w><w>means</w><w>that</w><w>a</w><w>model</w><w>will</w><w>train</w><w>on</w><emph><w>everything</w></emph><w>given</w><w>to</w><w>it</w><w>as</w><w>input</w><w>,</w><w>including</w><w>odd</w><w>formatting</w><w>and</w><w>HTML</w><w>snippets</w><pc>.</pc></item></list><p><w>Additionally</w><w>,</w><w>another</w><w>important</w><w>aspect</w><w>to</w><w>consider</w><w>regarding</w><w>the</w><w>data</w><w>you</w><w>would</w><w>like</w><w>to</w><w>use</w><w>with</w><w>this</w><w>model</w><w>,</w><w>is</w><w>what</w><w>language</w><w>your</w><w>data</w><w>is</w><w>written</w><w>in</w><pc>.</pc><w>The</w><w>textual</w><w>data</w><w>that</w><w>was</w><w>used</w><w>to</w><w>train</w><w>GPT-2</w><w>is</w><w>exclusively</w><w>in</w><w>English</w><w>,</w><w>thus</w><w>attempting</w><w>to</w><w>use</w><w>non-English</w><w>text</w><w>with</w><w>this</w><w>tutorial</w><w>will</w><w>likely</w><w>yield</w><w>poor</w><w>results</w><pc>.</pc><ref type="footnotemark" target="#en_note_1"/><w>This</w><w>language</w><w>barrier</w><w>is</w><w>unfortunately</w><w>common</w><w>when</w><w>it</w><w>comes</w><w>to</w><w>text-based</w><w>machine</w><w>learning</w><w>due</w><w>to</w><w>greater</w><w>systemic</w><w>divides</w><w>in</w><w>the</w><w>field</w><w>of</w><w>natural</w><w>language</w><w>processing</w><w>(</w><w>NLP</w><w>)</w><w>and</w><w>academia</w><w>broadly</w><w>;</w><w>for</w><w>an</w><w>in-depth</w><w>explanation</w><w>of</w><w>this</w><w>topic</w><w>,</w><ref target="https://perma.cc/8A62-X9RM"><w>see</w><w>the</w><w>#</w><w>BenderRule</w></ref><pc>.</pc></p><p><w>Through</w><w>training</w><w>a</w><w>model</w><w>on</w><w>these</w><w>articles</w><w>,</w><w>we</w><w>can</w><w>attempt</w><w>to</w><w>view</w><w>this</w><w>macroscopic</w><w>narrative</w><w>—as</w><w>curated</w><w>by</w><w>popular</w><w>media</w><w>outlets</w><w>meant</w><w>for</w><w>the</w><w>average</w><w>UK</w><w>citizen</w><w>to</w><w>consume—</w><w>by</w><w>feeding</w><w>our</w><w>model</w><w>questions</w><w>about</w><w>the</w><w>topic</w><w>of</w><w>Brexit</w><pc>.</pc><w>For</w><w>example</w><w>,</w><w>we</w><w>can</w><w>ask</w><w>it</w><w>about</w><w>key</w><w>players</w><w>or</w><w>ask</w><w>it</w><w>to</w><w>describe</w><w>key</w><w>events</w><w>,</w><w>using</w><w>the</w><w>prefix</w><w>functionality</w><w>of</w><w>GPT-2</w><pc>.</pc><w>The</w><w>prefix</w><w>functionality</w><w>is</w><w>a</w><w>parameter</w><w>set</w><w>when</w><w>asking</w><w>your</w><w>model</w><w>to</w><w>generate</w><w>text</w><w>;</w><w>it</w><w>is</w><w>typically</w><w>set</w><w>to</w><w>a</w><w>single</w><w>word</w><w>which</w><w>the</w><w>model</w><w>uses</w><w>as</w><w>a</w><w>jumping-off</w><w>point</w><w>for</w><w>the</w><w>text</w><w>it</w><w>will</w><w>produce</w><w>,</w><w>but</w><w>it</w><w>can</w><w>also</w><w>be</w><w>set</w><w>to</w><w>phrases</w><w>or</w><w>questions</w><w>for</w><w>the</w><w>generation</w><w>of</w><w>more</w><w>specific</w><w>text</w><pc>.</pc><w>Essentially</w><w>,</w><w>we</w><w>can</w><w>set</w><w>the</w><w>prefix</w><w>to</w><w>something</w><w>like</w><w>``</w><w>Who</w><w>is</w><w>BoJo</w><pc>?</pc><w>``</w><w>,</w><w>and</w><w>our</w><w>model</w><w>will</w><w>output</w><w>a</w><w>paragraph</w><w>responding</w><w>to</w><w>our</w><w>query</w><pc>.</pc><w>By</w><w>``</w><w>interrogating</w><w>''</w><w>our</w><w>model</w><w>through</w><w>its</w><w>prefix</w><w>,</w><w>we</w><w>can</w><w>use</w><w>this</w><ref target="https://perma.cc/MJV3-BK4N"><w>``</w><w>computationally</w><w>creative</w><w>''</w></ref><w>technique</w><w>to</w><w>uncover</w><w>potential</w><w>trends</w><w>in</w><w>the</w><w>media</w><w>coverage</w><w>of</w><w>this</w><w>historical</w><w>turning</w><w>point</w><w>,</w><w>and</w><w>consider</w><w>further</w><w>how</w><w>this</w><w>method</w><w>may</w><w>be</w><w>applied</w><w>to</w><w>other</w><w>forms</w><w>of</w><w>historical</w><w>research</w><w>based</w><w>on</w><w>large-scale</w><w>text-based</w><w>data</w><pc>.</pc></p></div></div></div><div type="2" n="2"><head><w>Options</w><w>for</w><w>Running</w><w>GPT-2</w></head><p><w>GPT-2</w><w>,</w><w>like</w><w>many</w><w>other</w><w>forms</w><w>of</w><w>machine</w><w>learning</w><w>,</w><w>requires</w><w>a</w><w>significant</w><w>amount</w><w>of</w><w>computing</w><w>power</w><w>to</w><w>run</w><w>even</w><w>the</w><w>``</w><w>small</w><w>''</w><w>version</w><w>of</w><w>the</w><w>model</w><w>we</w><w>will</w><w>use</w><w>in</w><w>this</w><w>tutorial</w><w>,</w><w>which</w><w>still</w><w>has</w><w>124</w><w>million</w><w>parameters</w><w>(</w><w>as</w><w>opposed</w><w>to</w><w>the</w><w>aforementioned</w><w>1.5</w><w>billion</w><w>parameters</w><w>used</w><w>in</w><w>the</w><w>original</w><w>training</w><w>of</w><w>the</w><w>model</w><w>)</w><pc>.</pc><w>For</w><w>you</w><w>to</w><w>successfully</w><w>finetune</w><w>your</w><w>model</w><w>without</w><w>your</w><w>device</w><w>freezing</w><w>up</w><w>,</w><w>your</w><w>computer</w><w>must</w><w>have</w><w>a</w><ref target="https://perma.cc/B824-6W29"><w>CUDA-enabled</w></ref><w>graphics</w><w>processing</w><w>unit</w><w>(</w><w>GPU</w><w>)</w><w>with</w><w>at</w><w>least</w><w>8GB</w><w>of</w><w>VRAM</w><hi rend="bold"><w>or</w></hi><w>you</w><w>may</w><w>use</w><w>one</w><w>of</w><w>the</w><w>online</w><w>services</w><w>that</w><w>offer</w><w>cloud-based</w><w>GPU</w><w>computing</w><w>discussed</w><w>in</w><w>a</w><w>section</w><w>below</w><pc>.</pc></p><div type="3" n="2.1"><head><w>Machine</w><w>Learning</w><w>Hardware</w><w>101</w></head><p><w>If</w><w>that</w><w>last</w><w>sentence</w><w>left</w><w>you</w><w>with</w><w>many</w><w>questions</w><w>,</w><w>such</w><w>as</w><w>``</w><w>What</w><w>is</w><w>a</w><w>GPU</w><pc>?</pc><w>Why</w><w>do</w><w>I</w><w>need</w><w>one</w><pc>?</pc><w>''</w><w>then</w><w>read</w><w>this</w><w>section</w><w>for</w><w>a</w><w>basic</w><w>introduction</w><w>to</w><w>the</w><w>computer</w><w>hardware</w><w>used</w><w>in</w><w>machine</w><w>learning</w><w>;</w><w>otherwise</w><w>,</w><w>proceed</w><w>past</w><w>this</w><w>to</w><w>the</w><w>next</w><w>section</w><pc>.</pc></p><div type="4" n="2.1.1"><head><w>The</w><w>Central</w><w>Processing</w><w>Unit</w><w>(</w><w>CPU</w><w>)</w><w>vs</w><w>the</w><w>Graphics</w><w>Processing</w><w>Unit</w><w>(</w><w>GPU</w><w>)</w></head><p><w>Those</w><w>of</w><w>you</w><w>reading</w><w>this</w><w>lesson</w><w>will</w><w>likely</w><w>be</w><w>the</w><w>most</w><w>familiar</w><w>with</w><w>the</w><w>term</w><hi rend="bold"><w>CPU</w></hi><pc>.</pc><w>The</w><w>CPU</w><w>is</w><w>akin</w><w>to</w><w>the</w><w>brain</w><w>of</w><w>your</w><w>computer</w><w>,</w><w>accepting</w><w>a</w><w>constant</w><w>stream</w><w>of</w><w>information</w><w>and</w><w>using</w><w>its</w><w>numerous</w><w>encoded</w><w>instructions</w><w>to</w><w>process</w><w>and</w><w>perform</w><w>both</w><w>the</w><w>tasks</w><w>that</w><w>you</w><w>request</w><w>(</w><w>e.g.</w><w>,</w><w>loading</w><w>a</w><w>file</w><w>)</w><w>and</w><w>those</w><w>which</w><w>keep</w><w>your</w><w>computer</w><w>running</w><w>(</w><w>e.g.</w><w>,</w><w>booting</w><w>the</w><w>operating</w><w>system</w><w>when</w><w>you</w><w>power</w><w>your</w><w>device</w><w>on</w><w>)</w><pc>.</pc><w>A</w><hi rend="bold"><w>GPU</w></hi><w>is</w><w>more</w><w>akin</w><w>to</w><w>a</w><w>specialized</w><w>organ</w><w>like</w><w>the</w><w>stomach</w><w>,</w><w>as</w><w>it</w><w>only</w><w>has</w><w>a</w><w>small</w><w>number</w><w>of</w><w>specific</w><w>instructions</w><w>that</w><w>can</w><w>be</w><w>applied</w><w>to</w><w>the</w><w>data</w><w>it</w><w>is</w><w>given</w><pc>.</pc><w>Due</w><w>to</w><w>the</w><w>less</w><w>general-purpose</w><w>and</w><w>more</w><w>specialized</w><w>nature</w><w>of</w><w>GPUs</w><w>,</w><w>they</w><w>can</w><w>perform</w><w>tasks</w><w>—such</w><w>as</w><w>displaying</w><w>each</w><w>pixel</w><w>that</w><w>makes</w><w>up</w><w>the</w><w>image</w><w>you</w><w>see</w><w>on</w><w>your</w><w>screen—</w><w>very</w><w>efficiently</w><pc>.</pc><w>In</w><w>most</w><w>laptops</w><w>,</w><w>the</w><w>CPU</w><w>comes</w><w>with</w><w>a</w><w>built-in</w><w>low-power</w><w>GPU</w><w>to</w><w>handle</w><w>graphic</w><w>output</w><w>;</w><w>this</w><w>type</w><w>of</w><w>GPU</w><w>is</w><w>referred</w><w>to</w><w>as</w><w>an</w><hi rend="bold"><w>integrated</w><w>GPU</w><w>(</w><w>iGPU</w><w>)</w></hi><w>,</w><w>and</w><w>is</w><w>not</w><w>what</w><w>is</w><w>used</w><w>for</w><w>machine</w><w>learning</w><w>purposes</w><pc>.</pc><w>For</w><w>that</w><w>,</w><w>you</w><w>need</w><w>a</w><hi rend="bold"><w>dedicated</w><w>(</w><w>or</w><w>discrete</w><w>)</w><w>GPU</w><w>(</w><w>dGPU</w><w>)</w></hi><w>,</w><w>which</w><w>is</w><w>the</w><w>type</w><w>of</w><w>GPU</w><w>this</w><w>lesson</w><w>is</w><w>referring</w><w>to</w><w>when</w><w>the</w><w>term</w><w>is</w><w>mentioned</w><pc>.</pc></p></div><div type="4" n="2.1.2"><head><w>Computer</w><w>Cores</w></head><p><w>So</w><w>why</w><w>are</w><w>GPUs</w><w>—a</w><w>computer</w><w>part</w><w>seemingly</w><w>meant</w><w>just</w><w>for</w><w>graphics</w><w>processing—</w><w>used</w><w>for</w><w>machine</w><w>learning</w><w>instead</w><w>of</w><w>CPUs</w><pc>?</pc><w>The</w><w>answer</w><w>to</w><w>this</w><w>lies</w><w>in</w><w>the</w><ref target="https://perma.cc/E7H2-V689"><w>``</w><w>cores</w><w>''</w></ref><w>of</w><w>each</w><w>component</w><pc>.</pc><w>Both</w><w>CPUs</w><w>and</w><w>GPUs</w><w>have</w><w>cores</w><w>which</w><w>are</w><w>where</w><w>the</w><w>actual</w><w>computation</w><w>happens</w><pc>.</pc><w>Since</w><w>the</w><w>CPU</w><w>has</w><w>to</w><w>prioritize</w><w>the</w><w>processing</w><w>of</w><w>instructions</w><w>while</w><w>also</w><w>performing</w><w>a</w><w>variety</w><w>of</w><w>operations</w><w>to</w><w>complete</w><w>tasks</w><w>related</w><w>to</w><w>previously</w><w>given</w><w>instructions</w><w>,</w><w>each</w><w>core</w><w>in</w><w>a</w><w>CPU</w><w>must</w><w>have</w><w>features</w><w>like</w><w>a</w><w>memory</w><w>cache</w><w>to</w><w>temporarily</w><w>store</w><w>data</w><w>and</w><w>internal</w><w>logic</w><w>that</w><w>allows</w><w>all</w><w>of</w><w>the</w><w>instructions</w><w>it</w><w>receives</w><w>to</w><w>be</w><w>processed</w><w>optimally</w><w>,</w><w>such</w><w>as</w><w>the</w><w>ability</w><w>to</w><w>reorder</w><w>or</w><w>reassign</w><w>tasks</w><w>to</w><w>each</w><w>core</w><w>as</w><w>they</w><w>finish</w><w>performing</w><w>a</w><w>previously</w><w>assigned</w><w>task</w><pc>.</pc><w>Due</w><w>to</w><w>this</w><w>necessary</w><w>complexity</w><w>,</w><w>a</w><w>CPU</w><w>often</w><w>only</w><w>has</w><w>between</w><w>two</w><w>and</w><w>eight</w><w>cores</w><w>in</w><w>order</w><w>for</w><w>your</w><w>computer</w><w>to</w><w>run</w><w>at</w><w>a</w><w>reasonable</w><w>speed</w><w>while</w><w>also</w><w>keeping</w><w>CPUs</w><w>compact</w><w>and</w><w>affordable</w><pc>.</pc><w>A</w><w>GPU</w><w>core</w><w>on</w><w>the</w><w>other</w><w>hand</w><w>does</w><w>not</w><w>need</w><w>all</w><w>of</w><w>the</w><w>specialized</w><w>features</w><w>which</w><w>a</w><w>CPU</w><w>core</w><w>has</w><w>;</w><w>a</w><w>GPU</w><w>core</w><w>simply</w><w>receives</w><w>the</w><w>input</w><w>given</w><w>to</w><w>it</w><w>,</w><w>performs</w><w>a</w><w>singular</w><w>task</w><w>,</w><w>and</w><w>then</w><w>provides</w><w>output</w><pc>.</pc><w>Since</w><w>GPU</w><w>cores</w><w>are</w><w>much</w><w>more</w><w>simplistic</w><w>in</w><w>their</w><w>operations</w><w>,</w><w>a</w><w>single</w><w>GPU</w><w>can</w><w>have</w><w>hundreds</w><w>of</w><w>cores</w><w>,</w><w>all</w><w>capable</w><w>of</w><w>processing</w><w>data</w><w>simultaneously</w><w>(</w><w>formally</w><w>known</w><w>as</w><ref target="https://perma.cc/YT3E-47F4"><w>parallelization</w><w>or</w><w>parallel</w><w>computing</w></ref><w>)</w><pc>.</pc></p></div><div type="4" n="2.1.3"><head><w>CUDA</w></head><p><w>If</w><w>you</w><w>want</w><w>to</w><w>perform</w><w>a</w><w>large</w><w>number</w><w>of</w><w>smaller</w><w>calculations</w><w>on</w><w>a</w><w>significant</w><w>amount</w><w>of</w><w>data</w><w>—in</w><w>essence</w><w>,</w><w>what</w><w>machine</w><w>learning</w><w>entails—</w><w>a</w><w>GPU</w><w>can</w><w>do</w><w>that</w><w>much</w><w>faster</w><w>than</w><w>a</w><w>CPU</w><w>because</w><w>the</w><w>processes</w><w>have</w><w>more</w><w>cores</w><w>to</w><w>be</w><w>distributed</w><w>across</w><w>,</w><w>and</w><w>so</w><w>more</w><w>data</w><w>can</w><w>be</w><w>processed</w><w>at</w><w>once</w><pc>.</pc><w>When</w><w>GPUs</w><w>first</w><w>began</w><w>to</w><w>be</w><w>used</w><w>by</w><w>researchers</w><w>to</w><w>speed</w><w>up</w><w>scientific</w><w>computing</w><w>,</w><w>the</w><w>researcher</w><w>would</w><w>have</w><w>to</w><w>map</w><w>their</w><w>problems</w><w>to</w><w>a</w><w>simple</w><w>graphic</w><w>output</w><w>,</w><w>such</w><w>as</w><w>generating</w><w>a</w><w>series</w><w>of</w><w>triangles</w><w>,</w><w>using</w><w>a</w><w>graphics</w><w>programming</w><w>language</w><w>which</w><w>the</w><w>GPU</w><w>understood</w><w>in</w><w>order</w><w>to</w><w>see</w><w>the</w><w>results</w><w>of</w><w>their</w><w>experiments</w><pc>.</pc><ref type="footnotemark" target="#en_note_2"/><w>This</w><w>was</w><w>a</w><w>very</w><w>time-consuming</w><w>endeavour</w><w>,</w><w>and</w><w>ultimately</w><w>what</w><w>prompted</w><w>the</w><w>creation</w><w>of</w><w>CUDA</w><w>as</w><w>a</w><w>solution</w><pc>.</pc><w>CUDA</w><w>is</w><w>a</w><w>parallel</w><w>computing</w><w>platform</w><w>that</w><w>works</w><w>with</w><w>common</w><w>programming</w><w>languages</w><w>such</w><w>as</w><w>C</w><w>and</w><w>C++</w><w>,</w><w>thus</w><w>eliminating</w><w>the</w><w>need</w><w>for</w><w>converting</w><w>problems</w><w>into</w><w>a</w><w>graphics</w><w>programming</w><w>language</w><w>when</w><w>using</w><w>a</w><w>GPU</w><w>for</w><w>general-purpose</w><w>computing</w><w>and</w><w>overall</w><w>simplifying</w><w>this</w><w>once-tedious</w><w>task</w><pc>.</pc><w>This</w><w>is</w><w>why</w><w>most</w><w>machine</w><w>learning</w><w>tasks</w><w>require</w><w>a</w><w>CUDA-enabled</w><w>GPU</w><w>,</w><w>because</w><w>the</w><w>software</w><w>used</w><w>to</w><w>create</w><w>and</w><w>train</w><w>models</w><w>communicates</w><w>with</w><w>your</w><w>GPU</w><w>through</w><w>CUDA</w><pc>.</pc><w>Note</w><w>that</w><w>CUDA</w><emph><w>is</w></emph><w>a</w><w>proprietary</w><w>software</w><w>created</w><w>by</w><ref target="https://perma.cc/3T6E-3KDW"><w>Nvidia</w></ref><w>,</w><w>thus</w><w>in</w><w>order</w><w>to</w><w>use</w><w>CUDA</w><w>,</w><w>you</w><w>must</w><w>have</w><w>a</w><w>GPU</w><w>manufactured</w><w>by</w><w>Nvidia</w><pc>.</pc></p></div></div><div type="3" n="2.2"><head><w>Cloud</w><w>GPUs</w></head><p><ref target="https://perma.cc/B4D7-U82B"><w>Cloud</w><w>computing</w></ref><w>allows</w><w>for</w><w>you</w><w>to</w><w>access</w><w>the</w><w>resources</w><w>of</w><w>another</w><w>computer</w><w>through</w><w>the</w><w>internet</w><w>;</w><w>similarly</w><w>,</w><w>a</w><w>cloud</w><w>GPU</w><w>allows</w><w>you</w><w>to</w><w>access</w><w>and</w><w>use</w><w>a</w><w>GPU</w><w>over</w><w>the</w><w>internet</w><pc>.</pc><w>If</w><w>you</w><w>do</w><w>not</w><w>have</w><w>a</w><w>GPU</w><w>you</w><w>can</w><w>use</w><w>for</w><w>this</w><w>lesson</w><w>,</w><w>Google</w><w>offers</w><w>two</w><w>accessible</w><w>cloud</w><w>GPU</w><w>services</w><w>that</w><w>have</w><w>a</w><w>free</w><w>tier</w><w>and</w><w>which</w><w>function</w><w>similarly</w><w>to</w><w>Jupyter</w><w>notebooks</w><w>,</w><w>using</w><w>the</w><w>same</w><code rend="inline"><w>.ipynb</w></code><w>format</w><w>:</w></p><list type="unordered"><item><ref target="https://perma.cc/QV5C-R2W5"><hi rend="bold"><w>Google</w><w>Colab</w></hi></ref><w>is</w><w>perhaps</w><w>the</w><w>most</w><w>well-known</w><w>of</w><w>these</w><w>services</w><pc>.</pc><w>You</w><w>can</w><w>enable</w><w>the</w><w>usage</w><w>of</w><w>a</w><w>GPU</w><w>in</w><w>Colab</w><w>by</w><w>creating</w><w>a</w><w>new</w><w>notebook</w><w>to</w><w>program</w><w>in</w><w>,</w><w>then</w><w>going</w><w>to</w><w>``</w><w>Runtime</w><w>''</w><w>in</w><w>the</w><w>menu</w><w>and</w><w>selecting</w><w>``</w><w>Change</w><w>runtime</w><w>type</w><w>''</w><w>&gt;</w><w>``</w><w>GPU</w><w>''</w><pc>.</pc><w>When</w><w>using</w><w>this</w><w>service</w><w>for</w><w>free</w><w>,</w><w>you</w><w>can</w><w>only</w><w>have</w><w>a</w><w>single</w><w>notebook</w><w>running</w><w>for</w><w>up</w><w>to</w><w>12</w><w>hours</w><w>at</w><w>a</w><w>time</w><w>,</w><w>which</w><w>is</w><w>more</w><w>than</w><w>enough</w><w>for</w><w>this</w><w>tutorial</w><pc>.</pc></item><item><ref target="https://perma.cc/YW9W-B9EJ"><hi rend="bold"><w>Kaggle</w></hi></ref><w>is</w><w>an</w><w>online</w><w>community</w><w>dedicated</w><w>to</w><w>data</w><w>science</w><w>and</w><w>machine</w><w>learning</w><pc>.</pc><w>It</w><w>hosts</w><w>competitions</w><w>,</w><w>courses</w><w>,</w><w>and</w><w>a</w><w>large</w><w>number</w><w>of</w><w>datasets</w><w>created</w><w>for</w><w>the</w><w>purpose</w><w>of</w><w>training</w><w>models</w><w>alongside</w><w>its</w><w>notebook</w><w>functionality</w><pc>.</pc><w>To</w><w>use</w><w>Kaggle</w><w>for</w><w>this</w><w>lesson</w><w>,</w><w>select</w><w>the</w><w>``</w><w>Code</w><w>''</w><w>tab</w><w>on</w><w>the</w><w>home</w><w>page</w><w>,</w><w>and</w><w>then</w><w>the</w><w>``</w><w>New</w><w>Notebook</w><w>''</w><w>button</w><pc>.</pc><w>In</w><w>the</w><w>``</w><w>Settings</w><w>''</w><w>tab</w><w>located</w><w>on</w><w>the</w><w>notebook</w><w>page</w><w>'s</w><w>sidebar</w><w>,</w><w>you</w><w>can</w><w>toggle</w><w>the</w><w>usage</w><w>of</w><w>a</w><w>GPU</w><w>under</w><w>the</w><w>``</w><w>Accelerator</w><w>''</w><w>label</w><pc>.</pc><w>Kaggle</w><w>limits</w><w>GPU</w><w>usage</w><w>to</w><w>30</w><w>hours</w><w>a</w><w>week</w><w>on</w><w>average</w><w>,</w><w>which</w><w>again</w><w>is</w><w>more</w><w>than</w><w>adequate</w><w>for</w><w>the</w><w>finetuning</w><w>being</w><w>performed</w><w>in</w><w>this</w><w>lesson</w><pc>.</pc></item></list><p><w>Note</w><w>that</w><w>both</w><w>services</w><w>are</w><w>web-based</w><w>and</w><w>require</w><w>you</w><w>to</w><w>have</w><w>an</w><w>account</w><w>with</w><w>the</w><w>site</w><pc>.</pc><w>To</w><w>follow</w><w>this</w><w>tutorial</w><w>using</w><w>either</w><w>of</w><w>these</w><w>services</w><w>,</w><w>you</w><w>can</w><w>enter</w><w>each</w><w>line</w><w>of</w><w>code</w><w>into</w><w>a</w><w>cell</w><w>in</w><w>your</w><w>notebook</w><w>and</w><w>hit</w><w>the</w><w>``</w><w>Run</w><w>''</w><w>button</w><w>to</w><w>run</w><w>the</w><w>code</w><pc>.</pc></p></div><div type="3" n="2.3"><head><w>Running</w><w>Locally</w></head><p><w>If</w><w>you</w><w>have</w><w>a</w><w>GPU</w><w>in</w><w>your</w><w>computer</w><w>that</w><w>meets</w><w>the</w><w>specifications</w><w>for</w><w>finetuning</w><w>GPT-2</w><w>,</w><w>then</w><w>you</w><w>may</w><w>follow</w><w>along</w><w>with</w><w>this</w><w>tutorial</w><w>using</w><w>your</w><w>own</w><w>device</w><pc>.</pc><w>In</w><w>order</w><w>to</w><w>do</w><w>so</w><w>,</w><w>follow</w><w>these</w><w>instructions</w><w>to</w><w>prepare</w><w>your</w><w>runtime</w><w>environment</w><w>:</w></p><p style="alert alert-warning"><w>This</w><w>set-up</w><w>process</w><w>involves</w><w>installing</w><w>large</w><w>packages</w><w>pulled</w><w>from</w><w>remote</w><w>(</w><w>i.e.</w><w>,</w><w>web-based</w><w>)</w><w>repositories</w><w>,</w><w>thus</w><w>it</w><w>may</w><w>take</w><w>up</w><w>to</w><w>an</w><w>hour</w><w>to</w><w>complete</w><w>if</w><w>your</w><w>internet</w><w>connection</w><w>is</w><w>not</w><w>strong</w><pc>.</pc></p><list type="ordered"><item><p><w>If</w><w>you</w><w>do</w><w>not</w><w>already</w><w>have</w><w>a</w><code rend="inline"><w>conda</w></code><w>distribution</w><w>installed</w><w>on</w><w>your</w><w>device</w><w>(</w><w>i.e.</w><w>,</w><w>Anaconda</w><w>or</w><w>Miniconda</w><w>)</w><w>,</w><w>install</w><ref target="https://perma.cc/7CVD-ZY4X"><w>Miniconda</w></ref><w>so</w><w>that</w><w>we</w><w>may</w><w>create</w><w>an</w><w>environment</w><w>for</w><w>this</w><w>lesson</w><w>and</w><w>download</w><w>all</w><w>dependencies</w><w>into</w><w>this</w><w>environment</w><w>rather</w><w>than</w><w>onto</w><w>your</w><w>computer</w><w>,</w><w>using</w><w>the</w><code rend="inline"><w>conda</w></code><w>package</w><w>manager</w><pc>.</pc></p></item><item><p><w>Once</w><w>Miniconda</w><w>is</w><w>installed</w><w>,</w><w>open</w><w>the</w><w>terminal</w><w>if</w><w>you</w><w>are</w><w>using</w><w>macOS</w><w>or</w><w>the</w><w>``</w><w>Miniconda</w><w>''</w><w>prompt</w><w>if</w><w>you</w><w>are</w><w>on</w><w>Windows</w><w>,</w><w>and</w><w>create</w><w>a</w><w>new</w><ref target="https://perma.cc/V4NS-QZ22"><w>environment</w></ref><w>using</w><w>the</w><w>command</w><w>:</w></p></item></list><ab><code xml:id="code_interrogating-national-narrative-gpt_0" corresp="code_interrogating-national-narrative-gpt_0.txt" rend="block"/></ab><p><w>Then</w><w>activate</w><w>the</w><w>environment</w><w>with</w><w>the</w><w>command</w><w>:</w></p><ab><code xml:id="code_interrogating-national-narrative-gpt_1" corresp="code_interrogating-national-narrative-gpt_1.txt" rend="block"/></ab><list type="ordered"><item><w>To</w><w>ensure</w><w>that</w><w>your</w><w>GPU</w><w>can</w><w>interact</w><w>with</w><w>the</w><w>CUDA</w><w>platform</w><w>correctly</w><w>,</w><w>you</w><w>must</w><w>first</w><w>install</w><ref target="https://perma.cc/5WJF-X86P"><w>cuDNN</w></ref><w>with</w><w>the</w><w>command</w><w>:</w></item></list><ab><code xml:id="code_interrogating-national-narrative-gpt_2" corresp="code_interrogating-national-narrative-gpt_2.txt" rend="block"/></ab><p><w>Then</w><w>you</w><w>must</w><w>install</w><w>the</w><ref target="https://perma.cc/9CFH-MS4Z"><w>CUDA</w><w>Toolkit</w></ref><w>with</w><w>this</w><w>command</w><w>:</w></p><ab><code xml:id="code_interrogating-national-narrative-gpt_3" corresp="code_interrogating-national-narrative-gpt_3.txt" rend="block"/></ab><list type="ordered"><item><w>Lastly</w><w>you</w><w>must</w><w>install</w><w>the</w><ref target="https://perma.cc/SD9L-ZT6W"><code rend="inline"><w>tensorflow-gpu</w></code></ref><w>Python</w><w>package</w><w>with</w><w>the</w><w>following</w><code rend="inline"><w>pip</w></code><w>command</w><w>:</w></item></list><ab><code xml:id="code_interrogating-national-narrative-gpt_4" corresp="code_interrogating-national-narrative-gpt_4.txt" rend="block"/></ab><p><w>To</w><w>verify</w><w>that</w><w>everything</w><w>was</w><w>installed</w><w>correctly</w><w>,</w><w>run</w><w>the</w><w>following</w><w>two</w><w>commands</w><w>individually</w><w>:</w></p><ab><code xml:id="code_interrogating-national-narrative-gpt_5" corresp="code_interrogating-national-narrative-gpt_5.txt" rend="block"/></ab><ab><code xml:id="code_interrogating-national-narrative-gpt_6" corresp="code_interrogating-national-narrative-gpt_6.txt" rend="block"/></ab><p><w>If</w><w>the</w><w>first</w><w>command</w><w>correctly</w><w>lists</w><w>your</w><w>GPU</w><w>and</w><w>the</w><w>next</w><w>command</w><w>runs</w><w>with</w><w>no</w><code rend="inline"><w>``</w><w>Could</w><w>not</w><w>load</w><w>dynamic</w><w>library</w><w>...</w><w>''</w></code><w>errors</w><w>,</w><w>then</w><w>you</w><w>are</w><w>ready</w><w>to</w><w>continue</w><w>the</w><w>lesson</w><pc>.</pc></p></div></div><div type="2" n="3"><head><w>Creating</w><w>our</w><w>GPT-2</w><w>Model</w></head><p><w>As</w><w>you</w><w>will</w><w>see</w><w>,</w><w>the</w><w>actual</w><w>code</w><w>for</w><w>this</w><w>tutorial</w><w>is</w><w>quite</w><w>minimal</w><w>;</w><w>when</w><w>it</w><w>comes</w><w>to</w><w>finetuning</w><w>a</w><w>pre-trained</w><w>model</w><w>,</w><w>the</w><w>power</w><w>lies</w><w>in</w><w>how</w><w>you</w><w>modify</w><w>the</w><w>parameters</w><pc>.</pc></p><p><w>The</w><w>last</w><w>step</w><w>before</w><w>we</w><w>begin</w><w>training</w><w>is</w><w>to</w><w>install</w><code rend="inline"><w>aitextgen</w></code><w>,</w><w>the</w><w>library</w><w>we</w><w>will</w><w>use</w><w>for</w><w>training</w><w>and</w><w>generating</w><w>text</w><w>via</w><w>GPT-2</w><pc>.</pc><w>If</w><w>you</w><w>are</w><w>following</w><w>along</w><w>with</w><w>this</w><w>tutorial</w><w>using</w><w>Jupyter</w><w>Notebook</w><w>or</w><w>one</w><w>of</w><w>the</w><w>cloud</w><w>GPU</w><w>services</w><w>covered</w><w>previously</w><w>,</w><w>you</w><w>will</w><w>enter</w><w>and</w><w>run</w><w>the</w><w>following</w><w>into</w><w>a</w><w>new</w><w>cell</w><w>:</w></p><ab><code xml:id="code_interrogating-national-narrative-gpt_7" corresp="code_interrogating-national-narrative-gpt_7.txt" rend="block"/></ab><p><w>If</w><w>you</w><w>are</w><w>using</w><w>your</w><w>own</w><w>device</w><w>,</w><w>you</w><w>can</w><w>enter</w><w>this</w><w>same</w><w>command</w><hi rend="bold"><w>without</w></hi><w>the</w><w>beginning</w><w>exclamation</w><w>mark</w><w>in</w><w>the</w><w>command</w><w>line</w><w>window</w><w>that</w><w>has</w><w>your</w><code rend="inline"><w>conda</w></code><w>environment</w><w>activated</w><pc>.</pc><w>To</w><w>ensure</w><w>that</w><w>this</w><w>tutorial</w><w>functions</w><w>as</w><w>intended</w><w>,</w><w>we</w><w>are</w><w>downloading</w><w>the</w><w>version</w><w>of</w><code rend="inline"><w>aitextgen</w></code><w>that</w><w>is</w><w>being</w><w>used</w><w>at</w><w>the</w><w>time</w><w>of</w><w>writing</w><pc>.</pc><w>If</w><w>you</w><w>would</w><w>like</w><w>to</w><w>attempt</w><w>the</w><w>tutorial</w><w>using</w><w>the</w><w>latest</w><w>version</w><w>,</w><w>then</w><w>you</w><w>can</w><w>remove</w><code rend="inline"><w>==0.5.2</w></code><w>from</w><w>the</w><w>end</w><w>of</w><w>this</w><w>command</w><pc>.</pc></p><p><w>After</w><w>this</w><w>,</w><w>we</w><w>begin</w><w>the</w><w>actual</w><w>Python</w><w>script</w><pc>!</pc><w>The</w><w>import</w><w>statement</w><w>needed</w><w>at</w><w>the</w><w>top</w><w>of</w><w>the</w><w>script</w><w>(</w><w>both</w><w>for</w><w>those</w><w>doing</w><w>the</w><w>tutorial</w><w>locally</w><w>and</w><w>those</w><w>using</w><w>a</w><w>cloud</w><w>GPU</w><w>service</w><w>)</w><w>is</w><w>:</w></p><ab><code xml:id="code_interrogating-national-narrative-gpt_8" corresp="code_interrogating-national-narrative-gpt_8.txt" rend="block"/></ab><p><w>Kaggle</w><w>and</w><w>Colab</w><w>both</w><w>have</w><code rend="inline"><w>tensorflow-gpu</w></code><w>activated</w><w>by</w><w>default</w><w>,</w><w>so</w><w>an</w><w>import</w><w>statement</w><w>for</w><w>this</w><w>is</w><w>n't</w><w>necessary</w><w>;</w><w>but</w><w>,</w><w>if</w><w>you</w><w>are</w><w>writing</w><w>this</w><w>script</w><w>on</w><w>your</w><w>own</w><w>device</w><w>then</w><w>you</w><w>should</w><w>include</w><w>the</w><w>following</w><w>import</w><w>statement</w><w>so</w><w>that</w><w>your</w><w>program</w><w>recognizes</w><w>and</w><w>uses</w><w>your</w><w>GPU</w><w>:</w></p><ab><code xml:id="code_interrogating-national-narrative-gpt_9" corresp="code_interrogating-national-narrative-gpt_9.txt" rend="block"/></ab><p><w>Next</w><w>,</w><w>we</w><w>have</w><w>to</w><w>select</w><w>and</w><w>load</w><w>the</w><w>GPT-2</w><w>model</w><w>we</w><w>want</w><w>to</w><w>finetune</w><pc>.</pc><w>Do</w><w>so</w><w>by</w><w>adding</w><w>your</w><w>next</w><w>line</w><w>of</w><w>code</w><w>,</w><w>which</w><w>states</w><w>your</w><w>chosen</w><w>model</w><w>and</w><w>confirms</w><w>that</w><w>you</w><w>want</w><w>the</w><w>code</w><w>to</w><w>call</w><w>upon</w><w>your</w><w>GPU</w><w>to</w><w>run</w><w>:</w></p><ab><code xml:id="code_interrogating-national-narrative-gpt_10" corresp="code_interrogating-national-narrative-gpt_10.txt" rend="block"/></ab><p><w>For</w><w>this</w><w>tutorial</w><w>,</w><w>as</w><w>stated</w><w>previously</w><w>,</w><w>we</w><w>are</w><w>using</w><w>the</w><w>smallest</w><w>available</w><code rend="inline"><w>124M</w></code><w>GPT-2</w><w>model</w><w>to</w><w>reduce</w><w>training</w><w>time</w><w>and</w><w>save</w><w>memory</w><w>,</w><w>as</w><w>the</w><w>``</w><w>medium</w><w>''</w><code rend="inline"><w>355M</w></code><w>model</w><w>and</w><w>the</w><w>``</w><w>large</w><w>''</w><code rend="inline"><w>774M</w></code><w>model</w><w>will</w><w>take</w><w>longer</w><w>to</w><w>train</w><w>and</w><w>depending</w><w>on</w><w>your</w><w>GPU</w><w>and</w><w>the</w><w>size</w><w>of</w><w>your</w><w>dataset</w><w>,</w><w>may</w><w>be</w><w>too</w><w>large</w><w>to</w><w>complete</w><w>training</w><w>without</w><w>running</w><w>out</w><w>of</w><w>memory</w><pc>.</pc><w>Since</w><w>GPU</w><w>cores</w><w>do</w><w>not</w><w>have</w><w>a</w><w>memory</w><w>cache</w><w>in</w><w>the</w><w>same</w><w>capacity</w><w>as</w><w>a</w><w>CPU</w><w>core</w><w>,</w><w>the</w><w>GPU</w><w>itself</w><w>comes</w><w>with</w><w>VRAM</w><w>which</w><w>is</w><w>used</w><w>to</w><w>temporarily</w><w>store</w><w>the</w><w>data</w><w>needed</w><w>within</w><w>the</w><w>GPU</w><w>while</w><w>performing</w><w>calculations</w><pc>.</pc><w>During</w><w>the</w><w>process</w><w>of</w><w>training</w><w>,</w><w>data</w><w>is</w><w>sent</w><w>in</w><w>batches</w><w>to</w><w>the</w><w>GPU</w><w>along</w><w>with</w><w>the</w><w>model</w><w>and</w><w>eventually</w><w>,</w><w>the</w><w>growing</w><w>output</w><w>;</w><w>if</w><w>these</w><w>combined</w><w>factors</w><w>exceed</w><w>the</w><w>amount</w><w>of</w><w>VRAM</w><w>available</w><w>on</w><w>your</w><w>GPU</w><w>,</w><w>you</w><w>will</w><w>get</w><w>an</w><w>error</w><w>that</w><w>looks</w><w>like</w><w>this</w><w>:</w></p><ab><code xml:id="code_interrogating-national-narrative-gpt_11" corresp="code_interrogating-national-narrative-gpt_11.txt" rend="block"/></ab><p><w>In</w><w>plain</w><w>language</w><w>,</w><w>this</w><w>error</w><w>is</w><w>stating</w><w>that</w><w>it</w><w>needed</w><w>198</w><w>MB</w><w>of</w><w>space</w><w>to</w><w>continue</w><w>training</w><w>,</w><w>but</w><w>there</w><w>was</w><w>only</w><w>189.75</w><w>MB</w><w>of</w><w>space</w><w>available</w><w>on</w><w>your</w><w>GPU</w><w>and</w><w>thus</w><w>training</w><w>could</w><w>not</w><w>continue</w><pc>!</pc><w>To</w><w>get</w><w>around</w><w>this</w><w>error</w><w>,</w><w>you</w><w>can</w><w>decrease</w><w>the</w><w>batch</w><w>size</w><w>(</w><w>data</w><w>being</w><w>sent</w><w>to</w><w>your</w><w>GPU</w><w>)</w><w>but</w><w>more</w><w>often</w><w>than</w><w>not</w><w>it</w><w>is</w><w>a</w><w>limitation</w><w>of</w><w>your</w><w>hardware</w><w>which</w><w>can</w><w>be</w><w>fixed</w><w>by</w><w>training</w><w>with</w><w>a</w><w>smaller</w><w>model</w><w>(</w><w>assuming</w><w>you</w><w>do</w><w>not</w><w>wish</w><w>to</w><w>reduce</w><w>the</w><w>amount</w><w>of</w><w>data</w><w>you</w><w>are</w><w>using</w><w>)</w><pc>.</pc></p><p><w>After</w><w>loading</w><w>the</w><w>model</w><w>,</w><w>you</w><w>can</w><w>now</w><w>import</w><w>the</w><w>text</w><w>file</w><w>which</w><w>contains</w><w>the</w><w>data</w><w>you</w><w>will</w><w>be</w><w>using</w><w>for</w><w>training</w><w>by</w><w>adding</w><w>this</w><w>line</w><w>:</w></p><ab><code xml:id="code_interrogating-national-narrative-gpt_12" corresp="code_interrogating-national-narrative-gpt_12.txt" rend="block"/></ab><p><w>The</w><w>data</w><w>can</w><w>be</w><w>downloaded</w><w>from</w><ref target="/assets/interrogating-national-narrative-gpt/articles.txt"><w>here</w></ref><w>in</w><w>case</w><w>you</w><w>did</w><w>not</w><w>download</w><w>it</w><w>when</w><w>it</w><w>was</w><w>linked</w><w>earlier</w><w>in</w><w>this</w><w>lesson</w><pc>.</pc><w>If</w><w>you</w><w>are</w><w>using</w><w>a</w><w>cloud</w><w>GPU</w><w>service</w><w>,</w><w>you</w><w>must</w><w>upload</w><w>the</w><w>file</w><w>to</w><w>use</w><w>it</w><w>in</w><w>your</w><w>program</w><pc>.</pc><w>If</w><w>you</w><w>are</w><w>following</w><w>along</w><w>using</w><w>your</w><w>own</w><w>device</w><w>,</w><w>you</w><w>must</w><w>include</w><w>this</w><w>file</w><w>in</w><w>the</w><w>same</w><w>directory</w><w>that</w><w>your</w><w>script</w><w>is</w><w>being</w><w>run</w><w>in</w><pc>.</pc></p><p><w>At</w><w>last</w><w>,</w><w>we</w><w>are</w><w>now</w><w>ready</w><w>to</w><w>begin</w><w>retraining</w><w>GPT-2</w><w>with</w><w>our</w><w>own</w><w>data</w><pc>!</pc><w>This</w><w>is</w><w>done</w><w>in</w><w>a</w><w>single</w><w>line</w><w>of</w><w>code</w><w>specifying</w><w>the</w><emph><w>hyperparameters</w></emph><w>:</w></p><ab><code xml:id="code_interrogating-national-narrative-gpt_13" corresp="code_interrogating-national-narrative-gpt_13.txt" rend="block"/></ab><p><w>In</w><w>machine</w><w>learning</w><w>,</w><w>a</w><w>hyperparameter</w><w>is</w><w>a</w><w>parameter</w><w>set</w><w>manually</w><w>prior</w><w>to</w><w>training</w><w>that</w><w>outlines</w><w>how</w><w>the</w><w>model</w><w>approaches</w><w>learning</w><w>from</w><w>the</w><w>data</w><w>it</w><w>is</w><w>given</w><w>;</w><w>this</w><w>is</w><w>different</w><w>from</w><w>the</w><w>124</w><w>million</w><w>parameters</w><w>contained</w><w>in</w><w>the</w><w>GPT-2</w><w>model</w><w>we</w><w>are</w><w>using</w><w>,</w><w>which</w><w>are</w><w>determined</w><w>through</w><w>running</w><w>the</w><w>training</w><w>dataset</w><pc>.</pc><w>To</w><w>expand</w><w>upon</w><w>the</w><w>parameters</w><w>we</w><w>use</w><w>for</w><w>our</w><w>code</w><w>:</w></p><p><code rend="inline"><w>num_steps</w></code><w>:</w><w>This</w><w>refers</w><w>to</w><w>the</w><w>number</w><w>of</w><w>``</w><w>steps</w><w>''</w><w>to</w><w>train</w><w>the</w><w>model</w><w>for</w><pc>.</pc><w>In</w><w>each</w><w>step</w><w>,</w><w>1024</w><w>tokens</w><w>from</w><w>your</w><w>dataset</w><w>are</w><w>passed</w><w>to</w><w>the</w><w>model</w><pc>.</pc><w>To</w><w>calculate</w><w>the</w><w>minimum</w><w>number</w><w>of</w><w>steps</w><w>your</w><w>model</w><w>should</w><w>have</w><w>,</w><w>divide</w><w>the</w><w>number</w><w>of</w><w>tokens</w><w>in</w><w>your</w><w>dataset</w><w>by</w><w>1024</w><w>—</w><w>this</w><w>number</w><w>is</w><w>the</w><w>amount</w><w>of</w><w>steps</w><w>needed</w><w>for</w><w>all</w><w>of</w><w>your</w><w>data</w><w>to</w><w>have</w><w>been</w><w>seen</w><w>at</w><w>least</w><w>once</w><w>by</w><w>the</w><w>model</w><pc>.</pc><w>Ideally</w><w>,</w><w>though</w><w>,</w><w>the</w><w>number</w><w>of</w><w>steps</w><w>should</w><w>be</w><w>higher</w><w>than</w><w>this</w><w>minimum</w><w>as</w><w>the</w><w>model</w><w>outcomes</w><w>are</w><w>best</w><w>when</w><w>it</w><w>sees</w><w>the</w><w>same</w><w>data</w><w>more</w><w>than</w><w>once</w><w>,</w><w>allowing</w><w>for</w><w>it</w><w>to</w><w>gauge</w><w>improvement</w><pc>.</pc></p><p><code rend="inline"><w>generate_every</w></code><w>:</w><w>At</w><w>the</w><w>interval</w><w>of</w><w>steps</w><w>specified</w><w>with</w><w>this</w><w>hyperparameter</w><w>,</w><w>the</w><w>model</w><w>will</w><w>print</w><w>randomly</w><w>generated</w><w>text</w><w>which</w><w>can</w><w>be</w><w>used</w><w>to</w><w>validate</w><w>improvement</w><w>over</w><w>the</w><w>course</w><w>of</w><w>training</w><pc>.</pc><w>Since</w><code rend="inline"><w>num_steps</w></code><w>is</w><w>currently</w><w>set</w><w>to</w><w>3000</w><w>and</w><code rend="inline"><w>generate_every</w></code><w>is</w><w>1000</w><w>,</w><w>there</w><w>will</w><w>be</w><w>three</w><w>instances</w><w>where</w><w>the</w><w>model</w><w>outputs</w><w>randomly</w><w>generated</w><w>text</w><w>;</w><w>if</w><w>you</w><w>'d</w><w>like</w><w>to</w><w>see</w><w>how</w><w>the</w><w>text</w><w>your</w><w>model</w><w>generates</w><w>is</w><w>changing</w><w>(</w><w>and</w><w>,</w><w>ideally</w><w>,</w><w>improving</w><w>)</w><w>more</w><w>frequently</w><w>than</w><w>every</w><w>1000</w><w>steps</w><w>,</w><w>you</w><w>could</w><w>change</w><w>this</w><w>hyperparameter</w><w>to</w><w>something</w><w>like</w><w>500</w><pc>.</pc></p><p><code rend="inline"><w>save_every</w></code><w>:</w><w>When</w><w>this</w><w>interval</w><w>of</w><w>steps</w><w>is</w><w>reached</w><w>,</w><w>the</w><w>model</w><w>is</w><w>saved</w><w>to</w><w>the</w><code rend="inline"><w>/trained_model</w></code><w>folder</w><w>so</w><w>that</w><w>if</w><w>something</w><w>goes</w><w>wrong</w><w>while</w><w>you</w><w>are</w><w>training</w><w>and</w><w>the</w><w>training</w><w>must</w><w>halt</w><w>,</w><w>you</w><w>can</w><ref target="https://perma.cc/AFE6-SBJZ"><w>can</w><w>continue</w><w>your</w><w>training</w><w>from</w><w>this</w><w>lastest</w><w>save</w><w>point</w></ref><pc>.</pc></p><p><code rend="inline"><w>learning_rate</w></code><w>:</w><w>For</w><w>each</w><w>step</w><w>,</w><w>your</w><w>model</w><w>generates</w><w>a</w><w>random</w><w>sample</w><w>of</w><w>text</w><w>and</w><w>then</w><w>compares</w><w>this</w><w>to</w><w>the</w><w>original</w><w>text</w><w>;</w><w>this</w><w>process</w><w>is</w><w>how</w><w>your</w><w>model</w><w>learns</w><pc>!</pc><w>In</w><w>machine</w><w>learning</w><w>,</w><w>the</w><w>``</w><w>learning</w><w>rate</w><w>''</w><w>controls</w><w>how</w><w>``</w><w>big</w><w>''</w><w>each</w><w>of</w><w>these</w><w>steps</w><w>are</w><w>,</w><w>determining</w><w>how</w><w>significantly</w><w>the</w><w>model</w><w>must</w><w>be</w><w>altered</w><w>in</w><w>the</w><w>next</w><w>step</w><w>based</w><w>on</w><w>how</w><w>different</w><w>the</w><w>generated</w><w>text</w><w>is</w><w>from</w><w>the</w><w>original</w><w>text</w><pc>.</pc><w>The</w><w>series</w><w>of</w><w>calculations</w><w>behind</w><w>this</w><w>are</w><w>formally</w><w>known</w><w>as</w><w>a</w><ref target="https://perma.cc/BYZ7-FJK2"><w>gradient</w><w>descent</w><w>algorithm</w></ref><w>,</w><w>but</w><w>for</w><w>this</w><w>tutorial</w><w>I</w><w>will</w><w>spare</w><w>you</w><w>the</w><w>details</w><w>of</w><w>linear</w><w>algebra</w><w>and</w><w>calculus</w><w>(</w><w>although</w><ref target="https://perma.cc/BDS8-CELC"><w>here</w></ref><w>is</w><w>a</w><w>more</w><w>in-depth</w><w>article</w><w>should</w><w>you</w><w>wish</w><w>to</w><w>learn</w><w>the</w><w>details</w><w>)</w><w>and</w><w>instead</w><w>explain</w><w>the</w><w>concept</w><w>behind</w><w>this</w><w>algorithm</w><w>using</w><w>an</w><w>analogy</w><w>to</w><w>make</w><w>things</w><w>more</w><w>digestible</w><pc>.</pc></p><div type="3" n="3.1"><head><w>Gradient</w><w>Descent</w><w>Explained</w></head><p><w>There</w><w>is</w><w>an</w><w>archaeologist</w><w>working</w><w>at</w><w>a</w><w>dig</w><w>site</w><w>,</w><w>and</w><w>presently</w><w>,</w><w>they</w><w>are</w><w>standing</w><w>on</w><w>the</w><w>edge</w><w>of</w><w>a</w><w>trench</w><pc>.</pc><w>In</w><w>a</w><w>gradient</w><w>descent</w><w>algorithm</w><w>,</w><w>this</w><w>archaeologist</w><w>represents</w><w>the</w><w>starting</w><w>point</w><w>(</w><w>i.e.</w><w>,</w><w>your</w><w>untrained</w><w>model</w><w>)</w><w>and</w><w>the</w><w>trench</w><w>is</w><w>the</w><ref target="https://perma.cc/LHA7-N627"><w>gradient</w></ref><w>,</w><w>a</w><ref target="https://www.researchgate.net/profile/Jesper-Christensen-8/publication/284419329/figure/fig8/AS:669960540004354@1536742448305/example-of-a-continuous-convex-function.jpg"><w>convex</w><w>function</w></ref><w>,</w><w>which</w><w>must</w><w>be</w><w>traversed</w><pc>.</pc></p><p><w>The</w><w>archaeologist</w><w>notices</w><w>a</w><w>large</w><ref target="https://perma.cc/W7V6-RYPT"><w>amphora</w></ref><w>at</w><w>the</w><w>bottom</w><w>of</w><w>this</w><w>deep</w><w>trench</w><w>–</w><w>they</w><w>must</w><w>retrieve</w><w>it</w><pc>!</pc><w>Here</w><w>,</w><w>the</w><w>amphora</w><w>represents</w><w>our</w><w>original</w><w>text</w><w>that</w><w>the</w><w>generated</w><w>text</w><w>is</w><w>striving</w><w>to</w><w>resemble</w><w>,</w><w>which</w><w>is</w><w>also</w><w>the</w><ref target="https://perma.cc/W8QH-TMLH"><w>global</w><w>minimum</w></ref><w>of</w><w>our</w><w>gradient</w><pc>.</pc><w>The</w><w>archaeologist</w><w>must</w><w>plan</w><w>how</w><w>they</w><w>will</w><w>descend</w><w>into</w><w>this</w><w>steep</w><w>trench</w><w>in</w><w>order</w><w>to</w><w>retrieve</w><w>the</w><w>amphora</w><w>,</w><w>and</w><w>the</w><w>way</w><w>they</w><w>choose</w><w>to</w><w>mentally</w><w>calculate</w><w>each</w><w>careful</w><w>step</w><w>they</w><w>take</w><w>downwards</w><w>is</w><w>the</w><w>learning</w><w>rate</w><pc>.</pc></p><p><w>While</w><w>training</w><w>your</w><w>model</w><w>you</w><w>will</w><w>see</w><w>lines</w><w>outputted</w><w>that</w><w>look</w><w>like</w><w>so</w><w>:</w></p><ab><code xml:id="code_interrogating-national-narrative-gpt_14" corresp="code_interrogating-national-narrative-gpt_14.txt" rend="block"/></ab><p><w>Here</w><w>,</w><w>``</w><w>loss</w><w>''</w><w>is</w><w>a</w><w>way</w><w>to</w><w>gauge</w><w>how</w><w>your</w><w>model</w><w>is</w><w>performing</w><w>,</w><w>with</w><w>the</w><w>number</w><w>representing</w><w>how</w><w>similar</w><w>your</w><w>generated</w><w>text</w><w>is</w><w>to</w><w>the</w><w>original</w><w>text</w><pc>.</pc><w>Much</w><w>like</w><w>how</w><w>the</w><w>distance</w><w>between</w><w>the</w><w>archaeologist</w><w>and</w><w>the</w><w>amphora</w><w>decreases</w><w>as</w><w>they</w><w>descend</w><w>and</w><w>subsequently</w><w>get</w><w>closer</w><w>to</w><w>it</w><w>,</w><w>as</w><w>your</w><w>model</w><w>trains</w><w>it</w><w>should</w><w>be</w><w>improving</w><w>with</w><w>each</w><w>step</w><w>;</w><w>assuming</w><w>the</w><w>learning</w><w>rate</w><w>is</w><w>set</w><w>correctly</w><w>,</w><w>this</w><w>should</w><w>result</w><w>in</w><w>the</w><w>loss</w><w>decreasing</w><pc>.</pc></p><p><w>In</w><w>an</w><w>ideal</w><w>situation</w><w>,</w><w>the</w><w>archaeologist</w><w>would</w><w>be</w><w>able</w><w>to</w><w>perfectly</w><w>calculate</w><w>each</w><w>step</w><w>down</w><w>the</w><w>trench</w><w>towards</w><w>the</w><w>amphora</w><w>,</w><w>but</w><w>alas</w><w>,</w><w>life</w><w>is</w><w>not</w><w>perfect</w><pc>.</pc><w>If</w><w>the</w><w>archaeologist</w><w>'s</w><w>steps</w><w>downward</w><w>are</w><w>too</w><w>small</w><w>,</w><w>they</w><w>may</w><w>get</w><w>stuck</w><w>and</w><w>become</w><w>unable</w><w>to</w><w>progress</w><w>further</w><pc>.</pc><w>Similarly</w><w>,</w><w>if</w><w>the</w><w>archaeologist</w><w>decides</w><w>to</w><w>take</w><w>drastic</w><w>measures</w><w>such</w><w>as</w><w>making</w><w>use</w><w>of</w><w>a</w><w>wingsuit</w><w>to</w><w>get</w><w>to</w><w>the</w><w>amphora</w><w>quickly</w><w>,</w><w>their</w><w>``</w><w>steps</w><w>''</w><w>may</w><w>be</w><w>too</w><w>large</w><w>and</w><w>they</w><w>'ll</w><w>miss</w><w>the</w><w>amphora</w><w>entirely</w><pc>!</pc><w>Likewise</w><w>,</w><w>during</w><w>training</w><w>,</w><w>if</w><w>the</w><w>learning</w><w>rate</w><w>is</w><w>set</w><w>to</w><w>too</w><w>small</w><w>a</w><w>value</w><w>then</w><w>our</w><w>model</w><w>will</w><w>take</w><w>a</w><w>very</w><w>long</w><w>time</w><w>to</w><w>train</w><w>and</w><w>may</w><w>get</w><w>stuck</w><w>on</w><w>a</w><ref target="https://upload.wikimedia.org/wikipedia/commons/6/68/Extrema_example_original.svg"><w>local</w><w>minimum</w></ref><w>instead</w><w>of</w><w>reaching</w><w>the</w><w>global</w><w>minimum</w><w>as</w><w>it</w><w>should</w><w>since</w><w>the</w><w>model</w><w>changes</w><w>so</w><w>insignificantly</w><w>from</w><w>one</w><w>step</w><w>to</w><w>the</w><w>next</w><w>(</w><w>Figure</w><w>1</w><w>)</w><pc>.</pc><w>If</w><w>the</w><w>learning</w><w>rate</w><w>is</w><w>too</w><w>large</w><w>,</w><w>then</w><w>the</w><w>model</w><w>will</w><w>train</w><w>too</w><w>quickly</w><w>and</w><w>overstep</w><w>the</w><w>global</w><w>minimum</w><w>since</w><w>it</w><w>is</w><w>altered</w><w>so</w><w>dramatically</w><w>at</w><w>each</w><w>step</w><w>(</w><w>Figure</w><w>2</w><w>)</w><pc>.</pc></p><figure><desc><w>Visual</w><w>aid</w><w>demonstrating</w><w>a</w><w>learning</w><w>rate</w><w>that</w><w>is</w><w>too</w><w>small</w></desc><figDesc><w>There</w><w>is</w><w>an</w><w>amphora</w><w>at</w><w>the</w><w>bottom</w><w>of</w><w>a</w><w>gorge</w><w>representing</w><w>the</w><w>original</w><w>text/local</w><w>minimum</w><pc>.</pc><w>A</w><w>figure</w><w>which</w><w>represents</w><w>our</w><w>model</w><w>is</w><w>attempting</w><w>to</w><w>climb</w><w>down</w><w>the</w><w>steep</w><w>cliff</w><w>to</w><w>retrieve</w><w>the</w><w>amphora</w><w>,</w><w>but</w><w>they</w><w>are</w><w>taking</w><w>many</w><w>,</w><w>overly</w><w>cautious</w><w>steps</w><w>which</w><w>result</w><w>in</w><w>them</w><w>getting</w><w>stuck</w><w>when</w><w>a</w><w>bigger</w><w>step</w><w>is</w><w>needed</w><pc>.</pc></figDesc><graphic url="interrogating-national-narrative-gpt-1.png"/></figure><figure><desc><w>Visual</w><w>aid</w><w>demonstrating</w><w>a</w><w>learning</w><w>rate</w><w>that</w><w>is</w><w>too</w><w>large</w></desc><figDesc><w>There</w><w>is</w><w>an</w><w>amphora</w><w>at</w><w>the</w><w>bottom</w><w>of</w><w>a</w><w>gorge</w><w>representing</w><w>the</w><w>original</w><w>text/local</w><w>minimum</w><pc>.</pc><w>A</w><w>figure</w><w>which</w><w>represents</w><w>our</w><w>model</w><w>is</w><w>attempting</w><w>to</w><w>drop</w><w>down</w><w>the</w><w>steep</w><w>cliff</w><w>to</w><w>retrieve</w><w>the</w><w>amphora</w><w>using</w><w>a</w><w>wingsuit</w><pc>.</pc><w>The</w><w>wingsuit</w><w>results</w><w>in</w><w>steps</w><w>so</w><w>large</w><w>that</w><w>the</w><w>figure</w><w>complete</w><w>overshoots</w><w>the</w><w>amphora</w><w>and</w><w>ends</w><w>up</w><w>on</w><w>the</w><w>other</w><w>side</w><w>of</w><w>the</w><w>gorge</w><pc>.</pc></figDesc><graphic url="interrogating-national-narrative-gpt-2.png"/></figure><p><w>There</w><w>is</w><w>n't</w><w>a</w><w>straightforward</w><w>way</w><w>of</w><w>choosing</w><w>the</w><w>perfect</w><w>learning</w><w>rate</w><w>for</w><w>your</w><w>model</w><w>;</w><w>it</w><w>is</w><w>mostly</w><w>a</w><w>process</w><w>of</w><w>trial</w><w>and</w><w>error</w><pc>.</pc><w>In</w><w>this</w><w>tutorial</w><w>,</w><w>we</w><w>are</w><w>using</w><w>the</w><w>standard</w><w>learning</w><w>rate</w><w>of</w><code rend="inline"><w>1e-3</w></code><w>(</w><w>0.001</w><w>)</w><w>since</w><w>it</w><w>works</w><w>for</w><w>the</w><w>data</w><w>given</w><w>,</w><w>but</w><w>should</w><w>you</w><w>choose</w><w>to</w><w>use</w><w>your</w><w>own</w><w>data</w><w>the</w><w>learning</w><w>rate</w><w>may</w><w>have</w><w>to</w><w>be</w><w>changed</w><pc>.</pc><w>If</w><w>while</w><w>you</w><w>'re</w><w>training</w><w>you</w><w>notice</w><w>the</w><w>loss</w><w>decreasing</w><w>insignificantly</w><w>or</w><w>not</w><w>at</w><w>all</w><w>,</w><w>this</w><w>means</w><w>your</w><w>model</w><w>is</w><w>not</w><w>learning</w><pc>.</pc><w>It</w><w>is</w><w>more</w><w>common</w><w>for</w><w>a</w><w>learning</w><w>rate</w><w>to</w><w>be</w><w>too</w><w>large</w><w>,</w><w>thus</w><w>the</w><w>first</w><w>correction</w><w>attempt</w><w>that</w><w>should</w><w>be</w><w>made</w><w>is</w><w>reducing</w><w>the</w><w>learning</w><w>rate</w><w>(</w><w>i.e.</w><w>,</w><code rend="inline"><w>1e-3</w></code><w>can</w><w>be</w><w>changed</w><w>to</w><code rend="inline"><w>1e-4</w></code><w>)</w><pc>.</pc></p><p><code rend="inline"><w>batch_size</w></code><w>:</w><w>This</w><w>is</w><w>the</w><w>number</w><w>of</w><w>batches</w><w>in</w><w>which</w><w>the</w><w>training</w><w>set</w><w>is</w><w>split</w><w>during</w><w>the</w><w>training</w><w>loop</w><w>occurring</w><w>during</w><w>each</w><w>step</w><pc>.</pc><w>For</w><w>example</w><w>,</w><w>if</w><w>you</w><w>have</w><w>a</w><w>file</w><w>that</w><w>has</w><w>500</w><w>tokens</w><w>of</w><w>data</w><w>and</w><w>you</w><w>set</w><w>the</w><code rend="inline"><w>batch_size</w></code><w>to</w><w>five</w><w>,</w><w>the</w><w>data</w><w>will</w><w>be</w><w>divided</w><w>into</w><w>100</w><w>batches</w><w>(</w><w>500/5</w><w>)</w><w>with</w><w>each</w><w>batch</w><w>containing</w><w>five</w><w>samples</w><w>from</w><w>the</w><w>data</w><pc>.</pc><w>Batch</w><w>size</w><w>is</w><w>limited</w><w>by</w><w>the</w><w>hardware</w><w>being</w><w>used</w><w>,</w><w>so</w><w>by</w><w>default</w><w>having</w><w>one</w><w>batch</w><w>reduces</w><w>the</w><w>likelihood</w><w>of</w><w>an</w><w>out-of-memory</w><w>error</w><w>occurring</w><pc>.</pc></p><p><w>We</w><w>tune</w><w>hyperparameters</w><w>of</w><w>a</w><w>model</w><w>to</w><w>discover</w><w>what</w><w>settings</w><w>produce</w><w>the</w><w>model</w><w>parameters</w><w>with</w><w>the</w><w>best</w><w>predictive</w><w>ability</w><pc>.</pc><w>There</w><w>are</w><w>general</w><w>hyperparameters</w><w>such</w><w>as</w><w>the</w><w>ones</w><w>given</w><w>that</w><w>work</w><w>for</w><w>most</w><w>datasets</w><w>,</w><w>but</w><w>trial</w><w>and</w><w>error</w><w>through</w><w>repeat</w><w>training</w><w>and</w><w>adjustments</w><w>are</w><w>the</w><w>only</w><w>true</w><w>way</w><w>to</w><w>discover</w><w>the</w><w>``</w><w>best</w><w>''</w><w>values</w><pc>.</pc></p><p><w>Your</w><w>model</w><w>will</w><w>take</w><w>at</w><w>minimum</w><w>20</w><w>minutes</w><w>to</w><w>train</w><w>depending</w><w>on</w><w>the</w><w>GPU</w><w>you</w><w>have</w><w>,</w><w>but</w><w>once</w><w>this</w><w>time</w><w>has</w><w>passed</w><w>you</w><w>should</w><w>be</w><w>able</w><w>to</w><w>load</w><w>your</w><w>model</w><w>using</w><w>the</w><w>line</w><w>of</w><w>code</w><w>:</w></p><ab><code xml:id="code_interrogating-national-narrative-gpt_15" corresp="code_interrogating-national-narrative-gpt_15.txt" rend="block"/></ab><p><w>This</w><w>will</w><w>pull</w><w>your</w><w>final</w><w>model</w><w>from</w><w>the</w><code rend="inline"><w>trained_model</w></code><w>folder</w><w>and</w><w>set</w><w>this</w><w>as</w><w>the</w><w>model</w><w>you</w><w>would</w><w>like</w><w>to</w><w>use</w><pc>.</pc><w>Now</w><w>all</w><w>that</w><w>'s</w><w>left</w><w>to</w><w>do</w><w>is</w><w>use</w><w>your</w><w>model</w><w>:</w></p><ab><code xml:id="code_interrogating-national-narrative-gpt_16" corresp="code_interrogating-national-narrative-gpt_16.txt" rend="block"/></ab><p><w>The</w><w>hyperparameters</w><w>set</w><w>here</w><w>help</w><w>shape</w><w>the</w><w>text</w><w>generated</w><w>and</w><w>can</w><w>be</w><w>experimented</w><w>with</w><w>to</w><w>see</w><w>what</w><w>yields</w><w>the</w><w>most</w><w>coherent</w><w>results</w><pc>.</pc></p><list type="unordered"><item><code rend="inline"><w>n</w></code><w>:</w><w>This</w><w>parameter</w><w>indicates</w><w>the</w><w>number</w><w>of</w><w>texts</w><w>you</w><w>would</w><w>like</w><w>to</w><w>generate</w><w>at</w><w>one</w><w>time</w><w>in</w><w>response</w><w>to</w><w>your</w><w>prompt</w><pc>.</pc><w>Set</w><w>this</w><w>to</w><w>``</w><w>1</w><w>''</w><w>and</w><w>the</w><w>model</w><w>will</w><w>produce</w><w>only</w><w>one</w><w>response</w><w>to</w><w>the</w><w>given</w><w>prompt</w><w>,</w><w>set</w><w>this</w><w>to</w><w>``</w><w>5</w><w>''</w><w>and</w><w>the</w><w>model</w><w>will</w><w>produce</w><w>five</w><w>responses</w><pc>.</pc></item><item><code rend="inline"><w>batch_size</w></code><w>:</w><w>In</w><w>this</w><w>case</w><w>,</w><w>adding</w><w>a</w><w>batch</w><w>size</w><w>that</w><w>matches</w><code rend="inline"><w>n</w></code><w>allows</w><w>for</w><w>multiple</w><w>samples</w><w>to</w><w>be</w><w>generated</w><w>simultaneously</w><w>,</w><w>speeding</w><w>up</w><w>the</w><w>generation</w><w>of</w><w>text</w><pc>.</pc></item><item><code rend="inline"><w>prompt</w></code><w>:</w><w>This</w><w>is</w><w>the</w><w>key</w><w>component</w><w>of</w><w>this</w><w>exercise</w><w>—</w><w>the</w><code rend="inline"><w>prompt</w></code><w>is</w><w>where</w><w>you</w><w>can</w><w>place</w><w>the</w><w>question</w><w>to</w><w>which</w><w>you</w><w>would</w><w>like</w><w>your</w><w>model</w><w>to</w><w>respond</w><pc>.</pc><w>If</w><w>this</w><w>is</w><w>phrased</w><w>as</w><w>a</w><w>question</w><w>,</w><w>it</w><w>will</w><w>attempt</w><w>to</w><w>respond</w><w>,</w><w>but</w><w>your</w><w>prompt</w><w>may</w><w>also</w><w>be</w><w>given</w><w>in</w><w>the</w><w>form</w><w>of</w><w>a</w><w>phrase</w><w>that</w><w>you</w><w>would</w><w>like</w><w>the</w><w>model</w><w>to</w><w>complete</w><w>and</w><w>continue</w><w>(</w><w>e.g.</w><w>,</w><w>``</w><w>Theresa</w><w>May</w><w>is</w><w>...</w><w>''</w><w>)</w><pc>.</pc></item><item><code rend="inline"><w>max_length</w></code><w>:</w><w>The</w><w>maximum</w><w>length</w><w>is</w><w>the</w><w>number</w><w>of</w><w>tokens</w><w>generated</w><w>in</w><w>response</w><w>to</w><w>your</w><w>prompt</w><w>—</w><w>essentially</w><w>,</w><w>the</w><w>word</w><w>count</w><pc>.</pc><w>GPT-2</w><w>allows</w><w>for</w><w>up</w><w>to</w><w>1024</w><w>tokens</w><w>to</w><w>be</w><w>generated</w><w>at</w><w>one</w><w>time</w><pc>.</pc></item><item><code rend="inline"><w>temperature</w></code><w>:</w><w>Temperature</w><w>sets</w><w>how</w><w>``</w><w>crazy</w><w>''</w><w>the</w><w>text</w><w>generated</w><w>will</w><w>be</w><w>by</w><w>adjusting</w><w>how</w><w>many</w><w>random</w><w>completions</w><w>the</w><w>model</w><w>allows</w><w>while</w><w>generating</w><w>the</w><w>text</w><pc>.</pc><w>At</w><w>0.7</w><w>the</w><w>text</w><w>generated</w><w>is</w><w>relatively</w><w>``</w><w>normal</w><w>''</w><w>while</w><w>still</w><w>remaining</w><w>unique</w><pc>.</pc><w>The</w><w>highest</w><w>value</w><w>of</w><w>1.0</w><w>results</w><w>in</w><w>highly</w><w>random</w><w>text</w><w>,</w><w>while</w><w>values</w><w>below</w><w>0.7</w><w>up</w><w>until</w><w>zero</w><w>will</w><w>result</w><w>in</w><w>more</w><w>deterministic</w><w>text</w><w>that</w><w>may</w><w>simply</w><w>parrot</w><w>some</w><w>of</w><w>the</w><w>contents</w><w>from</w><w>the</w><w>original</w><w>dataset</w><pc>.</pc></item><item><code rend="inline"><w>top_p</w></code><w>:</w><w>The</w><code rend="inline"><w>top_p</w></code><w>value</w><w>generates</w><w>a</w><w>set</w><w>of</w><w>words</w><w>related</w><w>to</w><w>the</w><w>prompt</w><w>where</w><w>the</w><w>total</w><w>probability</w><w>of</w><w>these</w><w>words</w><w>occurring</w><w>in</w><w>association</w><w>with</w><w>the</w><w>words</w><w>within</w><w>the</w><w>prompt</w><w>is</w><w>greater</w><w>than</w><w>or</w><w>equal</w><w>to</w><w>the</w><w>value</w><w>given</w><pc>.</pc></item></list><p><w>Once</w><w>complete</w><w>,</w><w>your</w><w>script</w><w>should</w><w>look</w><w>like</w><w>something</w><w>like</w><w>this</w><w>:</w></p><ab><code xml:id="code_interrogating-national-narrative-gpt_17" corresp="code_interrogating-national-narrative-gpt_17.txt" rend="block"/></ab></div></div><div type="2" n="4"><head><w>Using</w><w>Generated</w><w>Text</w><w>as</w><w>an</w><w>Interrogative</w><w>Tool</w></head><div type="3" n="4.1"><head><w>Why</w><w>Use</w><w>Generated</w><w>Text</w><pc>?</pc></head><p><w>Before</w><w>we</w><w>begin</w><w>to</w><w>actually</w><w>generate</w><w>text</w><w>,</w><w>it</w><w>'s</w><w>important</w><w>to</w><w>pause</w><w>and</w><w>establish</w><w>why</w><w>we</w><w>would</w><w>want</w><w>to</w><w>use</w><w>generated</w><w>text</w><w>for</w><w>research</w><w>at</w><w>all</w><pc>.</pc><w>There</w><w>are</w><w>many</w><w>other</w><w>computational</w><w>methods</w><w>of</w><w>text</w><w>analysis</w><w>designed</w><w>to</w><w>offer</w><w>macroscopic</w><w>insight</w><w>into</w><w>a</w><w>large</w><w>body</w><w>of</w><w>text</w><w>;</w><ref target="/en/lessons/counting-frequencies"><w>you</w><w>could</w><w>count</w><w>word</w><w>frequencies</w><w>to</w><w>find</w><w>the</w><w>most</w><w>common</w><w>vocabulary</w><w>used</w><w>in</w><w>your</w><w>text</w></ref><w>,</w><w>or</w><w>you</w><w>could</w><w>advance</w><w>this</w><w>and</w><ref target="/en/lessons/topic-modeling-and-mallet"><w>use</w><w>topic</w><w>modelling</w><w>to</w><w>identify</w><w>topics</w><w>in</w><w>your</w><w>text</w><w>via</w><w>clustering</w><w>words</w><w>which</w><w>often</w><w>appear</w><w>together</w></ref><pc>.</pc><w>What</w><w>sets</w><w>GPT</w><w>apart</w><w>from</w><w>these</w><w>methods</w><w>is</w><w>how</w><w>the</w><w>model</w><w>extracts</w><w>what</w><w>is</w><w>significant</w><w>based</w><w>on</w><w>a</w><w>specific</w><w>prompt</w><w>it</w><w>is</w><w>given</w><w>,</w><w>and</w><w>then</w><w>attempts</w><w>to</w><w>create</w><w>context</w><w>around</w><w>what</w><w>it</w><w>deems</w><w>significant</w><w>through</w><w>identifying</w><w>other</w><w>words</w><w>most</w><w>commonly</w><w>associated</w><w>with</w><w>the</w><w>starting</w><w>topic</w><pc>.</pc><w>In</w><w>an</w><w>experiment</w><w>with</w><w>``</w><w>resurrecting</w><w>''</w><w>historical</w><w>figures</w><w>through</w><w>text</w><w>generation</w><w>,</w><w>digital</w><w>archaeologist</w><w>Dr</w><w>Shawn</w><w>Graham</w><w>describes</w><w>this</w><w>process</w><w>as</w><w>``</w><w>discovering</w><w>and</w><w>mapping</w><w>the</w><w>full</w><w>landscape</w><w>of</w><w>possibilities</w><pc>.</pc><w>''</w><ref type="footnotemark" target="#en_note_3"/><w>Although</w><w>this</w><w>generated</w><w>context</w><w>is</w><w>fictional</w><w>and</w><w>often</w><w>non-sensical</w><w>,</w><w>it</w><w>can</w><w>still</w><w>demonstrate</w><w>how</w><w>keywords</w><w>and</w><w>topics</w><w>are</w><w>interacting</w><w>with</w><w>each</w><w>other</w><w>in</w><w>the</w><w>context</w><w>of</w><w>your</w><w>research</w><pc>.</pc><w>In</w><w>a</w><w>way</w><w>,</w><w>the</w><w>output</w><w>of</w><w>GPT</w><w>is</w><w>various</w><w>interpretations</w><w>of</w><w>a</w><w>singular</w><w>history</w><w>being</w><w>performed</w><w>,</w><w>and</w><w>you</w><w>are</w><w>the</w><w>critic</w><w>meant</w><w>to</w><w>analyze</w><w>and</w><w>elucidate</w><w>each</w><w>performance</w><pc>.</pc><w>Are</w><w>these</w><w>performances</w><w>completely</w><w>accurate</w><w>to</w><w>their</w><w>source</w><w>material</w><pc>?</pc><w>No</w><w>,</w><w>but</w><w>in</w><w>their</w><w>``</w><w>inaccuracy</w><w>''</w><w>we</w><w>can</w><w>find</w><w>new</w><w>perspectives</w><w>and</w><w>expositions</w><w>that</w><w>differ</w><w>from</w><w>our</w><w>own</w><w>,</w><w>which</w><w>ultimately</w><w>expands</w><w>our</w><w>understanding</w><w>of</w><w>the</w><w>subject</w><w>at</w><w>hand</w><pc>.</pc></p><p><w>Keeping</w><w>this</w><w>in</w><w>mind</w><w>,</w><w>like</w><w>with</w><w>any</w><w>other</w><w>method</w><w>of</w><w>computational</w><w>analysis</w><w>,</w><w>GPT</w><w>still</w><w>requires</w><w>you</w><w>to</w><w>be</w><w>informed</w><w>about</w><w>the</w><w>concepts</w><w>you</w><w>are</w><w>attempting</w><w>to</w><w>analyse</w><w>,</w><w>even</w><w>if</w><w>the</w><w>model</w><w>is</w><w>informed</w><w>by</w><w>more</w><w>data</w><w>than</w><w>even</w><w>the</w><w>most</w><w>prolific</w><w>researcher</w><w>could</w><w>consume</w><w>and</w><w>remember</w><pc>.</pc><w>Computational</w><w>linguist</w><w>Emily</w><w>Bender</w><w>describes</w><w>human</w><w>language</w><w>as</w><w>being</w><w>composed</w><w>of</w><w>two</w><w>parts</w><w>:</w><emph><w>form</w></emph><w>,</w><w>which</w><w>is</w><w>the</w><w>observable</w><w>realization</w><w>of</w><w>language</w><w>such</w><w>as</w><w>marks</w><w>on</w><w>a</w><w>page</w><w>or</w><w>bytes</w><w>in</w><w>a</w><w>digital</w><w>representation</w><w>of</w><w>text</w><w>,</w><w>and</w><emph><w>meaning</w></emph><w>,</w><w>which</w><w>is</w><w>the</w><w>relation</w><w>between</w><w>these</w><w>linguistic</w><w>forms</w><w>and</w><w>something</w><w>outside</w><w>of</w><w>language</w><ref type="footnotemark" target="#en_note_4"/><pc>.</pc><w>We</w><w>currently</w><w>do</w><w>not</w><w>have</w><w>the</w><w>means</w><w>of</w><w>expressing</w><w>the</w><w>latter</w><w>component</w><w>of</w><w>language</w><w>,</w><w>nor</w><w>is</w><w>it</w><w>fully</w><w>understood</w><w>,</w><w>so</w><w>the</w><w>input</w><w>which</w><w>is</w><w>given</w><w>to</w><w>our</w><w>language</w><w>models</w><w>is</w><w>merely</w><w>the</w><w>form</w><w>of</w><w>language</w><w>,</w><w>making</w><w>the</w><w>output</w><w>of</w><w>language</w><w>models</w><w>simply</w><w>form</w><w>as</w><w>well</w><pc>.</pc><w>However</w><w>,</w><w>this</w><w>means</w><w>that</w><w>our</w><w>model</w><w>is</w><w>unhindered</w><w>by</w><w>our</w><w>burden</w><w>of</w><w>reason</w><w>,</w><w>with</w><w>the</w><w>output</w><w>it</w><w>produces</w><w>being</w><w>based</w><w>on</w><w>statistical</w><w>probability</w><w>of</w><w>connections</w><w>rather</w><w>than</w><w>our</w><w>less</w><w>tangible</w><w>``</w><w>logic</w><w>''</w><w>;</w><w>thus</w><w>,</w><w>as</w><w>computational</w><w>linguist</w><w>Patrick</w><w>Juola</w><w>states</w><w>when</w><w>discussing</w><w>the</w><w>topic</w><w>of</w><w>computer-generated</w><w>text</w><w>,</w><w>``</w><w>even</w><w>if</w><w>99.9</w><w>%</w><w>of</w><w>the</w><w>possible</w><w>readings</w><w>are</w><w>flat</w><w>gibberish</w><w>,</w><w>the</w><w>one</w><w>in</w><w>a</w><w>thousand</w><w>may</w><w>include</w><w>interesting</w><w>and</w><w>provocative</w><w>readings</w><w>that</w><w>human</w><w>authors</w><w>have</w><w>missed</w><pc>.</pc><w>''</w><ref type="footnotemark" target="#en_note_5"/><w>Our</w><w>model</w><w>is</w><w>producing</w><w>forms</w><w>which</w><w>we</w><w>may</w><w>have</w><w>never</w><w>considered</w><w>,</w><w>yet</w><w>suddenly</w><w>,</w><w>by</w><w>being</w><w>presented</w><w>with</w><w>these</w><w>new</w><w>forms</w><w>,</w><w>we</w><w>can</w><w>make</w><w>connections</w><w>between</w><w>themes</w><w>that</w><w>may</w><w>have</w><w>been</w><w>seemingly</w><w>unconnected</w><w>before</w><pc>.</pc><w>We</w><w>may</w><w>be</w><w>the</w><w>ones</w><w>prompting</w><w>the</w><w>model</w><w>with</w><w>questions</w><w>,</w><w>but</w><w>in</w><w>studying</w><w>the</w><w>model</w><w>'s</w><w>output</w><w>,</w><w>it</w><w>is</w><w>prompting</w><w>us</w><w>to</w><w>engage</w><w>creatively</w><w>with</w><w>our</w><w>research</w><w>and</w><w>pushing</w><w>us</w><w>to</w><w>investigate</w><w>in</w><w>a</w><w>way</w><w>we</w><w>as</w><w>historians</w><w>typically</w><w>would</w><w>not</w><pc>.</pc></p></div><div type="3" n="4.2"><head><w>Interrogating</w><w>our</w><w>Model</w></head><p><w>To</w><w>begin</w><w>,</w><w>we</w><w>can</w><w>prompt</w><w>the</w><w>model</w><w>with</w><w>the</w><w>basic</w><w>question</w><w>of</w><w>``</w><w>What</w><w>is</w><w>Brexit</w><pc>?</pc><w>''</w><w>to</w><w>garner</w><w>a</w><w>general</w><w>idea</w><w>of</w><w>the</w><w>word</w><w>associations</w><w>being</w><w>made</w><w>by</w><w>the</w><w>machine</w><w>when</w><w>prompted</w><w>with</w><w>the</w><w>topic</w><w>of</w><w>``</w><w>Brexit</w><w>''</w><pc>.</pc><w>As</w><w>indicated</w><w>by</w><w>the</w><w>hyperparameter</w><w>setting</w><w>of</w><code rend="inline"><w>n=5</w></code><w>,</w><w>I</w><w>will</w><w>be</w><w>asking</w><w>my</w><w>model</w><w>to</w><w>generate</w><w>five</w><w>responses</w><w>to</w><w>the</w><w>prompt</w><w>and</w><w>primarily</w><w>look</w><w>at</w><w>the</w><w>most</w><w>``</w><w>convincing</w><w>''</w><w>of</w><w>the</w><w>responses</w><pc>.</pc><w>While</w><w>text</w><w>generated</w><w>by</w><w>GPT-2</w><w>almost</w><w>always</w><w>has</w><w>some</w><w>level</w><w>of</w><w>coherence</w><w>,</w><w>only</w><w>a</w><w>small</w><w>percentage</w><w>is</w><w>truly</w><w>human-like</w><w>,</w><w>especially</w><w>when</w><w>training</w><w>using</w><w>the</w><w>smaller</w><w>models</w><w>;</w><w>by</w><w>choosing</w><w>to</w><w>generate</w><w>five</w><w>samples</w><w>at</w><w>a</w><w>time</w><w>,</w><w>I</w><w>am</w><w>giving</w><w>the</w><w>model</w><w>five</w><w>opportunities</w><w>to</w><w>produce</w><w>a</w><w>comprehensible</w><w>response</w><w>to</w><w>the</w><w>prompt</w><w>given</w><w>from</w><w>which</w><w>meaning</w><w>can</w><w>be</w><w>derived</w><pc>.</pc></p><p style="alert alert-info"><w>Reminder</w><w>:</w><w>The</w><w>text</w><w>generated</w><w>by</w><w>my</w><w>model</w><w>will</w><w>be</w><w>different</w><w>from</w><w>the</w><w>text</w><w>that</w><w>your</w><w>model</w><w>generates</w><w>even</w><w>if</w><w>you</w><w>are</w><w>following</w><w>along</w><w>with</w><w>this</w><w>lesson</w><w>verbatim</w><pc>.</pc><w>This</w><w>is</w><w>,</w><w>of</w><w>course</w><w>,</w><w>GPT-2</w><w>working</w><w>as</w><w>intended</w><w>because</w><w>it</w><w>was</w><w>designed</w><w>to</w><w>output</w><w>unique</w><w>text</w><pc>.</pc><w>You</w><w>may</w><w>view</w><w>all</w><w>of</w><w>the</w><w>text</w><w>generated</w><w>by</w><w>me</w><w>during</w><w>the</w><w>creation</w><w>of</w><w>this</w><w>lesson</w><ref target="/assets/interrogating-national-narrative-gpt/gpt-2-output.md"><w>here</w></ref><pc>.</pc></p><p><w>The</w><w>two</w><w>outputs</w><w>that</w><w>the</w><w>model</w><w>generated</w><w>which</w><w>directly</w><w>responded</w><w>to</w><w>this</w><w>initial</w><w>question</w><w>were</w><w>:</w></p><quote><p><w>``</w><w>It</w><w>is</w><w>the</w><w>only</w><w>way</w><w>out</w><w>of</w><w>the</w><w>trap</w><pc>.</pc><w>''</w></p></quote><quote><p><w>``</w><w>A</w><w>deal</w><w>dead</w><w>on</w><w>the</w><w>table</w><pc>.</pc><w>''</w></p></quote><p><w>The</w><w>sentiments</w><w>expressed</w><w>in</w><w>these</w><w>excerpts</w><w>are</w><w>rather</w><w>reflective</w><w>of</w><w>the</w><w>two</w><w>most</w><w>prominent</w><w>themes</w><w>found</w><w>in</w><w>Brexit-related</w><w>news</w><w>:</w><w>the</w><w>perspective</w><w>of</w><w>``</w><w>Brexiteers</w><w>''</w><w>who</w><w>desired</w><w>to</w><w>leave</w><w>the</w><w>EU</w><w>entirely</w><w>,</w><w>and</w><w>those</w><w>who</w><w>hoped</w><w>for</w><w>some</w><w>form</w><w>of</w><w>a</w><ref target="https://perma.cc/MJR5-N79F"><w>withdrawal</w><w>agreement</w></ref><w>despite</w><w>numerous</w><w>renegotiations</w><w>of</w><w>this</w><w>deal</w><w>once</w><w>the</w><w>UK</w><w>had</w><w>made</w><w>its</w><w>decision</w><w>to</w><w>withdraw</w><w>from</w><w>the</w><w>EU</w><pc>.</pc><w>The</w><w>remaining</w><w>generated</w><w>text</w><w>corroborated</w><w>the</w><w>findings</w><w>of</w><w>a</w><w>2018</w><w>report</w><w>on</w><w>European</w><w>media</w><w>coverage</w><w>of</w><w>Brexit</w><w>,</w><w>which</w><w>indicated</w><w>that</w><w>35</w><w>%</w><w>of</w><w>coverage</w><w>discussed</w><w>the</w><w>negotiations</w><w>happening</w><w>between</w><w>the</w><w>UK</w><w>and</w><w>the</w><w>EU</w><w>,</w><w>and</w><w>the</w><w>most</w><w>significant</w><w>topic</w><w>covered</w><w>outside</w><w>of</w><w>this</w><w>was</w><w>Brexit</w><w>'s</w><w>impact</w><w>on</w><w>the</w><w>economy</w><w>,</w><w>business</w><w>,</w><w>and</w><w>trade</w><w>,</w><w>particularly</w><w>concerning</w><w>trade</w><w>over</w><w>the</w><w>Irish</w><w>border</w><pc>.</pc><ref type="footnotemark" target="#en_note_6"/><w>For</w><w>example</w><w>,</w><w>instead</w><w>of</w><w>defining</w><w>Brexit</w><w>as</w><w>the</w><w>prompt</w><w>requested</w><w>,</w><w>one</w><w>response</w><w>instead</w><w>began</w><w>with</w><w>defining</w><w>the</w><ref target="https://perma.cc/B9R7-LCGJ"><w>Irish</w><w>backstop</w></ref><w>:</w></p><quote><p><w>``</w><w>The</w><w>backstop</w><w>is</w><w>an</w><w>insurance</w><w>policy</w><w>designed</w><w>to</w><w>prevent</w><w>a</w><w>hard</w><w>border</w><w>between</w><w>Northern</w><w>Ireland</w><w>and</w><w>the</w><w>Republic</w><w>of</w><w>Ireland</w><w>and</w><w>preserve</w><w>the</w><w>Good</w><w>Friday</w><w>Agreement</w><pc>.</pc><w>''</w></p></quote><p><w>In</w><w>the</w><w>responses</w><w>to</w><w>this</w><w>prompt</w><w>,</w><w>there</w><w>was</w><w>one</w><w>segment</w><w>that</w><w>did</w><w>seem</w><w>unexpected</w><w>and</w><w>fell</w><w>outside</w><w>of</w><w>the</w><w>repeat</w><w>outputs</w><w>related</w><w>to</w><w>economics</w><w>and</w><w>trade</w><w>:</w></p><quote><p><w>``</w><w>But</w><w>if</w><w>you</w><w>can</w><w>see</w><w>the</w><w>European</w><w>Union</w><w>,</w><w>you</w><w>can</w><w>see</w><w>the</w><w>British</w><w>people</w><w>who</w><w>are</w><w>not</w><w>only</w><w>themselves</w><w>as</w><w>being</w><w>ignorant</w><w>racists</w><pc>.</pc><w>There</w><w>is</w><w>a</w><w>lot</w><w>of</w><w>evidence</w><w>that</w><w>this</w><w>is</w><w>the</w><w>case</w><pc>.</pc><w>There</w><w>are</w><w>some</w><w>things</w><w>that</w><w>are</w><w>that</w><w>are</w><w>deeply</w><w>saddening</w><w>about</w><w>the</w><w>UK</w><w>’</w><w>s</w><w>attitude</w><w>to</w><w>Brexit</w><pc>.</pc><w>''</w></p></quote><p><w>The</w><w>grammar</w><w>of</w><w>this</w><w>response</w><w>is</w><w>somewhat</w><w>odd</w><w>,</w><w>but</w><w>what</w><w>this</w><w>statement</w><w>being</w><w>generated</w><w>indicates</w><w>is</w><w>that</w><w>there</w><w>is</w><w>a</w><w>branching</w><w>association</w><w>with</w><w>the</w><w>discussion</w><w>of</w><w>the</w><w>UK</w><w>and</w><w>racism</w><pc>.</pc><w>With</w><w>the</w><w>EU</w><w>allowing</w><w>free</w><w>movement</w><w>across</w><w>borders</w><w>,</w><w>the</w><w>topic</w><w>of</w><w>immigration</w><w>was</w><w>common</w><w>in</w><w>deliberations</w><w>over</w><w>Brexit</w><w>'s</w><w>potential</w><w>impact</w><pc>.</pc><w>For</w><w>those</w><w>campaigning</w><w>to</w><w>leave</w><w>the</w><w>EU</w><w>,</w><w>narratives</w><w>surrounding</w><w>the</w><w>open</w><w>border</w><w>'s</w><w>allowance</w><w>of</w><w>refugees</w><w>impacting</w><w>the</w><w>safety</w><w>of</w><w>English</w><w>citizens</w><w>were</w><w>popular</w><w>,</w><w>and</w><w>these</w><w>narratives</w><w>focused</w><w>on</w><w>Muslim</w><w>individuals</w><w>in</w><w>particular</w><pc>.</pc><ref type="footnotemark" target="#en_note_7"/><w>This</w><w>generated</w><w>response</w><w>is</w><w>likely</w><w>reflecting</w><w>the</w><w>public</w><w>response</w><w>to</w><w>those</w><w>narratives</w><w>that</w><w>were</w><w>present</w><w>in</w><w>media</w><w>coverage</w><w>based</w><w>on</w><w>citizens</w><w>'</w><w>opinions</w><pc>.</pc></p><p><w>Beyond</w><w>asking</w><w>your</w><w>model</w><w>to</w><w>answer</w><w>prompts</w><w>,</w><w>you</w><w>can</w><w>also</w><w>ask</w><w>it</w><w>to</w><w>complete</w><w>a</w><w>statement</w><pc>.</pc><w>For</w><w>this</w><w>next</w><w>point</w><w>of</w><w>analysis</w><w>,</w><w>I</w><w>will</w><w>ask</w><w>my</w><w>model</w><w>to</w><w>complete</w><w>a</w><w>prompt</w><w>regarding</w><w>the</w><w>two</w><w>prime</w><w>ministers</w><w>who</w><w>oversaw</w><w>the</w><w>UK</w><w>following</w><w>its</w><w>vote</w><w>to</w><w>withdraw</w><w>from</w><w>the</w><w>EU</w><w>:</w><ref target="https://perma.cc/5DL9-BQP3"><w>Theresa</w><w>May</w></ref><w>and</w><ref target="https://perma.cc/ZXC9-TJ4E"><w>Boris</w><w>Johnson</w></ref><pc>.</pc><w>To</w><w>begin</w><w>,</w><w>I</w><w>will</w><w>set</w><w>the</w><w>prompt</w><w>to</w><w>``</w><w>Theresa</w><w>May</w><w>is</w><w>''</w><pc>.</pc></p><p><w>Immediately</w><w>,</w><w>we</w><w>are</w><w>met</w><w>with</w><w>a</w><w>comical</w><w>example</w><w>of</w><w>accidental</w><w>sexism</w><w>as</w><w>the</w><w>model</w><w>writes</w><w>:</w></p><quote><p><w>``</w><w>Theresa</w><w>May</w><w>is</w><w>a</w><w>long-term</w><w>thorn</w><w>in</w><w>the</w><w>UK</w><w>,</w><w>and</w><w>has</w><w>a</w><w>record</w><w>of</w><w>making</w><w>decisions</w><pc>.</pc><w>''</w></p></quote><p><w>As</w><w>if</w><w>PM</w><w>Theresa</w><w>May</w><w>is</w><w>a</w><w>thorn</w><w>in</w><w>the</w><w>UK</w><w>'s</w><w>side</w><w>,</w><w>for</w><w>the</w><w>dreaded</w><w>crime</w><w>of</w><w>decision</w><w>making</w><pc>!</pc><w>While</w><w>it</w><w>is</w><w>unlikely</w><w>that</w><w>May</w><w>was</w><w>criticised</w><w>simply</w><w>for</w><w>making</w><w>decisions</w><w>,</w><w>output</w><w>such</w><w>as</w><w>this</w><w>could</w><w>reflect</w><w>a</w><w>level</w><w>of</w><w>harshness</w><w>in</w><w>the</w><w>media</w><w>'s</w><w>coverage</w><w>of</w><w>the</w><w>numerous</w><w>decisions</w><w>and</w><w>negotiations</w><w>she</w><w>performed</w><w>during</w><w>her</w><w>time</w><w>as</w><w>prime</w><w>minister</w><pc>.</pc></p><p><w>When</w><w>considering</w><w>covert</w><w>forms</w><w>of</w><w>sexism</w><w>that</w><w>are</w><w>more</w><w>likely</w><w>to</w><w>be</w><w>found</w><w>in</w><w>modern</w><w>media</w><w>,</w><w>a</w><w>more</w><w>insightful</w><w>response</w><w>to</w><w>this</w><w>prompt</w><w>was</w><w>the</w><w>following</w><w>:</w></p><quote><p><w>``</w><w>Theresa</w><w>May</w><w>is</w><w>a</w><w>headmistress</w><w>of</w><w>the</w><w>political</w><w>process</w><pc>.</pc><w>She</w><w>has</w><w>a</w><w>record</w><w>of</w><w>her</w><w>own</w><w>party</w><w>and</w><w>a</w><w>history</w><w>of</w><w>fierce</w><w>struggle</w><w>and</w><w>fierce</w><w>dedication</w><w>to</w><w>the</w><w>right-wing</w><w>Leavers</w><pc>.</pc><w>''</w></p></quote><p><w>In</w><w>a</w><w>comparative</w><w>analysis</w><w>of</w><w>the</w><w>media</w><w>coverage</w><w>of</w><w>former</w><w>female</w><w>prime</w><w>ministers</w><ref target="https://perma.cc/CF8Q-65Q7"><w>Margaret</w><w>Thatcher</w></ref><w>and</w><w>Theresa</w><w>May</w><w>,</w><w>political</w><w>scientist</w><w>Blair</w><w>Williams</w><w>posits</w><w>that</w><w>both</w><w>women</w><w>were</w><w>framed</w><w>using</w><w>stereotypically</w><w>feminine</w><w>norms</w><w>in</w><w>news</w><w>coverage</w><w>,</w><w>with</w><w>a</w><w>popular</w><w>strategy</w><w>to</w><w>do</w><w>so</w><w>being</w><w>the</w><w>comparison</w><w>of</w><w>these</w><w>leaders</w><w>to</w><w>schoolgirls</w><w>or</w><w>headmistresses</w><w>to</w><w>emphasise</w><w>their</w><w>femininity</w><pc>.</pc><ref type="footnotemark" target="#en_note_8"/><w>Our</w><w>model</w><w>seemingly</w><w>picks</w><w>up</w><w>on</w><w>this</w><w>discourse</w><w>,</w><w>and</w><w>as</w><w>was</w><w>common</w><w>in</w><w>the</w><w>coverage</w><w>of</w><w>May</w><w>in</w><w>the</w><w>media</w><w>,</w><w>states</w><w>that</w><w>she</w><w>is</w><w>the</w><w>fierce</w><w>``</w><w>headmistress</w><w>of</w><w>the</w><w>political</w><w>process</w><w>''</w><w>,</w><w>removing</w><w>her</w><w>from</w><w>the</w><w>prime</w><w>ministerial</w><w>role</w><w>she</w><w>actually</w><w>occupied</w><w>and</w><w>instead</w><w>returning</w><w>her</w><w>to</w><w>one</w><w>of</w><w>the</w><w>positions</w><w>of</w><w>leadership</w><w>that</w><w>women</w><w>can</w><w>acceptably</w><w>occupy</w><w>in</w><w>a</w><w>patriarchal</w><w>society</w><pc>.</pc></p><p><w>Outside</w><w>of</w><w>the</w><w>term</w><w>``</w><w>headmistress</w><w>''</w><w>,</w><w>other</w><w>terms</w><w>the</w><w>model</w><w>used</w><w>to</w><w>describe</w><w>May</w><w>—such</w><w>as</w><w>``</w><w>fierce</w><w>''</w><w>,</w><w>``</w><w>passionate</w><w>''</w><w>,</w><w>and</w><w>``</w><w>bold</w><w>''</w><w>—</w><w>take</w><w>on</w><w>a</w><w>similarly</w><w>gendered</w><w>nature</w><w>when</w><w>contrasted</w><w>with</w><w>the</w><w>generated</w><w>text</w><w>completing</w><w>the</w><w>phrase</w><w>``</w><w>Boris</w><w>Johnson</w><w>is</w><w>''</w><w>:</w></p><quote><p><w>``</w><w>Boris</w><w>Johnson</w><w>is</w><w>a</w><w>'realistic</w><w>leader</w><w>of</w><w>the</w><w>right</w><w>wing</w><w>of</w><w>the</w><w>House</w><w>of</w><w>Commons</w><w>who</w><w>has</w><w>put</w><w>clear</w><w>ground</w><w>between</w><w>him</w><w>and</w><w>the</w><w>rest</w><w>of</w><w>the</w><w>House</w><w>of</w><w>Commons</w><w>'</w><pc>.</pc><w>''</w></p></quote><quote><p><w>``</w><w>Boris</w><w>Johnson</w><w>is</w><w>a</w><w>long-term</w><w>,</w><w>highly</w><w>skilled</w><w>,</w><w>moderate</w><w>and</w><w>dynamic</w><w>politician</w><w>who</w><w>has</w><w>the</w><w>skills</w><w>to</w><w>make</w><w>sure</w><w>that</w><w>the</w><w>UK</w><w>is</w><w>ready</w><w>for</w><w>a</w><w>hard</w><w>Brexit</w><w>,</w><w>and</w><w>with</w><w>the</w><w>EU</w><w>too</w><w>,</w><w>he</w><w>has</w><w>the</w><w>faintest</w><w>idea</w><w>what</w><w>a</w><w>no-deal</w><w>scenario</w><w>will</w><w>happen</w><w>at</w><w>this</w><w>juncture</w><pc>.</pc><w>''</w></p></quote><p><w>In</w><w>a</w><w>2019</w><w>article</w><w>looking</w><w>at</w><w>the</w><w>role</w><w>of</w><w>masculinity</w><w>in</w><w>Brexit</w><w>campaigning</w><w>and</w><w>negotiations</w><w>,</w><w>it</w><w>has</w><w>been</w><w>theorised</w><w>that</w><w>toxic</w><w>masculinity</w><w>manifested</w><w>itself</w><w>through</w><w>the</w><w>usage</w><w>of</w><w>both</w><w>language</w><w>associated</w><w>with</w><w>militarism</w><w>and</w><w>language</w><w>associated</w><w>with</w><w>deal-making</w><w>and</w><w>business</w><w>rhetoric</w><pc>.</pc><ref type="footnotemark" target="#en_note_9"/><w>Militarism</w><w>valorises</w><w>traits</w><w>historically</w><w>associated</w><w>with</w><w>masculinity</w><w>:</w><w>heterosexuality</w><w>,</w><w>strength</w><w>,</w><w>power</w><w>,</w><w>autonomy</w><w>,</w><w>resilience</w><w>,</w><w>and</w><w>competence</w><pc>.</pc><w>Adding</w><w>to</w><w>these</w><w>traditional</w><w>perspectives</w><w>,</w><w>the</w><w>masculinised</w><w>spaces</w><w>of</w><w>corporate</w><w>business</w><w>idealise</w><w>competitive</w><w>individualism</w><w>,</w><w>reason</w><w>and</w><w>self-control</w><pc>.</pc><ref type="footnotemark" target="#en_note_10"/><w>In</w><w>describing</w><w>Johnson</w><w>as</w><w>a</w><w>``</w><w>realistic</w><w>leader</w><w>''</w><w>and</w><w>``</w><w>long-term</w><w>,</w><w>highly</w><w>skilled</w><w>,</w><w>moderate</w><w>and</w><w>dynamic</w><w>politician</w><w>''</w><w>,</w><w>our</w><w>model</w><w>confirms</w><w>this</w><w>notion</w><w>of</w><w>favouritism</w><w>towards</w><w>masculised</w><w>leadership</w><w>that</w><w>delegitimises</w><w>feminine</w><w>traits</w><w>,</w><w>especially</w><w>when</w><w>contrasted</w><w>with</w><w>the</w><w>more</w><w>emotional</w><w>language</w><w>used</w><w>to</w><w>describe</w><w>May</w><pc>.</pc></p><p><w>While</w><w>our</w><w>finetuned</w><w>GPT-2</w><w>model</w><w>does</w><w>not</w><w>always</w><w>respond</w><w>exactly</w><w>as</w><w>expected</w><w>based</w><w>on</w><w>the</w><w>prompt</w><w>you</w><w>have</w><w>given</w><w>it</w><w>,</w><w>from</w><w>just</w><w>these</w><w>three</w><w>prompts</w><w>the</w><w>paths</w><w>of</w><w>meaning</w><w>that</w><w>it</w><w>does</w><w>generate</w><w>can</w><w>map</w><w>out</w><w>the</w><w>macroscopic</w><w>themes</w><w>present</w><w>in</w><w>a</w><w>body</w><w>of</w><w>work</w><w>,</w><w>providing</w><w>guidance</w><w>for</w><w>more</w><w>in-depth</w><w>microscopic</w><w>analysis</w><pc>.</pc><w>What</w><w>makes</w><w>a</w><w>generated</w><w>text</w><w>interesting</w><w>for</w><w>historical</w><w>inquiry</w><w>is</w><w>not</w><w>necessarily</w><w>just</w><w>how</w><w>coherent</w><w>the</w><w>outputted</w><w>text</w><w>is</w><w>,</w><w>but</w><w>its</w><w>ability</w><w>to</w><w>create</w><w>patterns</w><w>from</w><w>the</w><w>inputted</w><w>text</w><w>that</w><w>we</w><w>as</w><w>humans</w><w>may</w><w>be</w><w>incapable</w><w>of</w><w>detecting</w><w>ourselves</w><pc>.</pc><w>As</w><w>exemplified</w><w>in</w><w>this</w><w>analysis</w><w>,</w><w>when</w><w>studying</w><w>the</w><w>generated</w><w>text</w><w>,</w><w>make</w><w>note</w><w>of</w><w>the</w><w>points</w><w>which</w><w>reoccur</w><w>in</w><w>responses</w><w>generated</w><w>for</w><w>the</w><w>same</w><w>prompt—</w><w>why</w><w>might</w><w>the</w><w>model</w><w>be</w><w>repeating</w><w>these</w><w>points</w><pc>?</pc><w>In</w><w>contrast</w><w>,</w><w>there</w><w>can</w><w>also</w><w>be</w><w>value</w><w>in</w><w>asking</w><w>,</w><w>``</w><w>what</w><w>ideologies</w><w>resulted</w><w>in</w><w>the</w><w>formation</w><w>of</w><w>this</w><pc>?</pc><w>''</w><w>when</w><w>a</w><w>particularly</w><w>outlandish</w><w>response</w><w>is</w><w>generated</w><w>,</w><w>with</w><w>its</w><w>difference</w><w>from</w><w>the</w><w>other</w><w>responses</w><w>perhaps</w><w>pointing</w><w>towards</w><w>a</w><w>niche</w><w>yet</w><w>still</w><w>present</w><w>view</w><w>within</w><w>your</w><w>corpus</w><pc>.</pc><w>I</w><w>encourage</w><w>you</w><w>to</w><w>experiment</w><w>beyond</w><w>these</w><w>three</w><w>examples</w><w>,</w><w>and</w><w>when</w><w>looking</w><w>at</w><w>the</w><w>responses</w><w>generated</w><w>by</w><w>your</w><w>model</w><w>,</w><w>seek</w><w>to</w><w>understand</w><w>how</w><w>exactly</w><w>the</w><w>connections</w><w>your</w><w>model</w><w>has</w><w>made</w><w>may</w><w>have</w><w>come</w><w>to</w><w>be</w><w>in</w><w>order</w><w>to</w><w>seek</w><w>a</w><w>possible</w><w>source</w><pc>.</pc></p></div></div><div type="2" n="5"><head><w>Considering</w><w>the</w><w>Ethics</w><w>of</w><w>Large-Scale</w><w>Language</w><w>Models</w><w>and</w><w>Generative</w><w>Text</w></head><p><w>At</w><w>this</w><w>point</w><w>in</w><w>the</w><w>lesson</w><w>,</w><w>you</w><w>have</w><w>learned</w><w>what</w><w>language</w><w>models</w><w>are</w><w>and</w><w>how</w><w>they</w><w>work</w><w>,</w><w>about</w><w>the</w><w>computer</w><w>hardware</w><w>and</w><w>technologies</w><w>necessary</w><w>to</w><w>use</w><w>them</w><w>,</w><w>and</w><w>how</w><w>to</w><w>create</w><w>a</w><w>model</w><w>of</w><w>your</w><w>own</w><w>by</w><w>finetuning</w><w>an</w><w>existing</w><w>model</w><w>with</w><w>your</w><w>own</w><w>data</w><pc>.</pc><w>While</w><w>using</w><w>this</w><w>model</w><w>is</w><w>a</w><w>creative</w><w>way</w><w>to</w><w>aggregate</w><w>the</w><w>concepts</w><w>present</w><w>in</w><w>a</w><w>large</w><w>corpus</w><w>and</w><w>gain</w><w>a</w><w>macroscopic</w><w>perspective</w><w>on</w><w>its</w><w>most</w><w>prevalent</w><w>topics</w><w>,</w><w>no</w><w>technology</w><w>is</w><w>without</w><w>limitations</w><pc>.</pc></p><p><w>In</w><w>this</w><w>lesson</w><w>,</w><w>we</w><w>are</w><w>analyzing</w><w>a</w><w>very</w><w>recent</w><w>history</w><w>,</w><w>and</w><w>our</w><w>dataset</w><w>is</w><w>composed</w><w>of</w><w>many</w><w>articles</w><w>that</w><w>were</w><w>present</w><w>during</w><w>the</w><w>creation</w><w>of</w><w>GPT-2</w><pc>.</pc><w>When</w><w>WebText</w><w>was</w><w>being</w><w>created</w><w>,</w><w>Brexit</w><w>was</w><w>a</w><w>popular</w><w>topic</w><w>of</w><w>discussion</w><w>on</w><w>all</w><w>social</w><w>media</w><w>platforms</w><w>including</w><w>Reddit</w><w>,</w><w>meaning</w><w>that</w><w>even</w><w>prior</w><w>to</w><w>finetuning</w><w>GPT-2</w><w>with</w><w>our</w><w>data</w><w>,</w><w>Brexit</w><w>was</w><w>highly</w><w>represented</w><w>in</w><w>the</w><w>original</w><w>training</w><w>data</w><pc>.</pc><ref type="footnotemark" target="#en_note_11"/><w>Yet</w><w>,</w><w>despite</w><w>our</w><w>topic</w><w>being</w><w>highly</w><w>represented</w><w>in</w><w>WebText</w><w>,</w><w>it</w><w>is</w><w>important</w><w>to</w><w>consider</w><w>what</w><w>other</w><w>factors</w><w>went</w><w>into</w><w>the</w><w>creation</w><w>of</w><w>this</w><w>dataset</w><w>that</w><w>could</w><w>be</w><w>affecting</w><w>the</w><w>results</w><w>which</w><w>GPT-2</w><w>models</w><w>output</w><pc>.</pc><ref target="https://perma.cc/9ZYU-C7WM"><w>In</w><w>a</w><w>post</w><w>discussing</w><w>GPT-2</w><w>and</w><w>its</w><w>provenance</w></ref><w>by</w><w>the</w><w>group</w><w>of</w><w>individuals</w><w>who</w><w>developed</w><w>this</w><w>technology</w><w>(</w><w>OpenAI</w><w>)</w><w>,</w><w>they</w><w>describe</w><w>in</w><w>a</w><w>footnote</w><w>the</w><w>creation</w><w>of</w><w>WebText</w><w>as</w><w>follows</w><w>:</w></p><quote><p><w>``</w><w>We</w><w>created</w><w>a</w><w>new</w><w>dataset</w><w>which</w><w>emphasizes</w><w>diversity</w><w>of</w><w>content</w><w>,</w><w>by</w><w>scraping</w><w>content</w><w>from</w><w>the</w><w>Internet</w><pc>.</pc><w>In</w><w>order</w><w>to</w><w>preserve</w><w>document</w><w>quality</w><w>,</w><w>we</w><w>used</w><w>only</w><w>pages</w><w>which</w><w>have</w><w>been</w><w>curated/filtered</w><w>by</w><w>humans</w><w>—</w><w>specifically</w><w>,</w><w>we</w><w>used</w><w>outbound</w><w>links</w><w>from</w><w>Reddit</w><w>which</w><w>received</w><w>at</w><w>least</w><w>3</w><w>karma</w><pc>.</pc><w>''</w></p></quote><p><w>From</w><w>this</w><w>quote</w><w>,</w><w>it</w><w>seems</w><w>that</w><w>OpenAI</w><w>is</w><w>equating</w><w>diversity</w><w>of</w><w>data</w><w>with</w><w>quanitity</w><w>of</w><w>data</w><w>,</w><w>which</w><w>is</w><w>not</w><w>necessarily</w><w>accurate</w><w>,</w><w>especially</w><w>when</w><w>the</w><w>data</w><w>is</w><w>curated</w><w>from</w><w>one</w><w>source</w><pc>.</pc><w>In</w><w>a</w><w>study</w><w>done</w><w>by</w><w>the</w><w>Pew</w><w>Research</w><w>Center</w><w>in</w><w>2016</w><w>(</w><w>the</w><w>same</w><w>year</w><w>that</w><w>WebText</w><w>was</w><w>created</w><w>)</w><w>67</w><w>%</w><w>of</w><w>Reddit</w><w>users</w><w>identified</w><w>as</w><w>male</w><w>,</w><w>and</w><w>64</w><w>%</w><w>of</w><w>these</w><w>users</w><w>were</w><w>between</w><w>the</w><w>ages</w><w>of</w><w>18</w><w>to</w><w>29</w><w>;</w><w>further</w><w>,</w><w>70</w><w>%</w><w>of</w><w>this</w><w>user</w><w>base</w><w>fell</w><w>into</w><w>the</w><w>category</w><w>of</w><w>``</w><w>white</w><w>non-Hispanic</w><w>''</w><pc>.</pc><ref type="footnotemark" target="#en_note_12"/><w>This</w><w>indicates</w><w>that</w><w>a</w><w>majority</w><w>of</w><w>the</w><w>links</w><w>used</w><w>to</w><w>create</w><w>the</w><w>dataset</w><w>were</w><w>curated</w><w>by</w><w>those</w><w>who</w><w>fell</w><w>into</w><w>this</w><w>demographic</w><pc>.</pc><w>Narrowing</w><w>things</w><w>even</w><w>more</w><w>,</w><w>as</w><w>mentioned</w><w>earlier</w><w>in</w><w>this</w><w>tutorial</w><w>,</w><w>any</w><w>non-English</w><w>language</w><w>text</w><w>was</w><w>deliberately</w><w>removed</w><w>from</w><w>the</w><w>dataset</w><w>prior</w><w>to</w><w>training</w><w>the</w><w>original</w><w>GPT-2</w><w>model</w><w>,</w><w>meaning</w><w>that</w><w>WebText</w><w>is</w><w>largely</w><w>made</w><w>up</w><w>of</w><w>what</w><w>interests</w><w>English-speaking</w><w>,</w><w>young</w><w>,</w><w>white</w><w>men</w><w>—</w><w>not</w><w>very</w><w>representative</w><w>of</w><w>diverse</w><w>content</w><w>or</w><w>opinions</w><pc>.</pc><ref type="footnotemark" target="#en_note_13"/></p><p><w>There</w><w>is</w><w>also</w><w>a</w><w>more</w><w>insidious</w><w>element</w><w>to</w><w>massive</w><w>,</w><w>automatically</w><w>generated</w><w>datasets</w><w>like</w><w>WebText</w><w>,</w><w>as</w><w>their</w><w>scale</w><w>makes</w><w>it</w><w>difficult</w><w>to</w><w>entirely</w><w>know</w><w>their</w><w>contents</w><pc>.</pc><w>A</w><w>study</w><w>dedicated</w><w>to</w><w>evaluating</w><w>the</w><w>contents</w><w>of</w><w>WebText</w><w>and</w><w>its</w><w>open-source</w><w>replication</w><ref target="https://perma.cc/6PLA-EKYV"><w>OpenWebText</w><w>Corpus</w></ref><w>uncovered</w><w>that</w><w>at</w><w>least</w><w>12</w><w>%</w><w>(</w><w>272,000</w><w>)</w><w>of</w><w>the</w><w>news</w><w>sites</w><w>referenced</w><w>in</w><w>the</w><w>creation</w><w>of</w><w>these</w><w>datasets</w><w>came</w><w>from</w><w>sources</w><w>of</w><w>low</w><w>or</w><w>mixed</w><w>reliability</w><w>;</w><w>in</w><w>addition</w><w>to</w><w>this</w><w>,</w><w>63,000</w><w>of</w><w>the</w><w>links</w><w>came</w><w>from</w><w>subreddits</w><w>that</w><w>had</w><w>been</w><w>quarantined</w><w>or</w><w>have</w><w>since</w><w>been</w><w>outright</w><w>banned</w><w>from</w><w>the</w><w>site</w><pc>.</pc><ref type="footnotemark" target="#en_note_14"/></p><p><w>The</w><w>static</w><w>nature</w><w>of</w><w>training</w><w>data</w><w>can</w><w>also</w><w>be</w><w>a</w><w>potential</w><w>source</w><w>of</w><w>harm</w><w>;</w><w>much</w><w>has</w><w>happened</w><w>in</w><w>our</w><w>world</w><w>since</w><w>the</w><w>provenance</w><w>of</w><w>WebText</w><w>,</w><w>and</w><w>,</w><w>as</w><w>stated</w><w>in</w><w>the</w><w>article</w><w>``</w><w>On</w><w>the</w><w>Dangers</w><w>of</w><w>Stochastic</w><w>Parrots</w><w>:</w><w>Can</w><w>Language</w><w>Models</w><w>Be</w><w>Too</w><w>Big</w><pc>?</pc><w>''</w><w>by</w><w>Emily</w><w>Bender</w><w>,</w><w>Angelina</w><w>McMillan-Major</w><w>,</w><w>and</w><w>Timnit</w><w>Gebru</w><w>,</w><w>``</w><w>a</w><w>central</w><w>aspect</w><w>of</w><w>social</w><w>movement</w><w>formation</w><w>involves</w><w>using</w><w>language</w><w>strategically</w><w>to</w><w>destabilize</w><w>dominant</w><w>narratives</w><w>and</w><w>call</w><w>attention</w><w>to</w><w>underrepresented</w><w>social</w><w>perspectives</w><pc>.</pc><w>Social</w><w>movements</w><w>produce</w><w>new</w><w>norms</w><w>,</w><w>language</w><w>,</w><w>and</w><w>ways</w><w>of</w><w>communicating</w><pc>.</pc><w>''</w><ref type="footnotemark" target="#en_note_15"/><w>With</w><w>a</w><w>base</w><w>that</w><w>remains</w><w>stagnant</w><w>in</w><w>2016</w><w>,</w><w>GPT-2</w><w>and</w><w>many</w><w>other</w><w>large-scale</w><w>language</w><w>models</w><w>that</w><w>would</w><w>be</w><w>costly</w><w>to</w><w>retrain</w><w>lack</w><w>consciousness</w><w>of</w><w>the</w><w>language</w><w>formed</w><w>and</w><w>used</w><w>in</w><w>current</w><w>society</w><w>,</w><w>resulting</w><w>in</w><w>generated</w><w>text</w><w>that</w><w>may</w><w>reflect</w><w>a</w><w>previous</w><w>,</w><w>less</w><w>inclusive</w><w>world</w><w>view</w><pc>.</pc></p><p><w>With</w><w>that</w><w>being</w><w>said</w><w>,</w><w>there</w><w>have</w><w>been</w><w>efforts</w><w>to</w><w>combat</w><w>these</w><w>issues</w><w>unearthed</w><w>by</w><w>the</w><w>release</w><w>of</w><w>GPT-2</w><w>,</w><w>the</w><w>most</w><w>prominent</w><w>being</w><w>the</w><w>text</w><w>generation</w><w>models</w><w>developed</w><w>by</w><w>OpenAI</w><w>'s</w><w>open-source</w><w>competitor</w><w>,</w><ref target="https://perma.cc/M8BR-Q8XU"><w>EleutherAI</w></ref><pc>.</pc><w>This</w><w>organization</w><w>was</w><w>founded</w><w>in</w><w>2020</w><w>with</w><w>the</w><w>goal</w><w>of</w><w>replicating</w><w>and</w><w>improving</w><w>upon</w><w>OpenAI</w><w>'s</w><w>closed-source</w><w>and</w><w>paid-for</w><w>successor</w><w>of</w><w>GPT-2</w><w>,</w><ref target="https://perma.cc/793R-GGRT"><w>GPT-3</w></ref><w>,</w><w>which</w><w>had</w><w>just</w><w>been</w><w>released</w><pc>.</pc><w>EleutherAI</w><w>'s</w><w>efforts</w><w>resulted</w><w>in</w><w>the</w><w>creation</w><w>of</w><ref target="https://perma.cc/A9CQ-HVKY"><w>GPT-Neo</w></ref><w>,</w><w>a</w><w>large</w><w>scale</w><w>language</w><w>model</w><w>that</w><w>,</w><w>although</w><w>smaller</w><w>than</w><w>GPT-3</w><w>,</w><w>was</w><w>as</w><w>equally</w><w>powerful</w><w>in</w><w>performance</w><w>when</w><w>compared</w><w>with</w><w>GPT-3</w><w>'s</w><w>smaller</w><w>models</w><pc>.</pc><w>One</w><w>of</w><w>the</w><w>elements</w><w>that</w><w>made</w><w>GPT-Neo</w><w>distinct</w><w>from</w><w>the</w><w>original</w><w>GPT-3</w><w>was</w><w>that</w><w>it</w><w>was</w><w>trained</w><w>on</w><w>a</w><w>dataset</w><w>EleutherAI</w><w>compiled</w><w>called</w><ref target="https://perma.cc/G4UG-Z6WC"><w>the</w><w>Pile</w></ref><w>which</w><w>,</w><w>while</w><w>still</w><w>static</w><w>in</w><w>nature</w><w>,</w><w>was</w><w>designed</w><w>to</w><w>address</w><w>some</w><w>of</w><w>the</w><w>aforementioned</w><w>problems</w><w>of</w><w>diversity</w><w>in</w><w>data</w><w>through</w><w>incorporating</w><w>sources</w><w>outside</w><w>of</w><w>Reddit</w><w>—such</w><w>as</w><w>academic</w><w>journals</w><w>,</w><w>Wikipedia</w><w>,</w><w>and</w><w>other</w><w>web-based</w><w>forums—</w><w>and</w><w>attempted</w><w>to</w><w>more</w><w>effectively</w><w>and</w><w>transparently</w><w>document</w><w>this</w><w>dataset</w><w>'s</w><w>contents</w><w>through</w><w>the</w><w>creation</w><w>and</w><w>publication</w><w>of</w><w>a</w><w>datasheet</w><pc>.</pc><ref type="footnotemark" target="#en_note_16"/><w>The</w><w>open-source</w><w>approach</w><w>taken</w><w>by</w><w>EleutherAI</w><w>when</w><w>producing</w><w>this</w><w>model</w><w>combined</w><w>with</w><w>its</w><w>enhanced</w><w>performance</w><w>over</w><w>GPT-2</w><w>resulted</w><w>in</w><w>it</w><w>being</w><w>a</w><w>popular</w><w>choice</w><w>for</w><w>use</w><w>by</w><w>individuals</w><w>who</w><w>wanted</w><w>to</w><w>experiment</w><w>with</w><w>generative</w><w>text</w><w>;</w><w>in</w><w>fact</w><w>,</w><w>if</w><w>you</w><w>took</w><w>a</w><w>look</w><w>at</w><w>the</w><code rend="inline"><w>aitextgen</w></code><w>documentation</w><w>earlier</w><w>,</w><w>you</w><w>may</w><w>have</w><w>noticed</w><w>that</w><w>you</w><w>can</w><w>choose</w><w>to</w><w>use</w><w>GPT-Neo</w><w>instead</w><w>of</w><w>GPT-2</w><w>for</w><w>finetuning</w><pc>.</pc><w>This</w><w>tutorial</w><w>uses</w><w>GPT-2</w><w>because</w><w>even</w><w>the</w><w>smallest</w><w>GPT-Neo</w><w>model</w><w>is</w><w>still</w><w>slightly</w><w>larger</w><w>than</w><w>then</w><w>GPT-2</w><w>'s</w><w>smallest</w><w>model</w><w>,</w><w>thus</w><w>it</w><w>needs</w><w>slightly</w><w>more</w><w>powerful</w><w>hardware</w><w>to</w><w>train</w><w>;</w><w>if</w><w>you</w><w>do</w><w>have</w><w>an</w><w>adequate</w><w>GPU</w><w>,</w><w>to</w><w>finetune</w><w>with</w><w>GPT-Neo</w><w>,</w><w>change</w><w>the</w><w>line</w><code rend="inline"><w>ai</w><w>=</w><w>aitextgen</w><w>(</w><w>tf_gpt2=</w><w>''</w><w>124M</w><w>''</w><w>,</w><w>to_gpu=True</w><w>)</w></code><w>of</w><w>your</w><w>code</w><w>to</w><w>instead</w><w>use</w><code rend="inline"><w>ai</w><w>=</w><w>aitextgen</w><w>(</w><w>model=</w><w>''</w><w>EleutherAI/gpt-neo-125M</w><w>''</w><w>,</w><w>to_gpu=True</w><w>)</w></code><pc>.</pc></p><p><w>As</w><w>the</w><w>size</w><w>of</w><w>our</w><w>models</w><w>grow</w><w>,</w><w>our</w><w>understanding</w><w>of</w><w>the</w><w>training</w><w>data</w><w>is</w><w>not</w><w>the</w><w>only</w><w>thing</w><w>that</w><w>becomes</w><w>more</w><w>difficult</w><w>to</w><w>grapple</w><w>with</w><w>;</w><w>regardless</w><w>of</w><w>how</w><w>diverse</w><w>or</w><w>well-documented</w><w>the</w><w>training</w><w>data</w><w>is</w><w>,</w><w>there</w><w>remains</w><w>an</w><w>environmental</w><w>impact</w><w>that</w><w>should</w><w>be</w><w>considered</w><w>when</w><w>working</w><w>with</w><w>machine</w><w>learning</w><w>technologies</w><w>that</w><w>require</w><w>a</w><w>GPU</w><pc>.</pc><w>The</w><w>GPUs</w><w>required</w><w>for</w><w>the</w><w>creation</w><w>of</w><w>models</w><w>like</w><w>GPT-2</w><w>are</w><w>incredibly</w><w>power-hungry</w><w>pieces</w><w>of</w><w>hardware</w><w>;</w><w>in</w><w>2019</w><w>,</w><w>it</w><w>was</w><w>found</w><w>that</w><w>the</w><w>training</w><w>of</w><w>a</w><w>single</w><w>large</w><w>transformer</w><w>model</w><w>emitted</w><w>more</w><w>CO</w><hi rend="textsubscript"><w>2</w></hi><w>than</w><w>the</w><w>lifetime</w><w>use</w><w>of</w><w>a</w><w>car</w><w>driven</w><w>daily</w><pc>.</pc><ref type="footnotemark" target="#en_note_17"/><w>While</w><w>the</w><w>hyperparameter</w><w>tuning</w><w>done</w><w>with</w><w>a</w><w>small</w><w>dataset</w><w>as</w><w>demonstrated</w><w>in</w><w>this</w><w>lesson</w><w>has</w><w>very</w><w>minimal</w><w>impact</w><w>,</w><w>considering</w><w>it</w><w>is</w><w>estimated</w><w>that</w><w>we</w><w>must</w><w>cut</w><w>carbon</w><w>emissions</w><w>by</w><w>half</w><w>over</w><w>the</w><w>next</w><w>decade</w><w>to</w><w>deter</w><w>escalating</w><w>rates</w><w>of</w><w>natural</w><w>disaster</w><w>,</w><w>should</w><w>you</w><w>wish</w><w>to</w><w>perform</w><w>this</w><w>kind</w><w>of</w><w>analysis</w><w>using</w><w>a</w><w>much</w><w>larger</w><w>dataset</w><w>,</w><w>it</w><w>is</w><w>important</w><w>to</w><w>consider</w><w>the</w><w>ways</w><w>you</w><w>can</w><w>minimize</w><w>your</w><w>carbon</w><w>footprint</w><w>while</w><w>doing</w><w>so</w><w>;</w><w>for</w><w>example</w><w>,</w><w>choosing</w><w>to</w><w>use</w><w>a</w><w>cloud</w><w>GPU</w><w>service</w><w>rather</w><w>than</w><w>purchasing</w><w>your</w><w>own</w><w>GPU</w><w>to</w><w>run</w><w>at</w><w>home</w><w>(</w><w>unless</w><w>of</w><w>course</w><w>,</w><w>your</w><w>home</w><w>relies</w><w>on</w><w>a</w><w>sustainable</w><w>source</w><w>of</w><w>energy</w><w>)</w><pc>.</pc></p><p><w>In</w><w>their</w><w>totality</w><w>,</w><w>all</w><w>of</w><w>these</w><w>considerations</w><w>have</w><w>particular</w><w>implications</w><w>for</w><w>a</w><w>programming</w><w>historian</w><pc>.</pc><w>GPT-2</w><w>has</w><w>significant</w><w>potential</w><w>for</w><w>abuse</w><w>—</w><w>so</w><w>much</w><w>so</w><w>that</w><w>even</w><w>the</w><w>documentation</w><w>for</w><code rend="inline"><w>aitextgen</w></code><w>has</w><ref target="https://perma.cc/AZF4-2B5L"><w>a</w><w>page</w><w>discussing</w><w>ethical</w><w>usage</w><w>of</w><w>this</w><w>tool</w></ref><pc>.</pc><w>As</w><w>you</w><w>read</w><w>through</w><w>your</w><w>model</w><w>'s</w><w>output</w><w>,</w><w>you</w><w>may</w><w>have</w><w>felt</w><w>that</w><w>while</w><w>the</w><w>text</w><w>was</w><w>impressive</w><w>,</w><w>it</w><w>did</w><w>not</w><w>seem</w><w>quite</w><w>good</w><w>enough</w><w>to</w><w>have</w><w>been</w><w>believably</w><w>written</w><w>by</w><w>a</w><w>human</w><w>;</w><w>but</w><w>,</w><w>you</w><w>may</w><w>have</w><w>felt</w><w>this</w><w>way</w><w>because</w><w>you</w><w>were</w><w>conscious</w><w>of</w><w>the</w><w>fact</w><w>that</w><w>what</w><w>you</w><w>were</w><w>looking</w><w>at</w><w>was</w><w>computer</w><w>generated</w><pc>.</pc><w>Did</w><w>you</w><w>notice</w><w>how</w><w>the</w><w>model</w><w>,</w><w>in</w><w>an</w><w>effort</w><w>to</w><w>produce</w><w>``</w><w>convincing</w><w>''</w><w>news-like</w><w>output</w><w>,</w><w>would</w><w>create</w><w>and</w><w>attribute</w><w>quotes</w><w>to</w><w>various</w><w>actors</w><w>involved</w><w>in</w><w>Brexit</w><w>negotiations</w><pc>?</pc><w>What</w><w>might</w><w>happen</w><w>should</w><w>one</w><w>of</w><w>these</w><w>quotations</w><w>be</w><w>removed</w><w>from</w><w>the</w><w>context</w><w>of</w><w>generative</w><w>text</w><w>and</w><w>be</w><w>referenced</w><w>as</w><w>something</w><w>the</w><w>person</w><w>to</w><w>which</w><w>the</w><w>quote</w><w>was</w><w>randomly</w><w>attributed</w><w>had</w><w>actually</w><w>said</w><pc>?</pc><w>At</w><w>best</w><w>,</w><w>a</w><w>situation</w><w>like</w><w>this</w><w>would</w><w>contribute</w><w>to</w><w>spreading</w><w>misinformation</w><w>,</w><w>but</w><w>at</w><w>worst</w><w>,</w><w>the</w><w>quote</w><w>could</w><w>be</w><w>something</w><w>that</w><w>reflected</w><w>the</w><w>more</w><w>offensive</w><w>content</w><w>of</w><w>WebText</w><w>resulting</w><w>in</w><w>a</w><w>person</w><w>receiving</w><w>unjust</w><w>slander</w><pc>.</pc></p><p><w>Lastly</w><w>,</w><w>on</w><w>a</w><w>more</w><w>academic</w><w>note</w><w>,</w><w>should</w><w>you</w><w>decide</w><w>to</w><w>use</w><w>GPT-2</w><w>to</w><w>interrogate</w><w>a</w><w>historical</w><w>dataset</w><w>,</w><w>you</w><w>must</w><w>ensure</w><w>that</w><w>your</w><w>analysis</w><w>accounts</w><w>for</w><w>the</w><w>underlying</w><w>training</w><w>data</w><w>of</w><w>GPT-2</w><w>being</w><w>from</w><w>2016</w><pc>.</pc><w>Although</w><w>you</w><w>are</w><w>inflecting</w><w>the</w><w>language</w><w>model</w><w>with</w><w>your</w><w>own</w><w>historical</w><w>source</w><w>,</w><w>the</w><w>original</w><w>dataset</w><w>will</w><w>still</w><w>influence</w><w>how</w><w>connections</w><w>between</w><w>words</w><w>are</w><w>being</w><w>made</w><w>at</w><w>the</w><w>algorithmic</w><w>level</w><pc>.</pc><w>This</w><w>may</w><w>cause</w><w>misinterpretation</w><w>of</w><w>certain</w><w>vocabulary</w><w>that</w><w>has</w><w>changed</w><w>in</w><w>meaning</w><w>over</w><w>time</w><w>should</w><w>your</w><w>dataset</w><w>not</w><w>be</w><w>large</w><w>enough</w><w>for</w><w>your</w><w>model</w><w>to</w><w>learn</w><w>the</w><w>new</w><w>context</w><w>in</w><w>which</w><w>this</w><w>word</w><w>is</w><w>situated—</w><w>a</w><w>concern</w><w>that</w><w>is</w><w>consistently</w><w>present</w><w>in</w><w>all</w><w>forms</w><w>of</w><w>language-based</w><w>machine</w><w>learning</w><w>when</w><w>applied</w><w>to</w><w>historical</w><w>documents</w><pc>.</pc><ref type="footnotemark" target="#en_note_18"/><w>As</w><w>a</w><w>whole</w><w>,</w><w>the</w><w>use</w><w>of</w><w>GPT-2</w><w>for</w><w>historical</w><w>applications</w><w>offers</w><w>a</w><w>unique</w><w>(</w><w>and</w><w>often</w><w>humourous</w><w>)</w><w>alternative</w><w>to</w><w>more</w><w>traditional</w><w>methods</w><w>of</w><w>macroscopic</w><w>text</w><w>analysis</w><w>to</w><w>discern</w><w>broader</w><w>narratives</w><w>present</w><w>in</w><w>large</w><w>text-based</w><w>corpora</w><pc>.</pc><w>Yet</w><w>this</w><w>form</w><w>of</w><w>research</w><w>is</w><w>also</w><w>an</w><w>example</w><w>of</w><w>how</w><w>the</w><w>very</w><w>technology</w><w>you</w><w>are</w><w>using</w><w>can</w><w>influence</w><w>the</w><w>outcome</w><w>of</w><w>what</w><w>you</w><w>produce</w><pc>.</pc><w>It</w><w>is</w><w>important</w><w>to</w><w>be</w><w>conscious</w><w>of</w><w>how</w><w>the</w><w>tools</w><w>you</w><w>use</w><w>to</w><w>study</w><w>history</w><w>can</w><w>impact</w><w>not</w><w>only</w><w>your</w><w>own</w><w>work</w><w>,</w><w>but</w><w>also</w><w>the</w><w>world</w><w>around</w><w>you</w><pc>.</pc></p></div><div type="2" n="6"><head><w>Further</w><w>Readings</w></head><p><w>The</w><w>use</w><w>of</w><w>generated</w><w>text</w><w>as</w><w>an</w><w>analytical</w><w>tool</w><w>is</w><w>relatively</w><w>novel</w><w>,</w><w>as</w><w>is</w><w>the</w><w>application</w><w>of</w><w>AI</w><w>and</w><w>machine</w><w>learning</w><w>to</w><w>humanities</w><w>work</w><w>broadly</w><pc>.</pc><w>As</w><w>these</w><w>technologies</w><w>continue</w><w>to</w><w>rapidly</w><w>advance</w><w>,</w><w>so</w><w>does</w><w>the</w><w>research</w><w>related</w><w>to</w><w>the</w><w>ethics</w><w>of</w><w>their</w><w>use</w><w>and</w><w>applications</w><pc>.</pc><w>While</w><w>this</w><w>lesson</w><w>was</w><w>in</w><w>the</w><w>process</w><w>of</w><w>peer-review</w><w>,</w><emph><w>Dædalus</w></emph><w>,</w><w>a</w><w>multidisciplinary</w><w>journal</w><w>published</w><w>by</w><w>the</w><w>American</w><w>Academy</w><w>of</w><w>Arts</w><w>&amp;</w><w>Sciences</w><w>,</w><w>released</w><w>their</w><ref target="https://perma.cc/AGW3-RZ6H"><w>Spring</w><w>2022</w><w>issue</w><w>titled</w><w>``</w><w>AI</w><w>&amp;</w><w>Society</w><w>''</w></ref><w>which</w><w>grapples</w><w>extensively</w><w>with</w><w>topics</w><w>discussed</w><w>throughout</w><w>this</w><w>lesson</w><pc>.</pc><w>I</w><w>would</w><w>recommend</w><w>the</w><w>entire</w><w>issue</w><w>for</w><w>further</w><w>reading</w><w>,</w><w>but</w><w>articles</w><w>of</w><w>particular</w><w>relevance</w><w>to</w><w>this</w><w>lesson</w><w>are</w><w>:</w></p><list type="unordered"><item><p><w>Choi</w><w>,</w><w>Yejin</w><pc>.</pc><w>``</w><w>The</w><w>Curious</w><w>Case</w><w>of</w><w>Commonsense</w><w>Intelligence</w><pc>.</pc><w>''</w><emph><w>Dædalus</w></emph><w>151</w><w>,</w><w>no</w><pc>.</pc><w>2</w><w>(</w><w>Spring</w><w>2022</w><w>)</w><w>:</w><w>139-155</w><pc>.</pc><ref target="https://perma.cc/F2BT-Z6PR"><w>https</w><w>:</w><w>//www.amacad.org/publication/curious-case-commonsense-intelligence</w></ref><pc>.</pc></p></item><item><p><w>Rees</w><w>,</w><w>Tobias</w><pc>.</pc><w>``</w><w>Non-Human</w><w>Words</w><w>:</w><w>On</w><w>GPT-3</w><w>as</w><w>a</w><w>Philosophical</w><w>Laboratory</w><pc>.</pc><w>''</w><emph><w>Dædalus</w></emph><w>151</w><w>,</w><w>no</w><pc>.</pc><w>2</w><w>(</w><w>Spring</w><w>2022</w><w>)</w><w>:</w><w>168-182</w><pc>.</pc><ref target="https://perma.cc/57VU-5D8T"><w>https</w><w>:</w><w>//www.amacad.org/publication/non-human-words-gpt-3-philosophical-laboratory</w></ref><pc>.</pc></p></item><item><p><w>Agüera</w><w>y</w><w>Arcas</w><w>,</w><w>Blaise</w><pc>.</pc><w>``</w><w>Do</w><w>Large</w><w>Language</w><w>Models</w><w>Understand</w><w>Us</w><pc>?</pc><w>''</w><emph><w>Dædalus</w></emph><w>151</w><w>,</w><w>no</w><pc>.</pc><w>2</w><w>(</w><w>Spring</w><w>2022</w><w>)</w><w>:</w><w>183-197</w><pc>.</pc><ref target="https://perma.cc/GNW7-WWNH"><w>https</w><w>:</w><w>//www.amacad.org/publication/do-large-language-models-understand-us</w></ref><pc>.</pc></p></item></list></div><div type="2" n="7"><head><w>Endnotes</w></head><p><ref type="footnotemark" target="#en_note_1"/><w>:</w><w>Jeffrey</w><w>Wu</w><w>et</w><w>al.</w><w>,</w><w>``</w><w>Language</w><w>Models</w><w>Are</w><w>Unsupervised</w><w>Multitask</w><w>Learners</w><w>,</w><w>''</w><emph><w>OpenAI</w></emph><w>,</w><w>(</w><w>February</w><w>2019</w><w>)</w><w>:</w><w>7</w><w>,</w><ref target="https://perma.cc/7HCZ-DX87"><w>https</w><w>:</w><w>//cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf</w></ref><pc>.</pc><ref type="footnotemark" target="#en_note_2"/><w>:</w><w>David</w><w>Tarditi</w><w>,</w><w>Sidd</w><w>Puri</w><w>,</w><w>and</w><w>Jose</w><w>Oglesby</w><w>,</w><w>``</w><w>Accelerator</w><w>:</w><w>Using</w><w>data</w><w>parallelism</w><w>to</w><w>program</w><w>GPUs</w><w>for</w><w>general-purpose</w><w>uses</w><w>,</w><w>''</w><emph><w>Operating</w><w>Systems</w><w>Review</w></emph><w>40</w><w>,</w><w>(</w><w>2006</w><w>)</w><w>:</w><w>325-326</w><pc>.</pc><ref target="https://perma.cc/QDX9-33R6"><w>https</w><w>:</w><w>//www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-2005-184.pdf</w></ref><pc>.</pc><ref type="footnotemark" target="#en_note_3"/><w>:</w><w>Shawn</w><w>Graham</w><w>,</w><emph><w>An</w><w>Enchantment</w><w>of</w><w>Digital</w><w>Archaeology</w><w>:</w><w>Raising</w><w>the</w><w>Dead</w><w>with</w><w>Agent-Based</w><w>Models</w><w>,</w><w>Archaeogaming</w><w>,</w><w>and</w><w>Artificial</w><w>Intelligence</w></emph><w>(</w><w>New</w><w>York</w><w>:</w><w>Berghahn</w><w>Books</w><w>,</w><w>2020</w><w>)</w><w>,</w><w>118</w><pc>.</pc><ref type="footnotemark" target="#en_note_4"/><w>:</w><w>Emily</w><w>M.</w><w>Bender</w><w>and</w><w>Alexander</w><w>Koller</w><w>,</w><w>``</w><w>Climbing</w><w>towards</w><w>NLU</w><w>:</w><w>On</w><w>Meaning</w><w>,</w><w>Form</w><w>,</w><w>and</w><w>Understanding</w><w>in</w><w>the</w><w>Age</w><w>of</w><w>Data</w><w>,</w><w>''</w><w>(</w><w>paper</w><w>presented</w><w>at</w><w>Proceedings</w><w>of</w><w>the</w><w>58th</w><w>Annual</w><w>Meeting</w><w>of</w><w>the</w><w>Association</w><w>for</w><w>Computational</w><w>Linguistics</w><w>,</w><w>Online</w><w>,</w><w>July</w><w>5</w><w>2020</w><w>)</w><w>:</w><w>5187</w><pc>.</pc><ref target="http://dx.doi.org/10.18653/v1/2020.acl-main.463"><w>http</w><w>:</w><w>//dx.doi.org/10.18653/v1/2020.acl-main.463</w></ref><pc>.</pc><ref type="footnotemark" target="#en_note_5"/><w>:</w><w>Kari</w><w>Kraus</w><w>,</w><w>``</w><w>Conjectural</w><w>Criticism</w><w>:</w><w>Computing</w><w>Past</w><w>and</w><w>Future</w><w>Texts</w><w>,</w><w>''</w><emph><w>Digital</w><w>Humanities</w><w>Quarterly</w></emph><w>3</w><w>,</w><w>no</w><pc>.</pc><w>4</w><w>(</w><w>2009</w><w>)</w><pc>.</pc><ref target="https://perma.cc/C7D7-H7WY"><w>http</w><w>:</w><w>//www.digitalhumanities.org/dhq/vol/3/4/000069/000069.html</w></ref><pc>.</pc><ref type="footnotemark" target="#en_note_6"/><w>:</w><w>Alexandra</w><w>Borchardt</w><w>,</w><w>Felix</w><w>M.</w><w>Simon</w><w>,</w><w>and</w><w>Diego</w><w>Bironzo</w><w>,</w><emph><w>Interested</w><w>but</w><w>not</w><w>Engaged</w><w>:</w><w>How</w><w>Europe</w><w>’</w><w>s</w><w>Media</w><w>Cover</w><w>Brexit</w><w>,</w></emph><w>(</w><w>Oxford</w><w>:</w><w>Reuters</w><w>Institute</w><w>for</w><w>the</w><w>Study</w><w>of</w><w>Journalism</w><w>,</w><w>2018</w><w>)</w><w>,</w><w>23</w><w>,</w><ref target="https://perma.cc/8S2H-9ZDV"><w>https</w><w>:</w><w>//reutersinstitute.politics.ox.ac.uk/sites/default/files/2018-06/How</w><w>%</w><w>20Europe</w><w>%</w><w>27s</w><w>%</w><w>20Media</w><w>%</w><w>20Cover</w><w>%</w><w>20Brexit.pdf</w></ref><pc>.</pc><ref type="footnotemark" target="#en_note_7"/><w>:</w><w>Satnam</w><w>Virdee</w><w>&amp;</w><w>Brendan</w><w>McGeever</w><w>,</w><w>``</w><w>Racism</w><w>,</w><w>Crisis</w><w>,</w><w>Brexit</w><w>,</w><w>''</w><emph><w>Ethnic</w><w>and</w><w>Racial</w><w>Studies</w></emph><w>40</w><w>,</w><w>no</w><pc>.</pc><w>10</w><w>(</w><w>July</w><w>2017</w><w>)</w><w>:</w><w>1807</w><w>,</w><ref target="https://doi.org/10.1080/01419870.2017.1361544"><w>https</w><w>:</w><w>//doi.org/10.1080/01419870.2017.1361544</w></ref><pc>.</pc><ref type="footnotemark" target="#en_note_8"/><w>:</w><w>Blair</w><w>E</w><w>Williams</w><w>,</w><w>``</w><w>A</w><w>Tale</w><w>of</w><w>Two</w><w>Women</w><w>:</w><w>A</w><w>Comparative</w><w>Gendered</w><w>Media</w><w>Analysis</w><w>of</w><w>UK</w><w>Prime</w><w>Ministers</w><w>Margaret</w><w>Thatcher</w><w>and</w><w>Theresa</w><w>May</w><w>''</w><w>,</w><emph><w>Parliamentary</w><w>Affairs</w></emph><w>74</w><w>,</w><w>no</w><pc>.</pc><w>2</w><w>(</w><w>April</w><w>2021</w><w>)</w><w>:</w><w>408</w><w>,</w><ref target="https://doi.org/10.1093/pa/gsaa008"><w>https</w><w>:</w><w>//doi.org/10.1093/pa/gsaa008</w></ref><pc>.</pc><ref type="footnotemark" target="#en_note_9"/><w>:</w><w>Columba</w><w>Achilleos-Sarll</w><w>and</w><w>Benjamin</w><w>Martill</w><w>,</w><w>``</w><w>Toxic</w><w>Masculinity</w><w>:</w><w>Militarism</w><w>,</w><w>Deal-Making</w><w>and</w><w>the</w><w>Performance</w><w>of</w><w>Brexit</w><w>''</w><w>in</w><emph><w>Gender</w><w>and</w><w>Queer</w><w>Perspectives</w><w>on</w><w>Brexit</w></emph><w>(</w><w>London</w><w>:</w><w>Palgrave</w><w>Macmillan</w><w>,</w><w>2019</w><w>)</w><w>,</w><w>23</w><w>,</w><ref target="https://doi.org/10.1007/978-3-030-03122-0_2"><w>https</w><w>:</w><w>//doi.org/10.1007/978-3-030-03122-0_2</w></ref><pc>.</pc><ref type="footnotemark" target="#en_note_10"/><w>:</w><w>Ibid</w><pc>.</pc><ref type="footnotemark" target="#en_note_11"/><w>:</w><w>Alec</w><w>Radford</w><w>et</w><w>al.</w><w>,</w><w>``</w><w>Better</w><w>Language</w><w>Models</w><w>and</w><w>Their</w><w>Implications</w><w>,</w><w>''</w><emph><w>OpenAI</w></emph><w>(</w><w>blog</w><w>)</w><w>,</w><w>February</w><w>14</w><w>,</w><w>2019</w><w>,</w><ref target="https://perma.cc/583K-5N5G"><w>https</w><w>:</w><w>//openai.com/blog/better-language-models/</w></ref><pc>.</pc><ref type="footnotemark" target="#en_note_12"/><w>:</w><w>Michael</w><w>Barthel</w><w>et</w><w>al.</w><w>,</w><emph><w>Seven-in-Ten</w><w>Reddit</w><w>Users</w><w>Get</w><w>News</w><w>on</w><w>the</w><w>Site</w><w>,</w></emph><w>(</w><w>Washington</w><w>:</w><w>Pew</w><w>Research</w><w>Center</w><w>,</w><w>2016</w><w>)</w><w>,</w><ref target="https://perma.cc/YX2R-3KPV"><w>https</w><w>:</w><w>//www.pewresearch.org/journalism/2016/02/25/reddit-news-users-more-likely-to-be-male-young-and-digital-in-their-news-preferences/</w></ref><ref type="footnotemark" target="#en_note_13"/><w>:</w><w>Jeffrey</w><w>Wu</w><w>et</w><w>al.</w><w>,</w><w>7</w><pc>.</pc><ref type="footnotemark" target="#en_note_14"/><w>:</w><w>Samuel</w><w>Gehman</w><w>et</w><w>al.</w><w>,</w><w>``</w><w>RealToxicityPrompts</w><w>:</w><w>Evaluating</w><w>Neural</w><w>Toxic</w><w>Degeneration</w><w>in</w><w>Language</w><w>Models</w><w>,</w><w>''</w><emph><w>Findings</w><w>of</w><w>the</w><w>Association</w><w>for</w><w>Computational</w><w>Linguistics</w></emph><w>(</w><w>January</w><w>2020</w><w>)</w><w>:</w><w>3362</w><w>,</w><ref target="https://perma.cc/T4ZJ-SNKM"><w>https</w><w>:</w><w>//aclanthology.org/2020.findings-emnlp.301.pdf</w></ref><pc>.</pc><ref type="footnotemark" target="#en_note_15"/><w>:</w><w>Emily</w><w>M.</w><w>Bender</w><w>,</w><w>Timnit</w><w>Gebru</w><w>,</w><w>Angelina</w><w>McMillan-Major</w><w>,</w><w>and</w><w>Shmargaret</w><w>Shmitchell</w><w>,</w><w>``</w><w>On</w><w>the</w><w>Dangers</w><w>of</w><w>Stochastic</w><w>Parrots</w><w>:</w><w>Can</w><w>Language</w><w>Models</w><w>Be</w><w>Too</w><w>Big</w><pc>?</pc><w>🦜</w><w>,</w><w>''</w><emph><w>ACM</w><w>Conference</w><w>on</w><w>Fairness</w><w>,</w><w>Accountability</w><w>,</w><w>and</w><w>Transparency</w></emph><w>(</w><w>March</w><w>2021</w><w>)</w><w>:</w><w>614</w><w>,</w><ref target="https://doi.org/10.1145/3442188.3445922"><w>https</w><w>:</w><w>//doi.org/10.1145/3442188.3445922</w></ref><pc>.</pc><ref type="footnotemark" target="#en_note_16"/><w>:</w><w>Biderman</w><w>,</w><w>Stella</w><w>,</w><w>Kieran</w><w>Bicheno</w><w>,</w><w>and</w><w>Leo</w><w>Gao</w><w>,</w><w>``</w><w>Datasheet</w><w>for</w><w>the</w><w>Pile</w><pc>.</pc><w>''</w><emph><w>arXiv</w><w>preprint</w><w>arXiv:2201.07311</w></emph><w>(</w><w>2022</w><w>)</w><ref type="footnotemark" target="#en_note_17"/><w>:</w><w>Emma</w><w>Strubell</w><w>,</w><w>Ananya</w><w>Ganesh</w><w>,</w><w>and</w><w>Andrew</w><w>McCallum</w><w>,</w><w>``</w><w>Energy</w><w>and</w><w>Policy</w><w>Considerations</w><w>for</w><w>Deep</w><w>Learning</w><w>in</w><w>NLP</w><w>,</w><w>''</w><emph><w>Association</w><w>for</w><w>Computational</w><w>Linguistics</w></emph><w>(</w><w>June</w><w>2019</w><w>)</w><w>:</w><w>1</w><w>,</w><ref target="https://doi.org/10.48550/arXiv.1906.02243"><w>https</w><w>:</w><w>//doi.org/10.48550/arXiv.1906.02243</w></ref><pc>.</pc><ref type="footnotemark" target="#en_note_18"/><w>:</w><w>Maud</w><w>Ehrmann</w><w>et</w><w>al.</w><w>,</w><w>``</w><w>Named</w><w>Entity</w><w>Recognition</w><w>and</w><w>Classification</w><w>on</w><w>Historical</w><w>Documents</w><w>:</w><w>A</w><w>Survey</w><w>,</w><w>''</w><w>(</w><w>Preprint</w><w>,</w><w>submitted</w><w>in</w><w>2021</w><w>)</w><w>:</w><w>12-13</w><pc>.</pc><ref target="https://doi.org/10.48550/arXiv.2109.11406"><w>https</w><w>:</w><w>//doi.org/10.48550/arXiv.2109.11406</w></ref><pc>.</pc></p></div></body>
    </text>
</TEI>
