<TEI xmlns="http://www.tei-c.org/ns/1.0" xml:id="analyse-de-documents-avec-tfidf">
  <teiHeader>
 <fileDesc>
  <titleStmt>
   <title>Analyse de documents avec TF-IDF</title>
  <author role="original_author">Matthew J. Lavin</author><editor role="reviewers"><persName>Quinn Dombrowski</persName><persName>Catherine Nygren</persName></editor><author role="translators">Fran&#231;ois Dominic Laram&#233;e</author><editor role="translation-reviewers"><persName>Am&#233;lie Daloz</persName><persName>R&#233;mi Cardon</persName></editor><editor role="editors">Zoe LeBlanc</editor></titleStmt>
  <publicationStmt>
   <idno type="doi">10.46430/phfr0022</idno><date type="published">05/13/2019</date><date type="translated">06/27/2022</date><p>Lesson reviewed and published in Programming Historian.</p>
  </publicationStmt>
  <sourceDesc>
  <p>Born digital, in a markdown format. Original file: <ref type="original_file" target="#analyzing-documents-with-tfidf"/>.</p><p>There are other translations: <ref target=""/></p></sourceDesc>
 </fileDesc>
 <profileDesc><abstract><p>Cette le&#231;on pr&#233;sente une m&#233;thode de traitement automatique des langues et de recherche d'informations nomm&#233;e Term Frequency - Inverse Document Frequency (tf-idf). Elle en expose les fondations et introduit &#224; l'occasion des questions et des concepts li&#233;s &#224; l'analyse de textes.</p></abstract><textClass><keywords><term xml:lang="en">distant-reading</term></keywords></textClass></profileDesc>
</teiHeader>
  <text xml:lang="fr">
    <body>
      <div type="2"><head>Aper&#231;u</head>
<p>Cette le&#231;on pr&#233;sente une m&#233;thode de traitement automatique des langues et de recherche d'informations nomm&#233;e <hi rend="bold">tf-idf</hi>, une appellation tir&#233;e de l'anglais <emph>Term Frequency - Inverse Document Frequency</emph>. Vous avez peut-&#234;tre d&#233;j&#224; entendu parler du <hi rend="bold">tf-idf</hi> dans le contexte d'une discussion de la mod&#233;lisation th&#233;matique, de l'apprentissage automatique ou d'autres m&#233;thodes d'analyse textuelle. <hi rend="bold">Tf-idf</hi> appara&#238;t r&#233;guli&#232;rement dans la litt&#233;rature scientifique car il s'agit &#224; la fois d'une m&#233;thode d'exploration de <ref target="https://perma.cc/G2LA-EKTH">corpus</ref> et d'une &#233;tape de pr&#233;traitement utile pour plusieurs autres m&#233;thodes de fouille de textes et de mod&#233;lisation.</p>
<p>En &#233;tudiant <hi rend="bold">tf-idf</hi>, vous d&#233;couvrirez une m&#233;thode d'analyse textuelle que vous pourrez appliquer imm&#233;diatement. Cette le&#231;on vous permettra aussi de vous familiariser avec certaines des questions et certains des concepts de l'analyse textuelle assist&#233;e par ordinateur. Notamment, cette le&#231;on explique comment isoler les mots les plus significatifs d'un document, des mots qui ont tendance &#224; appara&#238;tre fr&#233;quemment dans de nombreux documents r&#233;dig&#233;s dans une m&#234;me langue. Outre <hi rend="bold">tf-idf</hi>, il existe de nombreuses m&#233;thodes qui permettent de d&#233;terminer les mots et les locutions sp&#233;cifiques &#224; un ensemble de documents. Je recommande fortement la lecture de ce billet de blogue de Ted Underwood<ref type="footnotemark" target="#note_1"/> en compl&#233;ment d'information.</p>
</div>
      <div type="2"><head>Pr&#233;paration</head>
<div type="3"><head>Connaissances pr&#233;alables recommand&#233;es</head>
<list type="unordered">
<item>&#202;tre familiaris&#233;(e) avec Python ou un langage de programmation similaire. Le code de cette le&#231;on a &#233;t&#233; programm&#233; en Python 3.6, mais vous pouvez ex&#233;cuter <hi rend="bold">tf-idf</hi> dans toutes les versions courantes de Python, en utilisant l'un des divers modules appropri&#233;s, ainsi que dans plusieurs autres langages de programmation. Le niveau de comp&#233;tence en programmation requis est difficile &#224; &#233;valuer, mais vous devrez au moins &#234;tre &#224; l'aise avec les types de donn&#233;es et les op&#233;rations &#233;l&#233;mentaires. Pour tirer profit de cette le&#231;on, il serait aussi souhaitable de suivre un cours comme celui propos&#233; par Antoine Rozo sur <ref target="https://perma.cc/7WJ4-WD3P">zestedesavoir.com</ref> ou d'avoir suivi certaines des <ref target="/fr/lecons/introduction-et-installation">le&#231;ons d'introduction &#224; la programmation en Python</ref> du <emph>Programming Historian</emph>. Si vous avez acc&#232;s &#224; une biblioth&#232;que, n'h&#233;sitez pas &#224; consulter le livre d'&#201;milien Schultz et de Matthias Bussonnier <ref target="http://www.worldcat.org/oclc/1232233436"><emph>Python pour les sciences humaines et sociales</emph></ref>.   </item>
<item>&#192; d&#233;faut de pouvoir suivre la recommandation pr&#233;c&#233;dente, vous pourriez <ref target="https://perma.cc/YDT4-9JJ6">r&#233;viser les bases de Python</ref>, dont les types de donn&#233;es &#233;l&#233;mentaires (cha&#238;nes de caract&#232;res, nombres entiers, nombres r&#233;els, tuples, listes et dictionnaires), les variables, les boucles, les classes d'objets et leurs instances.</item>
<item>La ma&#238;trise des bases d'Excel ou d'un autre tableur pourrait &#234;tre utile si vous souhaitez examiner les feuilles de calcul au format CSV li&#233;es &#224; cette le&#231;on de plus pr&#232;s. Vous pouvez aussi employer le module Pandas du langage Python pour lire ces fichiers CSV.</item>
</list>
</div><div type="3"><head>Avant de commencer</head>
<list type="unordered">
<item>Installez la version Python 3 de l'environnement de d&#233;veloppement Anaconda. La m&#233;thode &#224; suivre est expliqu&#233;e dans la le&#231;on <ref target="/en/lessons/text-mining-with-extracted-features">Text Mining in Python through the HTRC Feature Reader</ref> (en anglais). Vous obtiendrez le langage Python 3.6 (ou une version plus r&#233;cente), le module <ref target="https://scikit-learn.org/stable/install.html">Scikit-Learn</ref> (qui contient la version de <hi rend="bold">tf-idf</hi> que nous pr&#233;sentons ici) et tout ce qu'il faut pour ex&#233;cuter du code Python dans un <ref target="https://jupyter.org/">carnet Jupyter</ref>.</item>
<item>Il est possible d'obtenir toutes les librairies n&#233;cessaires sans installer Anaconda ou en choisissant plut&#244;t une alternative plus l&#233;g&#232;re comme <ref target="https://docs.conda.io/en/latest/miniconda.html">Miniconda</ref>. Pour plus d'informations, consultez la section <ref target="#alternatives-%C3%A0-anaconda">&#171;&#8239;Alternatives &#224; Anaconda&#8239;&#187;</ref> &#224; la fin de cette le&#231;on.</item>
</list>
</div><div type="3"><head>Jeu de donn&#233;es</head>
<p>Pour comprendre comment fonctionne <hi rend="bold">tf-idf</hi>, prenons un exemple. J'ai donc pr&#233;par&#233; pour vous un jeu de donn&#233;es form&#233; de 366 <ref target="https://perma.cc/73CL-ZKL3">n&#233;crologies</ref> historiques publi&#233;es dans le <emph>New York Times</emph> et moissonn&#233;es sur le site <ref target="https://perma.cc/R2V7-UBXX">https://archive.nytimes.com/www.nytimes.com/learning/general/onthisday/</ref> sur lequel, &#224; chaque jour de l'ann&#233;e, le <emph>New York Times</emph> mettait en vedette la n&#233;crologie d'une personne dont c'&#233;tait l'anniversaire de naissance.</p>
<p>Les fichiers requis pour suivre la le&#231;on, dont ce jeu de donn&#233;es, peuvent &#234;tre t&#233;l&#233;charg&#233;s <ref target="/assets/tf-idf/lecon-fichiers.zip">ici</ref>. Le jeu de donn&#233;es est assez petit pour que vous puissiez ouvrir et lire au moins quelques-uns des fichiers textes. Les donn&#233;es moissonn&#233;es sont &#233;galement disponibles &#224; deux endroits&#8239;: </p>
<list type="ordered">
<item>Dans le r&#233;pertoire <code rend="inline">necrologies</code> contenant les fichiers .html t&#233;l&#233;charg&#233;s &#224; partir du site web &#171;&#8239;On This Day&#8239;&#187; de 2011</item>
<item>Dans le r&#233;pertoire <code rend="inline">txt</code> contenant des fichiers .txt.</item>
</list>
<p>Dans ces derniers se trouve le corps du texte de chaque n&#233;crologie. Ces fichiers ont &#233;t&#233; g&#233;n&#233;r&#233;s &#224; l'aide du <ref target="https://perma.cc/N6KK-ADEG">module Python</ref> nomm&#233; <ref target="https://perma.cc/2KTE-AEM3">BeautifulSoup</ref>.</p>
<p>Ce corpus n&#233;crologique constitue un art&#233;fact historique en soi. Le choix &#233;ditorial des n&#233;crologies est le reflet de choix d'inclusion et de repr&#233;sentation historiquement situ&#233;. Et cela a un fort impact sur le corpus. La signification de ce genre de d&#233;cisions a &#233;t&#233; soulign&#233;e par le <emph>New York Times</emph> lui-m&#234;me en mars 2018, lorsque le journal a commenc&#233; &#224; publier les n&#233;crologies de &#171;&#8239;femmes n&#233;glig&#233;es&#8239;&#187;.<ref type="footnotemark" target="#note_2"/> Comme l'ont soulign&#233; &#224; ce moment Amisha Padnani et Jessica Bennett, &#171;&#8239;de qui l'on se souvient - et comment on le fait - d&#233;pend invariablement d'un jugement. Revoir l'archive n&#233;crologique peut ainsi constituer une le&#231;on brutale sur la mani&#232;re dont la soci&#233;t&#233; &#233;valuait certaines r&#233;alisations et les personnes qui en sont responsables&#8239;&#187; (traduction libre). Vu sous cet angle, le jeu de donn&#233;es propos&#233; ici constitue non pas un &#233;chantillon repr&#233;sentatif des n&#233;crologies historiques, mais plut&#244;t une vitrine vers les personnes que le <emph>New York Times</emph> jugeait dignes d'&#234;tre mises en valeur en 2010-2011. Vous remarquerez que plusieurs des personnages historiques mentionn&#233;s sont bien connus, ce qui sugg&#232;re un effort conscient de se pencher sur l'histoire du <emph>New York Times</emph> pour choisir les n&#233;crologies selon des crit&#232;res particuliers.<ref type="footnotemark" target="#note_3"/></p>
</div><table>
<row>
<cell role="label">Rang</cell>
<cell role="label">Terme</cell>
<cell role="label">D&#233;compte (tf)</cell>
</row>
<row>
<cell>10</cell>
<cell>vexations</cell>
<cell>6.21</cell>
</row>
<row>
<cell>9</cell>
<cell>plume</cell>
<cell>6.21</cell>
</row>
<row>
<cell>8</cell>
<cell>ironclad</cell>
<cell>6.21</cell>
</row>
<row>
<cell>7</cell>
<cell>mark</cell>
<cell>8.64</cell>
</row>
<row>
<cell>6</cell>
<cell>nellie</cell>
<cell>9.92</cell>
</row>
<row>
<cell>5</cell>
<cell>bly</cell>
<cell>12.42</cell>
</row>
<row>
<cell>4</cell>
<cell>seaman</cell>
<cell>14.88</cell>
</row>
<row>
<cell>3</cell>
<cell>she</cell>
<cell>16.22</cell>
</row>
<row>
<cell>2</cell>
<cell>her</cell>
<cell>22.74</cell>
</row>
<row>
<cell>1</cell>
<cell>cochrane</cell>
<cell>24.85</cell>
</row>
</table><table>
<row>
<cell role="label">Rang</cell>
<cell role="label">Terme</cell>
<cell role="label">D&#233;compte (tf)</cell>
</row>
<row>
<cell>10</cell>
<cell>to</cell>
<cell>4</cell>
</row>
<row>
<cell>9</cell>
<cell>was</cell>
<cell>4</cell>
</row>
<row>
<cell>8</cell>
<cell>cochrane</cell>
<cell>4</cell>
</row>
<row>
<cell>7</cell>
<cell>at</cell>
<cell>8</cell>
</row>
<row>
<cell>6</cell>
<cell>she</cell>
<cell>10</cell>
</row>
<row>
<cell>5</cell>
<cell>and</cell>
<cell>13</cell>
</row>
<row>
<cell>4</cell>
<cell>in</cell>
<cell>14</cell>
</row>
<row>
<cell>3</cell>
<cell>her</cell>
<cell>15</cell>
</row>
<row>
<cell>2</cell>
<cell>of</cell>
<cell>16</cell>
</row>
<row>
<cell>1</cell>
<cell>the</cell>
<cell>21</cell>
</row>
</table></div>
      <div type="2"><head>Ex&#233;cution de tf-idf</head>
<table>
<row>
<cell role="label">Indice</cell>
<cell role="label">Mot</cell>
<cell role="label">D&#233;compte</cell>
<cell role="label">Df</cell>
<cell role="label">Idf</cell>
<cell role="label">Tf-idf</cell>
</row>
<row>
<cell>30</cell>
<cell>character</cell>
<cell>1</cell>
<cell>89</cell>
<cell>2.40555218</cell>
<cell>2.40555218</cell>
</row>
<row>
<cell>29</cell>
<cell>career</cell>
<cell>1</cell>
<cell>223</cell>
<cell>1.49371580</cell>
<cell>1.49371580</cell>
</row>
<row>
<cell>28</cell>
<cell>by</cell>
<cell>3</cell>
<cell>349</cell>
<cell>1.04742869</cell>
<cell>3.14228608</cell>
</row>
<row>
<cell>27</cell>
<cell>but</cell>
<cell>1</cell>
<cell>343</cell>
<cell>1.06472019</cell>
<cell>1.06472019</cell>
</row>
<row>
<cell>26</cell>
<cell>born</cell>
<cell>1</cell>
<cell>342</cell>
<cell>1.06763140</cell>
<cell>1.06763140</cell>
</row>
<row>
<cell>25</cell>
<cell>body</cell>
<cell>1</cell>
<cell>112</cell>
<cell>2.17797403</cell>
<cell>2.17797403</cell>
</row>
<row>
<cell>24</cell>
<cell>bly</cell>
<cell>2</cell>
<cell>1</cell>
<cell>6.21221467</cell>
<cell>12.42442933</cell>
</row>
<row>
<cell>23</cell>
<cell>bell</cell>
<cell>1</cell>
<cell>24</cell>
<cell>3.68648602</cell>
<cell>3.68648602</cell>
</row>
<row>
<cell>22</cell>
<cell>began</cell>
<cell>1</cell>
<cell>241</cell>
<cell>1.41642412</cell>
<cell>1.41642412</cell>
</row>
<row>
<cell>21</cell>
<cell>beat</cell>
<cell>1</cell>
<cell>33</cell>
<cell>3.37900132</cell>
<cell>3.37900132</cell>
</row>
<row>
<cell>20</cell>
<cell>be</cell>
<cell>1</cell>
<cell>332</cell>
<cell>1.09721936</cell>
<cell>1.09721936</cell>
</row>
<row>
<cell>19</cell>
<cell>baxter</cell>
<cell>1</cell>
<cell>4</cell>
<cell>5.29592394</cell>
<cell>5.29592394</cell>
</row>
<row>
<cell>18</cell>
<cell>barrel</cell>
<cell>1</cell>
<cell>7</cell>
<cell>4.82592031</cell>
<cell>4.82592031</cell>
</row>
<row>
<cell>17</cell>
<cell>bankruptcy</cell>
<cell>1</cell>
<cell>8</cell>
<cell>4.70813727</cell>
<cell>4.70813727</cell>
</row>
<row>
<cell>16</cell>
<cell>balloon</cell>
<cell>1</cell>
<cell>2</cell>
<cell>5.80674956</cell>
<cell>5.80674956</cell>
</row>
<row>
<cell>15</cell>
<cell>avenue</cell>
<cell>2</cell>
<cell>68</cell>
<cell>2.67125534</cell>
<cell>5.34251069</cell>
</row>
<row>
<cell>14</cell>
<cell>at</cell>
<cell>8</cell>
<cell>362</cell>
<cell>1.01095901</cell>
<cell>8.08767211</cell>
</row>
<row>
<cell>13</cell>
<cell>asylum</cell>
<cell>1</cell>
<cell>2</cell>
<cell>5.80674956</cell>
<cell>5.80674956</cell>
</row>
<row>
<cell>12</cell>
<cell>ascension</cell>
<cell>1</cell>
<cell>6</cell>
<cell>4.95945170</cell>
<cell>4.95945170</cell>
</row>
<row>
<cell>11</cell>
<cell>as</cell>
<cell>2</cell>
<cell>357</cell>
<cell>1.02482886</cell>
<cell>2.04965772</cell>
</row>
<row>
<cell>10</cell>
<cell>around</cell>
<cell>2</cell>
<cell>149</cell>
<cell>1.89472655</cell>
<cell>3.78945311</cell>
</row>
<row>
<cell>9</cell>
<cell>and</cell>
<cell>13</cell>
<cell>364</cell>
<cell>1.00546449</cell>
<cell>13.07103843</cell>
</row>
<row>
<cell>8</cell>
<cell>an</cell>
<cell>1</cell>
<cell>352</cell>
<cell>1.03889379</cell>
<cell>1.03889379</cell>
</row>
<row>
<cell>7</cell>
<cell>american</cell>
<cell>1</cell>
<cell>277</cell>
<cell>1.27774073</cell>
<cell>1.27774073</cell>
</row>
<row>
<cell>6</cell>
<cell>all</cell>
<cell>1</cell>
<cell>310</cell>
<cell>1.16556894</cell>
<cell>1.16556894</cell>
</row>
<row>
<cell>5</cell>
<cell>air</cell>
<cell>1</cell>
<cell>80</cell>
<cell>2.51091269</cell>
<cell>2.51091269</cell>
</row>
<row>
<cell>4</cell>
<cell>ago</cell>
<cell>1</cell>
<cell>161</cell>
<cell>1.81776551</cell>
<cell>1.81776551</cell>
</row>
<row>
<cell>3</cell>
<cell>age</cell>
<cell>1</cell>
<cell>224</cell>
<cell>1.48926145</cell>
<cell>1.48926145</cell>
</row>
<row>
<cell>2</cell>
<cell>against</cell>
<cell>1</cell>
<cell>189</cell>
<cell>1.65833778</cell>
<cell>1.65833778</cell>
</row>
<row>
<cell>1</cell>
<cell>afternoon</cell>
<cell>1</cell>
<cell>66</cell>
<cell>2.70066923</cell>
<cell>2.70066923</cell>
</row>
</table><table>
<row>
<cell role="label">Indice</cell>
<cell role="label">Mot</cell>
<cell role="label">D&#233;compte (tf)</cell>
<cell role="label">Df</cell>
</row>
<row>
<cell>30</cell>
<cell>character</cell>
<cell>1</cell>
<cell>89</cell>
</row>
<row>
<cell>29</cell>
<cell>career</cell>
<cell>1</cell>
<cell>223</cell>
</row>
<row>
<cell>28</cell>
<cell>by</cell>
<cell>3</cell>
<cell>349</cell>
</row>
<row>
<cell>27</cell>
<cell>but</cell>
<cell>1</cell>
<cell>343</cell>
</row>
<row>
<cell>26</cell>
<cell>born</cell>
<cell>1</cell>
<cell>342</cell>
</row>
<row>
<cell>25</cell>
<cell>body</cell>
<cell>1</cell>
<cell>112</cell>
</row>
<row>
<cell>24</cell>
<cell>bly</cell>
<cell>2</cell>
<cell>1</cell>
</row>
<row>
<cell>23</cell>
<cell>bell</cell>
<cell>1</cell>
<cell>24</cell>
</row>
<row>
<cell>22</cell>
<cell>began</cell>
<cell>1</cell>
<cell>241</cell>
</row>
<row>
<cell>21</cell>
<cell>beat</cell>
<cell>1</cell>
<cell>33</cell>
</row>
<row>
<cell>20</cell>
<cell>be</cell>
<cell>1</cell>
<cell>332</cell>
</row>
<row>
<cell>19</cell>
<cell>baxter</cell>
<cell>1</cell>
<cell>4</cell>
</row>
<row>
<cell>18</cell>
<cell>barrel</cell>
<cell>1</cell>
<cell>7</cell>
</row>
<row>
<cell>17</cell>
<cell>bankruptcy</cell>
<cell>1</cell>
<cell>8</cell>
</row>
<row>
<cell>16</cell>
<cell>balloon</cell>
<cell>1</cell>
<cell>2</cell>
</row>
<row>
<cell>15</cell>
<cell>avenue</cell>
<cell>2</cell>
<cell>68</cell>
</row>
<row>
<cell>14</cell>
<cell>at</cell>
<cell>8</cell>
<cell>362</cell>
</row>
<row>
<cell>13</cell>
<cell>asylum</cell>
<cell>1</cell>
<cell>2</cell>
</row>
<row>
<cell>12</cell>
<cell>ascension</cell>
<cell>1</cell>
<cell>6</cell>
</row>
<row>
<cell>11</cell>
<cell>as</cell>
<cell>2</cell>
<cell>357</cell>
</row>
<row>
<cell>10</cell>
<cell>around</cell>
<cell>2</cell>
<cell>149</cell>
</row>
<row>
<cell>9</cell>
<cell>and</cell>
<cell>13</cell>
<cell>364</cell>
</row>
<row>
<cell>8</cell>
<cell>an</cell>
<cell>1</cell>
<cell>352</cell>
</row>
<row>
<cell>7</cell>
<cell>american</cell>
<cell>1</cell>
<cell>277</cell>
</row>
<row>
<cell>6</cell>
<cell>all</cell>
<cell>1</cell>
<cell>310</cell>
</row>
<row>
<cell>5</cell>
<cell>air</cell>
<cell>1</cell>
<cell>80</cell>
</row>
<row>
<cell>4</cell>
<cell>ago</cell>
<cell>1</cell>
<cell>161</cell>
</row>
<row>
<cell>3</cell>
<cell>age</cell>
<cell>1</cell>
<cell>224</cell>
</row>
<row>
<cell>2</cell>
<cell>against</cell>
<cell>1</cell>
<cell>189</cell>
</row>
<row>
<cell>1</cell>
<cell>afternoon</cell>
<cell>1</cell>
<cell>66</cell>
</row>
</table><div type="3"><head>Comment ex&#233;cuter tf_idf en Python 3</head>
<p>Dans cette section de la le&#231;on, nous retracerons pas &#224; pas le chemin que j'ai parcouru pour calculer des valeurs de <hi rend="bold">tf-idf</hi> pour tous les termes apparaissant dans tous les documents du corpus n&#233;crologique. Si vous d&#233;sirez suivre le processus de plus pr&#232;s, vous pouvez t&#233;l&#233;charger les fichiers associ&#233;s &#224; la le&#231;on, ouvrir l'archive <code rend="inline">.zip</code> et ex&#233;cuter le carnet Jupyter Notebook intitul&#233; <code rend="inline">TF-IDF-code-fr.ipynb</code> qui se trouve dans le dossier <code rend="inline">lecon-fichiers</code>. Vous pouvez aussi cr&#233;er votre propre carnet Jupyter au m&#234;me endroit et copier-coller les blocs de code qui apparaissent ci-dessous au moment appropri&#233;. Si vous travaillez dans l'environnement Anaconda, consultez la <ref target="https://perma.cc/W92W-C3Z3">documentation des carnets Jupyter</ref> pour savoir comment changer le r&#233;pertoire de travail des carnets. Notez que, comme dans tous les langages de programmation, il existe plusieurs mani&#232;res de compl&#233;ter chacune des &#233;tapes que nous &#233;tudierons ci-dessous.</p>
<p>Mon premier bloc de code est con&#231;u pour r&#233;cup&#233;rer les noms de tous les fichiers .txt qui se trouvent dans le r&#233;pertoire <code rend="inline">txt</code>. Ces lignes de code importent la classe <code rend="inline">Path</code> du module <code rend="inline">pathlib</code> et invoquent la m&#233;thode <code rend="inline">Path().rglob()</code> pour produire une liste de tous les fichiers qui se trouvent dans le r&#233;pertoire 'txt' et dont les noms se terminent avec l'extension .txt. <code rend="inline">pathlib</code> concat&#233;nera le chemin du r&#233;pertoire, <code rend="inline">file.parent</code>, &#224; chaque nom de fichier pour construire des chemins complets pour chaque fichier (sous macOS ou Windows).</p>
<p>J'ajoute ainsi chaque nom de fichier &#224; une liste nomm&#233;e <code rend="inline">tous_fichiers_txt</code>. Enfin, je renvoie la longueur de <code rend="inline">tous_fichiers_txt</code> pour v&#233;rifier que j'ai bien trouv&#233; les 366 fichiers attendus. Cette approche boucler-et-ajouter est tr&#232;s courante en Python.</p>
<ab><code xml:id="code_analyse-de-documents-avec-tfidf_0" corresp="code_analyse-de-documents-avec-tfidf_0.txt" lang="language-python" rend="block"/></ab>
<p>Concernant le choix des noms de variables il existe deux m&#233;thodes courantes qui donne respectivement la priorit&#233; &#224; la commodit&#233; puis &#224; la s&#233;mantique. Par commodit&#233;, on pourrait choisir de nommer une variable <hi rend="bold">x</hi> pour qu'il soit facile et rapide de taper son nom au besoin. Un nom de variable s&#233;mantique tente, quant &#224; lui, de transmettre au lecteur une information sur la fonction ou l'usage de la variable. En nommant ma liste de fichiers textuels <code rend="inline">tous_fichiers_txt</code> et la variable qui contient la taille de cette liste <code rend="inline">n_fichiers</code>, j'accorde la priorit&#233; &#224; la s&#233;mantique. En m&#234;me temps, j'utilise des abr&#233;viations comme <code rend="inline">txt</code> pour &#171;&#8239;texte&#8239;&#187; et <code rend="inline">n</code> pour &#171;&#8239;nombre&#8239;&#187; pour gagner du temps et j'ai choisi <code rend="inline">tous_fichiers_txt</code> plut&#244;t que <code rend="inline">les_noms_de_tous_les_fichiers_textuels</code> parce que la concision demeure un objectif important. Les normes concernant l'utilisation des majuscules et des barres de soulignement en Python sont codifi&#233;es dans PEP-8, le guide stylistique officiel du langage, avec lequel je vous recommande de vous familiariser.<ref type="footnotemark" target="#note_9"/></p>
<p>Pour diverses raisons, nous voulons que nos calculs s'effectuent par ordre journalier et mensuel (le corpus contient un fichier pour chaque jour et pour chaque mois de l'ann&#233;e). Pour ce faire, nous pouvons utiliser la m&#233;thode <code rend="inline">sort()</code> pour classer les fichiers par ordre num&#233;rique ascendant, puis afficher le premier nom de fichier pour nous assurer qu'il s'agit bien de <code rend="inline">txt/0101.txt</code>.</p>
<ab><code xml:id="code_analyse-de-documents-avec-tfidf_1" corresp="code_analyse-de-documents-avec-tfidf_1.txt" lang="language-python" rend="block"/></ab>
<p>Nous pouvons ensuite utiliser la liste des noms de fichiers pour lire chaque fichier en m&#233;moire et le convertir en un format que Python peut interpr&#233;ter comme du texte. Le prochain bloc de code contient une autre op&#233;ration de type boucler-et-ajouter qui parcourt la liste de noms de fichiers et ouvre chacun d'entre eux. L'instruction  <code rend="inline">with open(txt_file) as f</code> permet notamment d'ouvrir un fichier, d'effectuer une action sur celui-ci et de le refermer, ce que nous faisons ici sur tout les fichiers de notre liste. J'invoque ensuite la m&#233;thode <code rend="inline">read()</code> de Python pour convertir le contenu de chaque fichier textuel en une cha&#238;ne de caract&#232;res (<code rend="inline">str</code>), ce qui constitue la mani&#232;re d'indiquer &#224; Python que les donn&#233;es doivent &#234;tre interpr&#233;t&#233;es comme du texte. J'ajoute chacune de ces cha&#238;nes de caract&#232;res, une par une, &#224; une nouvelle liste nomm&#233;e <code rend="inline">tous_documents</code>. Note importante&#8239;: les cha&#238;nes de caract&#232;res qui constituent cette liste y apparaissent dans le m&#234;me ordre que les noms de fichiers dans la liste <code rend="inline">tous_fichiers_txt</code>.</p>
<ab><code xml:id="code_analyse-de-documents-avec-tfidf_2" corresp="code_analyse-de-documents-avec-tfidf_2.txt" lang="language-python" rend="block"/></ab>
<p>C'est tout le travail de mise en place dont nous avons besoin. Les &#233;tapes de traitement du texte comme la <ref target="https://perma.cc/8SZP-DCGF">tokenisation</ref> et l'&#233;limination de la ponctuation seront effectu&#233;es automatiquement lorsque nous utiliserons le <code rend="inline">TfidfVectorizer</code> de Scikit-Learn pour repr&#233;senter nos documents &#224; l'aide des scores <hi rend="bold">tf-idf</hi> calcul&#233;s en fonction de leur contenu. Le bloc de code ci-dessous importe <code rend="inline">TfidfVectorizer</code> du module Scikit-Learn, qui est pr&#233;install&#233; avec Anaconda. <code rend="inline">TfidfVectorizer</code> est une classe d'objets Python d&#233;velopp&#233;e en programmation orient&#233;e objet. Je construis donc une instance de cette classe, nomm&#233;e <code rend="inline">vectoriseur</code>, &#224; laquelle je fournis des param&#232;tres sp&#233;cifiques (j&#8217;aurai plus de choses &#224; dire au sujet de ces param&#232;tres dans la section intitul&#233;e <ref target="#param%C3%A8tres-scikit-learn">&#171;&#8239;Param&#232;tres Scikit-Learn&#8239;&#187;</ref>). J'applique ensuite la m&#233;thode <code rend="inline">fit_transform()</code> de cet objet &#224; ma liste de cha&#238;nes de caract&#232;res (la variable nomm&#233;e <code rend="inline">tous_documents</code>). La variable <code rend="inline">documents_transformes</code> contient les r&#233;sultats de l'op&#233;ration <code rend="inline">fit_transform()</code>. Notez que nous pourrions aussi fournir &#224; <code rend="inline">TfidfVectorizer</code> une liste de mots vides (rappelons qu'il s'agit de mots structurels communs) dont nous ne voulons pas nous pr&#233;occuper. En outre, pour r&#233;aliser certaines op&#233;rations, comme la division en lex&#232;mes ou le filtrage des mots vides, dans une langue autre que l'anglais, il pourrait &#234;tre n&#233;cessaire de pr&#233;traiter les textes &#224; l'aide d'un autre module Python ou de fournir &#224; <code rend="inline">TfidfVectorizer</code> un analyseur (tokenizer) et/ou une liste de mots vides sur mesure.</p>
<ab><code xml:id="code_analyse-de-documents-avec-tfidf_3" corresp="code_analyse-de-documents-avec-tfidf_3.txt" lang="language-python" rend="block"/></ab>
<p>La m&#233;thode <code rend="inline">fit_transform()</code> ci-dessus transforme la liste de cha&#238;nes de caract&#232;res en une <ref target="https://perma.cc/4C3Y-M6FD">matrice creuse</ref>. Dans le cas qui nous concerne, la matrice contient des valeurs <hi rend="bold">tf-idf</hi> pour tous les mots et tous les textes. Les matrices creuses &#233;pargnent de la m&#233;moire en laissant de c&#244;t&#233; toutes les valeurs &#233;gales &#224; z&#233;ro. Nous avons cependant besoin d'acc&#233;der &#224; toutes les valeurs. Le prochain bloc de code invoque donc la m&#233;thode <code rend="inline">toarray()</code> pour convertir la matrice creuse en un <ref target="https://perma.cc/78YF-4K7K">tableau NumPy</ref>. Nous pouvons afficher la longueur de ce tableau pour nous assurer qu'il est de la m&#234;me taille que notre liste de documents.</p>
<ab><code xml:id="code_analyse-de-documents-avec-tfidf_4" corresp="code_analyse-de-documents-avec-tfidf_4.txt" lang="language-python" rend="block"/></ab>
<p>Un tableau NumPy ressemble &#224; une liste sans y &#234;tre identique. Je pourrais r&#233;diger une le&#231;on compl&#232;te rien que sur les diff&#233;rences entre les deux, mais une seule des caract&#233;ristiques des tableaux NumPy est importante pour le moment&#8239;: ils convertissent les donn&#233;es stock&#233;es dans <code rend="inline">documents_transformes</code> dans un format qui contient explicitement les scores <hi rend="bold">tf-idf</hi> de tous les mots dans tous les documents. Rappelons que la matrice creuse, elle, excluait toutes les valeurs &#233;gales &#224; z&#233;ro.</p>
<p>Nous voulons que toutes les valeurs soient repr&#233;sent&#233;es pour que chaque document soit associ&#233; au m&#234;me nombre de valeurs, soit une pour chaque mot qui existe dans le corpus. Chaque ligne du tableau <code rend="inline">documents_transformes_tableau</code> est elle-m&#234;me un tableau qui repr&#233;sente un des documents du corpus. Nous disposons donc essentiellement d'une grille dans laquelle chaque ligne repr&#233;sente un document et chaque colonne, un mot. Imaginez un tableau semblable &#224; ceux des sections pr&#233;c&#233;dentes pour chaque document, mais sans &#233;tiquettes pour identifier les lignes et les colonnes.</p>
<p>Pour combiner les valeurs avec leurs &#233;tiquettes, il nous faut deux &#233;l&#233;ments d'information&#8239;: l'ordre des documents et et l&#8217;ordre des tf-idf obtenu pour chaque mot. L'ordre des documents est facile &#224; obtenir puisqu'il s'agit du m&#234;me que dans la liste <code rend="inline">tous_documents</code>. La liste de tous les mots du corpus, elle, est stock&#233;e dans la variable <code rend="inline">vectoriseur</code> et elle suit le m&#234;me ordre qu'utilise <code rend="inline">documents_transformes_tableau</code> pour emmagasiner les donn&#233;es. Nous pouvons utiliser la m&#233;thode <code rend="inline">get_feature_names_out()</code> de la classe <code rend="inline">TFIDFVectorizer</code> pour acc&#233;der &#224; cette liste de mots. Puis, chaque ligne de <code rend="inline">documents_transformes_tableau</code> (qui contient les valeurs <hi rend="bold">tf-idf</hi> d'un document) peut &#234;tre jumel&#233;e avec la liste de mots. Pour plus de d&#233;tails sur les structures de donn&#233;es de type DataFrame du module Pandas de Python, veuillez consulter la le&#231;on <ref target="/en/lessons/visualizing-with-bokeh">&#171;&#8239;Visualizing Data with Bokeh and Pandas&#8239;&#187;</ref>.</p>
<ab><code xml:id="code_analyse-de-documents-avec-tfidf_5" corresp="code_analyse-de-documents-avec-tfidf_5.txt" lang="language-python" rend="block"/></ab>
<p>Le bloc de code ci-dessus est compos&#233; de trois parties&#8239;:</p>
<list type="ordered">
<item>Apr&#232;s avoir import&#233; le module pandas, le code v&#233;rifie l'existence du r&#233;pertoire de sortie <code rend="inline">tf_idf_resultats</code>. Si ce r&#233;pertoire n'existe pas d&#233;j&#224;, il est cr&#233;&#233; &#224; ce moment.</item>
<item>Un chemin vers un fichier .csv est construit &#224; partir de chacun des noms de fichiers .txt qui apparaissent dans la liste construite plus haut. Le processus de construction de la variable <code rend="inline">fichiers_resultats</code> convertira, par exemple, <code rend="inline">txt/0101.txt</code> (le chemin du premier fichier .txt de la liste) en <code rend="inline">tf_idf_resultats/0101.csv</code>, et ainsi de suite pour tous les fichiers du corpus.</item>
<item>&#192; l'aide d'une boucle, on associe chaque vecteur de scores <hi rend="bold">tf-idf</hi> avec la liste des mots extraite de <code rend="inline">vectoriseur</code>, on convertit les paires mot/score en objets de type DataFrame, et on enregistre chaque DataFrame dans son propre fichier .csv (un format textuel courant pour les feuilles de calcul).</item>
</list>
</div><div type="3"><head>Interpr&#233;ter les listes de mots : meilleures pratiques et mises en garde</head>
<p>Lorsque vous ex&#233;cuterez les blocs de code ci-dessus, vous obtiendrez un r&#233;pertoire nomm&#233; <code rend="inline">tf_idf_resultats</code> contenant 366 fichiers de type .csv. Chacun de ces fichiers contient une liste de mots et de leurs scores <hi rend="bold">tf-idf</hi> pour un document sp&#233;cifique. Comme nous avons pu le constater dans le cas de la n&#233;crologie de Nellie Bly, ces listes de mots peuvent &#234;tre tr&#232;s significatives, cependant, il faut bien comprendre qu'une surinterpr&#233;tation de ce genre de r&#233;sultats peut d&#233;former notre compr&#233;hension du texte sous-jacent.</p>
<p>En g&#233;n&#233;ral, il vaut mieux approcher ces listes de mots en se disant qu'elles seront utiles pour susciter des hypoth&#232;ses ou des questions de recherche, mais que les r&#233;sultats de <hi rend="bold">tf-idf</hi> ne justifieront peut-&#234;tre pas de conclusions d&#233;finitives &#224; eux seuls. &#192; titre d'exemple, j'ai assembl&#233; une liste de n&#233;crologies d'individus ayant v&#233;cus &#224; la fin du <span style="font-variant:small-caps;">XIX</span><sup>e</sup> et au d&#233;but du <span style="font-variant:small-caps;">XX</span><sup>e</sup> si&#232;cle qui ont &#233;crit pour des journaux ou pour des magazines et qui &#233;taient associ&#233;s d'une quelconque fa&#231;on aux mouvements de r&#233;forme sociale. Cette liste inclut Nellie Bly, <ref target="https://perma.cc/6RGB-UQHV">Willa Cather</ref>, <ref target="https://perma.cc/QYW8-SL8D">W.E.B. Du Bois</ref>, <ref target="https://perma.cc/43WH-G6XL">Upton Sinclair</ref> et <ref target="https://perma.cc/TC7V-8CEY">Ida Tarbell</ref>, mais il est possible que d'autres individus dont les n&#233;crologies apparaissent dans le corpus correspondent &#233;galement &#224; cette description.<ref type="footnotemark" target="#note_10"/></p>
<p>Je m'attendais initialement &#224; ce que plusieurs mots significatifs soient partag&#233;s entre ces individus, mais ce n'est pas toujours le cas. Le tableau ci-dessous pr&#233;sente les 20 mots dont les scores <hi rend="bold">tf-idf</hi> sont les plus &#233;lev&#233;s dans chacune des cinq n&#233;crologies. Chaque liste est domin&#233;e par des mots sp&#233;cifiques &#224; son document (noms propres, lieux, entreprises, etc.) que l'on peut filtrer &#224; l'aide des param&#232;tres de <hi rend="bold">tf-idf</hi> ou tout simplement ignorer. La section &#171;&#8239;Param&#232;tres Scikit-Learn&#8239;&#187; approfondit les questions li&#233;es aux entit&#233;s nomm&#233;es ou un syntagme comme des tokens uniques. D'autre part, on peut chercher des mots qui expriment clairement la relation entre un individu et sa profession litt&#233;raire.</p>
<p>| Rang Tf-idf | Nellie Bly | Willa Cather | W.E.B. Du Bois | Upton Sinclair | Ida Tarbell |
| 1 | cochrane | cather | dubois | sinclair | tarbell |
| 2 | her | her | dr | socialist | she |
| 3 | she | she | negro | upton | her |
| 4 | seaman | nebraska | ghana | <hi rend="bold">books</hi> | lincoln |
| 5 | bly | miss | peace | lanny | miss |
| 6 | nellie | forrester | <hi rend="bold">encyclopedia</hi> | social | oil |
| 7 | mark | sibert | communist | budd | abraham |
| 8 | ironclad | twilights | barrington | jungle | mcclure |
| 9 | <hi rend="bold">plume</hi> | willa | fisk | brass | easton |
| 10 | vexations | antonia | atlanta | california | <hi rend="bold">volumes</hi> |
| 11 | phileas | mcclure | folk | <hi rend="bold">writer</hi> | minerva |
| 12 | 597 | <hi rend="bold">novels</hi> | booker | vanzetti | standard |
| 13 | elizabeth | pioneers | successively | macfadden | business |
| 14 | <hi rend="bold">nom</hi> | cloud | souls | sacco | titusville |
| 15 | balloon | <hi rend="bold">book</hi> | council | <hi rend="bold">wrote</hi> | <hi rend="bold">articles</hi> |
| 16 | forgeries | calif | party | meat | bridgeport |
| 17 | mcalpin | <hi rend="bold">novel</hi> | disagreed | <hi rend="bold">pamphlets</hi> | expose |
| 18 | asylum | southwest | harvard | my | trusts |
| 19 | fogg | <hi rend="bold">verse</hi> | <hi rend="bold">arts</hi> | industry | mme
| 20 | verne | <hi rend="bold">wrote</hi> | soviet | <hi rend="bold">novel</hi> | <hi rend="bold">magazine</hi> |</p>
<p>J'ai utilis&#233; les caract&#232;res gras pour souligner des termes qui semblent particuli&#232;rement reli&#233;s &#224; l'&#233;criture. Cette liste inclut <emph>articles</emph>, <emph>arts</emph>, <emph>book</emph> (livre), <emph>books</emph> (livres), <emph>encyclopedia</emph> (encyclop&#233;die), <emph>magazine</emph>, <emph>nom</emph>, <emph>novel</emph> (roman), <emph>novels</emph> (romans), <emph>pamphlets</emph>, <emph>plume</emph>, <emph>verse</emph> (vers/po&#233;sie), <emph>volumes</emph>, <emph>writer</emph> (auteur/autrice) et <emph>wrote</emph> (&#233;crit), auxquels on pourrait ajouter les titres de livres sp&#233;cifiques ou les noms de magazines. Ne tenons pas compte de ces d&#233;tails pour le moment et remarquons que, si les listes de Cather et de Sinclair contiennent plusieurs mots associ&#233;s aux livres et &#224; l'&#233;criture, ce n'est pas le cas pour Bly, Du Bois et Tarbell.</p>
<p>On pourrait facilement tirer des conclusions h&#226;tives. L'identit&#233; de Cather semble fortement reli&#233;e &#224; son genre, &#224; son attachement &#224; des lieux, &#224; sa fiction et &#224; sa po&#233;sie. Sinclair est plus fortement associ&#233; &#224; la politique et &#224; ses &#233;crits au sujet de la viande, de l'industrie et du proc&#232;s controvers&#233; de <ref target="https://perma.cc/3VZK-PLDG">Nicola Sacco et Bartolomeo Vanzetti</ref> qui a men&#233; &#224; l'ex&#233;cution des deux individus. Bly est reli&#233;e &#224; son pseudonyme, &#224; son mari et &#224; ses &#233;crits portant sur les institutions psychiatriques. Du Bois est reli&#233; aux questions de race et &#224; sa carri&#232;re universitaire. Quant &#224; Tarbell, ce sont les th&#232;mes sur lesquels elle &#233;crit qui la d&#233;finissent&#8239;: les affaires, les monopoles, le g&#233;ant du p&#233;trole Standard Oil et le pr&#233;sident am&#233;ricain Abraham Lincoln. En allant un peu plus loin, je pourrais argumenter que la discussion du genre semble plus caract&#233;ristique des n&#233;crologies de femmes, tandis que la question raciale n'appara&#238;t parmi les termes les plus importants que dans le cas du seul Afro-Am&#233;ricain de la liste.</p>
<p>Chacune de ces observations n&#233;cessite d&#8217;&#234;tre approfondie et ne doit  pas impliquer une g&#233;n&#233;ralisation. D'abord, je dois v&#233;rifier si les param&#232;tres que j'ai choisis pour <hi rend="bold">tf-idf</hi> produisent des effets qui pourraient dispara&#238;tre dans d'autres conditions&#8239;; des r&#233;sultats probants devraient &#234;tre assez stables pour r&#233;sister &#224; ce genre d'ajustements. Notez que nous discuterons de certains de ces param&#232;tres dans la section <ref target="#param%C3%A8tres-scikit-learn">&#171;&#8239;Param&#232;tres Scikit-Learn&#8239;&#187;</ref>. Je devrai ensuite lire au moins quelques-unes des n&#233;crologies pour m'assurer que certains termes ne me transmettent pas de faux signaux. En lisant la n&#233;crologie de Du Bois, par exemple, je pourrais constater que les mentions de son oeuvre &#171;&#8239;The Encyclopedia of the Negro&#8239;&#187; contribue au moins en partie &#224; la valeur du score du mot <emph>negro</emph> dans le texte.</p>
<p>Par ailleurs, je pourrais d&#233;couvrir que la n&#233;crologie de Bly inclut effectivement des mots comme <emph>journalism</emph>, <emph>journalistic</emph>, <emph>newspapers</emph> (journaux) et <emph>writing</emph> (&#233;criture), mais cette n&#233;crologie est tr&#232;s courte et la plupart des mots qui y apparaissent ne le font qu'une ou deux fois. Des mots qui ont de tr&#232;s forts scores <hi rend="bold">idf</hi> sont donc plus susceptibles d'appara&#238;tre au sommet de sa liste. Puisque je veux vraiment &#233;quilibrer les poids de <hi rend="bold">tf</hi> et d'<hi rend="bold">idf</hi>, je pourrais ne pas tenir compte des mots qui apparaissent seulement dans quelques documents ou encore ignorer les r&#233;sultats provenant de n&#233;crologies dont la longueur est inf&#233;rieure &#224; un certain seuil.</p>
<p>Enfin, je peux concevoir des tests pour r&#233;pondre directement &#224; des questions comme: est-ce que les n&#233;crologies d'Afro-Am&#233;ricains sont plus susceptibles de mentionner la race&#8239;? Je crois que l'hypoth&#232;se &#171;&#8239;oui&#8239;&#187; est plausible mais je devrais tout de m&#234;me assujettir mes hypoth&#232;ses &#224; l'&#233;preuve d'un examen minutieux avant de tirer d'en des conclusions.</p>
</div><div type="3"><head>Quelques mani&#232;res d'utiliser tf-idf en histoire num&#233;rique</head>
<p>Comme je l'ai d&#233;j&#224; mentionn&#233;, <hi rend="bold">tf-idf</hi> provient du domaine de la reherche d'informations. La normalisation de la fr&#233;quence d'occurrence de mots dans les diff&#233;rents documents d'un corpus constitue d'ailleurs toujours une op&#233;ration courante dans l'industrie du d&#233;veloppement Web, notamment dans le cas des moteurs de recherche textuels. En contexte d'analyse culturelle ou d'histoire num&#233;rique, cependant, la pertinence de <hi rend="bold">tf-idf</hi> se limite &#224; des t&#226;ches bien pr&#233;cises. En g&#233;n&#233;ral, celles-ci appartiennent &#224; l'une de trois cat&#233;gories&#8239;:</p>
<div type="4"><head>1. Outil d'exploration ou de visualisation</head>
<p>Nous avons d&#233;j&#224; d&#233;montr&#233; que des listes de mots accompagn&#233;es de scores <hi rend="bold">tf-idf</hi> pour chacun des documents d'un corpus peuvent constituer de puissants outils d'interpr&#233;tation. Elles peuvent notamment sugg&#233;rer des hypoth&#232;ses ou des questions de recherche. Ces listes peuvent aussi former les bases de strat&#233;gies d'exploration et de visualisation plus sophistiqu&#233;es. L'article <ref target="https://perma.cc/QBZ4-DKTE">&#171;&#8239;A full-text visualization of the Iraq War Logs&#8239;&#187;</ref> de Jonathan Stray et Julian Burgess en constitue un bon exemple.<ref type="footnotemark" target="#note_11"/> Stray et Burgess utilisent des valeurs <hi rend="bold">tf-idf</hi> pour construire une visualisation de r&#233;seau dans laquelle des registres de la guerre en Irak sont reli&#233;s &#224; leurs mots-cl&#233;s les plus distinctifs. Cette technique de visualisation d'information textuelle a permis &#224; Stray de d&#233;velopper le <ref target="https://perma.cc/L8PN-KQ5B">projet Overview</ref>, qui propose aux usagers un tableau de bord &#224; partir duquel naviguer dans des milliers de documents pour visualiser leurs contenus. Nous pourrions employer cette approche pour visualiser notre corpus n&#233;crologique et peut-&#234;tre y identifier des groupes d'articles dont les mots-cl&#233;s se ressemblent.</p>
</div><div type="4"><head>2. Outil pour calculer la similarit&#233; des textes et des ensembles de traits caract&#233;ristiques</head>
<p>Puisque <hi rend="bold">tf-idf</hi> produit souvent des scores bas pour les mots structurels fr&#233;quents et des scores plus &#233;lev&#233;s pour les mots associ&#233;s au contenu th&#233;matique d'un texte, cette m&#233;thode est appropri&#233;e pour les t&#226;ches qui requi&#232;rent l'identification de similarit&#233;s entre des textes. Un moteur de recherche appliquera souvent <hi rend="bold">tf-idf</hi> &#224; un corpus pour ensuite proposer &#224; l'usager des r&#233;sultats class&#233;s en fonction de la <ref target="https://perma.cc/9NV6-SS9G">similarit&#233; cosinus</ref> entre les documents et les mots-cl&#233;s de recherche entr&#233;s par l'usager. Le m&#234;me raisonnement s'applique &#224; des questions comme: &#171;&#8239;quelle n&#233;crologie de notre corpus ressemble le plus &#224; celle de Nellie Bly&#8239;&#187;&#8239;?</p>
<p>Nous pouvons aussi utiliser <hi rend="bold">tf-idf</hi> pour d&#233;couvrir les mots les plus importants dans un document ou dans un groupe de documents. Par exemple, je pourrais regrouper un ensemble de n&#233;crologies de journalistes (dont celle de Nellie Bly) dans un seul document avant d'appliquer <hi rend="bold">tf-idf</hi> &#224; celui-ci. Les r&#233;sultats de l'op&#233;ration pourraient servir de r&#232;gle heuristique pour identifier des termes sp&#233;cifiques aux n&#233;crologies de journalistes, en comparaison avec l'ensemble des n&#233;crologies du corpus. La liste de mots ainsi obtenue pourrait ensuite servir dans une vari&#233;t&#233; d'autres t&#226;ches informatiques.</p>
</div><div type="4"><head>3. &#201;tape de pr&#233;traitement</head>
<p>Les paragraphes ci-dessus ont permis d'introduire les raisons pour lesquelles le score <hi rend="bold">tf-idf</hi> sert souvent d'&#233;tape de pr&#233;traitement dans les calculs d'apprentissage automatique. Par exemple, les scores <hi rend="bold">tf-idf</hi> ont tendance &#224; &#234;tre plus r&#233;v&#233;lateurs que les d&#233;comptes bruts lorsqu'on d&#233;veloppe un mod&#232;le de classification par apprentissage automatique supervis&#233;, notamment parce qu'ils augmentent les poids des mots reli&#233;s aux th&#232;mes des documents tout en r&#233;duisant ceux des mots structurels fr&#233;quents. Il existe cependant une exception notable &#224; cette r&#232;gle&#8239;: l'identification de l'auteur d'un texte anonyme, pour laquelle les mots structurels ont une forte valeur pr&#233;dictive. </p>
<p style="alert alert-info">
<p>Note du traducteur&#8239;: la le&#231;on intitul&#233;e <ref target="https://programminghistorian.org/fr/lecons/introduction-a-la-stylometrie-avec-python">&#171;&#8239;Introduction &#224; la stylom&#233;trie en Python&#8239;&#187;</ref> pr&#233;sente une application de ce genre de calculs.</p>
</p>    
<p>Comme nous le verrons dans la section sur les <ref target="#param%C3%A8tres-scikit-learn">param&#232;tres de Scikit-Learn</ref>, <hi rend="bold">tf-idf</hi> peut aussi &#233;monder les listes de traits caract&#233;ristiques des mod&#232;les d'apprentissage automatique&#8239;; or, il est souvent pr&#233;f&#233;rable de d&#233;velopper des mod&#232;les bas&#233;s sur le moins de traits caract&#233;ristiques possible.</p>
</div></div><div type="3"><head>Variations sur le th&#232;me de tf-idf</head>
<div type="4"><head>Param&#232;tres Scikit-Learn</head>
<p>L'objet <code rend="inline">TfidfVectorizer</code> de Scikit-Learn dispose de plusieurs param&#232;tres internes qu'on peut modifier pour influencer les r&#233;sultats de calcul. En r&#232;gle g&#233;n&#233;rale, tous ces param&#232;tres ont leurs avantages et leurs inconv&#233;nients&#8239;: il n'existe pas de configuration parfaite unique. Il est donc pr&#233;f&#233;rable de bien conna&#238;tre chacun des r&#233;glages possibles afin de pouvoir expliquer et d&#233;fendre vos choix le moment venu. La liste compl&#232;te des param&#232;tres peut &#234;tre consult&#233;e dans la <ref target="https://perma.cc/JUN8-39Z6">documentation de Scikit-Learn</ref>&#8239;; en voici quelques-uns parmi les plus importants&#8239;:</p>
<div type="5"><head>1. Mots vides (stopwords)</head>
<p>Dans le code ci-dessus, j'ai utilis&#233; <code rend="inline">stop_words=None</code> mais <code rend="inline">stop_words='english'</code> est aussi disponible. Ce r&#233;glage filtrera automatiquement de votre corpus les mots tr&#232;s courants, comme &#171;&#8239;the&#8239;&#187;, &#171;&#8239;to&#8239;&#187;, and &#171;&#8239;of&#8239;&#187;, qui apparaissent dans une <ref target="https://perma.cc/6CSZ-G9BL">liste pr&#233;d&#233;finie</ref>. Notez que la plupart de ces mots vides ont probablement d&#233;j&#224; des scores <hi rend="bold">tf-idf</hi> tr&#232;s bas en raison de leur ubiquit&#233;, m&#234;me si d'autres r&#233;glages peuvent influencer ces scores. Pour une discussion des listes de mots vides qu&#8217;on retrouve dans divers outils open-source de traitement du langage naturel, veuillez lire <ref target="https://perma.cc/V5WN-4E8P">&#171;&#8239;Stop Word Lists in Free Open-source Software Packages&#8239;&#187;</ref>.</p>
<p style="alert alert-info">
Note du traducteur&#8239;: il est aussi possible de remplacer &#171;&#8239;None&#8239;&#187; par une liste de mots vides personnalis&#233;e, comme `stop_words=['le', 'la', 'les']`. Si vous travaillez avec des documents en fran&#231;ais, il s'agit d'une alternative potentiellement plus efficace que de se fier au faible score <b>tf-idf</b> de la plupart des mots-vides.
</p>
</div><div type="5"><head>2. min_df, max_df</head>
<p>Ces param&#232;tres contr&#244;lent le nombre minimal et le nombre maximal de documents dans lesquels un mot doit appara&#238;tre pour &#234;tre inclus dans les calculs. Les deux param&#232;tres peuvent &#234;tre exprim&#233;s sous forme de nombres r&#233;els entre 0 et 1, qui repr&#233;sentent alors des pourcentages de l'ensemble du corpus, ou sous forme de nombres entiers qui repr&#233;sentent des d&#233;comptes de documents bruts. En r&#232;gle g&#233;n&#233;rale, sp&#233;cifier une valeur inf&#233;rieure &#224; 0.9 pour max_df &#233;liminera la majorit&#233; (voire la totalit&#233;) des mots vides.</p>
</div><div type="5"><head>3. max_features</head>
<p>Ce param&#232;tre &#233;lague les termes les moins fr&#233;quents du corpus avant d'appliquer <hi rend="bold">tf-idf</hi>. Il peut &#234;tre particuli&#232;rement utile en contexte d'apprentissage automatique, o&#249; l'on ne souhaite habituellement pas d&#233;passer le nombre de traits caract&#233;ristiques recommand&#233; par les concepteurs de l'algorithme choisi.</p>
</div><div type="5"><head>4. norm, smooth_idf, and sublinear_tf</head>
<p>Chacun de ces param&#232;tres influencera l'&#233;ventail de valeurs num&#233;riques que l'algorithme <hi rend="bold">tf-idf</hi> produira. Le param&#232;tre <code rend="inline">norm</code> est compatible avec la normalisation l1 et l2, expliqu&#233;e sur <ref target="https://perma.cc/3ULS-SUB2">machinelearningmastery.com</ref>. <code rend="inline">Smooth_idf</code> lisse les r&#233;sultats en ajoutant la valeur 1 &#224; chaque fr&#233;quence de document, comme s'il existait un document additionnel qui contient exactement une occurrence de tous les mots qui apparaissent dans le corpus. <code rend="inline">Sublinear_tf'</code> applique une op&#233;ration de changement d'&#233;chelle aux r&#233;sultats en rempla&#231;ant tf par log(tf). Pour plus de d&#233;tails au sujet du lissage et de la normalisation dans le contexte de <hi rend="bold">tf-idf</hi>, veuillez consulter Manning, Raghavan et Sch&#252;tze.<ref type="footnotemark" target="#note_12"/></p>
</div></div><div type="4"><head>Traits caract&#233;ristiques : au-del&#224; des mots</head>
<p>Le concept fondamental de <hi rend="bold">tf-idf</hi>, qui consiste &#224; pond&#233;rer les d&#233;comptes d'occurrences en fonction du nombre de documents dans lesquels les mots apparaissent, peut s'appliquer &#224; d'autres traits caract&#233;ristiques des textes. Par exemple, il est relativement facile de combiner <hi rend="bold">tf-idf</hi> avec la <ref target="https://perma.cc/WV3J-BF3B">racinisation</ref> ou la <ref target="https://perma.cc/T3XA-Q9HG">lemmatisation</ref>, deux m&#233;thodes courantes qui permettent de regrouper de multiples d&#233;clinaisons et conjugaisons du m&#234;me mot en une seule forme. Par exemple, la racine de <emph>happy</emph> et <emph>happiness</emph> est <emph>happi</emph> tandis que le lemme qui les regroupe est <emph>happy</emph>. Une fois la racinisation ou la lemmatisation compl&#233;t&#233;e, on peut remplacer les d&#233;comptes de mots par les d&#233;comptes de racines ou de lemmes avant d'appliquer <hi rend="bold">tf-idf</hi>. Notez que, puisque ces op&#233;rations fusionnent plusieurs formes apparent&#233;es en une seule, les lemmes et les racines auront des d&#233;comptes d'occurrences plus &#233;lev&#233;s que chacun des mots qu'ils regroupent, et donc des valeurs <hi rend="bold">tf-idf</hi> habituellement plus basses.</p>
<p>On peut aussi appliquer la transformation <hi rend="bold">tf-idf</hi> &#224; des locutions ou &#224; des n-grammes, c'est-&#224;-dire &#224; des s&#233;quences de mots cons&#233;cutifs. Un article intitul&#233;  <ref target="https://perma.cc/37WS-MB8F">&#171;&#8239;These Are The Phrases Each GOP Candidate Repeats Most&#8239;&#187;</ref>, publi&#233; sur fivethirtyeight.com en mars 2016, utilise cette approche pour calculer les fr&#233;quences inverses de documents de phrases enti&#232;res plut&#244;t que celles de mots.<ref type="footnotemark" target="#note_13"/></p>
</div></div><div type="3"><head>tf-idf et m&#233;thodes alternatives communes</head>
<p>On peut comparer <hi rend="bold">tf-idf</hi> &#224; plusieurs autres m&#233;thodes qui servent &#224; isoler et/ou &#224; classifier les mots les plus importants dans un document ou dans une collection de documents. Cette section mentionne bri&#232;vement trois de ces m&#233;thodes alternatives, apparent&#233;es mais distinctes, qui mesurent des aspects similaires mais non identiques de l'information textuelle.</p>
<div type="4"><head>1. Sp&#233;cificit&#233; (Keyness)</head>
<p>Plut&#244;t que de transformer les d&#233;comptes d'occurrences &#224; l'aide de calculs, la sp&#233;cificit&#233; produit une valeur num&#233;rique qui indique jusqu'&#224; quel point la pr&#233;sence d'un mot dans un document est statistiquement typique ou atypique par rapport &#224; l'ensemble du corpus. Par exemple, &#224; l'aide d'un <ref target="https://perma.cc/4Z2W-SZCS">test du khi-carr&#233;</ref>, il est possible de mesurer l'&#233;cart entre la fr&#233;quence d'occurrence d'un mot et la norme du corpus, puis de d&#233;river une <ref target="https://perma.cc/X3AW-F6B9">valeur p</ref> qui indique la probabilit&#233; d'observer cette fr&#233;quence d'occurrence dans un &#233;chantillon al&#233;atoire. Pour plus d'information sur la sp&#233;cificit&#233;, voir Bondi et Scott.<ref type="footnotemark" target="#note_14"/></p>
<p style="alert alert-info">
Note du traducteur &#8239;: En anglais, &#171;&#8239;keyness&#8239;&#187; est un terme g&#233;n&#233;rique qui regroupe toute une panoplie de mesures statistiques qui tentent d'assigner une signification quantifiable &#224; la pr&#233;sence d'un terme dans un document ou dans un ensemble de documents, en comparaison avec un corpus plus &#233;tendu. En fran&#231;ais, le terme &#171;&#8239;sp&#233;cificit&#233;&#8239;&#187; a acquis un sens plus pr&#233;cis suite aux travaux de Pierre Lafon&#8239;; voir notamment l'article de 1980 &#171;&#8239;Sur la variabilite&#769; de la fre&#769;quence des formes dans un corpus&#8239;&#187;, publi&#233; dans la revue <i>Mots</i>, vol. 1, no. 1.
</p>
</div><div type="4"><head>2. Mod&#232;les th&#233;matiques</head>
<p>La mod&#233;lisation th&#233;matique et <hi rend="bold">tf-idf</hi> sont des techniques radicalement diff&#233;rentes, mais je constate que les n&#233;ophytes en mati&#232;re d'humanit&#233;s num&#233;riques d&#233;sirent souvent mod&#233;liser les th&#232;mes d'un corpus d&#232;s le d&#233;but alors que <hi rend="bold">tf-idf</hi> constituerait parfois un meilleur choix.<ref type="footnotemark" target="#note_15"/> Puisque l'algorithme est transparent et que ses r&#233;sultats sont reproductibles, <hi rend="bold">tf-idf</hi> est particuli&#232;rement utile lorsqu'on souhaite obtenir une vue d'ensemble d'un corpus, &#224; vol d'oiseau, pendant la phase d'exploration initiale de la recherche. Comme le mentionne Ben Schmidt, les chercheurs qui emploient la mod&#233;lisation th&#233;matique doivent reconna&#238;tre que les th&#232;mes qui en ressortent ne sont pas forc&#233;ment aussi coh&#233;rents qu'on le souhaiterait.<ref type="footnotemark" target="#note_16"/> C'est l'une des raisons pour lesquelles <hi rend="bold">tf-idf</hi> a &#233;t&#233; int&#233;gr&#233; au <ref target="https://perma.cc/L8PN-KQ5B">projet Overview</ref>.</p>
<p>Les mod&#232;les th&#233;matiques peuvent aussi aider les chercheurs &#224; explorer leurs corpus et ils offrent de nombreux avantages, notamment la capacit&#233; de sugg&#233;rer de vastes cat&#233;gories ou &#171;&#8239;communaut&#233;s&#8239;&#187; de textes, mais il s'agit d'une caract&#233;ristique commune &#224; l'ensemble des m&#233;thodes d'apprentissage automatique non supervis&#233;es. Les mod&#232;les th&#233;matiques sont particuli&#232;rement attrayants parce qu'ils assignent &#224; chaque document des valeurs num&#233;riques qui mesurent jusqu'&#224; quel point chacun des th&#232;mes y est important et parce qu'ils repr&#233;sentent ces th&#232;mes sous forme de listes de mots copr&#233;sents, ce qui suscite de fortes impressions de coh&#233;rence. Cependant, l'algorithme probabiliste qui sous-tend la mod&#233;lisation th&#233;matique est tr&#232;s sophistiqu&#233; et simple d'en d&#233;former les r&#233;sultats si l'on n'est pas assez prudent. Les math&#233;matiques derri&#232;re <hi rend="bold">tf-idf</hi>, elles, sont assez simples pour &#234;tre expliqu&#233;es dans une feuille de calcul Excel.</p>
</div><div type="4"><head>3. R&#233;sum&#233; automatique des textes</head>
<p>Le r&#233;sum&#233; automatique est une autre mani&#232;re d'explorer un corpus. Rada Mihalcea et Paul Tarau, par exemple, ont publi&#233; au sujet de TextRank, un mod&#232;le de classement bas&#233; sur la th&#233;orie des graphes, aux possibilit&#233;s prometteuses pour l'extraction automatique de mots et de phrases-cl&#233;s.<ref type="footnotemark" target="#note_17"/> Comme dans le cas de la mod&#233;lisation th&#233;matique, TextRank approche la recherche d'informations d'une mani&#232;re compl&#232;tement diff&#233;rente du <hi rend="bold">tf-idf</hi> mais les objectifs des deux algorithmes ont beaucoup en commun. Cette m&#233;thode pourrait &#234;tre appropri&#233;e pour votre propre recherche, surtout si votre but consiste &#224; obtenir assez rapidement une impression g&#233;n&#233;rale du contenu de vos documents avant de construire un projet de recherche plus pouss&#233;.</p>
</div></div></div>
      <div type="2"><head>R&#233;f&#233;rences et lectures suppl&#233;mentaires</head>
<list type="unordered">
<item>
<p>Milo Beckman, &#171;&#160;These Are The Phrases Each GOP Candidate Repeats Most,&#160;&#187;, <emph>FiveThirtyEight</emph>, le 10 mars 2016,  consult&#233; le 9 juin 2022, <ref target="https://perma.cc/37WS-MB8F">https://fivethirtyeight.com/features/these-are-the-phrases-each-gop-candidate-repeats-most/</ref>.</p>
</item>
<item>
<p>Jessica Bennett et Amisha Padnani, &#171;&#160;Overlooked&#160;&#187;, <emph>The New York Times</emph>, 8 mars 2018, <ref target="https://perma.cc/HWZ7-XS23">https://www.nytimes.com/interactive/2018/obituaries/overlooked.html</ref>.</p>
</item>
<item>
<p>David M. Blei, Andrew Y. Ng et Michael I. Jordan, &#171;&#160;Latent Dirichlet Allocation&#171;&#160;, <emph>Journal of Machine Learning Research</emph> 3 (Janvier 2003): 993-1022.</p>
</item>
<item>
<p>Marina Bondi et Mike Scott, dirs. <emph>Keyness in Texts</emph>. Philadelphie: John Benjamins, 2010.</p>
</item>
<item>
<p>Scikit-Learn Developers &#171;&#160;TfidfVectorizer&#160;&#187;(en anglais), consult&#233; le 9 juin 2022, <ref target="https://perma.cc/JUN8-39Z6">https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html</ref>.</p>
</item>
<item>
<p>Justin Grimmer et Gary King. <ref target="https://perma.cc/4YAL-H6VN">&#171;&#160;Quantitative Discovery from Qualitative Information: A General-Purpose Document Clustering Methodology (2009)&#160;&#187;</ref>, <emph>Rencontre APSA 2009 &#224; Toronto</emph>, le 24 ao&#251;t 2009, <ref target="https://perma.cc/NUS2-J3YP">PDF</ref>.</p>
</item>
<item>
<p>&#171;&#160;Ida M. Tarbell, 86, Dies in Bridgeport&#160;&#187;, <ref target="https://perma.cc/NBV6-S2XM"><emph>The New York Times</emph>, 17 janvier 1944</ref>.</p>
</item>
<item>
<p>Pierre Lafon, &#171;&#160;Sur la variabilite&#769; de la fre&#769;quence des formes dans un corpus&#160;&#187;, <emph>Mots</emph> 1, no. 1 (1980): 127-165.</p>
</item>
<item>
<p>C.D. Manning, P. Raghavan et H. Sch&#252;tze, <emph>Introduction to Information Retrieval</emph>. Cambridge: Cambridge University Press, 2008.</p>
</item>
<item>
<p>Rada Mihalcea et Paul Tarau. &#171;&#160;Textrank: Bringing order into text&#160;&#187;, <emph>Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing</emph>, Barcelone, Espagne, 2004. <ref target="https://perma.cc/SMV5-7MYY">http://www.aclweb.org/anthology/W04-3252</ref></p>
</item>
<item>
<p>&#171;&#160;Nellie Bly, Journalist, Dies of Pneumonia&#160;&#187;, <ref target="https://perma.cc/LA5B-65HL"><emph>The New York Times</emph>, 28 janvier 1922</ref>.</p>
</item>
<item>
<p>G. Salton et M.J. McGill, <emph>Introduction to Modern Information Retrieval</emph>. New York: McGraw-Hill, 1983.</p>
</item>
<item>
<p>Ben Schmidt, &#171;&#160;Do Digital Humanists Need to Understand Algorithms?&#160;&#187;, <emph>Debates in the Digital Humanities 2016</emph>. &#201;dition en ligne. Minneapois: University of Minnesota Press. <ref target="https://perma.cc/95WD-SDM5">http://dhdebates.gc.cuny.edu/debates/text/99</ref>.</p>
</item>
<item>
<p>Ben Schmidt, &#171;&#160;Words Alone: Dismantling Topic Models in the Humanities&#160;&#187;, <emph>Journal of Digital Humanities</emph>. Vol. 2, No. 1 (2012): n.p. <ref target="https://perma.cc/LT4N-X4MZ">http://journalofdigitalhumanities.org/2-1/words-alone-by-benjamin-m-schmidt/</ref>.</p>
</item>
<item>
<p>Karen Sp&#228;rck Jones, &#171;&#160;A Statistical Interpretation of Term Specificity and Its Application in Retrieval.&#160;&#187;, <emph>Journal of Documentation</emph> 28, no. 1 (1972): 11&#8211;21.</p>
</item>
<item>
<p>Jonathan Stray et Julian Burgess. &#171;&#160;A Full-text Visualization of the Iraq War Logs&#160;&#187;, 10 d&#233;cembre 2010 (derni&#232;re mise &#224; jour en avril 2012), <ref target="https://perma.cc/QBZ4-DKTE">http://jonathanstray.com/a-full-text-visualization-of-the-iraq-war-logs</ref>.</p>
</item>
<item>
<p>Ted Underwood, &#171;&#160;Identifying diction that characterizes an author or genre: why Dunning's may not be the best method&#160;&#187;, <emph>The Stone and the Shell</emph>, 9 novembre 2011, <ref target="https://perma.cc/SY25-UXK3">https://tedunderwood.com/2011/11/09/identifying-the-terms-that-characterize-an-author-or-genre-why-dunnings-may-not-be-the-best-method/</ref>.</p>
</item>
<item>
<p>Ted Underwood, &#171;&#160;The Historical Significance of Textual Distances&#160;&#187;, Atelier LaTeCH-CLfL (Version pr&#233;impression), COLING, Santa Fe, 2018, <ref target="https://doi.org/10.48550/arXiv.1807.00181">https://doi.org/10.48550/arXiv.1807.00181</ref>.</p>
</item>
<item>
<p>Guido van Rossum, Barry Warsaw et Nick Coghlan. &#171;&#160;PEP 8 - Style Guide for Python Code&#160;&#187;, 5 juillet 2001 (mise &#224; jour ao&#251;t 2013), <ref target="https://perma.cc/P2ZM-VPQM">https://www.python.org/dev/peps/pep-0008/</ref>.</p>
</item>
<item>
<p>Alden Whitman, &#171;&#160;Upton Sinclair, Author, Dead; Crusader for Social Justice, 90&#160;&#187;, <ref target="https://perma.cc/E4N7-2KD6"><emph>The New York Times</emph>, 26 novembre 1968</ref>.</p>
</item>
<item>
<p>&#171;&#160;W. E. B. DuBois Dies in Ghana; Negro Leader and Author, 95&#160;&#187;, <ref target="https://perma.cc/W5NX-XZRV"><emph>The New York Times</emph>, 28 ao&#251;t 1963</ref>.</p>
</item>
<item>
<p>&#171;&#160;Willa Cather Dies; Noted Novelist, 70&#160;&#187;, <ref target="https://perma.cc/2L7H-WGKN"><emph>The New York Times</emph>, 25 avril 1947</ref>.</p>
</item>
</list>
<div type="3"><head>Alternatives &#224; Anaconda</head>
<p>Si vous n'utilisez pas Anaconda, il faudra vous assurer de disposer des outils pr&#233;requis suivants&#8239;:</p>
<list type="ordered">
<item>Une installation de Python 3 (pr&#233;f&#233;rablement Python 3.6 ou une version plus r&#233;cente)</item>
<item>Id&#233;alement, un environnement virtuel dans lequel installer et ex&#233;cuter le Python</item>
<item>Le module Scikit-Learn et ses d&#233;pendances (voir <ref target="http://scikit-learn.org/stable/install.html">http://scikit-learn.org/stable/install.html</ref>)</item>
<item>Jupyter Notebook et ses d&#233;pendances</item>
</list>
</div></div>
      <div type="2"><head>Notes</head>
<p><ref type="footnotemark" target="#note_1"/> : Ted Underwood, &#171;&#160;Identifying diction that characterizes an author or genre: why Dunning's may not be the best method&#160;&#187;, <emph>The Stone and the Shell</emph>, 9 novembre 2011, <ref target="https://perma.cc/SY25-UXK3">https://tedunderwood.com/2011/11/09/identifying-the-terms-that-characterize-an-author-or-genre-why-dunnings-may-not-be-the-best-method/</ref>.</p>
<p><ref type="footnotemark" target="#note_2"/> : Jessica Bennett et Amisha Padnani, &#171;&#160;Overlooked&#160;&#187;, <emph>The New York Times</emph>, 8 mars 2018, <ref target="https://perma.cc/HWZ7-XS23">https://www.nytimes.com/interactive/2018/obituaries/overlooked.html</ref>.</p>
<p><ref type="footnotemark" target="#note_3"/> : Ce jeu de donn&#233;es est tir&#233; d'une version du site &#171;&#8239;On This Day&#8239;&#187; du <emph>New York Times</emph> qui n'a pas &#233;t&#233; mise &#224; jour depuis le 31 janvier 2011 et qui a &#233;t&#233; remplac&#233;e par un nouveau blogue plus &#233;l&#233;gant situ&#233; au <ref target="https://perma.cc/W627-RBUS">https://learning.blogs.nytimes.com/on-this-day/</ref>. Ce qui reste sur le site "On This Day" est une page HTML statique pour chaque jour de l'ann&#233;e (0101.html, 0102.html, etc.), y compris une page pour le 29 f&#233;vrier (0229.html). Le contenu semble avoir &#233;t&#233; &#233;cras&#233; &#224; chaque mise &#224; jour&#8239;; il n'y a donc pas d'archives du contenu publi&#233; &#224; chaque ann&#233;e. On peut pr&#233;sumer que les pages associ&#233;es aux jours de janvier ont &#233;t&#233; mises &#224; jour pour la derni&#232;re fois en 2011, tandis que celles pour les dates entre le 1er f&#233;vrier et de 31 d&#233;cembre ont probablement &#233;t&#233; mises &#224; jour pour la derni&#232;re fois en 2010. La page du 29 f&#233;vrier a probablement &#233;t&#233; chang&#233;e pour la derni&#232;re fois le 29 f&#233;vrier 2008.</p>
<p><ref type="footnotemark" target="#note_4"/> : Karen Sp&#228;rck Jones, &#171;&#160;A Statistical Interpretation of Term Specificity and Its Application in Retrieval.&#160;&#187;, <emph>Journal of Documentation</emph> 28, no. 1 (1972): 16.</p>
<p><ref type="footnotemark" target="#note_5"/> : &#171;&#160;Nellie Bly, Journalist, Dies of Pneumonia&#160;&#187;, <ref target="https://perma.cc/LA5B-65HL"><emph>The New York Times</emph>, 28 janvier 1922: 11</ref>.</p>
<p><ref type="footnotemark" target="#note_6"/> : Scikit-Learn Developers, &#171;&#160;TfidfVectorizer&#160;&#187; (en anglais), consult&#233; le 9 juin 2022, <ref target="https://perma.cc/JUN8-39Z6">https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html</ref>.</p>
<p><ref type="footnotemark" target="#note_7"/> : Ben Schmidt, &#171;&#160;Do Digital Humanists Need to Understand Algorithms?&#160;&#187;, <emph>Debates in the Digital Humanities 2016</emph>. &#201;dition en ligne. Minneapolis: University of Minnesota Press. <ref target="https://perma.cc/95WD-SDM5">http://dhdebates.gc.cuny.edu/debates/text/99</ref>.</p>
<p><ref type="footnotemark" target="#note_8"/> : Guido van Rossum, Barry Warsaw et Nick Coghlan. &#171;&#160;PEP 8 - Style Guide for Python Code&#160;&#187;, 5 juillet 2001 (mise &#224; jour ao&#251;t 2013), <ref target="https://perma.cc/P2ZM-VPQM">https://www.python.org/dev/peps/pep-0008/</ref>.</p>
<p><ref type="footnotemark" target="#note_9"/> : &#171;&#160;Ida M. Tarbell, 86, Dies in Bridgeport&#160;&#187;, <ref target="https://perma.cc/NBV6-S2XM"><emph>The New York Times</emph>, 17 janvier 1944</ref>; &#171;&#160;W. E. B. DuBois Dies in Ghana; Negro Leader and Author, 95&#160;&#187;, <ref target="https://perma.cc/W5NX-XZRV"><emph>The New York Times</emph>, 28 ao&#251;t 1963</ref>; Alden Whitman, &#171;&#160;Upton Sinclair, Author, Dead; Crusader for Social Justice, 90&#160;&#187;, <ref target="https://perma.cc/E4N7-2KD6"><emph>The New York Times</emph>, 26 novembre 1968</ref>; &#171;&#160;Willa Cather Dies; Noted Novelist, 70&#160;&#187;, <ref target="https://perma.cc/2L7H-WGKN"><emph>The New York Times</emph>, 25 avril 1947</ref>.</p>
<p><ref type="footnotemark" target="#note_10"/> : Jonathan Stray et Julian Burgess. &#171;&#160;A Full-text Visualization of the Iraq War Logs&#160;&#187;, 10 d&#233;cembre 2010 (derni&#232;re mise &#224; jour en avril 2012), <ref target="https://perma.cc/QBZ4-DKTE">http://jonathanstray.com/a-full-text-visualization-of-the-iraq-war-logs</ref>.</p>
<p><ref type="footnotemark" target="#note_11"/> : C.D. Manning, P. Raghavan et H. Sch&#252;tze, <emph>Introduction to Information Retrieval</emph> (Cambridge: Cambridge University Press, 2008), 118-120.</p>
<p><ref type="footnotemark" target="#note_12"/> : Milo Beckman, &#171;&#160;These Are The Phrases Each GOP Candidate Repeats Most&#160;&#187;, <emph>FiveThirtyEight</emph>, le 10 mars 2016,  consult&#233; le 9 juin 2022, <ref target="https://perma.cc/37WS-MB8F">https://fivethirtyeight.com/features/these-are-the-phrases-each-gop-candidate-repeats-most/</ref>.</p>
<p><ref type="footnotemark" target="#note_13"/> : Marina Bondi et Mike Scott (dir.). <emph>Keyness in Texts</emph>. (Philadelphie: John Benjamins, 2010).</p>
<p><ref type="footnotemark" target="#note_14"/> : Il n'est habituellement pas recommand&#233; d'appliquer <hi rend="bold">tf-idf</hi> comme pr&#233;traitement avant de produire un mod&#232;le th&#233;matique. Voir&#160;: <ref target="https://perma.cc/N5W9-TYX7">https://datascience.stackexchange.com/questions/21950/why-we-should-not-feed-lda-with-tfidf</ref>.</p>
<p><ref type="footnotemark" target="#note_15"/> : Ben Schmidt, &#171;&#160;Words Alone: Dismantling Topic Models in the Humanities&#160;&#187;, <emph>Journal of Digital Humanities</emph>. Vol. 2, No. 1 (2012): n.p., <ref target="https://perma.cc/LT4N-X4MZ">http://journalofdigitalhumanities.org/2-1/words-alone-by-benjamin-m-schmidt/</ref>.</p>
<p><ref type="footnotemark" target="#note_16"/> : Rada Mihalcea et Paul Tarau. &#171;&#160;Textrank: Bringing order into text&#160;&#187;, <emph>Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing</emph>, Barcelone, Espagne, 2004, <ref target="https://perma.cc/SMV5-7MYY">http://www.aclweb.org/anthology/W04-3252</ref>.</p>
</div>
    </body>
  </text>
</TEI>
