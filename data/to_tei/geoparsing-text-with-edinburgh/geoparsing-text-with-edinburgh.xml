<TEI xmlns="https://tei-c.org/ns/1-0/">
  <metadata>
  <title>Geoparsing English-Language Text with the Edinburgh Geoparser</title>
  <collection>lessons</collection>
  <layout>lesson</layout>
  <slug>geoparsing-text-with-edinburgh</slug>
  <date>2017-10-31</date>
  <modified>2023-01-06</modified>
  <authors>Beatrice Alex</authors>
  <reviewers>Anouk Lang,Sarah Simpkin</reviewers>
  <editors>Ian Milligan</editors>
  <difficulty>3</difficulty>
  <review-ticket>https://github.com/programminghistorian/ph-submissions/issues/26</review-ticket>
  <activity>presenting</activity>
  <topics>mapping</topics>
  <abstract>This tutorial teaches users how to use the Edinburgh Geoparser to process a piece of English-language text, extract and resolve the locations contained within it, and plot them as a web map.</abstract>
  <redirect_from>/lessons/geoparsing-text-with-edinburgh</redirect_from>
  <avatar_alt>Map of the city of Edinburgh</avatar_alt>
  <doi>10.46430/phen0067</doi>
</metadata>
  <text>
    <body>
      <div n="1"><head>Introduction</head>
<p>This is a lesson on how to use the <link target="https://www.ltg.ed.ac.uk/software/geoparser/">Edinburgh Geoparser</link>.  The Geoparser allows you to process a piece of English-language text and extract and resolve the locations contained within it. Among other uses, geo-resolution of locations makes it possible to map the data.</p>
<p>The Geoparser works best on running text, as it considers locations in context for disambiguation. For example, if you would like to get a sense of the place names mentioned in a piece of text, the Geoparser can be used to identify terms in a document that are likely to refer to place names.  It will then provide its best guess as to where those places are in terms of latitute/longitude coordinates.</p>
<p>In December 2015, the Edinburgh Geoparser was released under the University of Edinburgh&#8217;s GPL license to be used by other researchers in the field of text mining and natural language processing as well as scholars who are interested in geoparsing text. More information on its documentation, publications using it and how to download it can be found <link target="https://www.ltg.ed.ac.uk/software/geoparser/">here</link>.</p>
<p>A simple online demo of the vanilla Edinburgh Geoparser can be tried out <link target="http://jekyll.inf.ed.ac.uk/geoparser.html">here</link>. It provides only the visual interface to the Geoparser output after uploading a text file and selecting a gazetteer.  The demo is otherwise not configurable and should only be used to try out small examples and not for geo-parsing a large number of files.</p>
<p>The following lesson explains how the Edinburgh Geoparser works under the hood and contains information on:</p>
<ul>
<li>Prerequisites and terminology</li>
<li>Downloading and setting up the Edinbugh Geoparser</li>
<li>Setting up mapping</li>
<li>Geo-parsing a text file</li>
<li>Other useful options for running the Geoparser</li>
<li>Geo-parsing multiple text files</li>
<li>Extracting geo-resolution output to TSV</li>
</ul>
</div>
      <div n="1"><head>Prerequisites and Terminology</head>
<p>This lesson requires users to be familiar with the command line.  If not then you should first follow the lesson <link target="/en/lessons/intro-to-bash">Introduction to the Bash Command Line</link>.</p>
<p>The Geoparser works on MacOS or Linux but is not supported for Windows. The following lesson provides command line instructions for MacOSX users and equivalent commands for Linux users (only if different to the Mac versions).</p>
<p>The terms geo-parsing and geo-referencing are used interchangeably in this lesson and refer to the entire process of identifying place names in text (place name recognition) and disambiguating them by assigning their most likely latitude/longitude pairs (geo-resolution).</p>
<p>The Edinburgh Geoparser is used in conjunction with various gazetteers. The term <link target="https://en.wikipedia.org/wiki/Gazetteer">gazetteer</link> here refers to a list of place names and information about them (e.g. their latitude/longitude coordinates, population size and country they are contained in).  More information on <link target="/en/lessons/extracting-keywords">Using Gazetteers to Extract Sets of Keywords from Free-Flowing Texts</link> can be found in Adam Cryble's Programming Historian lesson. His lesson focusses on matching gazetteer entries in text to identify place names.  The Edinburgh Geoparser goes beyond string matching as it applies a large number of rules to identify place names and other types of named entities in text and goes on to ground the extracted entities (either by geo-resolution or date normalisation).</p>
</div>
      <div n="1"><head>Downloading and Setting up the Geoparser</head>
<p>The current Edinburgh Geoparser download can be found at <link target="https://www.ltg.ed.ac.uk/software/geoparser/">https://www.ltg.ed.ac.uk/software/geoparser/</link>.</p>
<p>Go to the Download section and click on The Edinburgh Geoparser link.  All you need to do then is accept the license, fill in some personal details, and then press <hi rend="bold">Download</hi>. &#160;A compressed file called&#160;<code type="inline">geoparser-1.3.tar.gz</code> will be downloaded to your Download directory or to wherever you specified the download to go.  Note that this file name will change when new versions of the tool are released.</p>
<p>Some machines will automatically decompress the .gz file and create the directory <code type="inline">geoparser-1.3</code>.  If this happens, and you see the <code type="inline">geoparser-1.3</code> directory appear, move this new directory to wherever you want it to be installed and go to step 2.  If this does not happen, and your machine does not decompress the <code type="inline">.tar.gz</code> file and create a new directory automatically, follow step 1 first.  (Note that version 1.3 is the current release but this number will change in the future.)</p>
<h3>Installation Steps via the GUI interface</h3>
<p>1. Go to the download of the Geoparser and move it to the directory of your choice (e.g. into the <code type="inline">Software</code> directory).  Then double-click on the <code type="inline">.gz</code> or <code type="inline">.tar</code> file (if is was already decompressed automatically).  A new directory called <code type="inline">geoparser-1.3</code> will appear (see Figure 1).</p>
<figure><desc>Figure 1: The new geoparser-1.3 directory.</desc><graphic url="geoparser_figure13.png"/></figure>
<p>If you double-click on the geoparser-1.3 folder you can see the content of the Geoparser (see Figure 2). That's it. You're ready to geo-parse.</p>
<figure><desc>Figure 2: Content of the Geoparser.</desc><graphic url="geoparser_figure14.png"/></figure>
<div n="2"><head>Installation Steps for the Command Line</head>
<p>1. Move (<code type="inline">mv</code>) the <code type="inline">.tar.gz</code> file to the directory where you want to install the Geoparser. &#160;In this case, I'd like the Geoparser to be installed in my <code type="inline">Software</code> directory inside the <code type="inline">Documents</code> directory. &#160;If you don&#8217;t have a Software directory, create it first:</p>
<pre><code xml:id="code_geoparsing-text-with-edinburgh_0" type="block" corresp="code_geoparsing-text-with-edinburgh_0.txt"></code></pre>
<p>Then type:</p>
<pre><code xml:id="code_geoparsing-text-with-edinburgh_1" type="block" corresp="code_geoparsing-text-with-edinburgh_1.txt"></code></pre>
<p>For this lesson it is assumed that the geoparser is now located inside the <code type="inline">~/Documents/Software</code> directory.  You may however want to specify a different directory you&#8217;d like to install it in and adjust these commands by specifying the place where the Geoparser was downloaded and save at. For example if you'd like to create a new directory called <code type="inline">geoparsing</code> in your home directory and put the Geoparser there, then you would type:</p>
<pre><code xml:id="code_geoparsing-text-with-edinburgh_2" type="block" corresp="code_geoparsing-text-with-edinburgh_2.txt"></code></pre>
<p>2. Next, you need to change into the directory containing the <code type="inline">geoparser-1.3.tar.gz</code> file so that the following command is local to that directory and you do not have to specify the entire path leading to it.  To do that you use the command <code type="inline">cd</code> (change directory), e.g.:&#160;</p>
<pre><code xml:id="code_geoparsing-text-with-edinburgh_3" type="block" corresp="code_geoparsing-text-with-edinburgh_3.txt"></code></pre>
<p>3. Run the following command on the command line to decompress the download:</p>
<pre><code xml:id="code_geoparsing-text-with-edinburgh_4" type="block" corresp="code_geoparsing-text-with-edinburgh_4.txt"></code></pre>
<p>You should see a long list of files appear on screen that are part of the distribution. &#160;The <code type="inline">Software</code> directory will now contain a new directory called <code type="inline">geoparser-1.3</code>. &#160;It contains:</p>
<ul>
<li><code type="inline">README:</code> a file with basic instructions for how to run the Geoparser</li>
<li><code type="inline">bin:</code> a set of executables, programs to be run by a computer, for different operating systems. There are executables for Linux (x86_64) and MacOSX.</li>
<li><code type="inline">in:</code> a directory with example input files</li>
<li><code type="inline">lib:</code> a set of libraries required for various processing steps</li>
<li><code type="inline">models</code> a directory containing the part-of-speech tagging model</li>
<li><code type="inline">out:</code> a directory with example output files</li>
<li><code type="inline">resolve:</code> a directory containing programs required for geo-resolution</li>
<li><code type="inline">scripts:</code> a directory with a set of scripts to run the Geoparser</li>
</ul>
<p>You can list (<code type="inline">ls</code>) and check its content by typing:</p>
<pre><code xml:id="code_geoparsing-text-with-edinburgh_5" type="block" corresp="code_geoparsing-text-with-edinburgh_5.txt"></code></pre>
<p>Congratulations! You have successfully downloaded and set up the Geoparser, and you can now begin geo-parsing.</p>
</div></div>
      <div n="1"><head>Setting up Mapping</head>
<p>The visualisation component of the Geoparser uses Leaflet mapping software in conjunction with either Mapbox or OpenStreetMap map tiles.</p>
<p>Out of the box the Geoparser uses OpenStreetMap tiles for mapping. You can run the Geoparser (see next Section) as is without setting the environment variable <code type="inline">GEOPARSER_MAP_KEY</code>. If <code type="inline">GEOPARSER_MAP_KEY</code> is not set, OpenStreetMap tiles will be used by default. The main disadvantage of this - from the point of view of an English-language geoparser - is that OpenStreetMap generally displays maps in the language of the area, rather than English.</p>
<p>To use the Geoparser with Mapbox tiles you will need a Mapbox key (access token) which can be obtained from <link target="http://www.mapbox.com">www.mapbox.com</link>. When you create a Mapbox account you are automatically assigned a public access token. You can use that or create a new one.  Before running the Geoparser you should set the environment variable <code type="inline">GEOPARSER_MAP_KEY</code> to your access token. To do that you have to type the following command into your terminal, replacing "TOKEN" with your Mapbox access token:</p>
<pre><code xml:id="code_geoparsing-text-with-edinburgh_6" type="block" corresp="code_geoparsing-text-with-edinburgh_6.txt"></code></pre>
<p>You can also assign this variable in the same way in your <code type="inline">.bashrc</code>, <code type="inline">.profile</code> or <code type="inline">.bash_profile</code> file depending on your operating system and setup, which will set this variable every time a terminal is started up.</p>
<p>Note that Mapbox now also requires you to provide a credit card number when creating an account, and you may not want to do this in which case you still have the default OpenStreetMap mapping option. </p>
</div>
      <div n="1"><head>Geo-parsing a Text File</head>
<p>In this section you will learn how to geo-parse a simple text file. &#160;Use the <code type="inline">cd</code> command to go the geoparser&#8217;s script directory:</p>
<pre><code xml:id="code_geoparsing-text-with-edinburgh_7" type="block" corresp="code_geoparsing-text-with-edinburgh_7.txt"></code></pre>
<p>and try out one of the examples provided as part of the distribution by running the following two commands:</p>
<pre><code xml:id="code_geoparsing-text-with-edinburgh_8" type="block" corresp="code_geoparsing-text-with-edinburgh_8.txt"></code></pre>
<p>For those not so familiar with working on the command line, let's look at the syntax used here.  Firstly, it is useful to know that the pipe character (<code type="inline">|</code>) is used to concatenate different commands.</p>
<p>In the previous example the first command is:</p>
<pre><code xml:id="code_geoparsing-text-with-edinburgh_9" type="block" corresp="code_geoparsing-text-with-edinburgh_9.txt"></code></pre>
<p>The command <code type="inline">cat</code> prints a file (in this case the file is called <code type="inline">172172.txt</code> and it is located in the <code type="inline">in</code> directory of the geoparser) to your screen (or to <emph>standard out</emph> or short <emph>stdout</emph>). &#160;The pipe character (<code type="inline">|</code>) is used to send the standard output of one command to the next command which can then use it as <emph>standard in</emph> (or short <emph>stdin</emph>).</p>
<p>The second command is:</p>
<pre><code xml:id="code_geoparsing-text-with-edinburgh_10" type="block" corresp="code_geoparsing-text-with-edinburgh_10.txt"></code></pre>
<p>It takes the stdout from the first command and runs the Geoparser with the following options (<code type="inline">-t</code>, <code type="inline">-g</code> and <code type="inline">-o</code>):</p>
<ul>
<li>
<p><code type="inline">-t</code> specifies the format of your input. &#160;Text input (<code type="inline">plain</code>) is recommended for geo-parsing.</p>
</li>
<li>
<p><code type="inline">-g</code> specifies the gazetteer that should be queried. &#160;In the above example, the gazetteer selected is <link target="http://www.geonames.org/">GeoNames</link> (<code type="inline">geonames</code>), a large global gazetteer. &#160;You can also specify other gazetteers, for example the DEEP gazetteer of historical placenames in England (<code type="inline">deep</code>) or the&#160;Pleiades+ gazetteer of ancient places (<code type="inline">plplus</code>). &#160;For more information on the types of gazetteers offered as part of the distribution see the Geoparser documentation <link target="http://groups.inf.ed.ac.uk/geoparser/documentation/v1.3/html/gaz.html">here</link>.</p>
</li>
<li>
<p><code type="inline">-o</code> specifies two pieces of information, the output directory (<code type="inline">../out</code>) which is located within the <code type="inline">geoparser-1.3</code> directory and a prefix for the output file name (in this case <code type="inline">172172</code>, the same prefix as that of the input file name). Once the command is run and the Geoparser is finished, the result files appear in the output directory (<code type="inline">../out</code>) starting with the specified prefix.</p>
</li>
</ul>
<p>When running the Geoparser, the specified text file is going through a series of processing steps which are combined into one pipeline. &#160;It is first <link target="https://en.wikipedia.org/wiki/Lexical_analysis#Tokenization_">tokenised</link>, <link target="https://en.wikipedia.org/wiki/Part-of-speech_tagging">part-of-speech-tagged</link> and <link target="https://en.wikipedia.org/wiki/Lemmatisation">lemmatised</link>. After these initial steps, <link target="https://en.wikipedia.org/wiki/Named-entity_recognition">named entity recognition</link> is performed to identify location and person names as well as dates. &#160;It was  found that identifying location and person names in parallel helps to distinguish some ambiguous cases (like the string "Lewis" which could refer to a first name or the Scottish island) and where their context helps to distinguish between them. &#160;The extracted locations are then resolved to latitude/longitude coordinate pairs. &#160;The text is then further processed by identifying syntactic phrases (chunking) and temporal relations. &#160;The latter two steps are not very relevant to this lesson and will therefore not be explained in detail. &#160;Finally, visualisations are created to be able to inspect the file and the Geoparser output using a map interface in a browser. &#160;For more information on each of the sub-components of the Geoparser, see the documentation <link target="http://groups.inf.ed.ac.uk/geoparser/documentation/v1.3/html/pipeline.html">here</link>.</p>
<p>Note that when using the Geoparser in combination with the GeoNames gazetteer some historical place names will not be identified as they are missing from the gazetteer.  Also the Geoparser team can provide additional pre-processing to improve the quality of optical-character recognised output (e.g. to fix soft-hyphen splitting or to deal with the long &#8220;s&#8221; character).  Those scripts are not distributed with the standard distribution but available on request.</p>
<p>To see the output files, go to the <code type="inline">out</code> directory:</p>
<pre><code xml:id="code_geoparsing-text-with-edinburgh_11" type="block" corresp="code_geoparsing-text-with-edinburgh_11.txt"></code></pre>
<p>Now you can see all the files that the Geoparser has produced from the original <code type="inline">172172.txt</code> file.  Use the <code type="inline">ls</code> command and the <code type="inline">*</code> wildcard operator to see all the files beginning witht the prefix <code type="inline">172172</code>, like so:</p>
<pre><code xml:id="code_geoparsing-text-with-edinburgh_12" type="block" corresp="code_geoparsing-text-with-edinburgh_12.txt"></code></pre>
<p>The most relevant Geoparser output files contain the following information:</p>
<ul>
<li><code type="inline">172172.out.xml</code>: This is the XML file containing the text of the file in XML including all linguistic processing information specified in line with the text as well as the named entity recognition and the geo-resolution output. &#160;In this file only the top-ranked geo-coordinates per resolved location are stored. &#160;If you are not familiar with XML, looking at this file might be quite daunting. I will explain below how to extract the geo-resolution information to TSV (tab separated values) format.</li>
<li><code type="inline">172172.gaz.xml</code>: This is an XML file containing a ranked list of geo-resolution candidates for each extracted location mention. &#160;The gazetteer (e.g. GeoNames) may contain more than one location per location mention and therefore all candidates are listed here. &#160;By default, the number of location candidates returned is capped at 20 if more candidates are present in the gazetteer. &#160;Increasing the number of candidates to be considered by the Geoparser does not increase performance considerably but increases processing time significantly (Alex et al., 2015).</li>
<li><code type="inline">172172.display.html</code>: This is a visual display of the geo-parsed text file containing the text, a map and a list of geo-coordinates for each extracted location.</li>
</ul>
<p>You can view <code type="inline">172172.display.html</code> in your browser by typing:</p>
<ul>
<li>On MacOSX: <code type="inline">open 172172.display.html</code></li>
<li>On Linux: 		<code type="inline">xdg-open 172172.display.html</code></li>
</ul>
<figure><desc>Figure 3: Display of file 172172.display.html in a browser.</desc><graphic url="geoparser_figure15.png"/></figure>
<p>At the top of the browser window (see Figure 3) you will see a Google map interface with green and red pins. &#160;At the bottom left is a window containing the text of the geo-parsed file with recognised locations highlighted in light green and at the bottom right there is a window containing the different geo-coordinate pairs for all the candidates considered per extracted location mention. &#160;The ones in green are the top-ranked coordinate pairs which correspond to the green pins on the map. &#160;The red pairs are lower ranked alternatives which correspond to the red pins on the map.</p>
<p>You can also specify the option <code type="inline">-top</code> on the command line. This creates output files which only contain the top-ranked location candidates, so only the green geo-coordinate pairs and pins are displayed (see Figure 4).</p>
<pre><code xml:id="code_geoparsing-text-with-edinburgh_13" type="block" corresp="code_geoparsing-text-with-edinburgh_13.txt"></code></pre>
<figure><desc>Figure 4: Display of file 172172.display.html in a browser with only top location candidates displayed.</desc><graphic url="geoparser_figure16.png"/></figure>
<p>The vanilla download works most accurately with running English text.  It even works on individual sentences.  Geo-resolution accuracy increases however if the Geoparser has access to more context, including other place names.  On the other hand, the Geoparser is not well suited to process large documents made up of several sub-texts, e.g. a journal issue made up of articles. In the latter case it would be better to split the document into the articles first and geo-parse each article individually.</p>
</div>
      <div n="1"><head>Other Useful Options for Running the Geoparser</head>
<div n="2"><head>Giving Preference to a Geographical Area</head>
<p>If you know that your text is about a particular geographical area you can instruct the Geoparser to give this area higher weighting during the geo-resolution step. For example, if you know that your data is mostly set in Canada then it may make sense to give candidate locations inside Canada higher preference.  By doing so the Geoparser will prefer places within the specified area but it will still consider locations outside it if other factors give them higher weighting.</p>
<p>A bounding area can be specified as a circle (<code type="inline">-l locality</code>) or a box (<code type="inline">-lb locality box</code>).  To specify a circular locality use the following command:</p>
<pre><code xml:id="code_geoparsing-text-with-edinburgh_14" type="block" corresp="code_geoparsing-text-with-edinburgh_14.txt"></code></pre>
<p>where:</p>
<ul>
<li><code type="inline">lat</code> and <code type="inline">long</code> are in decimal degrees (i.e.&#160;57.5 for 57 degrees 30 mins)</li>
<li><code type="inline">radius</code> is specified in km</li>
<li><code type="inline">score</code> is a numeric weight assigned to locations within the area (else 0).</li>
</ul>
<p>To specify a locality box use:</p>
<pre><code xml:id="code_geoparsing-text-with-edinburgh_15" type="block" corresp="code_geoparsing-text-with-edinburgh_15.txt"></code></pre>
<p>where</p>
<ul>
<li><code type="inline">W</code>(est) <code type="inline">N</code>(orth) <code type="inline">E</code>(ast) <code type="inline">S</code>(outh) are decimal degrees</li>
<li><code type="inline">score</code> is the same as for option <code type="inline">-l</code>.</li>
</ul>
<p>You can grab the coordinates of a bounding box for a particular area using this online <link target="http://boundingbox.klokantech.com">BoundingBox</link> tool. For example, a bounding box for Canada is <code type="inline">[W:-141.002701, N:83.110619, E:-52.620201, S:41.681019]</code> (see Figure 5)</p>
<figure><desc>Figure 5: Bounding box for Canada drawn on [BoundingBox](http://boundingbox.klokantech.com).</desc><graphic url="geoparser_figure03.png"/></figure>
<p>To specify this bounding box using the previous example, go back to the scripts directory and run the following command:</p>
<pre><code xml:id="code_geoparsing-text-with-edinburgh_16" type="block" corresp="code_geoparsing-text-with-edinburgh_16.txt"></code></pre>
<p>Here, the <code type="inline">score</code> has been set to 2. &#160;This gives a location within the bounding box twice as much weight as for example the population size of a location during geo-resolution.</p>
<figure><desc>Figure 6: Display of file 172172.display.html after geo-parsing with a specified bounding box.</desc><graphic url="geoparser_figure17.png"/></figure>
<p>In this case, all place names (including Washington, Wimbledon, Germany and France) were resolved to locations within the bounding box (see Figure 6). &#160;The locality option should therefore be used with care and should ideally only be applied to documents where you are relatively certain that all or most locations appear within the specified area.</p>
</div><div n="2"><head>Specifying a Document Date</head>
<p>As well as identifying locations and person names within text, the Geoparser also recognises temporal expressions (dates and times) in textual data and normalises them. Normalisation here means that the temporal expressions are enriched with additional information of when exactly they occurred. For example, it computes which the exact calendar date the expression "last Friday" refers to.</p>
<p>In order to do this well, it is preferable to provide the Geoparser with the date of the document (if known). To try this out using the previous example, type the following command:</p>
<pre><code xml:id="code_geoparsing-text-with-edinburgh_17" type="block" corresp="code_geoparsing-text-with-edinburgh_17.txt"></code></pre>
<ul>
<li><code type="inline">-d</code> specifies the document date (<code type="inline">YEAR-MONTH-DATE</code>). &#160;This option is optional. &#160;It is used for normalisation (or grounding) of temporal expressions in the document, for example to compute which particular calendar date the string &#8220;Sunday&#8221; refers to.</li>
</ul>
<p>The document date specified on the command line is stored in the XML output and all relative temporal expression will be automatically interpreted with respect to it. &#160;The document date (<code type="inline">docdate</code>) is stored in the meta section at the top of the XML output file. &#160;Use the <code type="inline">head</code> command to list the first 5 lines of the output file where you can see it:</p>
<pre><code xml:id="code_geoparsing-text-with-edinburgh_18" type="block" corresp="code_geoparsing-text-with-edinburgh_18.txt"></code></pre>
<p>Using the example output file, the first recognised date string in the named &#160;entity output is &#8220;Sunday&#8221; which appears in the sentence:</p>
<blockquote>
<p>"Rafael Nadal and Andy Murray are both through to the semifinals of the Rogers Cup in Toronto, where they will face each other for a place in Sunday's final."</p>
</blockquote>
<p>Since the document date is Aug 8th 2010 which was a Tuesday, the Sunday referred to in this text is Aug 15th 2010. &#160;The output of the correct temporal resolution for this example can be seen in the entity output in the standoff section of the <code type="inline">172172.out.xml</code> file:</p>
<pre><code xml:id="code_geoparsing-text-with-edinburgh_19" type="block" corresp="code_geoparsing-text-with-edinburgh_19.txt"></code></pre>
<p><part ew="w204" sw="w204">Sunday</part>

</p>
<p>Besides the obvious <code type="inline">date</code>, <code type="inline">month</code>, <code type="inline">year</code> and <code type="inline">day</code> attributes:</p>
<ul>
<li><code type="inline">sdate</code> refers to the grounded date expressed as a string,</li>
<li><code type="inline">day-number</code> refers to a unique day number where 1 corresponds to the 1st of January 1 AD, and</li>
<li><code type="inline">wdaynum</code> refers to the week day number where 1 corresponds to Monday, 2 to Tuesday etc.</li>
</ul>
<p>This type of normalisation makes it possible to plot the events mentioned in a piece of text on a timeline.  A timeline view is automatically created at the end of each geoparser run. To view the one for our example <code type="inline">172172</code>, open the <code type="inline">172172.timeline.html</code> file in Firefox (this view is not configured for other browsers at the moment).</p>
<p>On MacOSX:</p>
<pre><code xml:id="code_geoparsing-text-with-edinburgh_20" type="block" corresp="code_geoparsing-text-with-edinburgh_20.txt"></code></pre>
<p>On Linux:</p>
<pre><code xml:id="code_geoparsing-text-with-edinburgh_21" type="block" corresp="code_geoparsing-text-with-edinburgh_21.txt"></code></pre>
<figure><desc>Figure 7: Timeline view for the example `172172` displayed in Firefox. You can see that the dates are normalised to the timeline at the bottom of the screen.</desc><graphic url="geoparser_figure12.png"/></figure>
<p>Figure 7 is a screenshot of the timeline view in Firefox.  At the top of the screen you can see the text of the example with different entity types (person, location, organisation and temporal expression) marked up in different colours.  Underneath you can see the timeline view with normalised dates and their events pinned to the calendar.</p>
<p>If the document date is not specified all temporal expressions will be interpreted relative to the date when the Geoparser is run. &#160;While this setting does not affect the performance of the geo-resolution of place names in this release, one could imagine a possible extension where the document date affects the type of gazetteer used or the location name variants that should be considered as place names change over time.</p>
</div><div n="2"><head>Geo-parsing Multiple Text Files</head>
<p>Now that you know how to geo-parse one file, you may want to do the same thing for a set of documents all at once. You can download a simple shell script which geo-parses multiple files <link target="http://groups.inf.ed.ac.uk/geoparser/scripts/run-multiple-files.sh">here</link>. Please refer to the <link target="http://homepages.inf.ed.ac.uk/balex/publications/geoparser-workshop.pdf">Geoparser workshop</link> slides for more information on how to make this script executable, run and it and adapt it to your needs.</p>
</div><div n="2"><head>Extracting&#160;Geo-Resolution Output to TSV</head>
<p>The output of the Geoparser is in XML format. This is useful as XML can store various types of information present in text along with it.  For example, it can store low-level information like the boundaries of words, their part-of-speech tags and lemmas.  It can also store more complex information like phrases and entities occurring in the text as well as links between them, for example the subject and object of a sentence or the location (e.g. birthplace) of a person.  The advantage is that all the computed structural and linguistic information computed for a piece of text is stored along with it and downstream natural language processing tools have all the information available.</p>
<p>While XML is easy to process by a machine it is difficult to read by human readers. You may also not be interested in all the information computed by the Geoparser and might only want to see which locations were identified along with their coordinates. So rather than dealing with an XML file, you might find it easier to work with the Geoparser output in a form such as tab-separated values (TSV) in order to inspect it in a spreadsheet or use it with an application such as QGIS or Google Maps/Google Earth for which there are already useful Programming Historian lessons available (<link target="/en/lessons/qgis-layers">Installing QGIS 2.0 and Adding Layers</link> and <link target="/en/lessons/googlemaps-googleearth">Intro to Google Maps and Google Earth</link>).</p>
<p>The Geoparser is distributed with a useful set of XML processing tools called <link target="https://www.ltg.ed.ac.uk/software/ltxml2/">LT-XML2</link>, authored by Richard Tobin, which can be used to extract the location entities in a Geoparser XML output file and to present them in tab-separated value (TSV) format. The executables for these tools are located in the <code type="inline">./geoparser/bin</code> directory, inside:</p>
<ul>
<li><code type="inline">sys-i386-64</code>: if you are using a 64 bit Linux machine or</li>
<li><code type="inline">sys-i386-snow-leopard</code>: if you&#8217;re using MacOSX. &#160;Don&#8217;t be confused by the name of this directory. &#160;The executables should work for all MacOSX installations and not just on Snow Leopard.</li>
</ul>
<p>All the executables starting with <emph>lx</emph> are LT-XML tools which work in combination with Xpath expressions to process or manipulate XML. &#160;Going in detail over Xpath is beyond the scope of this lesson, so I will give clear examples to show how things work. &#160;If you are interested in XML data manipulation you will find further detail in <link target="/en/lessons/transforming-xml-with-xsl">Transforming Data for Reuse and Re-publication</link>.</p>
<p>The best tool for printing XML content in a different format is <code type="inline">lxprintf</code>. Depending on your operating system, go to the <code type="inline">geoparser</code> directory and run <code type="inline">lxprintf</code> as follows:</p>
<p>On Linux use:</p>
<pre><code xml:id="code_geoparsing-text-with-edinburgh_22" type="block" corresp="code_geoparsing-text-with-edinburgh_22.txt"></code></pre>
<p>and on MacOSX type:</p>
<pre><code xml:id="code_geoparsing-text-with-edinburgh_23" type="block" corresp="code_geoparsing-text-with-edinburgh_23.txt"></code></pre>
<p>The previous <code type="inline">lxprintf</code> command reads through a geo-parsed XML output file, extracts all location entities identified by the Geoparser and presents them in TSV format. In the example above, the XML input file (containing the location entities) is <code type="inline">./out/172172.out.xml</code>, and the TSV file is <code type="inline">./out/172172.out.tsv</code>. The <code type="inline">&lt;</code> symbol signifies "standard in" (or stdin) which tells the script to read in the file that follows it and the <code type="inline">&gt;</code> symbol signifies standard out (or stdout) which specifies sending the output to the file that follows it.</p>
<p>The way this command works is that lxprintf looks for XML entities specified after the option <code type="inline">-e</code>. &#160;In this case, entities of type location are to be extracted (<code type="inline">"ent[@type='location&#8217;]&#8221;</code>).  Here is an example of an entity of type location in the XML:</p>
<pre><code xml:id="code_geoparsing-text-with-edinburgh_24" type="block" corresp="code_geoparsing-text-with-edinburgh_24.txt"></code></pre>
<p>The next part of the command (<code type="inline">&#8220;%s\t%s\t%s\t%s\t%s\n&#8221;</code>) specifies how the output should be printed. &#160;In this case, each specified string (<code type="inline">%s</code>) is delimited by a tab (<code type="inline">\t</code>) character and the last string is followed by a new line. &#160;In this case, the following 5 strings for each location entity are specified:</p>
<ul>
<li><code type="inline">"normalize-space(parts)"</code> refers to the location mention&#160;recognised in&#160;the text. normalize() removes any unnecessary whitespace.</li>
<li><code type="inline">"@gazref&#8221;</code> refers to&#160;the ID reference of the location in&#160;the gazetteer, if resolved.</li>
<li><code type="inline">"@in-country&#8221;</code> refers to&#160;the country the location appears in, if this information was identified.</li>
<li><code type="inline">"@lat&#8221;</code> refers to the latitude of the location, if this information was identified.</li>
<li><code type="inline">"@long&#8221;</code> refers to&#160;the longitude of the location, if this information was identified.</li>
</ul>
<p>When printed to screen, the content of the TSV output file is therefore the following:</p>
<pre><code xml:id="code_geoparsing-text-with-edinburgh_25" type="block" corresp="code_geoparsing-text-with-edinburgh_25.txt"></code></pre>
<p>If you open <code type="inline">./out/172172.out.tsv</code> in Excel, for example, you can see that the information is now presented in column format, in this case listing the place name, the GeoNames ID, the country code, the latitude and the longitude (see Figure 8).</p>
<figure><desc>Figure 8: Geo-parsed location information from the example `172172` displayed in Excel.</desc><graphic url="geoparser_figure10.png"/></figure>
<p>Once you have extracted the geo-location information from the <code type="inline">*out.xml</code> file(s) you can read it into a data frame and use it as input into your favourite mapping tool though you will have to adjust the format depending on your needs.</p>
</div></div>
      <div n="1"><head>Credits and Citation</head>
<p>The Geoparser and its demo were developed over a number of years in a team effort by members of the <link target="https://www.ltg.ed.ac.uk/">Edinburgh Language Technology Group</link>, including Claire Grover, Richard Tobin, Kate Byrne and myself (Beatrice Alex).</p>
<p>If you found this lesson useful for your work, please cite it as:</p>
<p>Beatrice Alex, "Geoparsing English-Language Text with the Edinburgh Geoparser," <emph>Programming Historian</emph> 6 (2017), <link target="https://doi.org/10.46430/phen0067">https://doi.org/10.46430/phen0067</link>.</p>
<p>or cite one of the publications listed <link target="https://www.ltg.ed.ac.uk/software/geoparser/">here</link>.</p>
<p>The lesson is also available in workshop form.  If you're interested in running a workshop on how to use the Edinburgh Geoparser, do get in touch.</p>
<p>The Geoparser team also welcomes suggestions for future collaboration to tailor the Geoparser to different needs.  Please get in touch if you have ideas about how it could be applied.</p>
<p>In the past the Geoparser was used to identify place names for different purposes and in different types of data (e.g. Grover et al., 2010 and Alex et al., 2015).  For example, it was adapted to perform fine-grained geo-parsing for literature set in Edinburgh (<link target="http://palimpsest.blogs.edina.ac.uk/">Palimpsest</link>) presented in the <link target="http://litlong.org/">LitLong</link> interface.  It was used to geo-parse</p>
<ul>
<li>volumes of the Survey of English Place Names (<link target="http://web.archive.org/web/20170722115758/http://englishplacenames.cerch.kcl.ac.uk/">DEEP</link>, see Grover and Tobin, 2014),</li>
<li>large historical collections related to commodity trading in the 19th century British Empire (<link target="http://tradingconsequences.blogs.edina.ac.uk/">Trading Consequences</link>) and</li>
<li>19th century British newspapers by <link target="http://www.lancaster.ac.uk/staff/gregoryi/">Prof. Ian Gregory</link>&#8217;s group at Lancaster University.</li>
</ul>
<p>The Geoparser was also adapted to the ancient world for the&#160;<link target="https://googleancientplaces.wordpress.com/">Google Ancient Places</link> project (e.g. see Isaksen et al., 2011), with its <link target="http://nrabinowitz.github.io/gapvis/">GapVis</link>&#160; interface. More recently, the Geoparser was used to geo-parse Twitter user profile locations (Alex et al, 2016) and the mass digitised text, including the Gazetteers of Scotland (Filgueira et al., 2020) and Encyclopaedia Britannica (Filgueira et al., 2021)</p>
</div>
      <div n="1"><head>References</head>
<p>Beatrice Alex, Clare Llewellyn, Claire Grover, Jon Oberlander and Richard Tobin (2016). Homing in on Twitter users: Evaluating an Enhanced Geoparser for User Profile Locations. 2016. In the Proceedings of the 10th Language Resources and Evaluation Conference (LREC), 23-28 May 2016. [<link target="http://www.lrec-conf.org/proceedings/lrec2016/pdf/129_Paper.pdf">pdf</link>]</p>
<p>Beatrice Alex, Kate Byrne, Claire Grover and Richard Tobin (2015). Adapting the Edinburgh Geoparser for Historical Georeferencing. International Journal for Humanities and Arts Computing, 9(1), pp. 15-35, March 2015.[<link target="http://www.euppublishing.com/doi/pdfplus/10.3366/ijhac.2015.0136">pdf</link>]</p>
<p>Rosa Filgueira, Claire Grover, Vasilios Karaiskos, Beatrice Alex, Sarah Van Eyndhoven, Lisa Gotthard, and Melissa Terras (2021). Extending defoe for the efficient analysis of historical texts at scale. In 2021 IEEE 17th International Conference on eScience (eScience), pp. 21-29.</p>
<p>Rosa Filgueira, Claire Grover, Melissa Terras, and Beatrice Alex (2020). Geoparsing the historical Gazetteers of Scotland: accurately computing location in mass digitised texts. In Proceedings of the 8th Workshop on Challenges in the Management of Large Corpora, pages 24&#8211;30, Marseille, France. European Language Resources Association.</p>
<p>Claire Grover and Richard Tobin (2014). A Gazetteer and Georeferencing for Historical English Documents. In Proceedings of LaTeCH 2014 at EACL 2014. Gothenburg, Sweden. <link target="http://www.aclweb.org/anthology/W14-0617">[pdf]</link></p>
<p>Claire Grover, Richard Tobin, Kate Byrne, Matthew Woollard, James Reid, Stuart Dunn, and Julian Ball (2010). Use of the Edinburgh Geoparser for georeferencing digitised historical collections. Philosophical Transactions of the Royal Society A. [<link target="http://homepages.inf.ed.ac.uk/grover/papers/PTRS-A-2010-Grover-3875-89.pdf">pdf</link>]</p>
<p>Leif Isaksen, Elton Barker, Eric C. Kansa, Kate Byrne (2012). GAP: A NeoGeo Approach to Classical Resources. Leonardo 45 (1): 82&#8211;83. [<link target="https://direct.mit.edu/leon/article/45/1/82/46956/GAP-A-NeoGeo-Approach-to-Classical-Resources#.U48IuXWx15Q">pdf</link>]</p>
</div>
    </body>
  </text>
</TEI>
