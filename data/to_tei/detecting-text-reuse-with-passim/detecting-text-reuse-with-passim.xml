<TEI xmlns="http://www.tei-c.org/ns/1.0" xml:id="detecting-text-reuse-with-passim">
  <teiHeader>
 <fileDesc>
  <titleStmt>
   <title>Detecting Text Reuse with Passim</title>
  <author role="original_author"><persName>Matteo Romanello</persName><persName>Simon Hengchen</persName></author><editor role="reviewers"><persName>Ryan Muther</persName><persName>Marco B&#252;chler</persName></editor><editor role="editors"><persName>A</persName><persName>n</persName><persName>n</persName><persName>a</persName><persName>-</persName><persName>M</persName><persName>a</persName><persName>r</persName><persName>i</persName><persName>a</persName><persName> </persName><persName>S</persName><persName>i</persName><persName>c</persName><persName>h</persName><persName>a</persName><persName>n</persName><persName>i</persName></editor></titleStmt>
  <publicationStmt>
   <idno type="doi">10.46430/phen0092</idno><date type="published">05/16/2021</date><p>Lesson reviewed and published in Programming Historian.</p>
  </publicationStmt>
  <sourceDesc>
  <p>Born digital, in a markdown format. This lesson is original. Available translations are the following:<ref type="translations" target="#detecter-la-reutilisation-de-texte-avec-passim"/></p></sourceDesc>
 </fileDesc>
 <profileDesc><abstract><p>In this lesson you will learn about text reuse detection -- the automatic identification of reused passages in texts -- and why you might want to use it in your research. Through a detailed installation guide and two case studies, this lesson will teach you the ropes of Passim, an open source and scalable tool for text reuse detection.</p></abstract><textClass><keywords><term xml:lang="en">data-manipulation</term></keywords></textClass></profileDesc>
</teiHeader>
  <text xml:lang="en">
    <body><p>In this lesson you will be introduced to the automatic detection of text reuse with the Passim library. You will learn how to install and run Passim and its dependencies, how to prepare your texts as input files suitable for use with Passim and, finally, how to process the output generated by Passim to carry out basic analyses.</p>
<p>This lesson targets digital humanities (DH) practitioners without any prior knowledge of text reuse, but with a working knowledge of <ref target="https://en.wikipedia.org/wiki/Bash_(Unix_shell)">bash scripting</ref> and Python as well as some data manipulation. For tutorials on bash scripting and <ref target="https://en.wikipedia.org/wiki/Python_(programming_language)">Python</ref>, you can refer to the Programming Historian <ref target="/en/lessons/intro-to-bash">&#8220;Introduction to the Bash Command Line</ref> tutorial and the <ref target="/en/lessons/?topic=python">library of current Python lessons</ref> on the <emph>Programming Historian</emph> website.</p>
<p>This lesson includes an overview of <ref target="https://github.com/dasmiq/passim">Passim</ref>, an open source tool for automatic text reuse detection. While the tool has been used in a number of small and large DH projects, it lacks a user-friendly documentation with examples and set up instructions, a gap that we aim to fill with this <emph>Programming Historian</emph> lesson.</p>
<div type="2"><head>Introduction to Text Reuse</head>
<p>Text reuse can be defined as "the meaningful reiteration of text, usually beyond the simple repetition of common language" (Romanello et al. 2014). It is such a broad concept that it can be understood at different levels and studied in a large variety of contexts. In a publishing or teaching context, for example, instances of text reuse can constitute plagiarism should portions of someone else&#8217;s text be repeated without appropriate attribution. In the context of literary studies, text reuse is often just a synonym for literary phenomena like allusions, paraphrases and direct quotations.</p>
<p>The following list includes just some of the libraries available that perform automatic text reuse detection:</p>
<list type="unordered">
<item>The <ref target="https://docs.ropensci.org/textreuse/">R textreuse package</ref> (R) written by Lincoln Mullen</item>
<item><ref target="https://www.etrap.eu/research/tracer/">TRACER</ref> (Java) developed by Marco B&#252;chler and colleagues</item>
<item><ref target="https://blast.ncbi.nlm.nih.gov/Blast.cgi">Basic Local Alignment Search Tool (BLAST)</ref></item>
<item><ref target="https://github.com/tesserae/tesserae">Tesserae</ref> (PHP, Perl)</item>
<item><ref target="https://github.com/ARTFL-Project/text-pair">TextPAIR (Pairwise Alignment for Intertextual Relations)</ref></item>
<item><ref target="https://github.com/dasmiq/passim">Passim</ref> (Scala) developed by <ref target="http://www.ccs.neu.edu/home/dasmith/">David Smith</ref> (Northeastern University)</item>
</list>
<p>For this tutorial we chose the Passim library for three main reasons. Firstly, it can be adapted to a variety of use cases as it works well on a small text collection as well as on a large-scale corpus. Secondly, while the documentation for Passim is extensive, because of its relatively advanced user audience, a more user-centered step-by-step tutorial about detecting text reuse with Passim would be beneficial to the user community. Lastly, the following examples illustrate the variety of scenarios in which text reuse is a useful methodology:</p>
<list type="unordered">
<item>To determine whether a digital library contains multiple editions of the same work(s)</item>
<item>To find quotations in a text, provided that the target works are known (e.g. find quotations of the Bible within 17c English literature)  </item>
<item>To study the virality and spread of texts (e.g. <ref target="https://viraltexts.org/">Viral Texts</ref> by Cordell and Smith for historical newspapers)</item>
<item>To identify (and possibly filter out) duplicate documents within a text collection before performing further processing steps (e.g. topic modelling as illustrated by Schofield et al. (2017))</item>
</list>
<p>For these reasons, Passim is usually a great choice. It will help you automate the search for repeated text passages in a corpus &#8212; whether these are running ads in newspapers, multiple copies of the same poem, or direct (and slightly indirect) quotations in someone else's book.
Text reuse detection as implemented in Passim aims at identifying these copies and repetitions automatically, and yields clusters of passages that were deemed to be related with one another. Ultimately, what a cluster contains can vary a lot and will depend on your research question. For example, Passim can group together copies of the same article that differ only with respect to optical character recognition (OCR) errors, but it can also help to retrieve texts that share the same journalistic template, such as horoscopes or advertisements.</p>
</div><div type="2"><head>Prerequisites</head>
<p>This tutorial requires the following:</p>
<list type="unordered">
<item>A basic understanding of Bash scripts. For readers needing a review on Bash scripts, read the <emph>Programming Historian</emph> lesson <ref target="/en/lessons/intro-to-bash">"Introduction to the Bash Command Line"</ref>.</item>
<item>Knowledge of JSON. To learn more about JSON, read the <emph>Programming Historian</emph> lesson <ref target="/en/lessons/json-and-jq">"Reshaping JSON with jq"</ref>.</item>
</list>
<p>Moreover, while a basic understanding of Python &#8212; and a working Python installation &#8212; are not strictly needed to work with Passim, they are required to run some parts of this tutorial (e.g. the Jupyter notebook with data exploration, or the Early English Books Online (EEBO) data preparation script). If you are not familiar with Python, please read the <emph>Programming Historian</emph> lesson <ref target="/en/lessons/introduction-and-installation">"Python Introduction and Installation"</ref>.   </p>
<p>Note that installing Passim on Windows is more arduous than macOS or Linux. As a result, we recommend using macOS or Linux (or a virtual environment) for this lesson.</p>
</div><div type="2"><head>Installing Passim</head>
<p>Installing Passim requires installing the following software:</p>
<list type="unordered">
<item><ref target="https://www.java.com/fr/download/">Java JDK (version 8)</ref></item>
<item><ref target="https://www.scala-sbt.org/">Scala Build Tool (SBT)</ref></item>
<item><ref target="https://spark.apache.org/">Apache Spark</ref></item>
</list>
<p>But why are all these dependencies needed?</p>
<p>Passim is written in a programming language called Scala. To execute a software written in Scala, its sources need to be compiled into an executable JAR file, which is performed by <code rend="inline">sbt</code>, Scala's interactive build tool. Finally, since Passim is designed to work also on large-scale text collections (with several thousands or millions of documents), behind the scenes it uses Spark, a cluster-computing framework written in Java. Using Spark allows Passim to handle the distributed processing of certain parts of the code, which is useful when handling large amounts of data. The <ref target="https://spark.apache.org/docs/latest/cluster-overview.html#glossary">Spark glossary</ref> is a useful resource to learn basic Spark terminology (words like "driver", "executor", etc.) but learning this terminology may not be necessary if you are running Passim on a small dataset.</p>
<p>Before installing this set of software, you'll need to download the Passim version 1 source code from GitHub:</p>
<ab><code xml:id="code_detecting-text-reuse-with-passim_0" corresp="code_detecting-text-reuse-with-passim_0.txt" lang="language-bash" rend="block"/></ab>
<p>or download the source code <ref target="https://github.com/dasmiq/passim/releases/tag/v1.0.0">from the v1.0 release page</ref>.</p>
<p>If you are not familiar with Git and GitHub, we recommend reading the <emph>Programming Historian</emph> lesson <ref target="https://doi.org/10.46430/phen0051">"An Introduction to Version Control Using GitHub Desktop"</ref>.</p>
<div type="3"><head>macOS instructions</head>
<p>These instructions are aimed at users of Apple's macOS and were tested under version 10.13.4 (a.k.a. High Sierra).</p>
<div type="4"><head>Check Java Installation</head>
<p>Ensure that you have Java Development Kit 8 by typing the following command in a new Terminal window:</p>
<ab><code xml:id="code_detecting-text-reuse-with-passim_1" corresp="code_detecting-text-reuse-with-passim_1.txt" lang="language-bash" rend="block"/></ab>
<p>If the output of this command looks similar to the following example, then Java 8 is installed on your machine.</p>
<ab><code xml:id="code_detecting-text-reuse-with-passim_2" corresp="code_detecting-text-reuse-with-passim_2.txt" rend="block"/></ab>
</div><div type="4"><head>Installing Java 8</head>
<p>In case another version of Java is installed on your machine, follow the following steps to install Java 8 alongside the existing Java version.</p>
<p>This is important so as not to break already installed software that needs more recent Java versions.</p>
<list type="ordered">
<item>
<p>Install the <code rend="inline">brew</code> package manager by following installation instructions on the <ref target="https://brew.sh/">Brew.sh</ref> website. Once the installation is completed, run <code rend="inline">brew --help</code> to verify it works.</p>
</item>
<item>
<p>Use <code rend="inline">brew</code> to install Java 8.</p>
</item>
</list>
<ab><code xml:id="code_detecting-text-reuse-with-passim_3" corresp="code_detecting-text-reuse-with-passim_3.txt" lang="language-bash" rend="block"/></ab>
<p>Verify that Java 8 is installed.</p>
<ab><code xml:id="code_detecting-text-reuse-with-passim_4" corresp="code_detecting-text-reuse-with-passim_4.txt" lang="language-bash" rend="block"/></ab>
<p>This command should output something similar to the following:</p>
<ab><code xml:id="code_detecting-text-reuse-with-passim_5" corresp="code_detecting-text-reuse-with-passim_5.txt" lang="language-bash" rend="block"/></ab>
<list start="3" type="ordered">
<item>Install <code rend="inline">jenv</code>, a tool that allows you to manage multiple Java versions installed on the same machine, and to easily switch between them.</item>
</list>
<ab><code xml:id="code_detecting-text-reuse-with-passim_6" corresp="code_detecting-text-reuse-with-passim_6.txt" lang="language-bash" rend="block"/></ab>
<p>To be able to call <code rend="inline">jenv</code> without specifying the executable's full path don't forget to add <code rend="inline">jenv</code> to your <code rend="inline">$PATH</code> environment variable by opening the file <code rend="inline">~/.bashrc</code> with your favorite text editor and adding the following lines at the end of the file:</p>
<ab><code xml:id="code_detecting-text-reuse-with-passim_7" corresp="code_detecting-text-reuse-with-passim_7.txt" lang="language-bash" rend="block"/></ab>
<p>After adding these lines, you need to open another terminal window or run the following line so that the <code rend="inline">$PATH</code> variable is updated with the change you just made (the command <code rend="inline">source</code> triggers the reload of your <code rend="inline">bash</code> configuration).</p>
<ab><code xml:id="code_detecting-text-reuse-with-passim_8" corresp="code_detecting-text-reuse-with-passim_8.txt" lang="language-bash" rend="block"/></ab>
<p>Once installed, add the existing Java versions to <code rend="inline">jenv</code> (i.e. those listed by the command <code rend="inline">/usr/libexec/java_home -V</code>):</p>
<ab><code xml:id="code_detecting-text-reuse-with-passim_9" corresp="code_detecting-text-reuse-with-passim_9.txt" lang="language-bash" rend="block"/></ab>
<p>Now you can set the default version of Java for this project by running the following:</p>
<ab><code xml:id="code_detecting-text-reuse-with-passim_10" corresp="code_detecting-text-reuse-with-passim_10.txt" lang="language-bash" rend="block"/></ab>
</div><div type="4"><head>Compiling Passim From the Sources (macOS)</head>
<p>Passim is written in a programming language called Scala. Before being able to execute a software written in Scala, its sources need to be compiled. This task is performed by <code rend="inline">sbt</code>, the Interactive Build Tool.</p>
<p>To determine whether <code rend="inline">sbt</code> is installed on your machine, run the following command:</p>
<ab><code xml:id="code_detecting-text-reuse-with-passim_11" corresp="code_detecting-text-reuse-with-passim_11.txt" lang="language-bash" rend="block"/></ab>
<p>If this command prints <code rend="inline">bash: sbt: command not found</code> it means <code rend="inline">sbt</code> is not installed.
However, Passim comes with a useful script (<code rend="inline">build/sbt</code>) that will download and install SBT automatically before compiling the sources from Passim.</p>
<p><hi rend="bold">NB</hi>: Using an external (i.e. already installed) SBT may lead to issues, we recommend the following method for compiling Passim.</p>
<p>To compile the program, run the following command from the directory where you've previously cloned Passim's GH repository:</p>
<ab><code xml:id="code_detecting-text-reuse-with-passim_12" corresp="code_detecting-text-reuse-with-passim_12.txt" lang="language-bash" rend="block"/></ab>
<p>This command will take some time (around 3 minutes on a modern connection), but will let you know of the progress. As your computer starts downloading required files, a log will be printed on screen. At the end of this process, <code rend="inline">sbt</code> will have created a <code rend="inline">.jar</code> archive contaning the compiled sources for Passim. This file is found in the <code rend="inline">target</code> directory: <code rend="inline">target/scala-2.11/Passim_2.11-0.2.0.jar</code>. Depending on the version of Scala and Passim, the actual path might be slightly different on your computer.</p>
<p>The <code rend="inline">bin</code> directory contains a Passim file: this is the executable that will launch Passim. In order for your computer the location of this file, and thus for it to recognise the Passim command, we need to add the path to the <code rend="inline">PATH</code> environment variable.</p>
<ab><code xml:id="code_detecting-text-reuse-with-passim_13" corresp="code_detecting-text-reuse-with-passim_13.txt" lang="language-bash" rend="block"/></ab>
<p>To add the path permanently to the <code rend="inline">PATH</code> environment variable, open the file <code rend="inline">~/.bashrc</code> with your favorite text editor and add the following line anywhere in the file (then execute <code rend="inline">source ~/.bashrc</code> to apply this change):</p>
<ab><code xml:id="code_detecting-text-reuse-with-passim_14" corresp="code_detecting-text-reuse-with-passim_14.txt" lang="language-bash" rend="block"/></ab>
</div><div type="4"><head>Installing Spark</head>
<list type="ordered">
<item>
<p>Navigate to the <ref target="http://spark.apache.org/downloads">download section</ref> of the Spark website and select Spark release version '3.x.x' (where '<emph>x</emph>' means any version that starts with '3.'), and package type 'Pre-built for Apache Hadoop 2.7' from the dropdown menus.</p>
</item>
<item>
<p>Extract the compressed binaries to a directory of your choice (e.g. <code rend="inline">/Applications</code>):</p>
</item>
</list>
<ab><code xml:id="code_detecting-text-reuse-with-passim_15" corresp="code_detecting-text-reuse-with-passim_15.txt" lang="language-bash" rend="block"/></ab>
<list start="3" type="ordered">
<item>Add the directory where you installed Spark to your <code rend="inline">PATH</code> environment variable. To do so temporarily run the following command:</item>
</list>
<ab><code xml:id="code_detecting-text-reuse-with-passim_16" corresp="code_detecting-text-reuse-with-passim_16.txt" lang="language-bash" rend="block"/></ab>
<p>To add the path installation directory permanently to your <code rend="inline">PATH</code> environment variable, open the file <code rend="inline">~/.bashrc</code> with your favorite text editor and add the following line anywhere in the file:</p>
<ab><code xml:id="code_detecting-text-reuse-with-passim_17" corresp="code_detecting-text-reuse-with-passim_17.txt" lang="language-bash" rend="block"/></ab>
<p>After editing <code rend="inline">~/.bashrc</code>, open another terminal window or run the following command:</p>
<ab><code xml:id="code_detecting-text-reuse-with-passim_18" corresp="code_detecting-text-reuse-with-passim_18.txt" lang="language-bash" rend="block"/></ab>
</div></div><div type="3"><head>Linux instructions</head>
<p>These instructions are aimed at Debian-based distributions (Debian, Ubuntu, Linux Mint, etc.). If you run another type of distribution (Fedora, Gentoo, etc.), replace the distribution-specific commands (eg <code rend="inline">apt</code>) with those used by your specific distribution.</p>
<div type="4"><head>Check Java Installation</head>
<p>To ensure that you have the Java Development Kit 8 installed, run the following command:</p>
<ab><code xml:id="code_detecting-text-reuse-with-passim_19" corresp="code_detecting-text-reuse-with-passim_19.txt" lang="language-bash" rend="block"/></ab>
<p>If the command above returns <code rend="inline">1.8.0_252</code> or similar, then you have Java Development Kit 8 installed (the <code rend="inline">8</code> lets you know you have correct kit installed and selected by default). If your output looks different, choose one of the following commands accordingly:</p>
<ab><code xml:id="code_detecting-text-reuse-with-passim_20" corresp="code_detecting-text-reuse-with-passim_20.txt" lang="language-bash" rend="block"/></ab>
<ab><code xml:id="code_detecting-text-reuse-with-passim_21" corresp="code_detecting-text-reuse-with-passim_21.txt" lang="language-bash" rend="block"/></ab>
</div><div type="4"><head>Compiling Passim from the Sources</head>
<p>Refer to the <ref target="#compiling-passim-from-the-sources-(macOS)">compilation instructions for macOS</ref>, as they are the same for the Linux environment.</p>
</div><div type="4"><head>Installing Spark</head>
<list type="ordered">
<item>Download the Spark binaries by using <code rend="inline">wget</code>:</item>
</list>
<ab><code xml:id="code_detecting-text-reuse-with-passim_22" corresp="code_detecting-text-reuse-with-passim_22.txt" lang="language-bash" rend="block"/></ab>
<list start="2" type="ordered">
<item>Extract the compressed binaries to a directory of your choice:</item>
</list>
<ab><code xml:id="code_detecting-text-reuse-with-passim_23" corresp="code_detecting-text-reuse-with-passim_23.txt" lang="language-bash" rend="block"/></ab>
<list start="3" type="ordered">
<item>Add the directory where you installed Spark to your <code rend="inline">PATH</code> environment variable. To add the directory to your&#160;<code rend="inline">PATH</code>&#160;environment variable temporarily, run the following command:</item>
</list>
<ab><code xml:id="code_detecting-text-reuse-with-passim_24" corresp="code_detecting-text-reuse-with-passim_24.txt" lang="language-bash" rend="block"/></ab>
<p>To add the directory to your&#160;<code rend="inline">PATH</code>&#160;environment variable permanently, open the file <code rend="inline">~/.bashrc</code> with your favorite text editor and add the following line anywhere in the file:</p>
<ab><code xml:id="code_detecting-text-reuse-with-passim_25" corresp="code_detecting-text-reuse-with-passim_25.txt" lang="language-bash" rend="block"/></ab>
<p>After editing <code rend="inline">~/.bashrc</code>, you need to open another terminal window or run the following line so that your <code rend="inline">PATH</code> variable is updated with the change you just made.</p>
<ab><code xml:id="code_detecting-text-reuse-with-passim_26" corresp="code_detecting-text-reuse-with-passim_26.txt" lang="language-bash" rend="block"/></ab>
</div></div><div type="3"><head>Verify the Installation</head>
<p>At this point you have installed Passim and all required packages on your machine. If you type <code rend="inline">Passim --help</code> in the command line, you should see output similar to the following:</p>
<ab><code xml:id="code_detecting-text-reuse-with-passim_27" corresp="code_detecting-text-reuse-with-passim_27.txt" lang="language-bash" rend="block"/></ab>
</div></div><div type="2"><head>Preparing Data for Passim</head>
<p>The goal of using Passim is to automate the search for repeated text passages in a corpus. For example, a newspaper corpus contains multiple copies of the same article, identical or with slight differences from one another, as well as repetitions of smaller portions of a newspaper page (e.g. advertisement, event listings, etc.).</p>
<p>As the documentation for Passim specifies "the input to Passim is a set of documents. Depending on the kind of data you have, you might choose documents to be whole books, pages of books, whole issues of newspapers, individual newspaper articles, etc. Minimally, a document consists of an identifier string and a single string of text content" (Refer to the minimal JSON input example in the next section for more information about the structure of input for Passim).</p>
<p>Figure 1 gives a schematic representation of input and output data for Passim. Given an input set of documents, divided into document series, Passim will attempt to identify reuse of text from documents in different series, and not within these series. In the case of a newspaper corpus, articles from the same newspaper will belong to the same document series, as we are not interested in detecting reuse within the same newspaper, but across different newspapers.</p>
<p>Ultimately, what constitutes a document, and how these documents should be divided into series, are the choices you'll need to make when preparing your data for Passim.  Naturally, the decision on what constitutes a <emph>series</emph> of documents is directly dependent on your goals or research questions. Finding quotations of the Bible in a corpus of books is a "one-to-many" case of text reuse detection, which requires documents to be grouped into two series (<code rend="inline">bible</code> and <code rend="inline">non_bible</code>). Instead, the comparison between multiple editions of the Bible (also known as collation) can be seen a "many-to-many" case, where each edition will correspond to and constitute a series of documents (e.g. pages).  If your research questions change at some point, thus requiring a re-definition of document series, you will need also to produce new input data for Passim to reflect this change.</p>
<figure><desc>Figure 1. Schematic representation of text reuse clusters; each cluster consists of similar passages found in several series of documents.</desc><graphic url="textreuse-generic.png"/></figure>
<div type="3"><head>Basic JSON format</head>
<p>The input format for Passim consists of JSON documents in the <ref target="http://jsonlines.org/">JSON lines format</ref> (i.e. each line of text contains a single JSON document).</p>
<p>The following file content for a file named <code rend="inline">test.json</code> illustrates a minimal example of the input format for Passim: </p>
<ab><code xml:id="code_detecting-text-reuse-with-passim_28" corresp="code_detecting-text-reuse-with-passim_28.txt" lang="language-json" rend="block"/></ab>
<p>The fields <code rend="inline">id</code>, <code rend="inline">series</code> and <code rend="inline">text</code> are the only fields required by Passim. Given this file as input, the software will try to detect text reuse between documents in the series <code rend="inline">abc</code> and those in the series <code rend="inline">def</code>, on the basis of the contents in <code rend="inline">text</code>.</p>
<p>Throughout this tutorial we will be using the command-line tool <ref target="https://stedolan.github.io/jq/"><code rend="inline">jq</code></ref> to inspect and do some basic process on both input and output JSON data. Note that, if you don't have <code rend="inline">jq</code> installed, you'll need to execute <code rend="inline">sudo apt-get install jq</code> under Ubuntu or <code rend="inline">brew install jq</code> under macOS (for other operating systems <ref target="https://stedolan.github.io/jq/download/">refer to the official JQ installation page</ref>).</p>
<p>For example, to select and print the field <code rend="inline">series</code> of your input <code rend="inline">test.json</code>, run the following command:</p>
<ab><code xml:id="code_detecting-text-reuse-with-passim_29" corresp="code_detecting-text-reuse-with-passim_29.txt" lang="language-bash" rend="block"/></ab>
<p>Note: If you are using <code rend="inline">jq</code> to look at your JSON data, you need to use the <code rend="inline">--slurp</code> parameter whenever you want to treat the content of one or more JSON line files as a single array of JSON documents and apply some filters to it (e.g. to select and print only one document, use the following command <code rend="inline">jq --slurp '.[-1]' test.json</code>). Otherwise <code rend="inline">jq</code> will treat each document separately thus causing the following error:</p>
<ab><code xml:id="code_detecting-text-reuse-with-passim_30" corresp="code_detecting-text-reuse-with-passim_30.txt" lang="language-bash" rend="block"/></ab>
</div><div type="3"><head>A Note on Packaging Data</head>
<p>Depending one the total size of your data, it may be a good idea to store Passim input files as compressed archives. Passim supports several compression schemes like .gzip and .bzip2. Note that a compressed datastream will be slower to process than an uncompressed one, so using this option will only be beneficial if your data is large (i.e. gigabytes of text), if you have access to many computing cores, or have a limited amount of disk space.</p>
<p>This command (or, better, chain of commands) will output the first document in a bzip2-compressed JSON lines file (some fields have been truncated for the sake of readability):</p>
<ab><code xml:id="code_detecting-text-reuse-with-passim_31" corresp="code_detecting-text-reuse-with-passim_31.txt" lang="language-bash" rend="block"/></ab>
<p>And will output the following:</p>
<ab><code xml:id="code_detecting-text-reuse-with-passim_32" corresp="code_detecting-text-reuse-with-passim_32.txt" lang="language-json" rend="block"/></ab>
</div><div type="3"><head>Custom JSON format</head>
<p>(Note: This subsection is not strictly necessary to run Passim, as the second case study will showcase. Nonetheless, these steps may be useful to readers with advanced needs with the regards to the format and structure of input data.)</p>
<p>There are cases where you may want to include additional information (i.e. JSON fields) in each input document, in addition to the required ones (<code rend="inline">id</code>, <code rend="inline">series</code>, <code rend="inline">text</code>). As an example, when working with OCR data you may want to pass image coordinate information alongside the article text. Passim does support the use of input data that follow a custom JSON format as behind the scenes it relies on Spark to infer the structure of the input data (i.e. the JSON schema). Passim will not directly use these fields, but it will keep them in the produced output.</p>
<p>However, there may be cases where Spark fails to infer the correct structure of input data (e.g. by inferring a wrong data type for a given field). In these cases, you need to inform Passim about the correct schema of the input data. </p>
<p>The following example illustrates a step-by-step approach to troubleshooting this relatively rare situation where one needs to correct the inferred JSON schema. Passim comes with the command <code rend="inline">json-df-schema</code>, which runs a (Python) script to infer the schema from any JSON input. The following steps are necessary to infer the structure from any JSON data:</p>
<list type="ordered">
<item>Install the necessary Python libraries.</item>
</list>
<ab><code xml:id="code_detecting-text-reuse-with-passim_33" corresp="code_detecting-text-reuse-with-passim_33.txt" lang="language-bash" rend="block"/></ab>
<list start="2" type="ordered">
<item>Extract an input example from one of our compressed input files.</item>
</list>
<ab><code xml:id="code_detecting-text-reuse-with-passim_34" corresp="code_detecting-text-reuse-with-passim_34.txt" lang="language-bash" rend="block"/></ab>
<list start="3" type="ordered">
<item>Ask <code rend="inline">json-df-schema</code> to infer the schema of our data from our sample file.</item>
</list>
<ab><code xml:id="code_detecting-text-reuse-with-passim_35" corresp="code_detecting-text-reuse-with-passim_35.txt" lang="language-bash" rend="block"/></ab>
<p><code rend="inline">json-df-schema</code> will try to guess the JSON schema of input data and output it to a file. The following example is what the schema generated by Passim (<code rend="inline">Passim.schema.orig</code>) looks like:</p>
<ab><code xml:id="code_detecting-text-reuse-with-passim_36" corresp="code_detecting-text-reuse-with-passim_36.txt" lang="language-json" rend="block"/></ab>
<p>Passim has failed to recognize the coordinate field as containing integer values and it has interpreted as a long data type.  At this point, we need to change the type of the sub-fields of <code rend="inline">coords</code> (i.e. <code rend="inline">h</code>, <code rend="inline">w</code>, <code rend="inline">x</code>, and <code rend="inline">y</code>) from <code rend="inline">"type": "long"</code> to <code rend="inline">"type": "integer"</code>. This type mismatch needs to be fixed, otherwise Passim will treat <code rend="inline">int</code> values as if they were <code rend="inline">long</code>, thus potentially leading to issues or inconsistencies in the generated output.</p>
<p>We can now save the schema for later into a new file (<code rend="inline">passim.schema</code>) for later use. This schema is needed when processing the input data provided for <ref target="#case-study-2:-text-reuse-in-a-large-corpus-of-historical-newspapers">the second case study</ref> presented in this lesson.</p>
</div></div><table>
<row>
<cell role="label">Parameter</cell>
<cell role="label">Default value</cell>
<cell role="label">Description</cell>
<cell role="label">Explanation</cell>
</row>
<row>
<cell><code rend="inline">--max-repeat</code> (<code rend="inline">-r</code>)</cell>
<cell>10</cell>
<cell>Maximum repeat of one series in a cluster</cell>
<cell>This paramter allows you to specify how much a given series can be present in a cluster.</cell>
</row>
<row>
<cell><code rend="inline">--relative-overlap</code> (<code rend="inline">-o</code>)</cell>
<cell>0.8</cell>
<cell>Proportion that two different aligned passages from the same document must overlap to be clustered together, as measured on the longer passage <!-- TODO SH: Current mismatch between official doc and code, see what is going to be changed after David answers to this issue https://github.com/dasmiq/passim/issues/10 --></cell>
<cell>This parameter determines the degree of string similarity two passages need to have in order to be clustered together.<br/><br/>In the case of very noisy texts, it may be desirable to set this parameter to a  smaller value.</cell>
</row>
<row>
<cell><code rend="inline">--min-match</code> (<code rend="inline">-m</code>)</cell>
<cell>5</cell>
<cell>Minimum number of matching n-grams between two documents</cell>
<cell>This parameter allows you to decide how many n-grams must be found between two documents.</cell>
</row>
<row>
<cell><code rend="inline">--maxDF</code> (<code rend="inline">-u</code>)</cell>
<cell>100</cell>
<cell>Upper limit on document frequency of n-grams used.</cell>
<cell>This parameter will filter out n-grams that are too common, thus occurring many times in a given document. <br/><br/>This value has an impact on the performances as it will reduce the number of document pairs retrieved by Passim that will need to be compared.</cell>
</row>
<row>
<cell><code rend="inline">--minDF</code> (<code rend="inline">-l</code>)</cell>
<cell>2</cell>
<cell>Lower limit on document frequency of n-grams used</cell>
<cell>Since n-grams are used in Passim to retrieve document candidate pairs, an n-gram occurring only once is not useful as it will retrieve only one document (and not a pair). For this reason <code rend="inline">--minDF</code> defaults to <code rend="inline">2</code>.</cell>
</row>
<row>
<cell><code rend="inline">--n</code></cell>
<cell>5</cell>
<cell>N-gram order for text-reuse detection</cell>
<cell>N-grams are chains of words of length N. This setting allows you to decide what type of n-gram (unigram, bigram, trigram...) Passim should use when creating a list of possible text reuse candidates.<br/><br/>Setting this parameter to a lower value can help in the case of very noisy texts (i.e. when many words in a text are affected by one or more OCR errors). In fact, the longer the n-gram, the more likely it is to contain OCR mistakes.</cell>
</row>
</table><div type="2"><head>Using Passim's Output</head>
<p>Since the usage of text reuse data ultimately depends on the research questions at hand &#8212; and there many possible applications of text reuse, as we have seen above &#8212; covering how to use Passim's output falls beyond the scope of this lesson.</p>
<p>Code that 'does something' with the data output by Passim can be written in many different programming languages. Extracted clusters can be used to deduplicate documents in a corpus, or even collate together multiple witnesses of the same text, but this will entirely depend on the research context and specific use case.</p>
<p>To given an example of where to go next, for those who want to manipulate and further analyse text reuse data in Python, we provide a Jupyter notebook (<ref target="https://github.com/impresso/PH-passim-tutorial/blob/master/explore-passim-output.ipynb"><code rend="inline">explore-Passim-output.ipynb</code></ref>) that shows how to import Passim's JSON output into a <code rend="inline">pandas.DataFrame</code> and how to analyse the distribution of text reuse clusters in both uses cases presented above. For readers that are not familair with the Python library <code rend="inline">pandas</code>, the <emph>Programming Historian</emph> lesson written by Charlie Harper on <ref target="/en/lessons/visualizing-with-bokeh"><emph>Visualizing Data with Bokeh and Pandas</emph></ref> is a nice (and required) introductory reading.</p>
<p>The code contained and explained in the notebook will produce the two plots of Figures 3 and 4, showing how the sizes of text reuse clusters are distributed in the impresso and Bible data respectively.</p>
<figure><desc>Figure 3. Distribution of text reuse cluster sizes in the impresso sample data.</desc><graphic url="plot-impresso.png"/></figure>
<figure><desc>Figure 4. Distribution of text reuse cluster sizes in the Bible sample data.</desc><graphic url="plot-bible.png"/></figure>
<p>As you can see from the plots, in both cases the majority of text reuse clusters contains at most two passages. In the impresso sample data, however, there is much more variance in the size of clusters, with 10% of them having a size comprised between 6 and 296 passages, as opposed to the Bible data where the maximum cluster size is 3.</p>
</div><div type="2"><head>Further readings</head>
<p><hi rend="bold">Passim</hi></p>
<list type="unordered">
<item>Smith et al. (2015) introduce in detail the text reuse detection algorithm implemented in Passim</item>
<item>Cordell (2015) applied Passim to study text reuse within a large corpus of American newspapers</item>
</list>
<p><hi rend="bold">textreuse</hi></p>
<list type="unordered">
<item>Vogler et al. (2020) apply the <code rend="inline">textreuse</code> R package (Mullen 2016) to study the phenomenon of <emph>media concentration</emph> in contemporary journalism</item>
</list>
<p><hi rend="bold">TRACER</hi></p>
<list type="unordered">
<item>B&#252;chler et al. (2014) explain the algorithms for text reuse detection that are implemented in TRACER;</item>
<item>Franzini et al. (2018) use and evaluate TRACER for the extraction of quotations from a Latin text (the <emph>Summa contra Gentiles</emph> of Thomas Aquinas)</item>
</list>
<p><hi rend="bold">BLAST</hi></p>
<list type="unordered">
<item>Vierthaler et al. (2019) use the BLAST alignment algorithm to detect reuse in Chinese texts</item>
<item>Vesanto et al. (2017) and Salmi et al. (2019) apply BLAST to a comprehensive corpus of newspapers published in Finland</item>
</list>
</div><div type="2"><head>Acknowledgements</head>
<p>A sincere thanks goes to Marco B&#252;chler and Ryan Muther for reviewing this lesson, as well as to our colleagues Marten D&#252;ring and David Smith for their constructive feedback on an early version of this tutorial. Additional thanks go to Anna-Maria Sichani for serving as editor.</p>
<p>The authors warmly thank the newspaper <ref target="https://letemps.ch/">Le Temps</ref> &#8212; owner of <emph>La Gazette de Lausanne</emph> (GDL) and the <emph>Journal de Gen&#232;ve</emph> (JDG) &#8212; and the group <ref target="https://www.arcinfo.ch/">ArcInfo</ref> &#8212; owner of <emph>L&#8217;Impartial</emph> (IMP) and <emph>L&#8217;Express</emph> (EXP) &#8212;  for accepting to share their data for academic purposes.</p>
<p>MR gratefully acknowledges the financial support of the Swiss National Science Foundation (SNSF) for the project <ref target="https://impresso-project.ch/"><emph>impresso &#8211; Media Monitoring of the Past</emph></ref> under grant number CR-SII5_173719. SH's work was supported by the European Union&#8217;s Horizon 2020 research and innovation programme under grant 770299 (<ref target="https://www.newseye.eu/">NewsEye</ref>). SH was affiliated with the University of Helsinki and the University of Geneva for most of this work, and is currently funded by the project <emph>Towards Computational Lexical Semantic Change Detection</emph> supported by the Swedish Research Council (20192022; dnr 2018-01184).</p>
</div><div type="2"><head>Bibliography</head>
<list type="ordered">
<item>Greta Franzini, Maria Moritz, Marco B&#252;chler, Marco Passarotti. Using and evaluating TRACER for an Index fontium computatus of the Summa contra Gentiles of Thomas Aquinas. In <emph>Proceedings of the Fifth Italian Conference on Computational Linguistics (CLiC-it 2018)</emph>. (2018). <ref target="http://ceur-ws.org/Vol-2253/paper22.pdf">Link</ref></item>
<item>David A. Smith, Ryan Cordell, Abby Mullen. Computational Methods for Uncovering Reprinted Texts in Antebellum Newspapers. <emph>American Literary History</emph> <hi rend="bold">27</hi>, E1&#8211;E15 Oxford University Press, 2015. <ref target="http://dx.doi.org/10.1093/alh/ajv029">Link</ref></item>
<item>Ryan Cordell. Reprinting Circulation, and the Network Author in Antebellum Newspapers. <emph>American Literary History</emph> <hi rend="bold">27</hi>, 417&#8211;445 Oxford University Press (OUP), 2015. <ref target="http://dx.doi.org/10.1093/alh/ajv028">Link</ref></item>
<item>Daniel Vogler, Linards Udris, Mark Eisenegger. Measuring Media Content Concentration at a Large Scale Using Automated Text Comparisons. <emph>Journalism Studies</emph> <hi rend="bold">0</hi>, 1&#8211;20 Taylor &amp; Francis, 2020. <ref target="http://dx.doi.org/10.1080/1461670x.2020.1761865">Link</ref></item>
<item>Lincoln Mullen. textreuse: Detect Text Reuse and Document Similarity. (2016). <ref target="https://github.com/ropensci/textreuse">Link</ref></item>
<item>Marco B&#252;chler, Philip R. Burns, Martin M&#252;ller, Emily Franzini, Greta Franzini. Towards a Historical Text Re-use Detection. 221&#8211;238 In <emph>Text Mining: From Ontology Learning to Automated Text Processing Applications</emph>. Springer International Publishing, 2014. <ref target="http://dx.doi.org/10.1007/978-3-319-12655-5_11">Link</ref></item>
<item>Paul Vierthaler, Meet Gelein. A BLAST-based, Language-agnostic Text Reuse Algorithm with a MARKUS Implementation and Sequence Alignment Optimized for Large Chinese Corpora. <emph>Journal of Cultural Analytics</emph> (2019). <ref target="http://dx.doi.org/10.22148/16.034">Link</ref></item>
<item>Aleksi Vesanto, Asko Nivala, Heli Rantala, Tapio Salakoski, Hannu Salmi, Filip Ginter. Applying BLAST to Text Reuse Detection in Finnish Newspapers and Journals, 1771-1910. 54&#8211;58 In <emph>Proceedings of the NoDaLiDa 2017 Workshop on Processing Historical Language</emph>. Link&#246;ping University Electronic Press, 2017. <ref target="https://www.aclweb.org/anthology/W17-0510">Link</ref></item>
<item>Hannu Salmi, Heli Rantala, Aleksi Vesanto, Filip Ginter. The long-term reuse of text in the Finnish press, 1771&#8211;1920. <hi rend="bold">2364</hi>, 394&#8211;544 In <emph>CEUR Workshop Proceedings</emph>. (2019).</item>
<item>Axel J Soto, Abidalrahman Mohammad, Andrew Albert, Aminul Islam, Evangelos Milios, Michael Doyle, Rosane Minghim, Maria Cristina de Oliveira. Similarity-Based Support for Text Reuse in Technical Writing. 97&#8211;106 In <emph>Proceedings of the 2015 ACM Symposium on Document Engineering</emph>. ACM, 2015. <ref target="http://dx.doi.org/10.1145/2682571.2797068">Link</ref></item>
<item>Alexandra Schofield, Laure Thompson, David Mimno. Quantifying the Effects of Text Duplication on Semantic Models. 2737&#8211;2747 In <emph>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</emph>. Association for Computational Linguistics, 2017. <ref target="http://dx.doi.org/10.18653/v1/D17-1290">Link</ref></item>
<item>Matteo Romanello, Aur&#233;lien Berra, Alexandra Trachsel. Rethinking Text Reuse as Digital Classicists. <emph>Digital Humanities conference</emph>, 2014. <ref target="https://wiki.digitalclassicist.org/Text_Reuse">Link</ref></item>
</list>
</div></body>
  </text>
</TEI>
