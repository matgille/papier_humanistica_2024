<TEI xmlns="http://www.tei-c.org/ns/1.0" xml:id="som-dados-sonificacao-historiadores">
  <teiHeader>
 <fileDesc>
  <titleStmt>
   <title>Sonifica&#231;&#227;o de dados (uma introdu&#231;&#227;o &#224; sonifica&#231;&#227;o para historiadores)</title>
  <author type="original_author">Shawn Graham</author><editor type="reviewers"><persName>Jeff Veitch</persName><persName>Tim Compeau</persName></editor><author type="translators">Gabriela Kucuruza</author><editor type="translation-reviewers"><persName>Samuel Van Ransbeeck</persName><persName>Juliana Marques da Silva</persName></editor><editor type="editors">Ian Milligan</editor></titleStmt>
  <publicationStmt>
   <idno type="doi">10.46430/phpt0020</idno><date type="published">06/07/2016</date><date type="translated">03/26/2021</date><p>Lesson reviewed and published in Programming Historian.</p>
  </publicationStmt>
  <sourceDesc>
  <p>Born digital, in a markdown format. Original file: <ref type="original_file" target="#sonification"/>.</p><p>There are other translations: <ref target=""/></p></sourceDesc>
 </fileDesc>
 <profileDesc><abstract><p>Existem in&#250;meras li&#231;&#245;es que o ajudar&#227;o a visualizar o passado, mas esta li&#231;&#227;o o ajudar&#225; a ouvir o passado.</p></abstract><textClass><keyword xml:lang="en">distant-reading</keyword></textClass></profileDesc>
</teiHeader>
  <text xml:lang="pt">
    <body>
      <div type="1"><head>Introdu&#231;&#227;o</head>
<p>&#960;&#959;&#943;&#951;&#963;&#953;&#962; - fabrica&#231;&#227;o, cria&#231;&#227;o, produ&#231;&#227;o</p>
<p>Eu estou muito cansado de ver o passado. Existem diversos guias que ir&#227;o ajudar a  <emph>visualizar</emph> o passado que n&#227;o podemos ver, mas muitas vezes n&#243;s esquecemos que a visualiza&#231;&#227;o &#233; um ato de criatividade. N&#243;s talvez estejamos muito ligados &#224;s nossas telas, muito focados em "ver". Ao inv&#233;s disso, deixe-me ouvir algo do passado.</p>
<p>Enquanto existe uma hist&#243;ria e uma literatura profundas sobre arqueoac&#250;stica e paisagens sonoras que tentam capturar o som de um lugar  <emph>como ele era</emph> (<link target="https://www.digitalstudies.org/articles/10.16995/dscn.58">veja por exemplo a Virtual St. Paul's</link> ou o trabalho de <link target="https://jeffdveitch.wordpress.com/">Jeff Veitch em Ostia antiga</link>), eu tenho interesse em 'sonificar' o que eu tenho <emph>agora</emph>, os dados eles mesmos. Eu quero descobrir uma gram&#225;tica para representar dados em som que seja apropriada para Hist&#243;ria. <link target="#Drucker">Drucker</link> <link target="http://www.digitalhumanities.org/dhq/vol/5/1/000091/000091.html">notoriamente nos lembra</link> que &#8216;dados&#8217; n&#227;o s&#227;o coisas dadas, mas ao inv&#233;s disso, coisas capturadas, coisas transformadas. Na sonifica&#231;&#227;o de dados, eu literalmente realizo o passado no presente, e ent&#227;o as suposi&#231;&#245;es e as transforma&#231;&#245;es que fa&#231;o est&#227;o em primeiro plano. A experi&#234;ncia auditiva resultante &#233; uma "deforma&#231;&#227;o" literal que nos faz ouvir as camadas modernas do passado de uma nova maneira.</p>
<p>Eu quero ouvir os significados do passado, mas eu sei que n&#227;o posso. No entanto, quando ou&#231;o um instrumento, posso imaginar a materialidade do m&#250;sico tocando; posso discernir o espa&#231;o f&#237;sico em seus ecos e resson&#226;ncias. Eu posso sentir o som, eu posso me mover no ritmo. A m&#250;sica engaja o meu corpo inteiro, minha imagina&#231;&#227;o inteira. As suas associa&#231;&#245;es com sons, m&#250;sica e tons que eu ouvi antes criam uma experi&#234;ncia temporal profunda, um sistema de rela&#231;&#245;es incorporadas entre eu e o passado. Visual? N&#243;s temos representa&#231;&#245;es visuais do passado h&#225; tanto tempo, que n&#243;s quase nos esquecemos dos aspectos art&#237;stico e performativo dessas gram&#225;ticas de express&#227;o.</p>
<p>Nesse tutorial, voc&#234; aprender&#225; a fazer um pouco de barulho a partir dos seus dados sobre o passado. O <emph>significado</emph> desse barulho, bem... isso depende de voc&#234;. Parte do objetivo desse tutorial &#233; te fazer estranhar os seus dados. Traduzindo-o, transcodificando-o, <link target="http://blog.taracopplestone.co.uk/making-things-photobashing-as-archaeological-remediation/">remediando-o</link> (em ingl&#234;s), n&#243;s come&#231;aremos a ver elementos dos dados que a nossa familiaridade com modelos visuais nos impediu de enxergar. Essa deforma&#231;&#227;o est&#225; de acordo com os argumentos apresentados por, por exemplo, Mark Sample sobre <link target="http://www.samplereality.com/2012/05/02/notes-towards-a-deformed-humanities/">quebrar coisas</link> (em ingl&#234;s), ou Bethany Nowviskie sobre a '<link target="http://nowviskie.org/2013/resistance-in-the-materials/">resist&#234;ncia nos materiais</link>' (em ingl&#234;s). Sonifica&#231;&#227;o nos move atrav&#233;s do continuum de dados para capta&#231;&#227;o, ci&#234;ncias sociais para arte, <link target="http://nooart.org/post/73353953758/temkin-glitchhumancomputerinteraction">falha para est&#233;tica</link> (em ingl&#234;s). Ent&#227;o vamos ver como isso tudo soa.</p>
<div type="2"><head>Objetivos</head>
<p>Nesse tutorial, apresentarei tr&#234;s maneiras diferentes de gerar som ou m&#250;sica a partir de seus dados.</p>
<p>Na primeira, usaremos um sistema desenvolvido por Jonathan Middleton, dispon&#237;vel gratuitamente para uso, chamado  <emph>Musicalgorithms</emph> (Algor&#237;tmos Musicais) a fim de introduzir algumas das quest&#245;es e termos-chaves envolvidos. Na segunda, usaremos uma pequena biblioteca do Python para 'mapear por par&#226;metro' os nossos dados contra o teclado de 88 teclas e introduzir um pouco de arte em nosso trabalho. Finalmente, aprenderemos como carregar nossos dados no ambiente de codifica&#231;&#227;o ao vivo de c&#243;digo aberto para som e m&#250;sica, <emph>Sonic Pi</emph>, momento em que te deixarei para que explore os abundantes tutoriais e recursos desse projeto.</p>
<p>Voc&#234; ver&#225; que "sonifica&#231;&#227;o" nos movimenta atrav&#233;s do espectro partindo de simples 'visualiza&#231;&#227;o/auraliza&#231;&#227;o' para performance real.  </p>
<div type="3"><head>Ferramentas</head>
<ul>
<li>Musicalgorithms <link target="http://musicalgorithms.org/">http://musicalgorithms.org/</link></li>
<li>MIDITime <link target="https://github.com/cirlabs/miditime">https://github.com/cirlabs/miditime</link> (Eu bifurquei uma c&#243;pia no GitHub <link target="https://github.com/shawngraham/miditime">aqui</link>)</li>
<li>Sonic Pi <link target="http://sonic-pi.net/">http://sonic-pi.net/</link></li>
</ul>
</div><div type="3"><head>Dados de Exemplo</head>
<ul>
<li><link target="/assets/sonification-roman-data.csv">Dados sobre artefatos romanos</link></li>
<li><link target="/assets/sonification-diary.csv">Excerto do modelo de t&#243;picos do di&#225;rio de John Adams</link></li>
<li><link target="/assets/sonification-jesuittopics.csv">Excerto do modelo de t&#243;picos das rela&#231;&#245;es jesu&#237;ticas</link></li>
</ul>
</div></div></div>
      <div type="1"><head>Um pouco de contexto sobre  sonifica&#231;&#227;o</head>
<p>Sonifica&#231;&#227;o &#233; a pr&#225;tica de mapear aspectos dos dados para produzir sinais sonoros. Em geral, uma t&#233;cnica pode ser chamada de "sonifica&#231;&#227;o" se cumprir certas condi&#231;&#245;es. Elas incluem reprodutibilidade (os mesmos dados podem ser transformados da mesma maneira por outros pesquisadores de forma que produzam os mesmos resultados) e o que pode ser chamado de inteligibilidade - que os elementos "objetivos" dos dados originais sejam sistematicamente refletidos no som resultante (veja <link target="http://www.icad.org/Proceedings/2008/Hermann2008.pdf">Hermann (2008)</link> (em ingl&#234;s) para uma taxonomia da sonifica&#231;&#227;o). <link target="https://www.researchgate.net/publication/282504359_Listen_to_the_Sound_of_Data">Last e Usyskin (2015)</link> (em ingl&#234;s) realizaram uma s&#233;rie de experimentos para determinar quais tarefas de an&#225;lise de dados poderiam ser performadas quando os dados eram sonificados.  Os seus resultados experimentais mostraram que mesmo um grupo de ouvintes n&#227;o-treinados (sem treinamento formal em m&#250;sica) podem fazer distin&#231;&#245;es &#250;teis nos dados. Eles encontraram ouvintes que conseguiam distinguir tarefas comuns de explora&#231;&#227;o de dados nos dados sonificados, como classifica&#231;&#227;o e agrupamento. Os seus resultados sonificados mapearam os dados fundamentais da escala musical ocidental.</p>
<p>Last e Usyskin focaram em dados de s&#233;ries temporais. Eles argumentam que dados de s&#233;ries temporais s&#227;o particularmente bons para sonifica&#231;&#227;o, pois h&#225; paralelos naturais com sons musicais. M&#250;sica &#233; sequencial, ela tem dura&#231;&#227;o e ela se desenvolve ao longo do tempo, assim como dados de s&#233;ries temporais. <link target="https://www.researchgate.net/publication/282504359_Listen_to_the_Sound_of_Data">(Last e Usyskin 2015, p. 424)</link>. Torna-se um problema combinar os dados com as sa&#237;das s&#244;nicas apropriadas. Em muitas aplica&#231;&#245;es de sonifica&#231;&#227;o, uma t&#233;cnica chamada "mapeamento de par&#226;metros" &#233; usada para combinar aspectos dos dados ao longo de v&#225;rias dimens&#245;es da audi&#231;&#227;o, como  <link target="#tom">tom</link>, varia&#231;&#227;o, brilho e in&#237;cio. O problema com esta abordagem &#233; que onde n&#227;o h&#225; rela&#231;&#227;o temporal (ou melhor, nenhuma rela&#231;&#227;o n&#227;o linear) entre os pontos de dados originais, o som resultante pode ser "confuso" (2015, p. 422).</p>
<h2>Escutando as lacunas</h2>
<p>H&#225; tamb&#233;m o modo que preenchemos as lacunas do som com as nossas expectativas. Considere esse v&#237;deo em que <link target="#mp3">mp3</link> foi convertido para <link target="#midi">MIDI</link> e  de volta para mp3; a  m&#250;sica foi 'achatada' para que todas as informa&#231;&#245;es sonoras sejam tocadas por apenas um instrumento. (Gerar esse efeito &#233; como salvar uma p&#225;gina da web como .txt, abri-la no Word e, ent&#227;o, salv&#225;-la novamente como .html). Todos os sons (inclusive vocais) foram traduzidos para os seus valores de nota correspondentes e, em seguida, transformados de volta em mp3.</p>
<p>&#201; barulhento, entretanto percebemos o significado. Considere o v&#237;deo abaixo:</p>
<iframe src="https://player.vimeo.com/video/149070596" width="640" height="360" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""/>
<p>O que est&#225; acontecendo aqui? Se j&#225; conhecia essa m&#250;sica, provavelmente ouviu as 'palavras'. No entanto, nenhuma palavra est&#225; presente na m&#250;sica! Se voc&#234; n&#227;o conhecia esse m&#250;sica, deve ter soado como um absurdo inaud&#237;vel (veja mais exemplos no website de <link target="http://waxy.org/2015/12/if_drake_was_born_a_piano/">Andy Baio</link>). Esse efeito &#233;, &#224;s vezes, chamado de 'alucina&#231;&#227;o auditiva' (cf. <link target="#Koebler">Koebler, 2015</link>). Esses exemplos mostram como qualquer representa&#231;&#227;o de dados que podemos ouvir/ver n&#227;o est&#225; l&#225;, estritamente falando. N&#243;s preenchemos as lacunas com as nossas pr&#243;prias expectativas.</p>
<p>Considere as implica&#231;&#245;es para a Hist&#243;ria. Se sonificarmos nossos dados e come&#231;armos a ouvir padr&#245;es no som, ou pontos fora da curva, nossas expectativas culturais sobre como a m&#250;sica funciona (nossas mem&#243;rias de fragmentos musicais semelhantes, ouvidos em contextos espec&#237;ficos) ir&#227;o colorir nossa interpreta&#231;&#227;o. Isso, eu argumentaria, &#233; verdadeiro para todas as representa&#231;&#245;es do passado, mas sonificar &#233; apenas estranho o suficiente em rela&#231;&#227;o aos nossos m&#233;todos regulares, de forma que essa autoconsci&#234;ncia nos ajudar&#225; a identificar ou comunicar os padr&#245;es cr&#237;ticos nos dados do passado.</p>
<p>Iremos progredir por meio de tr&#234;s ferramentas diferentes para sonifica&#231;&#227;o de dados, observando como as escolhas em uma ferramenta afetam o resultado e podem ser atenuadas imaginando novamente os dados por meio de outra ferramenta. No fim das contas, n&#227;o h&#225; nada mais objetivo em 'sonifica&#231;&#227;o' do que h&#225; em 'visualiza&#231;&#227;o', ent&#227;o quem pesquisa deve estar preparado para justificar as suas escolhas, e fazer escolhas transparentes e reprodut&#237;veis para outros. E para que n&#227;o pensemos que a sonifica&#231;&#227;o e a m&#250;sica gerada por algoritmos s&#227;o de alguma forma algo "novo", indico ao leitor interessado <link target="http://www.icad.org/Proceedings/2008/Hermann2008.pdf">Hedges, (1978)</link>.</p>
<p>Em cada se&#231;&#227;o, irei dar uma introdu&#231;&#227;o conceitual, seguida por um passo a passo usando dados arqueol&#243;gicos ou hist&#243;ricos de amostra.</p>
</div>
      <div type="1"><head>Musicalgorithms</head>
<p>H&#225; uma grande variedade de ferramentas para sonificar dados. Algumas, por exemplo, s&#227;o pacotes amplamente usadas do <link target="https://cran.r-project.org/">ambiente de estat&#237;stica R</link>, como &#8216;<link target="https://cran.r-project.org/web/packages/playitbyr/index.html">playitbyR</link>&#8217; e &#8216;<link target="https://cran.r-project.org/web/packages/audiolyzR/index.html">AudiolyzR</link>&#8217;. O primeiro desses pacotes, entretanto, n&#227;o tem sido mantido ou atualizado para as vers&#245;es atuais do R (sua &#250;ltima atualiza&#231;&#227;o foi muitos anos atr&#225;s) e o segundo precisa de um n&#250;mero consider&#225;vel de configura&#231;&#245;es adicionais de software para que funcione adequadamente.  </p>
<p>Por outro lado, o site <link target="http://musicalgorithms.org/">Musicalgorithms</link> &#233; bem f&#225;cil de usar. O site Musicalgorithms est&#225; online h&#225; mais de uma d&#233;cada. Embora n&#227;o seja c&#243;digo aberto, ele &#233; um projeto de pesquisa de longa-dura&#231;&#227;o em m&#250;sica computacional do seu criador, Jonathan Middleton. Ele est&#225; atualmente em sua terceira maior itera&#231;&#227;o (intera&#231;&#245;es anteriores permanecem dispon&#237;veis para uso online). Come&#231;aremos com o Musicalalgorithms porque ele nos permite entrar e ajustar os nossos dados para produzir um ficheiro de representa&#231;&#227;o MIDI. Tenha aten&#231;&#227;o e seleccione a '<link target="http://musicalgorithms.org/3.0/index.html">Vers&#227;o 3</link>'.</p>
<figure><desc>O site Musicalgorithms como aparecia em 2 de agosto de 2016</desc><graphic url="sonification-musicalgorithms-main-site-1.png"/></figure>
<blockquote>
<p>Nota da tradu&#231;&#227;o: h&#225; novas vers&#245;es dispon&#237;veis para uso, mas de forma a seguir o tutorial, seguimos a vers&#227;o 3 do Musicallgorithms, usada em 2016, e ainda dispon&#237;vel no site para uso.</p>
</blockquote>
<p>O Musicalgorithms efetua uma s&#233;rie de transforma&#231;&#245;es nos dados. Nos dados de amostra abaixo (o padr&#227;o do pr&#243;prio site), h&#225; apenas uma linha de dados, mesmo que pare&#231;a v&#225;rias linhas. Os dados de amostra s&#227;o compostos de campos separados por v&#237;rgula que s&#227;o delimitados por espa&#231;o.</p>
<pre><code xml:id="code_som-dados-sonificacao-historiadores_0" type="block" corresp="code_som-dados-sonificacao-historiadores_0.txt"/></pre>
<p>Esses dados representam os dados de origem e as suas transforma&#231;&#245;es; compartilhar esses dados permitiria a outro pesquisador replicar ou estender a sonifica&#231;&#227;o usando outras ferramentas. No entanto, quando se come&#231;a, apenas os dados b&#225;sicos abaixo s&#227;o necess&#225;rios (uma lista de pontos de dados):</p>
<pre><code xml:id="code_som-dados-sonificacao-historiadores_1" type="block" corresp="code_som-dados-sonificacao-historiadores_1.txt"/></pre>
<p>O campo-chave para n&#243;s &#233; &#8216;areaPitch1&#8217;, que cont&#233;m os dados de entrada delimitados por espa&#231;o. Os outros campos ser&#227;o preenchidos &#224; medida que avan&#231;amos pelas v&#225;rias configura&#231;&#245;es de Musicalgorithms. Nos dados acima (por exemplo, 24 72 12 84 etc.), os valores s&#227;o contagens brutas de inscri&#231;&#245;es de uma s&#233;rie de locais ao longo de uma estrada romana na Gr&#227;-Bretanha. (Vamos praticar com outros dados em breve, abaixo).</p>
<figure><desc>Depois de carregar seus dados, &#233; poss&#237;vel selecionar as diferentes opera&#231;&#245;es na barra de menu superior do site. Na captura de tela, o mouseover de informa&#231;&#245;es est&#225; explicando o que acontece com o dimensionamento de seus dados se voc&#234; selecionar a opera&#231;&#227;o de divis&#227;o para dimensionar os seus dados para o intervalo de notas selecionado.</desc><graphic url="sonification-musicalgorithms-pitch-mapping-2.png"/></figure>
<p>Agora, conforme se percorre as v&#225;rias guias da interface &#8216;duration input&#8217; (entrada de dura&#231;&#227;o) , &#8216;pitch mapping' (mapeamento de tom), &#8216;duration mapping&#8217; (mapeamento de dura&#231;&#227;o), &#8216;scale options&#8217; (op&#231;&#245;es de escala musical) &#233; poss&#237;vel realizar v&#225;rias transforma&#231;&#245;es.  Em &#8216;pitch mapping&#8217; (mapeamento de tom), h&#225; uma s&#233;rie de op&#231;&#245;es matem&#225;ticas para mapear os dados contra as 88 teclas/tons completos de um teclado de piano (em um mapeamento linear, a <emph>m&#233;dia</emph> dos dados de algu&#233;m seria mapeado para d&#243; m&#233;dio, ou 40). Tamb&#233;m &#233; poss&#237;vel escolher o tipo de escala, se &#233; um tom maior ou menor. Nesse ponto, uma vez que se tenha selecionado v&#225;rias transforma&#231;&#245;es, salve o ficheiro de texto. No menu 'play' &#233; poss&#237;vel realizar o download de um ficheiro MIDI. O seu programa de &#225;udio padr&#227;o pode tocar ficheiros MIDI (geralmente padronizando para um tom de piano). Uma instrumenta&#231;&#227;o mais complicada pode ser atribu&#237;da abrindo o ficheiro MIDI em programas de mixagem de m&#250;sica, como GarageBand (Mac) ou <link target="https://lmms.io/">LMMS</link> (Windows, Mac, Linux). (O uso do Garageband ou LMMS est&#225; fora do escopo desse tutorial. Um tutorial em v&#237;deo sobre LMMS est&#225; dispon&#237;vel <link target="https://youtu.be/4dYxV3tqTUc">aqui</link>, enquanto h&#225; muitos tutoriais do Garageband online. Lynda.com tem <link target="http://www.lynda.com/GarageBand-tutorials/Importing-audio-tracks/156620/164050-4.html">um tutorial excelente</link>).</p>
<p>Se tivesse v&#225;rias colunas de dados para os mesmos pontos - digamos, em nosso exemplo da Gr&#227;-Bretanha romana, tamb&#233;m quer&#237;amos sonificar contagens de um tipo de cer&#226;mica para essas mesmas cidades - &#233; poss&#237;vel recarregar sua pr&#243;xima s&#233;rie de dados, efetuar as transforma&#231;&#245;es e mapeamentos, e gerar outro ficheiro MIDI. Como o Garageband e o LMMS permitem a sobreposi&#231;&#227;o de vozes, voc&#234; pode come&#231;ar a criar sequ&#234;ncias musicais complicadas.</p>
<figure><desc>Captura de tela do Garageband, onde os ficheiros MIDI s&#227;o t&#243;picos sonorizados do Di&#225;rio de John Adams. Na interface do Garageband (o LMMS &#233; semelhante), cada ficheiro MIDI &#233; arrastado e solto no lugar. A instrumenta&#231;&#227;o para cada ficheiro MIDI (ou seja, trilha) pode ser selecionada nos menus do Garageband. Os r&#243;tulos de cada faixa foram alterados aqui para refletir as palavras-chave em cada t&#243;pico. A &#225;rea verde &#224; direita representa uma visualiza&#231;&#227;o das notas em cada faixa. Voc&#234; pode ver esta interface em a&#231;&#227;o e ouvir a m&#250;sica [aqui](https://youtu.be/ikqRXtI3JeA) (em ingl&#234;s)</desc><graphic url="sonification-garageband-john-adams-3.png"/></figure>
<p>Quais transforma&#231;&#245;es devem ser usadas? Se tiver duas colunas de dados, ter&#225; duas vozes. Pode fazer sentido, em nossos dados hipot&#233;ticos, tocar a primeira voz bem alto, em uma tonalidade maior: as inscri&#231;&#245;es 'falam' conosco, afinal de contas. (As inscri&#231;&#245;es romanas de fato se dirigem ao leitor, o transeunte, literalmente: '&#211; tu que passas ...'). Ent&#227;o, se acaso as cer&#226;micas de interesse forem mercadorias mais despretensiosas, talvez elas possam ser mapeadas em rela&#231;&#227;o &#224; extremidade inferior da escala ou receberem notas de dura&#231;&#227;o mais longas para representar sua onipresen&#231;a nas classes nessa regi&#227;o.</p>
<p><emph>N&#227;o h&#225; forma 'certa' de representar os seus dados como som, ao menos n&#227;o por enquanto</emph>, mas mesmo com essa amostra de exemplo, come&#231;amos a ver como sombras de significado e interpreta&#231;&#227;o podem ser atribu&#237;das aos nossos dados e &#224; nossa experi&#234;ncia dos dados.  </p>
<p>Mas e o tempo? Dados hist&#243;ricos usualmente t&#234;m um ponto de inflex&#227;o, um distinto "tempo quando" algo aconteceu. Ent&#227;o, a quantidade de tempo entre dois pontos de dados precisa ser considerada. &#201; nesse ponto que a nossa pr&#243;xima ferramenta se torna bem &#250;til, para quando nossos pontos de dados tiverem uma rela&#231;&#227;o com outro espa&#231;o temporal. Come&#231;amos a nos mover de sonifica&#231;&#227;o (pontos de dados) para m&#250;sica (rela&#231;&#245;es entre pontos).</p>
<h3>Pr&#225;tica</h3>
<p>O <link target="/assets/sonification-roman-data.csv">conjunto de dados de amostra</link> apresentado cont&#233;m a contagem de moedas romanas na sua primeira coluna e a contagem de materiais romanos dos mesmos locais, conforme contido no banco de dados do Portable Antiquities Scheme (Esquema de Antiguidades Port&#225;veis) do British Museum. A sonifica&#231;&#227;o desses dados pode revelar ou acentuar aspectos da situa&#231;&#227;o econ&#244;mica ao longo da rua Watling, uma grande rota atrav&#233;s da Brit&#226;nia Romana. Esses pontos de dados est&#227;o organizados geograficamente do Noroeste ao Sudeste; ent&#227;o, na medida em que o som toca, n&#243;s estamos escutando movimento atrav&#233;s do espa&#231;o. Cada nota representa outro passo no caminho.</p>
<ol>
<li>Abra o <link target="/assets/sonification-roman-data.csv">dados-sonifica&#231;&#227;o-romana.csv</link> em uma tabela. Copie a primeira coluna em um editor de texto. Delete os finais das linhas de forma que os dados fiquem todos em uma linha &#250;nica.</li>
<li>Adicione a seguinte informa&#231;&#227;o de coluna assim:</li>
</ol>
<pre><code xml:id="code_som-dados-sonificacao-historiadores_2" type="block" corresp="code_som-dados-sonificacao-historiadores_2.txt"/></pre>
<p>...para que os seus dados sigam imediatamente depois da &#250;ltima v&#237;rgula (como <link target="/assets/sonification-romancoin-data-music.csv">esse exemplo</link>). Salve o ficheiro com um nome &#250;til como <code type="inline">sonsdasmoedas1.csv</code>.</p>
<ol start="3">
<li>Acesse o site do <link target="http://musicalgorithms.org/3.0/index.html">Musicalgorithms</link> (vers&#227;o 3) e clique no bot&#227;o "load" (carregar). No pop-up, clique no bot&#227;o azul "load" (carregar) e selecione o ficheiro salvo no passo 2. O site carregar&#225; os seus materiais e exibir&#225; uma marca de sele&#231;&#227;o verde se tiver sido carregado com &#234;xito. Caso contr&#225;rio, certifique-se de que os seus valores estejam separados por espa&#231;os e que sigam imediatamente a &#250;ltima v&#237;rgula no bloco de c&#243;digo na etapa 2. Tamb&#233;m &#233; poss&#237;vel tentar carregar o <link target="/assets/sonification-romancoin-data-music.csv">ficheiro de demonstra&#231;&#227;o desse tutorial</link> ao inv&#233;s.</li>
</ol>
<figure><desc>Clique em 'load' na tela principal para acessar essa caixa de di&#225;logo. Ent&#227;o 'load csv'. (carregue o csv) Selecione o ficheiro; ele aparecer&#225; na caixa. Ent&#227;o clique no bot&#227;o 'load' (carregar).</desc><graphic url="sonification-musicalgorithms-upload-4.png"/></figure>
<ol start="4">
<li>
<p>Clique em 'Pitch Input'. Os valores dos seus dados ser&#227;o exibidos. Por enquanto,  <hi rend="bold">n&#227;o selecione</hi> nenhuma outra op&#231;&#227;o nesse p&#225;gina (consequentemente, usaremos os valores padr&#227;o do site).  </p>
</li>
<li>
<p>Clique em 'Duration Input'. <hi rend="bold">N&#227;o selecione nenhuma op&#231;&#227;o aqui por enquanto</hi>. As op&#231;&#245;es aqui ir&#227;o mapear v&#225;rias transforma&#231;&#245;es em rela&#231;&#227;o aos dados que alterar&#227;o a dura&#231;&#227;o para cada nota. N&#227;o se preocupe com as op&#231;&#245;es por enquanto: siga adiante.  </p>
</li>
<li>
<p>Clique em 'Pitch Mapping'. Essa &#233; a escolha mais crucial, pois ir&#225; transformar (isso &#233;, escalar) os seus dados brutos para um mapeamento em rela&#231;&#227;o &#224;s teclas do teclado. Deixe a configura&#231;&#227;o de <code type="inline">mapping</code> em 'division'.  (As outras op&#231;&#245;es s&#227;o m&#243;dulo e logar&#237;tmico). A op&#231;&#227;o <code type="inline">Range</code> 1 a 88 usa todas as 88 teclas do teclado, assim, seu valor mais baixo estaria de acordo com a nota mais profunda do piano e seu valor mais alto com a nota mais alta. Em vez disso, voc&#234; pode restringir sua m&#250;sica em torno de d&#243; m&#233;dio, ent&#227;o insira 25 a 60 como seu intervalo. O resultado deveria mudar para: <code type="inline">31,34,34,34,25,28,30,60,28,25,26,26,25,25,60,25,25,38,33,26,25,25,25</code> Essas n&#227;o s&#227;o mais suas contagens; s&#227;o as notas do teclado.</p>
</li>
</ol>
<figure><desc>Clique na caixa 'range' e defina-o para 25. Os valores abaixo ser&#227;o alterados automaticamente. Clique na caixa 'to' e defina-o para 60. Clique novamente na outra caixa; os valores ser&#227;o atualizados.</desc><graphic url="sonification-musicalgorithms-settings-for-pitch-mapping-5.png"/></figure>
<ol start="8">
<li>Clique em 'Duration Mapping'. Como Pitch Mapping, isso pega o intervalo de tempo especificado e usa v&#225;rias op&#231;&#245;es matem&#225;ticas para mapear o intervalo de possibilidade contra as suas notas. Se passar o seu cursor por cima de <code type="inline">i</code> ver&#225; como os n&#250;meros correspondem com notas inteiras, sem&#237;nimas, colcheias e assim por diante. Deixe os valores padr&#227;o por enquanto.</li>
<li>Clique em 'Scale Options'. Aqui n&#243;s podemos come&#231;ar a selecionar o que pode ser chamado de aspecto 'emocional' do som. N&#243;s geralmente pensamos que escalas maiores s&#227;o 'alegres' enquanto escalas menores s&#227;o 'tristes'; para uma discuss&#227;o acess&#237;vel acesse esse <link target="http://www.ethanhein.com/wp/2010/scales-and-emotions/">post de blog</link> (em ingl&#234;s). Por enquanto, escolha 'scale by: major' (escala maior). Deixe a 'scale' (escala) como <code type="inline">C</code>.</li>
</ol>
<p>Agora sonificamos uma coluna de dados! Clique no bot&#227;o 'save' (salvar), ent&#227;o 'save csv' (salvar csv).</p>
<figure><desc>A caixa de di&#225;logo salvar dados.</desc><graphic url="sonification-musicalgorithms-save-6.png"/></figure>
Haver&#225; um ficheiro que se parecer&#225; com isso:
<pre><code xml:id="code_som-dados-sonificacao-historiadores_3" type="block" corresp="code_som-dados-sonificacao-historiadores_3.txt"/></pre>
<p>&#201; poss&#237;vel ver os dados originais no campo 'areaPitch1' e os subsequentes mapeamentos. O site permite que sejam geradas at&#233; quatro vozes por vez em um ficheiro MIDI; dependendo de como se quer adicionar instrumenta&#231;&#227;o depois, pode-se querer gerar um ficheiro MIDI por vez. Vamos tocar a m&#250;sica - clique em 'Play'. &#201; poss&#237;vel selecionar o tempo aqui, e um instrumento. &#201; poss&#237;vel ouvir os seus dados no navegador, ou salv&#225;-los como um ficheiro MIDI clicando no bot&#227;o azul 'Save MIDI file'.</p>
<p>Retorne ao come&#231;o e carregue as duas colunas de dados nesse modelo:</p>
<pre><code xml:id="code_som-dados-sonificacao-historiadores_4" type="block" corresp="code_som-dados-sonificacao-historiadores_4.txt"/></pre>
<figure><desc>Coloque 2 na caixa de vozes no topo da interface. Quando voc&#234; for para qualquer uma das p&#225;ginas de op&#231;&#227;o - aqui, n&#243;s estamos em 'pitch input' - dois monitores abrem para mostrar os dados das duas vozes. Carregue os seus dados do csv como antes, mas formate o seu csv para ter o 'areaPitch1' e o 'areaPitch2' como descrito no texto principal. Os dados para a primeira voz ir&#227;o aparecer na esquerda, e a segunda voz na direita.</desc><graphic url="sonification-2voices-7.png"/></figure>
<p>Quando se tem dados com v&#225;rias vozes, o que se destaca? Observe que, nessa abordagem, a dist&#226;ncia entre os pontos no mundo real n&#227;o &#233; considerada em nossa sonifica&#231;&#227;o. Essa dist&#226;ncia, se fosse considerada, poderia ser crucial. A dist&#226;ncia, &#233; claro, n&#227;o precisa ser geogr&#225;fica - pode ser temporal. A pr&#243;xima ferramenta que exploraremos nos permite abordar isso em nossa sonifica&#231;&#227;o explicitamente.</p>
</div>
      <div type="1"><head>Algumas palavras sobre configurar o Python</head>
<p>A pr&#243;xima se&#231;&#227;o desse tutorial precisa de Python. Se n&#227;o usou Python ainda, ser&#225; preciso passar algum tempo <link target="/en/lessons/intro-to-bash">se familiarizando com a linha de comando (PC) ou terminal (OS)</link> (em ingl&#234;s). Voc&#234; pode achar esse r&#225;pido <link target="/pt/licoes/instalacao-modulos-python-pip">guia de instala&#231;&#227;o dos m&#243;dulos do python</link> &#250;til (mas retorne para ele depois de ler o resto da se&#231;&#227;o).</p>
<p>Usu&#225;rios do Mac j&#225; possuir&#227;o o Python instalado na m&#225;quina deles. &#201; poss&#237;vel testar isso apertando o bot&#227;o COMMAND e a barra de espa&#231;o; na janela de pesquisa, digite <code type="inline">terminal</code> e clique na aplica&#231;&#227;o do terminal. No prompt de comando, por exemplo, no cursor piscando em <code type="inline">$</code> digite <code type="inline">python --version</code> e o computador responder&#225; com a vers&#227;o do python existente no seu computador. <emph>A pr&#243;xima se&#231;&#227;o desse tutorial usa a vers&#227;o Python 2.7; ela n&#227;o foi testada em Python 3</emph>.  </p>
<p>Para usu&#225;rios do Windows, Python n&#227;o &#233; instalado por padr&#227;o na sua m&#225;quina ent&#227;o <link target="http://docs.python-guide.org/en/latest/starting/install/win/">essa p&#225;gina</link> te ajudar&#225; a iniciar, apesar das coisas serem um pouco mais complicadas do que parece de acordo com a p&#225;gina (nota de tradu&#231;&#227;o: pode usar tamb&#233;m a <link target="/pt/licoes/introducao-instalacao-python">li&#231;&#227;o de instala&#231;&#227;o do Python</link> do <emph>Programming Historian em portugu&#234;s</emph>, mas tenha em aten&#231;&#227;o que nessa li&#231;&#227;o &#233; instalada a vers&#227;o 3 do Python). Primeiro, realize o download do ficheiro <code type="inline">.msi</code> que a p&#225;gina recomenda (Python 2.7). Clique duas vezes no ficheiro e ele deve se instalar em um novo diret&#243;rio, por exemplo, <code type="inline">C:\Python27\</code>. Ent&#227;o, n&#243;s temos de dizer para o Windows a localiza&#231;&#227;o para onde buscar pelo Python sempre que um programa em python for executado; ou seja, colocaremos a localiza&#231;&#227;o do diret&#243;rio no seu 'path', ou a vari&#225;vel do ambiente que o Windows sempre apresenta quando confrontado com um novo comando. Existem algumas formas de fazer isso, mas talvez a mais f&#225;cil seja buscar no seu computador pelo programa <code type="inline">Powershell</code> (digite 'powershell' na janela de pesquisa do seu computador). Abra o Powershell e, no <code type="inline">&gt;</code> prompt, copie essa linha inteira:</p>
<p><code type="inline">[Environment]::SetEnvironmentVariable("Path", "$env:Path;C:\Python27\;C:\Python27\Scripts\", "User")</code></p>
<p>Feche o powershell quando terminar. Voc&#234; saber&#225; que funcionou se nada acontecer quando clicar em 'enter'. Para testar se tudo est&#225; funcionando, abra o prompt de comando (aqui h&#225; <link target="http://www.howtogeek.com/235101/10-ways-to-open-the-command-prompt-in-windows-10/">10 forma de fazer isso</link>) (em ingl&#234;s) e digite no prompt <code type="inline">&gt;</code>, <code type="inline">python --version</code>. Ele deve retornar <code type="inline">Python 2.7.10</code> ou algo similar.</p>
<p>A &#250;ltima pe&#231;a do quebra-cabe&#231;a que todos os usu&#225;rios precisar&#227;o &#233; um programa chamado <code type="inline">Pip</code>. Os usu&#225;rios de Mac podem instal&#225;-lo digitando no terminal: :<code type="inline">sudo easy_install pip</code>. Usu&#225;rios do Windows ter&#227;o um pouco mais de dificuldade (nota de tradu&#231;&#227;o: pode usar tamb&#233;m a <link target="/pt/licoes/instalacao-modulos-python-pip">li&#231;&#227;o de instala&#231;&#227;o de m&#243;dulos Python com pip</link> do <emph>Programming Historian em portugu&#234;s</emph>, mas tenha em aten&#231;&#227;o que nessa li&#231;&#227;o &#233; usada a vers&#227;o 3 do Python). Primeiro, clique no bot&#227;o direito do seu cursor e salve esse link: <link target="https://bootstrap.pypa.io/get-pip.py">https://bootstrap.pypa.io/get-pip.py</link> (Se apenas clicar no link, ele ir&#225; te mostrar o c&#243;digo no seu navegador). Salve em algum lugar &#250;til. Abra o prompt de comando no diret&#243;rio em que salvou <code type="inline">get-pip.py</code>. Ent&#227;o, digite no prompt de comando, <code type="inline">python get-pip.py</code>. Convencionalmente, nos tutoriais, ver&#225; <code type="inline">&gt;</code> ou <code type="inline">$</code> em lugares em que &#233; preciso digitar algo no prompt de comando ou no terminal. Nunca &#233; necess&#225;rio digitar esses dois caracteres.</p>
<p>Finalmente, quando voc&#234; tem um c&#243;digo python que deseja executar, pode inseri-lo em seu editor de texto e salv&#225;-lo com a extens&#227;o <code type="inline">.py</code> (nota de tradu&#231;&#227;o: pode tamb&#233;m seguir as indica&#231;&#245;es das li&#231;&#245;es &#8220;Configurar um ambiente de desenvolvimento integrado para Python&#8221;, do <emph>Programming Historian em portugu&#234;s</emph>, nas suas vers&#245;es <link target="/pt/licoes/instalacao-windows">Windows</link> ou <link target="/pt/licoes/instalacao-mac">Mac</link>, mas tenha em aten&#231;&#227;o que nessas li&#231;&#245;es &#233; usada a vers&#227;o 3 do Python). O seu ficheiro &#233; um ficheiro de texto, mas a <hi rend="bold">extens&#227;o</hi> do ficheiro diz para o seu computador para usar o Python para interpret&#225;-lo; mas lembre, digite <code type="inline">python</code> no prompt primeiro, por exemplo: <code type="inline">$ python meu-script-legal.py</code>.</p>
</div>
      <div type="1"><head>MIDITime</head>
<p>MIDITime &#233; um pacote do python desenvolvido por <link target="https://www.revealnews.org/">Reveal News (antes, Centro de Reportagens Investigativas)</link>. O seu <link target="https://github.com/cirlabs/miditime">reposit&#243;rio no Github est&#225; aqui</link>. Miditime foi constru&#237;do explicitamente para dados de s&#233;ries temporais (ou seja, uma sequencia de observa&#231;&#245;es coletadas ao longo do tempo).</p>
<p>Enquanto a ferramenta Musicalgorithms tem uma interface mais ou menos intuitiva, quem pesquisa sacrifica a possibilidade de saber o que, exatamente, est&#225; acontecendo internamente.
Em princ&#237;pio, algu&#233;m poderia examinar o c&#243;digo subjacente para o pacote MIDITime para saber o que est&#225; acontecendo. Mais importante ainda, na ferramenta anterior n&#227;o h&#225; nenhuma habilidade de contabilizar os dados em que os pontos est&#227;o distantes uns dos outros no tempo do rel&#243;gio. MIDITime nos permite considerar que os nossos dados podem ser agrupados pelo tempo.</p>
<p>Vamos supor que voc&#234; tenha um di&#225;rio hist&#243;rico no qual voc&#234; encaixou um <link target="/en/lessons/topic-modeling-and-mallet">modelo de t&#243;picos</link>. A sa&#237;da resultante pode ter entradas de di&#225;rio como linhas, e a composi&#231;&#227;o percentual de cada t&#243;pico contribui para essa entrada como colunas. Nesse caso, <emph>ouvir</emph> esses valores pode te ajudar a entender os padr&#245;es de pensamento no di&#225;rio de uma forma que a visualiza&#231;&#227;o como um gr&#225;fico pode n&#227;o permitir. Outliers ou padr&#245;es musicais recorrentes poderiam se destacar ao serem ouvidos de um modo  que a gram&#225;tica dos gr&#225;ficos obscurece.  </p>
<h3>Instalando o MIDITime</h3>
<p>Instalar MIDItime &#233; simples com o <link target="/pt/licoes/instalacao-modulos-python-pip">pip</link>:</p>
<p><code type="inline">$ pip install miditime</code> ou <code type="inline">$ sudo pip install miditime</code> para uma m&#225;quina Mac ou Linux ;
<code type="inline">&gt; pip install miditime</code> em uma m&#225;quina Windows. (Usu&#225;rios Windows, se as instru&#231;&#245;es acima n&#227;o funcionaram muito bem, talvez queira tentar <link target="https://sites.google.com/site/pydatalog/python/pip-for-windows">esse programa de ajuda</link> para fazer o Pip funcionar adequadamente na sua m&#225;quina ou ent&#227;o seguir as instru&#231;&#245;es da <link target="/pt/licoes/instalacao-modulos-python-pip">li&#231;&#227;o sobre pip</link> do <emph>Programming Historian em portugu&#234;s</emph>).</p>
<h3>Pr&#225;tica</h3>
<p>Vamos olhar para o exemplo de script providenciado. Abra o seu editor de texto, e copie e cole o script de exemplo em:</p>
<pre><code class="language-python" xml:id="code_som-dados-sonificacao-historiadores_5" type="block" corresp="code_som-dados-sonificacao-historiadores_5.txt"/></pre>
<p>Salve o script como <code type="inline">musica1.py</code>. No seu terminal ou prompt de comando, execute o script:</p>
<p><code type="inline">$ python musica1.py</code></p>
<p>O novo ficheiro, <code type="inline">meuficheiro.mid</code> ser&#225; registrado no seu diret&#243;rio. Para ouvir esse ficheiro, &#233; poss&#237;vel abri-lo com  Quicktime ou Windows Media Player. (&#201; poss&#237;vel adicionar instrumenta&#231;&#227;o abrindo o ficheiro no Garageband ou <link target="https://lmms.io/">LMMS</link>).</p>
<p><code type="inline">Musica1.py</code> importa miditime (lembre, &#233; preciso realizar o <code type="inline">pip install miditime</code> antes de executar o script). Ent&#227;o, ele cria um ficheiro resultante de destina&#231;&#227;o e configura o tempo. Todas as notas s&#227;o listadas individualmente, onde o primeiro n&#250;mero &#233; o tempo em que a nota deve ser tocada, o tom da nota (ou seja, a nota de fato!), o qu&#227;o forte ou ritmicamente a nota &#233; atingida (o ataque), e a dura&#231;&#227;o da nota. As notas musicais s&#227;o ent&#227;o registradas na faixa e a faixa &#233; registrada no <code type="inline">myfile.mid</code>.</p>
<p>Agora, execute o script e adicione mais notas. As notas para a 'A barata diz que tem' s&#227;o:</p>
<pre><code xml:id="code_som-dados-sonificacao-historiadores_6" type="block" corresp="code_som-dados-sonificacao-historiadores_6.txt"/></pre>
<p>Voc&#234; consegue fazer o seu computador tocar essa m&#250;sica? (Esse <link target="http://www.electronics.dit.ie/staff/tscarff/Music_technology/midi/midi_note_numbers_for_octaves.html">material</link> (em ingl&#234;s) ir&#225; ajudar).</p>
<p><hi rend="bold">A prop&#243;sito</hi>, h&#225; uma especifica&#231;&#227;o de ficheiro de texto para descrever m&#250;sica chamado <link target="https://pt.wikipedia.org/wiki/ABC_(nota%C3%A7%C3%A3o_musical)">Nota&#231;&#227;o ABC</link>. Por enquanto, est&#225; al&#233;m de nossa compreens&#227;o, mas algu&#233;m poderia escrever um script de sonifica&#231;&#227;o em, por exemplo, uma planilha, mapeando valores para nomes de notas na especifica&#231;&#227;o ABC (se voc&#234; j&#225; usou um IF - THEN no Excel para converter notas percentuais em notas alfab&#233;ticas, ter&#225; uma no&#231;&#227;o de como isso pode ser feito) e ent&#227;o usando um site como <link target="http://trillian.mit.edu/~jc/music/abc/ABCcontrib.html">esse</link> (em ingl&#234;s) para converter a nota&#231;&#227;o ABC em um ficheiro .mid.</p>
<h3>Inserindo os seus pr&#243;prios dados</h3>
<p><link target="/assets/sonification-diary.csv">Esse ficheiro</link> &#233; uma sele&#231;&#227;o do modelo de t&#243;picos dos Di&#225;rios de John Adams do <link target="http://themacroscope.org">The Macroscope</link> (Explorando Grandes Dados Hist&#243;ricos: O Macrosc&#243;pico do Historiador). Apenas os sinais mais fortes foram preservados atrav&#233;s do arredondamento dos valores nas colunas para duas casas decimais (lembrando que 0.25, por exemplo, indica que aquele t&#243;pico est&#225; contribuindo para um quarto da composi&#231;&#227;o daquela entrada do di&#225;rio). Para obter esses dados em seu script de Python, eles devem ser formatados de uma maneira espec&#237;fica. A parte complicada &#233; acertar o campo de data.</p>
<p><emph>Para os prop&#243;sitos desse tutorial, n&#243;s iremos deixar os nomes das vari&#225;veis sem altera&#231;&#245;es em rela&#231;&#227;o ao script de amostra. O script de amostra foi desenvolvido com dados de um terremoto em mente; ent&#227;o onde diz 'magnitude' podemos pensar como '% composi&#231;&#227;o do t&#243;pico.'</emph></p>
<pre><code xml:id="code_som-dados-sonificacao-historiadores_7" type="block" corresp="code_som-dados-sonificacao-historiadores_7.txt"/></pre>
<p>Algu&#233;m poderia abordar o problema de obter os nossos dados no formato usando express&#245;es regulares; pode ser mais f&#225;cil abrir o modelo de t&#243;picos em uma tabela. Copie os t&#243;picos de dados em uma nova planilha, e deixe as colunas na esquerda e na direita dos dados. No exemplo abaixo, eu coloquei na coluna D e, ent&#227;o, preenchi o resto dos dados ao redor dela, assim:</p>
<table>
<thead>
<tr>
<th/>
<th>A</th>
<th>B</th>
<th>C</th>
<th>D</th>
<th>E</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>{'data_evento': datetime</td>
<td>(1753,6,8)</td>
<td>, 'magnitude':</td>
<td>0.0024499630</td>
<td>},</td>
</tr>
<tr>
<td>2</td>
<td/>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>3</td>
<td/>
<td/>
<td/>
<td/>
<td/>
</tr>
</tbody></table><p>Ent&#227;o copie e cole os elementos que n&#227;o mudaram para preencher a coluna inteira. O elemento de data tem de ser (ano, m&#234;s, dia). Uma vez que preencheu a tabela, copie e cole no seu editor de texto de forma que se torne parte do arranjo <code type="inline">meus_dados</code>, como:</p>
<p>Nota da tradu&#231;&#227;o: note que a ordem do <emph>datetime</emph> segue o padr&#227;o em ingl&#234;s estadunidense.</p>
<pre><code xml:id="code_som-dados-sonificacao-historiadores_8" type="block" corresp="code_som-dados-sonificacao-historiadores_8.txt"/></pre>
<p>Note que a &#250;ltima linha n&#227;o tem uma v&#237;rgula no seu fim.</p>
<p>O seu script final ser&#225; similar a essa, usando o exemplo da p&#225;gina do Miditime (as se&#231;&#245;es de c&#243;digo abaixo foram interrompidas pelos coment&#225;rios, mas devem ser coladas no seu editor de texto como um ficheiro &#250;nico):</p>
<pre><code class="language-python" xml:id="code_som-dados-sonificacao-historiadores_9" type="block" corresp="code_som-dados-sonificacao-historiadores_9.txt"/></pre>
<p>Os valores ap&#243;s MIDITime, <code type="inline">MIDITime(108, 'johnadams1.mid', 3, 4, 1)</code> configuram</p>
<ul>
<li>as batidas por minuto (108),</li>
<li>o ficheiro resultante ('johnadams1.mid'),</li>
<li>o n&#250;mero de segundos para representar o ano na m&#250;sica (3 segundos no calend&#225;rio anual, ent&#227;o todas as notas para as entradas desse di&#225;rio de 1753 ser&#227;o escaladas contra 3 segundos; h&#225; 50 anos nos dados, ent&#227;o a m&#250;sica final ter&#225; dura&#231;&#227;o de 50 x 3, ou um pouco mais de dois minutos),</li>
<li>a oitava base para a m&#250;sica (C m&#233;dio &#233; convencionalmente representado como C5, ent&#227;o aqui 4 representa uma oitava abaixo do C m&#233;dio),</li>
<li>o n&#186; de oitavas em que os tons s&#227;o mapeados.</li>
</ul>
<p>Agora passamos os seus dados para o script inserindo-o no arranjo <code type="inline">meus_dados</code> (isso ser&#225; colado em seguida):</p>
<pre><code class="language-python" xml:id="code_som-dados-sonificacao-historiadores_10" type="block" corresp="code_som-dados-sonificacao-historiadores_10.txt"/></pre>
<p>...tenha os seus dados aqui, lembrando-se de terminar a linha final data_evento  <hi rend="bold">sem</hi> uma v&#237;rgula, e finalizando os dados com um <code type="inline">]</code> na sua pr&#243;pria linha, por exemplo</p>
<pre><code class="language-python" xml:id="code_som-dados-sonificacao-historiadores_11" type="block" corresp="code_som-dados-sonificacao-historiadores_11.txt"/></pre>
<p>e ent&#227;o copie:</p>
<pre><code class="language-python" xml:id="code_som-dados-sonificacao-historiadores_12" type="block" corresp="code_som-dados-sonificacao-historiadores_12.txt"/></pre>
<p>Esta parte calcula o tempo entre as diferentes entradas do di&#225;rio; di&#225;rios que est&#227;o pr&#243;ximos no tempo ter&#227;o, portanto, suas notas soando mais pr&#243;ximas. Finalmente, n&#243;s definimos como os dados ser&#227;o mapeados em rela&#231;&#227;o ao tom. Lembre-se que os nossos dados s&#227;o porcentagens variando de 0.01 (ou seja, 1%) a 0.99 (99%), em <code type="inline">escala_pct</code> entre 0 e 1. Se n&#227;o estiver lidando com porcentagens, seria usado o menor valor e o maior valor (se, por exemplo, os seus dados fossem contagens de algum elemento de interesse, como nos dados arqueol&#243;gicos usados anteriormente). Ent&#227;o, n&#243;s colamos:</p>
<pre><code class="language-python" xml:id="code_som-dados-sonificacao-historiadores_13" type="block" corresp="code_som-dados-sonificacao-historiadores_13.txt"/></pre>
<p>e ent&#227;o cole nessa parte final do c&#243;digo para escrever os seus valores de som no ficheiro:</p>
<pre><code xml:id="code_som-dados-sonificacao-historiadores_14" type="block" corresp="code_som-dados-sonificacao-historiadores_14.txt"/></pre>
<p>Salve esse ficheiro com um novo nome e a extens&#227;o de ficheiro <code type="inline">.py</code>.</p>
<p>Para cada coluna de dados nos seus dados originais, <hi rend="bold">tenha um script &#250;nico e lembre-se de mudar o nome do ficheiro de sa&#237;da</hi>, pois, caso contr&#225;rio, voc&#234; ir&#225; sobrescrever seus dados. Ent&#227;o, voc&#234; pode carregar os ficheiros individuais midi no Garageband ou LMMS para instrumenta&#231;&#227;o. Aqui est&#225; a &#237;ntegra do <link target="https://www.youtube.com/watch?v=ikqRXtI3JeA">Di&#225;rio de John Adams</link>.</p>
</div>
      <div type="1"><head>Sonic Pi</head>
<p>Harmonizar ficheiros MIDI &#250;nicos (no Garageband ou em algum outro programa de composi&#231;&#227;o musical) nos leva de sonifica&#231;&#227;o para composi&#231;&#227;o e arte sonora. Nessa se&#231;&#227;o final, n&#227;o ser&#225; oferecido um tutorial completo sobre como usar o <link target="http://sonic-pi.net">Sonic Pi</link>, mas um direcionamento para um ambiente que permite a performance da codifica&#231;&#227;o dos seus dados ao vivo (veja <link target="https://www.youtube.com/watch?v=oW-3HVOeUQA">esse v&#237;deo</link> para uma performance ao vivo real de codifica&#231;&#227;o). Os tutoriais do pr&#243;prio Sonic Pi's mostrar&#227;o o potencial do uso do computador como um instrumento musical (em que voc&#234; digita c&#243;digo em Ruby no editor interno enquanto o interpretador toca o que est&#225; sendo codificado).</p>
<p>Por que algu&#233;m iria querer fazer isso? Como progressivamente ficou evidente no tutorial, quando os seus dados s&#227;o sonificados, escolhas passam a ser feitas sobre como mapear os dados em som, e essas escolhas refletem impl&#237;cita ou explicitamente decis&#245;es sobre quais dados importam. Existe um <emph>continuum</emph> de 'objetividade', se quiser. Em uma extremidade, uma sonifica&#231;&#227;o que apoia uma discuss&#227;o sobre o passado; do outro, uma apresenta&#231;&#227;o sobre o passado t&#227;o fascinante e pessoal quanto qualquer palestra p&#250;blica bem-feita. A sonifica&#231;&#227;o tira nossos dados das p&#225;ginas e os leva aos ouvidos de nossos ouvintes: &#233; uma esp&#233;cie de hist&#243;ria p&#250;blica. Apresentando nossos dados ... imagine s&#243;!</p>
<p>Aqui, eu ofere&#231;o simplesmente um trecho de c&#243;digo que possibilitar&#225; a importa&#231;&#227;o dos seus dados, que aqui s&#227;o simplesmente uma lista de valores salvos como csv. Estou em d&#237;vida com a bibliotec&#225;ria da George Washington University, Laura Wrubel, que postou em <link target="https://gist.github.com/lwrubel">gist.github.com</link> os experimentos dela de sonifica&#231;&#227;o das transa&#231;&#245;es de circula&#231;&#227;o de sua biblioteca.</p>
<p>Nesse <link target="/assets/sonification-jesuittopics.csv">ficheiro de amostra</link> (um modelo de t&#243;picos gerado do <link target="http://puffin.creighton.edu/jesuit/relations/">Jesuit Relations</link>, (Rela&#231;&#245;es Jesu&#237;tas)), h&#225; dois t&#243;picos. A primeira linha contem os cabe&#231;alhos: topic1 (em PT-BR, t&#243;pico1), topic2 (em PT-BR, t&#243;pico2).</p>
<h3>Pr&#225;tica</h3>
<p>Siga os tutoriais iniciais que o Sonic Pi oferece at&#233; se sentir confort&#225;vel com a interface e algumas das suas possibilidades. (Esses tutoriais tamb&#233;m est&#227;o agrupados <link target="https://gist.github.com/jwinder/e59be201082cca694df9">aqui</link>; tamb&#233;m &#233; poss&#237;vel escutar uma entrevista com Sam Aaron, o criador do Sonic Pi, <link target="https://devchat.cachefly.net/rubyrogues/RR215SonicPi.mp3?rss=true">aqui</link>). Ent&#227;o, em uma nova janela de edi&#231;&#227;o, copie o seguinte (novamente, o trecho de c&#243;digo a seguir eventualmente ser&#225; agrupado em um script &#250;nico na sua janela do Sonic Pi):</p>
<pre><code xml:id="code_som-dados-sonificacao-historiadores_15" type="block" corresp="code_som-dados-sonificacao-historiadores_15.txt"/></pre>
<p>Lembre, <code type="inline">path/to/your/directory/</code> &#233; a localiza&#231;&#227;o real dos seus dados na sua m&#225;quina. Tenha certeza de que eles est&#227;o nomeados como <code type="inline">dados.csv</code> ou altere a linha acima de forma que o seu ficheiro seja carregado!</p>
<p>Agora, vamos carregar esses dados na nossa m&#250;sica:</p>
<pre><code xml:id="code_som-dados-sonificacao-historiadores_16" type="block" corresp="code_som-dados-sonificacao-historiadores_16.txt"/></pre>
<p>As primeiras linhas carregam as colunas de dados; ent&#227;o dizemos qual amostra de som que desejamos usar (piano) e, em seguida, dizemos ao Sonic Pi para tocar o t&#243;pico 1 de acordo com os seguintes crit&#233;rios (um valor aleat&#243;rio menor que 0,5 para o ataque; um decaimento usando um valor aleat&#243;rio menor que 1; e uma <link target="#amplitude">amplitude</link> com um valor aleat&#243;rio menor que 0.25). V&#234; o x 100 na linha? Isso pega os valores dos nossos dados (que s&#227;o um decimal, lembre) e torna-os em um n&#250;mero inteiro. Nessa parte do c&#243;digo, (do modo que eu escrevi), aquele n&#250;mero equivale diretamente a nota. Se 88 &#233; a menor nota e 1 &#233; a maior, &#233; poss&#237;vel ver que essa abordagem &#233; um pouco problem&#225;tica: n&#243;s n&#227;o fizemos nenhum mapeamento de tom aqui! Nesse caso, &#233; poss&#237;vel usar o Musicalgorithms para fazer o seu mapeamento de tom, e ent&#227;o inserir esses valores no Sonic Pi. Alternativamente, uma vez que esse c&#243;digo &#233; praticamente em Ruby, &#233; poss&#237;vel buscar como normalizar os dados e ent&#227;o realizar um mapeamento linear dos valores entre 1 - 88. Um bom lugar para come&#231;ar seria estudar <link target="https://github.com/stevelloyd/Learn-sonification-with-Sonic-Pi">essa tabela do Steve Lloyd</link> sobre sonifica&#231;&#227;o de dados de clima com Sonic Pi. Finalmente, outra coisa a se notar &#233; que o valor 'rand' (random, aleat&#243;rio) permite que se adiciona um pouco de 'humanidade' na m&#250;sica em termos de din&#226;micas. Ent&#227;o n&#243;s faremos a mesma coisa novamente para o topic2 (t&#243;pico2).</p>
<p>&#201; poss&#237;vel adicionar batidas, loops, amostras, e toda a parafern&#225;lia que o Sonic Pi permite. Onde voc&#234; coloca os seus peda&#231;os de c&#243;digo afeta a reprodu&#231;&#227;o, se os loops forem colocados antes dos dados acima, ele ser&#225; reproduzido primeiro. Por exemplo, se o trecho a seguir for inserido depois da linha <code type="inline">use_bpm 100</code>,</p>
<pre><code xml:id="code_som-dados-sonificacao-historiadores_17" type="block" corresp="code_som-dados-sonificacao-historiadores_17.txt"/></pre>
<p>Haver&#225; um pouco de uma introdu&#231;&#227;o na sua obra. H&#225; uma pausa de 2 segundos, a amostra 'ambi_choir' &#233; reproduzida, ent&#227;o h&#225; uma pausa de mais 6 segundos antes dos seus dados serem tocados. Se quiser adicionar um pouco de um som de bateria sinistro ao longo da sua obra, insira esse trecho a seguir (e antes de seus pr&#243;prios dados):</p>
<pre><code xml:id="code_som-dados-sonificacao-historiadores_18" type="block" corresp="code_som-dados-sonificacao-historiadores_18.txt"/></pre>
<p>O c&#243;digo &#233; bem simples: realize um loop da amostra 'bd_boom' com o efeito de som de resson&#226;ncia, em um ritmo particular. Pause por 2 segundos entre os loops.</p>
<p>A prop&#243;sito, 'codifica&#231;&#227;o ao vivo'? O que torna esse ambiente um espa&#231;o de 'codifica&#231;&#227;o ao vivo' &#233; a possibilidade de se fazer altera&#231;&#245;es no c&#243;digo <emph>enquanto o Sonic Pi o transforma em m&#250;sica</emph>. N&#227;o gosta do que est&#225; ouvindo? Altere o c&#243;digo na hora!</p>
<p>Para mais sobre o Sonic Pi, <link target="https://www.miskatonic.org/music/access2015/">esse site de workshop</link> (em ingl&#234;s) &#233; um bom lugar para come&#231;ar. Veja tamb&#233;m o <link target="http://library.gwu.edu/scholarly-technology-group/posts/sound-library-work">relat&#243;rio de Laura Wrubel sobre participar desse worksop, e o trabalho dela e de seus colegas na &#225;rea</link> (em ingl&#234;s).</p>
</div>
      <div type="1"><head>Nihil Novi Sub Sole</head>
<p>Mais uma vez, para que n&#227;o pensemos que estamos na vanguarda atrav&#233;s da nossa gera&#231;&#227;o algor&#237;tmica de m&#250;sica, um lembrete foi publicado em 1978 sobre 'jogos de m&#250;sica de dados' no s&#233;culo XVIII, em que o lan&#231;amento de dados determinava a recombina&#231;&#227;o de trechos pr&#233;-escritos de m&#250;sica. <link target="https://rbnrpi.wordpress.com/project-list/mozart-dice-generated-waltz-revisited-with-sonic-pi/">Alguns desses jogos foram explorados e recodificados para o Sonic-Pi por Robin Newman</link>. Newman tamb&#233;m usa uma ferramenta que poderia ser descrita como um Markdown+Pandoc da  nota&#231;&#227;o musical, <link target="http://www.lilypond.org/">Lilypond</link> para pontuar essas composi&#231;&#245;es. Os antecedentes para tudo que pode ser encontrado no  <emph>The Programming Historian</emph> s&#227;o mais profundos do que se pode suspeitar!</p>
</div>
      <div type="1"><head>Conclus&#227;o</head>
<p>Sonificar os nossos dados nos faz confrontar os modos como os nossos dados s&#227;o, muitas vezes, n&#227;o sobre o passado, mas sobre o que constru&#237;mos dele. Isso ocorre em parte em virtude de sua novidade, e da arte e do artif&#237;cio necess&#225;rios para mapear os dados para o som. Mas isso tamb&#233;m acontece pelo contraste com as nossas no&#231;&#245;es pr&#233;-concebidas sobre visualiza&#231;&#227;o de dados. Pode ser que os sons gerados por algu&#233;m nunca cheguem ao n&#237;vel da 'm&#250;sica'; mas se ajudar a transformar como n&#243;s encontramos o passado, e como outros engajam com o passado, ent&#227;o o esfor&#231;o ter&#225; sido frut&#237;fero. Como Trevor Owens pode ter colocado, 'Sonifica&#231;&#227;o &#233; sobre <link target="http://www.trevorowens.org/2012/11/discovery-and-justification-are-different-notes-on-sciencing-the-humanities/">descoberta, n&#227;o justifica&#231;&#227;o</link>'.</p>
<h2>Termos</h2>
<ul>
<li><hi rend="bold">MIDI</hi>,<a name="midi"/> interface digital de instrumento musical. &#201; uma descri&#231;&#227;o do valor e do tempo de uma nota, n&#227;o de sua din&#226;mica ou de como algu&#233;m pode toc&#225;-la (esta &#233; uma distin&#231;&#227;o importante). Ele permite que computadores e instrumentos conversem entre si; pode-se aplicar instrumenta&#231;&#227;o diferente a um ficheiro MIDI da mesma forma que se mudaria a fonte em um peda&#231;o de texto (ou executar um ficheiro Markdown por meio do Pandoc).</li>
<li><hi rend="bold">MP3</hi>,<a name="mp3"/> formato de compress&#227;o que remove dados como parte de sua rotina de compacta&#231;&#227;o.</li>
<li><hi rend="bold">Tom</hi>,<a name="pitch"/> a  nota em si (C m&#233;dio, etc)</li>
<li><hi rend="bold">Ataque</hi>,<a name="attack"/> como a nota &#233; tocada ou atingida</li>
<li><hi rend="bold">Dura&#231;&#227;o</hi>,<a name="duration"/> quanto tempo a nota dura (notas inteiras, sem&#237;nimas, colcheias etc)</li>
<li><hi rend="bold">Mapeamento do Tom e Mapeamento da Dura&#231;&#227;o</hi>, <a name="pitch mapping"/> dimensionamento de valores de dados em rela&#231;&#227;o a um intervalo de notas ou a dura&#231;&#227;o da nota</li>
<li><hi rend="bold">Amplitude</hi>, <a name="amplitude"/> em resumo, o volume da nota</li>
</ul>
</div>
      <div type="1"><head>Refer&#234;ncias</head>
<p><a name="Baio"/>Baio, Andy. 2015. 'If Drake Was Born A Piano'. Waxy. <link target="https://waxy.org/2015/12/if_drake_was_born_a_piano/">http://waxy.org/2015/12/if_drake_was_born_a_piano/</link></p>
<p><a name="Drucker"/>Drucker, Johanna. 2011. Humanities Approaches to Graphical Display. DHQ 5.1 <link target="http://www.digitalhumanities.org/dhq/vol/5/1/000091/000091.html">http://www.digitalhumanities.org/dhq/vol/5/1/000091/000091.html</link></p>
<p><a name="Hedges"/>Hedges, Stephen A. 1978. &#8220;Dice Music in the Eighteenth Century&#8221;. Music &amp; Letters 59 (2). Oxford University Press: 180&#8211;87. <link target="http://www.jstor.org/stable/734136">http://www.jstor.org/stable/734136</link>.</p>
<p><a name="Hermann"/>Hermann, T. 2008. "Taxonomy and definitions for sonification and auditory display". In P. Susini and O. Warusfel (eds.) Proceedings of the 14th international conference on auditory display (ICAD 2008). IRCAM, Paris. <link target="http://www.icad.org/Proceedings/2008/Hermann2008.pdf">http://www.icad.org/Proceedings/2008/Hermann2008.pdf</link></p>
<p><a name="Koebler"/>Koebler, Jason. 2015. "The Strange Acoustic Phenomenon Behind These Wacked-Out Versions of Pop Songs" Motherboard, Dec 18. <link target="http://motherboard.vice.com/read/the-strange-acoustic-phenomenon-behind-these-wacked-out-versions-of-pop-songs">http://motherboard.vice.com/read/the-strange-acoustic-phenomenon-behind-these-wacked-out-versions-of-pop-songs</link></p>
<p><a name="Last"/>Last and Usyskin, 2015. "Listen to the Sound of Data". In Aaron K. Baughman et al. (eds.) Multimedia Data Mining and Analytics. Springer: Heidelberg. Pp. 419-446 <link target="https://www.researchgate.net/publication/282504359_Listen_to_the_Sound_of_Data">https://www.researchgate.net/publication/282504359_Listen_to_the_Sound_of_Data</link></p>
</div>
    </body>
  </text>
</TEI>
