<TEI xmlns="http://www.tei-c.org/ns/1.0" xml:id="som-dados-sonificacao-historiadores">
  <teiHeader>
 <fileDesc>
  <titleStmt>
   <title>Sonifica&#231;&#227;o de dados (uma introdu&#231;&#227;o &#224; sonifica&#231;&#227;o para historiadores)</title>
  <author role="original_author">Shawn Graham</author><editor role="reviewers"><persName>Jeff Veitch</persName><persName>Tim Compeau</persName></editor><author role="translators">Gabriela Kucuruza</author><editor role="translation-reviewers"><persName>Samuel Van Ransbeeck</persName><persName>Juliana Marques da Silva</persName></editor><editor role="editors">Ian Milligan</editor></titleStmt>
  <publicationStmt>
   <idno type="doi">10.46430/phpt0020</idno><date type="published">06/07/2016</date><date type="translated">03/26/2021</date><p>Lesson reviewed and published in Programming Historian.</p>
  </publicationStmt>
  <sourceDesc>
  <p>Born digital, in a markdown format. Original file: <ref type="original_file" target="#sonification"/>.</p><p>There are other translations: <ref target=""/></p></sourceDesc>
 </fileDesc>
 <profileDesc><abstract><p>Existem in&#250;meras li&#231;&#245;es que o ajudar&#227;o a visualizar o passado, mas esta li&#231;&#227;o o ajudar&#225; a ouvir o passado.</p></abstract><textClass><keywords><term xml:lang="en">distant-reading</term></keywords></textClass></profileDesc>
</teiHeader>
  <text xml:lang="pt">
    <body>
      <div type="1"><head>Introdu&#231;&#227;o</head>
<p>&#960;&#959;&#943;&#951;&#963;&#953;&#962; - fabrica&#231;&#227;o, cria&#231;&#227;o, produ&#231;&#227;o</p>
<p>Eu estou muito cansado de ver o passado. Existem diversos guias que ir&#227;o ajudar a  <emph>visualizar</emph> o passado que n&#227;o podemos ver, mas muitas vezes n&#243;s esquecemos que a visualiza&#231;&#227;o &#233; um ato de criatividade. N&#243;s talvez estejamos muito ligados &#224;s nossas telas, muito focados em "ver". Ao inv&#233;s disso, deixe-me ouvir algo do passado.</p>
<p>Enquanto existe uma hist&#243;ria e uma literatura profundas sobre arqueoac&#250;stica e paisagens sonoras que tentam capturar o som de um lugar  <emph>como ele era</emph> (<ref target="https://www.digitalstudies.org/articles/10.16995/dscn.58">veja por exemplo a Virtual St. Paul's</ref> ou o trabalho de <ref target="https://jeffdveitch.wordpress.com/">Jeff Veitch em Ostia antiga</ref>), eu tenho interesse em 'sonificar' o que eu tenho <emph>agora</emph>, os dados eles mesmos. Eu quero descobrir uma gram&#225;tica para representar dados em som que seja apropriada para Hist&#243;ria. <ref target="#Drucker">Drucker</ref> <ref target="http://www.digitalhumanities.org/dhq/vol/5/1/000091/000091.html">notoriamente nos lembra</ref> que &#8216;dados&#8217; n&#227;o s&#227;o coisas dadas, mas ao inv&#233;s disso, coisas capturadas, coisas transformadas. Na sonifica&#231;&#227;o de dados, eu literalmente realizo o passado no presente, e ent&#227;o as suposi&#231;&#245;es e as transforma&#231;&#245;es que fa&#231;o est&#227;o em primeiro plano. A experi&#234;ncia auditiva resultante &#233; uma "deforma&#231;&#227;o" literal que nos faz ouvir as camadas modernas do passado de uma nova maneira.</p>
<p>Eu quero ouvir os significados do passado, mas eu sei que n&#227;o posso. No entanto, quando ou&#231;o um instrumento, posso imaginar a materialidade do m&#250;sico tocando; posso discernir o espa&#231;o f&#237;sico em seus ecos e resson&#226;ncias. Eu posso sentir o som, eu posso me mover no ritmo. A m&#250;sica engaja o meu corpo inteiro, minha imagina&#231;&#227;o inteira. As suas associa&#231;&#245;es com sons, m&#250;sica e tons que eu ouvi antes criam uma experi&#234;ncia temporal profunda, um sistema de rela&#231;&#245;es incorporadas entre eu e o passado. Visual? N&#243;s temos representa&#231;&#245;es visuais do passado h&#225; tanto tempo, que n&#243;s quase nos esquecemos dos aspectos art&#237;stico e performativo dessas gram&#225;ticas de express&#227;o.</p>
<p>Nesse tutorial, voc&#234; aprender&#225; a fazer um pouco de barulho a partir dos seus dados sobre o passado. O <emph>significado</emph> desse barulho, bem... isso depende de voc&#234;. Parte do objetivo desse tutorial &#233; te fazer estranhar os seus dados. Traduzindo-o, transcodificando-o, <ref target="http://blog.taracopplestone.co.uk/making-things-photobashing-as-archaeological-remediation/">remediando-o</ref> (em ingl&#234;s), n&#243;s come&#231;aremos a ver elementos dos dados que a nossa familiaridade com modelos visuais nos impediu de enxergar. Essa deforma&#231;&#227;o est&#225; de acordo com os argumentos apresentados por, por exemplo, Mark Sample sobre <ref target="http://www.samplereality.com/2012/05/02/notes-towards-a-deformed-humanities/">quebrar coisas</ref> (em ingl&#234;s), ou Bethany Nowviskie sobre a '<ref target="http://nowviskie.org/2013/resistance-in-the-materials/">resist&#234;ncia nos materiais</ref>' (em ingl&#234;s). Sonifica&#231;&#227;o nos move atrav&#233;s do continuum de dados para capta&#231;&#227;o, ci&#234;ncias sociais para arte, <ref target="http://nooart.org/post/73353953758/temkin-glitchhumancomputerinteraction">falha para est&#233;tica</ref> (em ingl&#234;s). Ent&#227;o vamos ver como isso tudo soa.</p>
<div type="2"><head>Objetivos</head>
<p>Nesse tutorial, apresentarei tr&#234;s maneiras diferentes de gerar som ou m&#250;sica a partir de seus dados.</p>
<p>Na primeira, usaremos um sistema desenvolvido por Jonathan Middleton, dispon&#237;vel gratuitamente para uso, chamado  <emph>Musicalgorithms</emph> (Algor&#237;tmos Musicais) a fim de introduzir algumas das quest&#245;es e termos-chaves envolvidos. Na segunda, usaremos uma pequena biblioteca do Python para 'mapear por par&#226;metro' os nossos dados contra o teclado de 88 teclas e introduzir um pouco de arte em nosso trabalho. Finalmente, aprenderemos como carregar nossos dados no ambiente de codifica&#231;&#227;o ao vivo de c&#243;digo aberto para som e m&#250;sica, <emph>Sonic Pi</emph>, momento em que te deixarei para que explore os abundantes tutoriais e recursos desse projeto.</p>
<p>Voc&#234; ver&#225; que "sonifica&#231;&#227;o" nos movimenta atrav&#233;s do espectro partindo de simples 'visualiza&#231;&#227;o/auraliza&#231;&#227;o' para performance real.  </p>
<div type="3"><head>Ferramentas</head>
<list type="unordered">
<item>Musicalgorithms <ref target="http://musicalgorithms.org/">http://musicalgorithms.org/</ref></item>
<item>MIDITime <ref target="https://github.com/cirlabs/miditime">https://github.com/cirlabs/miditime</ref> (Eu bifurquei uma c&#243;pia no GitHub <ref target="https://github.com/shawngraham/miditime">aqui</ref>)</item>
<item>Sonic Pi <ref target="http://sonic-pi.net/">http://sonic-pi.net/</ref></item>
</list>
</div><div type="3"><head>Dados de Exemplo</head>
<list type="unordered">
<item><ref target="/assets/sonification-roman-data.csv">Dados sobre artefatos romanos</ref></item>
<item><ref target="/assets/sonification-diary.csv">Excerto do modelo de t&#243;picos do di&#225;rio de John Adams</ref></item>
<item><ref target="/assets/sonification-jesuittopics.csv">Excerto do modelo de t&#243;picos das rela&#231;&#245;es jesu&#237;ticas</ref></item>
</list>
</div></div></div>
      <div type="1"><head>Um pouco de contexto sobre  sonifica&#231;&#227;o</head>
<p>Sonifica&#231;&#227;o &#233; a pr&#225;tica de mapear aspectos dos dados para produzir sinais sonoros. Em geral, uma t&#233;cnica pode ser chamada de "sonifica&#231;&#227;o" se cumprir certas condi&#231;&#245;es. Elas incluem reprodutibilidade (os mesmos dados podem ser transformados da mesma maneira por outros pesquisadores de forma que produzam os mesmos resultados) e o que pode ser chamado de inteligibilidade - que os elementos "objetivos" dos dados originais sejam sistematicamente refletidos no som resultante (veja <ref target="http://www.icad.org/Proceedings/2008/Hermann2008.pdf">Hermann (2008)</ref> (em ingl&#234;s) para uma taxonomia da sonifica&#231;&#227;o). <ref target="https://www.researchgate.net/publication/282504359_Listen_to_the_Sound_of_Data">Last e Usyskin (2015)</ref> (em ingl&#234;s) realizaram uma s&#233;rie de experimentos para determinar quais tarefas de an&#225;lise de dados poderiam ser performadas quando os dados eram sonificados.  Os seus resultados experimentais mostraram que mesmo um grupo de ouvintes n&#227;o-treinados (sem treinamento formal em m&#250;sica) podem fazer distin&#231;&#245;es &#250;teis nos dados. Eles encontraram ouvintes que conseguiam distinguir tarefas comuns de explora&#231;&#227;o de dados nos dados sonificados, como classifica&#231;&#227;o e agrupamento. Os seus resultados sonificados mapearam os dados fundamentais da escala musical ocidental.</p>
<p>Last e Usyskin focaram em dados de s&#233;ries temporais. Eles argumentam que dados de s&#233;ries temporais s&#227;o particularmente bons para sonifica&#231;&#227;o, pois h&#225; paralelos naturais com sons musicais. M&#250;sica &#233; sequencial, ela tem dura&#231;&#227;o e ela se desenvolve ao longo do tempo, assim como dados de s&#233;ries temporais. <ref target="https://www.researchgate.net/publication/282504359_Listen_to_the_Sound_of_Data">(Last e Usyskin 2015, p. 424)</ref>. Torna-se um problema combinar os dados com as sa&#237;das s&#244;nicas apropriadas. Em muitas aplica&#231;&#245;es de sonifica&#231;&#227;o, uma t&#233;cnica chamada "mapeamento de par&#226;metros" &#233; usada para combinar aspectos dos dados ao longo de v&#225;rias dimens&#245;es da audi&#231;&#227;o, como  <ref target="#tom">tom</ref>, varia&#231;&#227;o, brilho e in&#237;cio. O problema com esta abordagem &#233; que onde n&#227;o h&#225; rela&#231;&#227;o temporal (ou melhor, nenhuma rela&#231;&#227;o n&#227;o linear) entre os pontos de dados originais, o som resultante pode ser "confuso" (2015, p. 422).</p>
<h2>Escutando as lacunas</h2>
<p>H&#225; tamb&#233;m o modo que preenchemos as lacunas do som com as nossas expectativas. Considere esse v&#237;deo em que <ref target="#mp3">mp3</ref> foi convertido para <ref target="#midi">MIDI</ref> e  de volta para mp3; a  m&#250;sica foi 'achatada' para que todas as informa&#231;&#245;es sonoras sejam tocadas por apenas um instrumento. (Gerar esse efeito &#233; como salvar uma p&#225;gina da web como .txt, abri-la no Word e, ent&#227;o, salv&#225;-la novamente como .html). Todos os sons (inclusive vocais) foram traduzidos para os seus valores de nota correspondentes e, em seguida, transformados de volta em mp3.</p>
<p>&#201; barulhento, entretanto percebemos o significado. Considere o v&#237;deo abaixo:</p>
<iframe src="https://player.vimeo.com/video/149070596" width="640" height="360" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""/>
<p>O que est&#225; acontecendo aqui? Se j&#225; conhecia essa m&#250;sica, provavelmente ouviu as 'palavras'. No entanto, nenhuma palavra est&#225; presente na m&#250;sica! Se voc&#234; n&#227;o conhecia esse m&#250;sica, deve ter soado como um absurdo inaud&#237;vel (veja mais exemplos no website de <ref target="http://waxy.org/2015/12/if_drake_was_born_a_piano/">Andy Baio</ref>). Esse efeito &#233;, &#224;s vezes, chamado de 'alucina&#231;&#227;o auditiva' (cf. <ref target="#Koebler">Koebler, 2015</ref>). Esses exemplos mostram como qualquer representa&#231;&#227;o de dados que podemos ouvir/ver n&#227;o est&#225; l&#225;, estritamente falando. N&#243;s preenchemos as lacunas com as nossas pr&#243;prias expectativas.</p>
<p>Considere as implica&#231;&#245;es para a Hist&#243;ria. Se sonificarmos nossos dados e come&#231;armos a ouvir padr&#245;es no som, ou pontos fora da curva, nossas expectativas culturais sobre como a m&#250;sica funciona (nossas mem&#243;rias de fragmentos musicais semelhantes, ouvidos em contextos espec&#237;ficos) ir&#227;o colorir nossa interpreta&#231;&#227;o. Isso, eu argumentaria, &#233; verdadeiro para todas as representa&#231;&#245;es do passado, mas sonificar &#233; apenas estranho o suficiente em rela&#231;&#227;o aos nossos m&#233;todos regulares, de forma que essa autoconsci&#234;ncia nos ajudar&#225; a identificar ou comunicar os padr&#245;es cr&#237;ticos nos dados do passado.</p>
<p>Iremos progredir por meio de tr&#234;s ferramentas diferentes para sonifica&#231;&#227;o de dados, observando como as escolhas em uma ferramenta afetam o resultado e podem ser atenuadas imaginando novamente os dados por meio de outra ferramenta. No fim das contas, n&#227;o h&#225; nada mais objetivo em 'sonifica&#231;&#227;o' do que h&#225; em 'visualiza&#231;&#227;o', ent&#227;o quem pesquisa deve estar preparado para justificar as suas escolhas, e fazer escolhas transparentes e reprodut&#237;veis para outros. E para que n&#227;o pensemos que a sonifica&#231;&#227;o e a m&#250;sica gerada por algoritmos s&#227;o de alguma forma algo "novo", indico ao leitor interessado <ref target="http://www.icad.org/Proceedings/2008/Hermann2008.pdf">Hedges, (1978)</ref>.</p>
<p>Em cada se&#231;&#227;o, irei dar uma introdu&#231;&#227;o conceitual, seguida por um passo a passo usando dados arqueol&#243;gicos ou hist&#243;ricos de amostra.</p>
</div>
      <div type="1"><head>Musicalgorithms</head>
<p>H&#225; uma grande variedade de ferramentas para sonificar dados. Algumas, por exemplo, s&#227;o pacotes amplamente usadas do <ref target="https://cran.r-project.org/">ambiente de estat&#237;stica R</ref>, como &#8216;<ref target="https://cran.r-project.org/web/packages/playitbyr/index.html">playitbyR</ref>&#8217; e &#8216;<ref target="https://cran.r-project.org/web/packages/audiolyzR/index.html">AudiolyzR</ref>&#8217;. O primeiro desses pacotes, entretanto, n&#227;o tem sido mantido ou atualizado para as vers&#245;es atuais do R (sua &#250;ltima atualiza&#231;&#227;o foi muitos anos atr&#225;s) e o segundo precisa de um n&#250;mero consider&#225;vel de configura&#231;&#245;es adicionais de software para que funcione adequadamente.  </p>
<p>Por outro lado, o site <ref target="http://musicalgorithms.org/">Musicalgorithms</ref> &#233; bem f&#225;cil de usar. O site Musicalgorithms est&#225; online h&#225; mais de uma d&#233;cada. Embora n&#227;o seja c&#243;digo aberto, ele &#233; um projeto de pesquisa de longa-dura&#231;&#227;o em m&#250;sica computacional do seu criador, Jonathan Middleton. Ele est&#225; atualmente em sua terceira maior itera&#231;&#227;o (intera&#231;&#245;es anteriores permanecem dispon&#237;veis para uso online). Come&#231;aremos com o Musicalalgorithms porque ele nos permite entrar e ajustar os nossos dados para produzir um ficheiro de representa&#231;&#227;o MIDI. Tenha aten&#231;&#227;o e seleccione a '<ref target="http://musicalgorithms.org/3.0/index.html">Vers&#227;o 3</ref>'.</p>
<figure><desc>O site Musicalgorithms como aparecia em 2 de agosto de 2016</desc><graphic url="sonification-musicalgorithms-main-site-1.png"/></figure>
<quote>
<p>Nota da tradu&#231;&#227;o: h&#225; novas vers&#245;es dispon&#237;veis para uso, mas de forma a seguir o tutorial, seguimos a vers&#227;o 3 do Musicallgorithms, usada em 2016, e ainda dispon&#237;vel no site para uso.</p>
</quote>
<p>O Musicalgorithms efetua uma s&#233;rie de transforma&#231;&#245;es nos dados. Nos dados de amostra abaixo (o padr&#227;o do pr&#243;prio site), h&#225; apenas uma linha de dados, mesmo que pare&#231;a v&#225;rias linhas. Os dados de amostra s&#227;o compostos de campos separados por v&#237;rgula que s&#227;o delimitados por espa&#231;o.</p>
<ab><code xml:id="code_som-dados-sonificacao-historiadores_0" corresp="code_som-dados-sonificacao-historiadores_0.txt" rend="block"/></ab>
<p>Esses dados representam os dados de origem e as suas transforma&#231;&#245;es; compartilhar esses dados permitiria a outro pesquisador replicar ou estender a sonifica&#231;&#227;o usando outras ferramentas. No entanto, quando se come&#231;a, apenas os dados b&#225;sicos abaixo s&#227;o necess&#225;rios (uma lista de pontos de dados):</p>
<ab><code xml:id="code_som-dados-sonificacao-historiadores_1" corresp="code_som-dados-sonificacao-historiadores_1.txt" rend="block"/></ab>
<p>O campo-chave para n&#243;s &#233; &#8216;areaPitch1&#8217;, que cont&#233;m os dados de entrada delimitados por espa&#231;o. Os outros campos ser&#227;o preenchidos &#224; medida que avan&#231;amos pelas v&#225;rias configura&#231;&#245;es de Musicalgorithms. Nos dados acima (por exemplo, 24 72 12 84 etc.), os valores s&#227;o contagens brutas de inscri&#231;&#245;es de uma s&#233;rie de locais ao longo de uma estrada romana na Gr&#227;-Bretanha. (Vamos praticar com outros dados em breve, abaixo).</p>
<figure><desc>Depois de carregar seus dados, &#233; poss&#237;vel selecionar as diferentes opera&#231;&#245;es na barra de menu superior do site. Na captura de tela, o mouseover de informa&#231;&#245;es est&#225; explicando o que acontece com o dimensionamento de seus dados se voc&#234; selecionar a opera&#231;&#227;o de divis&#227;o para dimensionar os seus dados para o intervalo de notas selecionado.</desc><graphic url="sonification-musicalgorithms-pitch-mapping-2.png"/></figure>
<p>Agora, conforme se percorre as v&#225;rias guias da interface &#8216;duration input&#8217; (entrada de dura&#231;&#227;o) , &#8216;pitch mapping' (mapeamento de tom), &#8216;duration mapping&#8217; (mapeamento de dura&#231;&#227;o), &#8216;scale options&#8217; (op&#231;&#245;es de escala musical) &#233; poss&#237;vel realizar v&#225;rias transforma&#231;&#245;es.  Em &#8216;pitch mapping&#8217; (mapeamento de tom), h&#225; uma s&#233;rie de op&#231;&#245;es matem&#225;ticas para mapear os dados contra as 88 teclas/tons completos de um teclado de piano (em um mapeamento linear, a <emph>m&#233;dia</emph> dos dados de algu&#233;m seria mapeado para d&#243; m&#233;dio, ou 40). Tamb&#233;m &#233; poss&#237;vel escolher o tipo de escala, se &#233; um tom maior ou menor. Nesse ponto, uma vez que se tenha selecionado v&#225;rias transforma&#231;&#245;es, salve o ficheiro de texto. No menu 'play' &#233; poss&#237;vel realizar o download de um ficheiro MIDI. O seu programa de &#225;udio padr&#227;o pode tocar ficheiros MIDI (geralmente padronizando para um tom de piano). Uma instrumenta&#231;&#227;o mais complicada pode ser atribu&#237;da abrindo o ficheiro MIDI em programas de mixagem de m&#250;sica, como GarageBand (Mac) ou <ref target="https://lmms.io/">LMMS</ref> (Windows, Mac, Linux). (O uso do Garageband ou LMMS est&#225; fora do escopo desse tutorial. Um tutorial em v&#237;deo sobre LMMS est&#225; dispon&#237;vel <ref target="https://youtu.be/4dYxV3tqTUc">aqui</ref>, enquanto h&#225; muitos tutoriais do Garageband online. Lynda.com tem <ref target="http://www.lynda.com/GarageBand-tutorials/Importing-audio-tracks/156620/164050-4.html">um tutorial excelente</ref>).</p>
<p>Se tivesse v&#225;rias colunas de dados para os mesmos pontos - digamos, em nosso exemplo da Gr&#227;-Bretanha romana, tamb&#233;m quer&#237;amos sonificar contagens de um tipo de cer&#226;mica para essas mesmas cidades - &#233; poss&#237;vel recarregar sua pr&#243;xima s&#233;rie de dados, efetuar as transforma&#231;&#245;es e mapeamentos, e gerar outro ficheiro MIDI. Como o Garageband e o LMMS permitem a sobreposi&#231;&#227;o de vozes, voc&#234; pode come&#231;ar a criar sequ&#234;ncias musicais complicadas.</p>
<figure><desc>Captura de tela do Garageband, onde os ficheiros MIDI s&#227;o t&#243;picos sonorizados do Di&#225;rio de John Adams. Na interface do Garageband (o LMMS &#233; semelhante), cada ficheiro MIDI &#233; arrastado e solto no lugar. A instrumenta&#231;&#227;o para cada ficheiro MIDI (ou seja, trilha) pode ser selecionada nos menus do Garageband. Os r&#243;tulos de cada faixa foram alterados aqui para refletir as palavras-chave em cada t&#243;pico. A &#225;rea verde &#224; direita representa uma visualiza&#231;&#227;o das notas em cada faixa. Voc&#234; pode ver esta interface em a&#231;&#227;o e ouvir a m&#250;sica [aqui](https://youtu.be/ikqRXtI3JeA) (em ingl&#234;s)</desc><graphic url="sonification-garageband-john-adams-3.png"/></figure>
<p>Quais transforma&#231;&#245;es devem ser usadas? Se tiver duas colunas de dados, ter&#225; duas vozes. Pode fazer sentido, em nossos dados hipot&#233;ticos, tocar a primeira voz bem alto, em uma tonalidade maior: as inscri&#231;&#245;es 'falam' conosco, afinal de contas. (As inscri&#231;&#245;es romanas de fato se dirigem ao leitor, o transeunte, literalmente: '&#211; tu que passas ...'). Ent&#227;o, se acaso as cer&#226;micas de interesse forem mercadorias mais despretensiosas, talvez elas possam ser mapeadas em rela&#231;&#227;o &#224; extremidade inferior da escala ou receberem notas de dura&#231;&#227;o mais longas para representar sua onipresen&#231;a nas classes nessa regi&#227;o.</p>
<p><emph>N&#227;o h&#225; forma 'certa' de representar os seus dados como som, ao menos n&#227;o por enquanto</emph>, mas mesmo com essa amostra de exemplo, come&#231;amos a ver como sombras de significado e interpreta&#231;&#227;o podem ser atribu&#237;das aos nossos dados e &#224; nossa experi&#234;ncia dos dados.  </p>
<p>Mas e o tempo? Dados hist&#243;ricos usualmente t&#234;m um ponto de inflex&#227;o, um distinto "tempo quando" algo aconteceu. Ent&#227;o, a quantidade de tempo entre dois pontos de dados precisa ser considerada. &#201; nesse ponto que a nossa pr&#243;xima ferramenta se torna bem &#250;til, para quando nossos pontos de dados tiverem uma rela&#231;&#227;o com outro espa&#231;o temporal. Come&#231;amos a nos mover de sonifica&#231;&#227;o (pontos de dados) para m&#250;sica (rela&#231;&#245;es entre pontos).</p>
<h3>Pr&#225;tica</h3>
<p>O <ref target="/assets/sonification-roman-data.csv">conjunto de dados de amostra</ref> apresentado cont&#233;m a contagem de moedas romanas na sua primeira coluna e a contagem de materiais romanos dos mesmos locais, conforme contido no banco de dados do Portable Antiquities Scheme (Esquema de Antiguidades Port&#225;veis) do British Museum. A sonifica&#231;&#227;o desses dados pode revelar ou acentuar aspectos da situa&#231;&#227;o econ&#244;mica ao longo da rua Watling, uma grande rota atrav&#233;s da Brit&#226;nia Romana. Esses pontos de dados est&#227;o organizados geograficamente do Noroeste ao Sudeste; ent&#227;o, na medida em que o som toca, n&#243;s estamos escutando movimento atrav&#233;s do espa&#231;o. Cada nota representa outro passo no caminho.</p>
<list type="ordered">
<item>Abra o <ref target="/assets/sonification-roman-data.csv">dados-sonifica&#231;&#227;o-romana.csv</ref> em uma tabela. Copie a primeira coluna em um editor de texto. Delete os finais das linhas de forma que os dados fiquem todos em uma linha &#250;nica.</item>
<item>Adicione a seguinte informa&#231;&#227;o de coluna assim:</item>
</list>
<ab><code xml:id="code_som-dados-sonificacao-historiadores_2" corresp="code_som-dados-sonificacao-historiadores_2.txt" rend="block"/></ab>
<p>...para que os seus dados sigam imediatamente depois da &#250;ltima v&#237;rgula (como <ref target="/assets/sonification-romancoin-data-music.csv">esse exemplo</ref>). Salve o ficheiro com um nome &#250;til como <code rend="inline">sonsdasmoedas1.csv</code>.</p>
<list start="3" type="ordered">
<item>Acesse o site do <ref target="http://musicalgorithms.org/3.0/index.html">Musicalgorithms</ref> (vers&#227;o 3) e clique no bot&#227;o "load" (carregar). No pop-up, clique no bot&#227;o azul "load" (carregar) e selecione o ficheiro salvo no passo 2. O site carregar&#225; os seus materiais e exibir&#225; uma marca de sele&#231;&#227;o verde se tiver sido carregado com &#234;xito. Caso contr&#225;rio, certifique-se de que os seus valores estejam separados por espa&#231;os e que sigam imediatamente a &#250;ltima v&#237;rgula no bloco de c&#243;digo na etapa 2. Tamb&#233;m &#233; poss&#237;vel tentar carregar o <ref target="/assets/sonification-romancoin-data-music.csv">ficheiro de demonstra&#231;&#227;o desse tutorial</ref> ao inv&#233;s.</item>
</list>
<figure><desc>Clique em 'load' na tela principal para acessar essa caixa de di&#225;logo. Ent&#227;o 'load csv'. (carregue o csv) Selecione o ficheiro; ele aparecer&#225; na caixa. Ent&#227;o clique no bot&#227;o 'load' (carregar).</desc><graphic url="sonification-musicalgorithms-upload-4.png"/></figure>
<list start="4" type="ordered">
<item>
<p>Clique em 'Pitch Input'. Os valores dos seus dados ser&#227;o exibidos. Por enquanto,  <hi rend="bold">n&#227;o selecione</hi> nenhuma outra op&#231;&#227;o nesse p&#225;gina (consequentemente, usaremos os valores padr&#227;o do site).  </p>
</item>
<item>
<p>Clique em 'Duration Input'. <hi rend="bold">N&#227;o selecione nenhuma op&#231;&#227;o aqui por enquanto</hi>. As op&#231;&#245;es aqui ir&#227;o mapear v&#225;rias transforma&#231;&#245;es em rela&#231;&#227;o aos dados que alterar&#227;o a dura&#231;&#227;o para cada nota. N&#227;o se preocupe com as op&#231;&#245;es por enquanto: siga adiante.  </p>
</item>
<item>
<p>Clique em 'Pitch Mapping'. Essa &#233; a escolha mais crucial, pois ir&#225; transformar (isso &#233;, escalar) os seus dados brutos para um mapeamento em rela&#231;&#227;o &#224;s teclas do teclado. Deixe a configura&#231;&#227;o de <code rend="inline">mapping</code> em 'division'.  (As outras op&#231;&#245;es s&#227;o m&#243;dulo e logar&#237;tmico). A op&#231;&#227;o <code rend="inline">Range</code> 1 a 88 usa todas as 88 teclas do teclado, assim, seu valor mais baixo estaria de acordo com a nota mais profunda do piano e seu valor mais alto com a nota mais alta. Em vez disso, voc&#234; pode restringir sua m&#250;sica em torno de d&#243; m&#233;dio, ent&#227;o insira 25 a 60 como seu intervalo. O resultado deveria mudar para: <code rend="inline">31,34,34,34,25,28,30,60,28,25,26,26,25,25,60,25,25,38,33,26,25,25,25</code> Essas n&#227;o s&#227;o mais suas contagens; s&#227;o as notas do teclado.</p>
</item>
</list>
<figure><desc>Clique na caixa 'range' e defina-o para 25. Os valores abaixo ser&#227;o alterados automaticamente. Clique na caixa 'to' e defina-o para 60. Clique novamente na outra caixa; os valores ser&#227;o atualizados.</desc><graphic url="sonification-musicalgorithms-settings-for-pitch-mapping-5.png"/></figure>
<list start="8" type="ordered">
<item>Clique em 'Duration Mapping'. Como Pitch Mapping, isso pega o intervalo de tempo especificado e usa v&#225;rias op&#231;&#245;es matem&#225;ticas para mapear o intervalo de possibilidade contra as suas notas. Se passar o seu cursor por cima de <code rend="inline">i</code> ver&#225; como os n&#250;meros correspondem com notas inteiras, sem&#237;nimas, colcheias e assim por diante. Deixe os valores padr&#227;o por enquanto.</item>
<item>Clique em 'Scale Options'. Aqui n&#243;s podemos come&#231;ar a selecionar o que pode ser chamado de aspecto 'emocional' do som. N&#243;s geralmente pensamos que escalas maiores s&#227;o 'alegres' enquanto escalas menores s&#227;o 'tristes'; para uma discuss&#227;o acess&#237;vel acesse esse <ref target="http://www.ethanhein.com/wp/2010/scales-and-emotions/">post de blog</ref> (em ingl&#234;s). Por enquanto, escolha 'scale by: major' (escala maior). Deixe a 'scale' (escala) como <code rend="inline">C</code>.</item>
</list>
<p>Agora sonificamos uma coluna de dados! Clique no bot&#227;o 'save' (salvar), ent&#227;o 'save csv' (salvar csv).</p>
<figure><desc>A caixa de di&#225;logo salvar dados.</desc><graphic url="sonification-musicalgorithms-save-6.png"/></figure>
Haver&#225; um ficheiro que se parecer&#225; com isso:
<ab><code xml:id="code_som-dados-sonificacao-historiadores_3" corresp="code_som-dados-sonificacao-historiadores_3.txt" rend="block"/></ab>
<p>&#201; poss&#237;vel ver os dados originais no campo 'areaPitch1' e os subsequentes mapeamentos. O site permite que sejam geradas at&#233; quatro vozes por vez em um ficheiro MIDI; dependendo de como se quer adicionar instrumenta&#231;&#227;o depois, pode-se querer gerar um ficheiro MIDI por vez. Vamos tocar a m&#250;sica - clique em 'Play'. &#201; poss&#237;vel selecionar o tempo aqui, e um instrumento. &#201; poss&#237;vel ouvir os seus dados no navegador, ou salv&#225;-los como um ficheiro MIDI clicando no bot&#227;o azul 'Save MIDI file'.</p>
<p>Retorne ao come&#231;o e carregue as duas colunas de dados nesse modelo:</p>
<ab><code xml:id="code_som-dados-sonificacao-historiadores_4" corresp="code_som-dados-sonificacao-historiadores_4.txt" rend="block"/></ab>
<figure><desc>Coloque 2 na caixa de vozes no topo da interface. Quando voc&#234; for para qualquer uma das p&#225;ginas de op&#231;&#227;o - aqui, n&#243;s estamos em 'pitch input' - dois monitores abrem para mostrar os dados das duas vozes. Carregue os seus dados do csv como antes, mas formate o seu csv para ter o 'areaPitch1' e o 'areaPitch2' como descrito no texto principal. Os dados para a primeira voz ir&#227;o aparecer na esquerda, e a segunda voz na direita.</desc><graphic url="sonification-2voices-7.png"/></figure>
<p>Quando se tem dados com v&#225;rias vozes, o que se destaca? Observe que, nessa abordagem, a dist&#226;ncia entre os pontos no mundo real n&#227;o &#233; considerada em nossa sonifica&#231;&#227;o. Essa dist&#226;ncia, se fosse considerada, poderia ser crucial. A dist&#226;ncia, &#233; claro, n&#227;o precisa ser geogr&#225;fica - pode ser temporal. A pr&#243;xima ferramenta que exploraremos nos permite abordar isso em nossa sonifica&#231;&#227;o explicitamente.</p>
</div>
      <div type="1"><head>Algumas palavras sobre configurar o Python</head>
<p>A pr&#243;xima se&#231;&#227;o desse tutorial precisa de Python. Se n&#227;o usou Python ainda, ser&#225; preciso passar algum tempo <ref target="/en/lessons/intro-to-bash">se familiarizando com a linha de comando (PC) ou terminal (OS)</ref> (em ingl&#234;s). Voc&#234; pode achar esse r&#225;pido <ref target="/pt/licoes/instalacao-modulos-python-pip">guia de instala&#231;&#227;o dos m&#243;dulos do python</ref> &#250;til (mas retorne para ele depois de ler o resto da se&#231;&#227;o).</p>
<p>Usu&#225;rios do Mac j&#225; possuir&#227;o o Python instalado na m&#225;quina deles. &#201; poss&#237;vel testar isso apertando o bot&#227;o COMMAND e a barra de espa&#231;o; na janela de pesquisa, digite <code rend="inline">terminal</code> e clique na aplica&#231;&#227;o do terminal. No prompt de comando, por exemplo, no cursor piscando em <code rend="inline">$</code> digite <code rend="inline">python --version</code> e o computador responder&#225; com a vers&#227;o do python existente no seu computador. <emph>A pr&#243;xima se&#231;&#227;o desse tutorial usa a vers&#227;o Python 2.7; ela n&#227;o foi testada em Python 3</emph>.  </p>
<p>Para usu&#225;rios do Windows, Python n&#227;o &#233; instalado por padr&#227;o na sua m&#225;quina ent&#227;o <ref target="http://docs.python-guide.org/en/latest/starting/install/win/">essa p&#225;gina</ref> te ajudar&#225; a iniciar, apesar das coisas serem um pouco mais complicadas do que parece de acordo com a p&#225;gina (nota de tradu&#231;&#227;o: pode usar tamb&#233;m a <ref target="/pt/licoes/introducao-instalacao-python">li&#231;&#227;o de instala&#231;&#227;o do Python</ref> do <emph>Programming Historian em portugu&#234;s</emph>, mas tenha em aten&#231;&#227;o que nessa li&#231;&#227;o &#233; instalada a vers&#227;o 3 do Python). Primeiro, realize o download do ficheiro <code rend="inline">.msi</code> que a p&#225;gina recomenda (Python 2.7). Clique duas vezes no ficheiro e ele deve se instalar em um novo diret&#243;rio, por exemplo, <code rend="inline">C:\Python27\</code>. Ent&#227;o, n&#243;s temos de dizer para o Windows a localiza&#231;&#227;o para onde buscar pelo Python sempre que um programa em python for executado; ou seja, colocaremos a localiza&#231;&#227;o do diret&#243;rio no seu 'path', ou a vari&#225;vel do ambiente que o Windows sempre apresenta quando confrontado com um novo comando. Existem algumas formas de fazer isso, mas talvez a mais f&#225;cil seja buscar no seu computador pelo programa <code rend="inline">Powershell</code> (digite 'powershell' na janela de pesquisa do seu computador). Abra o Powershell e, no <code rend="inline">&gt;</code> prompt, copie essa linha inteira:</p>
<p><code rend="inline">[Environment]::SetEnvironmentVariable("Path", "$env:Path;C:\Python27\;C:\Python27\Scripts\", "User")</code></p>
<p>Feche o powershell quando terminar. Voc&#234; saber&#225; que funcionou se nada acontecer quando clicar em 'enter'. Para testar se tudo est&#225; funcionando, abra o prompt de comando (aqui h&#225; <ref target="http://www.howtogeek.com/235101/10-ways-to-open-the-command-prompt-in-windows-10/">10 forma de fazer isso</ref>) (em ingl&#234;s) e digite no prompt <code rend="inline">&gt;</code>, <code rend="inline">python --version</code>. Ele deve retornar <code rend="inline">Python 2.7.10</code> ou algo similar.</p>
<p>A &#250;ltima pe&#231;a do quebra-cabe&#231;a que todos os usu&#225;rios precisar&#227;o &#233; um programa chamado <code rend="inline">Pip</code>. Os usu&#225;rios de Mac podem instal&#225;-lo digitando no terminal: :<code rend="inline">sudo easy_install pip</code>. Usu&#225;rios do Windows ter&#227;o um pouco mais de dificuldade (nota de tradu&#231;&#227;o: pode usar tamb&#233;m a <ref target="/pt/licoes/instalacao-modulos-python-pip">li&#231;&#227;o de instala&#231;&#227;o de m&#243;dulos Python com pip</ref> do <emph>Programming Historian em portugu&#234;s</emph>, mas tenha em aten&#231;&#227;o que nessa li&#231;&#227;o &#233; usada a vers&#227;o 3 do Python). Primeiro, clique no bot&#227;o direito do seu cursor e salve esse link: <ref target="https://bootstrap.pypa.io/get-pip.py">https://bootstrap.pypa.io/get-pip.py</ref> (Se apenas clicar no link, ele ir&#225; te mostrar o c&#243;digo no seu navegador). Salve em algum lugar &#250;til. Abra o prompt de comando no diret&#243;rio em que salvou <code rend="inline">get-pip.py</code>. Ent&#227;o, digite no prompt de comando, <code rend="inline">python get-pip.py</code>. Convencionalmente, nos tutoriais, ver&#225; <code rend="inline">&gt;</code> ou <code rend="inline">$</code> em lugares em que &#233; preciso digitar algo no prompt de comando ou no terminal. Nunca &#233; necess&#225;rio digitar esses dois caracteres.</p>
<p>Finalmente, quando voc&#234; tem um c&#243;digo python que deseja executar, pode inseri-lo em seu editor de texto e salv&#225;-lo com a extens&#227;o <code rend="inline">.py</code> (nota de tradu&#231;&#227;o: pode tamb&#233;m seguir as indica&#231;&#245;es das li&#231;&#245;es &#8220;Configurar um ambiente de desenvolvimento integrado para Python&#8221;, do <emph>Programming Historian em portugu&#234;s</emph>, nas suas vers&#245;es <ref target="/pt/licoes/instalacao-windows">Windows</ref> ou <ref target="/pt/licoes/instalacao-mac">Mac</ref>, mas tenha em aten&#231;&#227;o que nessas li&#231;&#245;es &#233; usada a vers&#227;o 3 do Python). O seu ficheiro &#233; um ficheiro de texto, mas a <hi rend="bold">extens&#227;o</hi> do ficheiro diz para o seu computador para usar o Python para interpret&#225;-lo; mas lembre, digite <code rend="inline">python</code> no prompt primeiro, por exemplo: <code rend="inline">$ python meu-script-legal.py</code>.</p>
</div>
      <table>
<row>
<cell role="label"/>
<cell role="label">A</cell>
<cell role="label">B</cell>
<cell role="label">C</cell>
<cell role="label">D</cell>
<cell role="label">E</cell>
</row>
<row>
<cell>3</cell>
<cell/>
<cell/>
<cell/>
<cell/>
<cell/>
</row>
<row>
<cell>2</cell>
<cell/>
<cell/>
<cell/>
<cell/>
<cell/>
</row>
<row>
<cell>1</cell>
<cell>{'data_evento': datetime</cell>
<cell>(1753,6,8)</cell>
<cell>, 'magnitude':</cell>
<cell>0.0024499630</cell>
<cell>},</cell>
</row>
</table>
      <div type="1"><head>Sonic Pi</head>
<p>Harmonizar ficheiros MIDI &#250;nicos (no Garageband ou em algum outro programa de composi&#231;&#227;o musical) nos leva de sonifica&#231;&#227;o para composi&#231;&#227;o e arte sonora. Nessa se&#231;&#227;o final, n&#227;o ser&#225; oferecido um tutorial completo sobre como usar o <ref target="http://sonic-pi.net">Sonic Pi</ref>, mas um direcionamento para um ambiente que permite a performance da codifica&#231;&#227;o dos seus dados ao vivo (veja <ref target="https://www.youtube.com/watch?v=oW-3HVOeUQA">esse v&#237;deo</ref> para uma performance ao vivo real de codifica&#231;&#227;o). Os tutoriais do pr&#243;prio Sonic Pi's mostrar&#227;o o potencial do uso do computador como um instrumento musical (em que voc&#234; digita c&#243;digo em Ruby no editor interno enquanto o interpretador toca o que est&#225; sendo codificado).</p>
<p>Por que algu&#233;m iria querer fazer isso? Como progressivamente ficou evidente no tutorial, quando os seus dados s&#227;o sonificados, escolhas passam a ser feitas sobre como mapear os dados em som, e essas escolhas refletem impl&#237;cita ou explicitamente decis&#245;es sobre quais dados importam. Existe um <emph>continuum</emph> de 'objetividade', se quiser. Em uma extremidade, uma sonifica&#231;&#227;o que apoia uma discuss&#227;o sobre o passado; do outro, uma apresenta&#231;&#227;o sobre o passado t&#227;o fascinante e pessoal quanto qualquer palestra p&#250;blica bem-feita. A sonifica&#231;&#227;o tira nossos dados das p&#225;ginas e os leva aos ouvidos de nossos ouvintes: &#233; uma esp&#233;cie de hist&#243;ria p&#250;blica. Apresentando nossos dados ... imagine s&#243;!</p>
<p>Aqui, eu ofere&#231;o simplesmente um trecho de c&#243;digo que possibilitar&#225; a importa&#231;&#227;o dos seus dados, que aqui s&#227;o simplesmente uma lista de valores salvos como csv. Estou em d&#237;vida com a bibliotec&#225;ria da George Washington University, Laura Wrubel, que postou em <ref target="https://gist.github.com/lwrubel">gist.github.com</ref> os experimentos dela de sonifica&#231;&#227;o das transa&#231;&#245;es de circula&#231;&#227;o de sua biblioteca.</p>
<p>Nesse <ref target="/assets/sonification-jesuittopics.csv">ficheiro de amostra</ref> (um modelo de t&#243;picos gerado do <ref target="http://puffin.creighton.edu/jesuit/relations/">Jesuit Relations</ref>, (Rela&#231;&#245;es Jesu&#237;tas)), h&#225; dois t&#243;picos. A primeira linha contem os cabe&#231;alhos: topic1 (em PT-BR, t&#243;pico1), topic2 (em PT-BR, t&#243;pico2).</p>
<h3>Pr&#225;tica</h3>
<p>Siga os tutoriais iniciais que o Sonic Pi oferece at&#233; se sentir confort&#225;vel com a interface e algumas das suas possibilidades. (Esses tutoriais tamb&#233;m est&#227;o agrupados <ref target="https://gist.github.com/jwinder/e59be201082cca694df9">aqui</ref>; tamb&#233;m &#233; poss&#237;vel escutar uma entrevista com Sam Aaron, o criador do Sonic Pi, <ref target="https://devchat.cachefly.net/rubyrogues/RR215SonicPi.mp3?rss=true">aqui</ref>). Ent&#227;o, em uma nova janela de edi&#231;&#227;o, copie o seguinte (novamente, o trecho de c&#243;digo a seguir eventualmente ser&#225; agrupado em um script &#250;nico na sua janela do Sonic Pi):</p>
<ab><code xml:id="code_som-dados-sonificacao-historiadores_15" corresp="code_som-dados-sonificacao-historiadores_15.txt" rend="block"/></ab>
<p>Lembre, <code rend="inline">path/to/your/directory/</code> &#233; a localiza&#231;&#227;o real dos seus dados na sua m&#225;quina. Tenha certeza de que eles est&#227;o nomeados como <code rend="inline">dados.csv</code> ou altere a linha acima de forma que o seu ficheiro seja carregado!</p>
<p>Agora, vamos carregar esses dados na nossa m&#250;sica:</p>
<ab><code xml:id="code_som-dados-sonificacao-historiadores_16" corresp="code_som-dados-sonificacao-historiadores_16.txt" rend="block"/></ab>
<p>As primeiras linhas carregam as colunas de dados; ent&#227;o dizemos qual amostra de som que desejamos usar (piano) e, em seguida, dizemos ao Sonic Pi para tocar o t&#243;pico 1 de acordo com os seguintes crit&#233;rios (um valor aleat&#243;rio menor que 0,5 para o ataque; um decaimento usando um valor aleat&#243;rio menor que 1; e uma <ref target="#amplitude">amplitude</ref> com um valor aleat&#243;rio menor que 0.25). V&#234; o x 100 na linha? Isso pega os valores dos nossos dados (que s&#227;o um decimal, lembre) e torna-os em um n&#250;mero inteiro. Nessa parte do c&#243;digo, (do modo que eu escrevi), aquele n&#250;mero equivale diretamente a nota. Se 88 &#233; a menor nota e 1 &#233; a maior, &#233; poss&#237;vel ver que essa abordagem &#233; um pouco problem&#225;tica: n&#243;s n&#227;o fizemos nenhum mapeamento de tom aqui! Nesse caso, &#233; poss&#237;vel usar o Musicalgorithms para fazer o seu mapeamento de tom, e ent&#227;o inserir esses valores no Sonic Pi. Alternativamente, uma vez que esse c&#243;digo &#233; praticamente em Ruby, &#233; poss&#237;vel buscar como normalizar os dados e ent&#227;o realizar um mapeamento linear dos valores entre 1 - 88. Um bom lugar para come&#231;ar seria estudar <ref target="https://github.com/stevelloyd/Learn-sonification-with-Sonic-Pi">essa tabela do Steve Lloyd</ref> sobre sonifica&#231;&#227;o de dados de clima com Sonic Pi. Finalmente, outra coisa a se notar &#233; que o valor 'rand' (random, aleat&#243;rio) permite que se adiciona um pouco de 'humanidade' na m&#250;sica em termos de din&#226;micas. Ent&#227;o n&#243;s faremos a mesma coisa novamente para o topic2 (t&#243;pico2).</p>
<p>&#201; poss&#237;vel adicionar batidas, loops, amostras, e toda a parafern&#225;lia que o Sonic Pi permite. Onde voc&#234; coloca os seus peda&#231;os de c&#243;digo afeta a reprodu&#231;&#227;o, se os loops forem colocados antes dos dados acima, ele ser&#225; reproduzido primeiro. Por exemplo, se o trecho a seguir for inserido depois da linha <code rend="inline">use_bpm 100</code>,</p>
<ab><code xml:id="code_som-dados-sonificacao-historiadores_17" corresp="code_som-dados-sonificacao-historiadores_17.txt" rend="block"/></ab>
<p>Haver&#225; um pouco de uma introdu&#231;&#227;o na sua obra. H&#225; uma pausa de 2 segundos, a amostra 'ambi_choir' &#233; reproduzida, ent&#227;o h&#225; uma pausa de mais 6 segundos antes dos seus dados serem tocados. Se quiser adicionar um pouco de um som de bateria sinistro ao longo da sua obra, insira esse trecho a seguir (e antes de seus pr&#243;prios dados):</p>
<ab><code xml:id="code_som-dados-sonificacao-historiadores_18" corresp="code_som-dados-sonificacao-historiadores_18.txt" rend="block"/></ab>
<p>O c&#243;digo &#233; bem simples: realize um loop da amostra 'bd_boom' com o efeito de som de resson&#226;ncia, em um ritmo particular. Pause por 2 segundos entre os loops.</p>
<p>A prop&#243;sito, 'codifica&#231;&#227;o ao vivo'? O que torna esse ambiente um espa&#231;o de 'codifica&#231;&#227;o ao vivo' &#233; a possibilidade de se fazer altera&#231;&#245;es no c&#243;digo <emph>enquanto o Sonic Pi o transforma em m&#250;sica</emph>. N&#227;o gosta do que est&#225; ouvindo? Altere o c&#243;digo na hora!</p>
<p>Para mais sobre o Sonic Pi, <ref target="https://www.miskatonic.org/music/access2015/">esse site de workshop</ref> (em ingl&#234;s) &#233; um bom lugar para come&#231;ar. Veja tamb&#233;m o <ref target="http://library.gwu.edu/scholarly-technology-group/posts/sound-library-work">relat&#243;rio de Laura Wrubel sobre participar desse worksop, e o trabalho dela e de seus colegas na &#225;rea</ref> (em ingl&#234;s).</p>
</div>
      <div type="1"><head>Nihil Novi Sub Sole</head>
<p>Mais uma vez, para que n&#227;o pensemos que estamos na vanguarda atrav&#233;s da nossa gera&#231;&#227;o algor&#237;tmica de m&#250;sica, um lembrete foi publicado em 1978 sobre 'jogos de m&#250;sica de dados' no s&#233;culo XVIII, em que o lan&#231;amento de dados determinava a recombina&#231;&#227;o de trechos pr&#233;-escritos de m&#250;sica. <ref target="https://rbnrpi.wordpress.com/project-list/mozart-dice-generated-waltz-revisited-with-sonic-pi/">Alguns desses jogos foram explorados e recodificados para o Sonic-Pi por Robin Newman</ref>. Newman tamb&#233;m usa uma ferramenta que poderia ser descrita como um Markdown+Pandoc da  nota&#231;&#227;o musical, <ref target="http://www.lilypond.org/">Lilypond</ref> para pontuar essas composi&#231;&#245;es. Os antecedentes para tudo que pode ser encontrado no  <emph>The Programming Historian</emph> s&#227;o mais profundos do que se pode suspeitar!</p>
</div>
      <div type="1"><head>Conclus&#227;o</head>
<p>Sonificar os nossos dados nos faz confrontar os modos como os nossos dados s&#227;o, muitas vezes, n&#227;o sobre o passado, mas sobre o que constru&#237;mos dele. Isso ocorre em parte em virtude de sua novidade, e da arte e do artif&#237;cio necess&#225;rios para mapear os dados para o som. Mas isso tamb&#233;m acontece pelo contraste com as nossas no&#231;&#245;es pr&#233;-concebidas sobre visualiza&#231;&#227;o de dados. Pode ser que os sons gerados por algu&#233;m nunca cheguem ao n&#237;vel da 'm&#250;sica'; mas se ajudar a transformar como n&#243;s encontramos o passado, e como outros engajam com o passado, ent&#227;o o esfor&#231;o ter&#225; sido frut&#237;fero. Como Trevor Owens pode ter colocado, 'Sonifica&#231;&#227;o &#233; sobre <ref target="http://www.trevorowens.org/2012/11/discovery-and-justification-are-different-notes-on-sciencing-the-humanities/">descoberta, n&#227;o justifica&#231;&#227;o</ref>'.</p>
<h2>Termos</h2>
<list type="unordered">
<item><hi rend="bold">MIDI</hi>,<a name="midi"/> interface digital de instrumento musical. &#201; uma descri&#231;&#227;o do valor e do tempo de uma nota, n&#227;o de sua din&#226;mica ou de como algu&#233;m pode toc&#225;-la (esta &#233; uma distin&#231;&#227;o importante). Ele permite que computadores e instrumentos conversem entre si; pode-se aplicar instrumenta&#231;&#227;o diferente a um ficheiro MIDI da mesma forma que se mudaria a fonte em um peda&#231;o de texto (ou executar um ficheiro Markdown por meio do Pandoc).</item>
<item><hi rend="bold">MP3</hi>,<a name="mp3"/> formato de compress&#227;o que remove dados como parte de sua rotina de compacta&#231;&#227;o.</item>
<item><hi rend="bold">Tom</hi>,<a name="pitch"/> a  nota em si (C m&#233;dio, etc)</item>
<item><hi rend="bold">Ataque</hi>,<a name="attack"/> como a nota &#233; tocada ou atingida</item>
<item><hi rend="bold">Dura&#231;&#227;o</hi>,<a name="duration"/> quanto tempo a nota dura (notas inteiras, sem&#237;nimas, colcheias etc)</item>
<item><hi rend="bold">Mapeamento do Tom e Mapeamento da Dura&#231;&#227;o</hi>, <a name="pitch mapping"/> dimensionamento de valores de dados em rela&#231;&#227;o a um intervalo de notas ou a dura&#231;&#227;o da nota</item>
<item><hi rend="bold">Amplitude</hi>, <a name="amplitude"/> em resumo, o volume da nota</item>
</list>
</div>
      <div type="1"><head>Refer&#234;ncias</head>
<p><a name="Baio"/>Baio, Andy. 2015. 'If Drake Was Born A Piano'. Waxy. <ref target="https://waxy.org/2015/12/if_drake_was_born_a_piano/">http://waxy.org/2015/12/if_drake_was_born_a_piano/</ref></p>
<p><a name="Drucker"/>Drucker, Johanna. 2011. Humanities Approaches to Graphical Display. DHQ 5.1 <ref target="http://www.digitalhumanities.org/dhq/vol/5/1/000091/000091.html">http://www.digitalhumanities.org/dhq/vol/5/1/000091/000091.html</ref></p>
<p><a name="Hedges"/>Hedges, Stephen A. 1978. &#8220;Dice Music in the Eighteenth Century&#8221;. Music &amp; Letters 59 (2). Oxford University Press: 180&#8211;87. <ref target="http://www.jstor.org/stable/734136">http://www.jstor.org/stable/734136</ref>.</p>
<p><a name="Hermann"/>Hermann, T. 2008. "Taxonomy and definitions for sonification and auditory display". In P. Susini and O. Warusfel (eds.) Proceedings of the 14th international conference on auditory display (ICAD 2008). IRCAM, Paris. <ref target="http://www.icad.org/Proceedings/2008/Hermann2008.pdf">http://www.icad.org/Proceedings/2008/Hermann2008.pdf</ref></p>
<p><a name="Koebler"/>Koebler, Jason. 2015. "The Strange Acoustic Phenomenon Behind These Wacked-Out Versions of Pop Songs" Motherboard, Dec 18. <ref target="http://motherboard.vice.com/read/the-strange-acoustic-phenomenon-behind-these-wacked-out-versions-of-pop-songs">http://motherboard.vice.com/read/the-strange-acoustic-phenomenon-behind-these-wacked-out-versions-of-pop-songs</ref></p>
<p><a name="Last"/>Last and Usyskin, 2015. "Listen to the Sound of Data". In Aaron K. Baughman et al. (eds.) Multimedia Data Mining and Analytics. Springer: Heidelberg. Pp. 419-446 <ref target="https://www.researchgate.net/publication/282504359_Listen_to_the_Sound_of_Data">https://www.researchgate.net/publication/282504359_Listen_to_the_Sound_of_Data</ref></p>
</div>
    </body>
  </text>
</TEI>
