<TEI xmlns="http://www.tei-c.org/ns/1.0" xml:id="download-multiplos-registros-query-strings">
  <teiHeader>
 <fileDesc>
  <titleStmt>
   <title>Download de M&#250;ltiplos Registros usando Query Strings</title>
  <author type="original_author">Adam Crymble</author><editor type="reviewers"><persName>Luke Bergmann</persName><persName>Sharon Howard</persName><persName>Frederik Elwert</persName></editor><author type="translators">Felipe Lamarca</author><editor type="translation-reviewers"><persName>Andr&#233; Salvo</persName><persName>Aracele Torres</persName></editor><editor type="editors">Fred Gibbs</editor></titleStmt>
  <publicationStmt>
   <idno type="doi">10.46430/phpt0034</idno><date type="published">11/11/2012</date><date type="translated">11/25/2022</date><p>Lesson reviewed and published in Programming Historian.</p>
  </publicationStmt>
  <sourceDesc>
  <p>Born digital, in a markdown format. Original file: <ref type="original_file" target="#downloading-multiple-records-using-query-strings"/>.</p><p>There are other translations: <ref target="#descarga-multiples-registros-usando-cadenas-de-consulta"/></p></sourceDesc>
 </fileDesc>
 <profileDesc><abstract><p>Fazer o download de um &#250;nico registro de um website &#233; f&#225;cil, mas fazer o download de v&#225;rios registros de uma vez - uma necessidade cada vez mais frequente para um historiador - &#233; muito mais eficiente usando uma linguagem de programa&#231;&#227;o como o Python. Nessa li&#231;&#227;o, escreveremos um programa que far&#225; o download de uma s&#233;rie de registros do Old Bailey Online usando crit&#233;rios de busca personalizados e ir&#225; armazen&#225;-los num diret&#243;rio no nosso computador.</p></abstract><textClass><keyword xml:lang="en">web-scraping</keyword></textClass></profileDesc>
</teiHeader>
  <text xml:lang="pt">
    <body>
      <div type="2"><head>Objetivos do M&#243;dulo</head>
<p>Fazer o <emph>download</emph> de um &#250;nico registro de um website &#233; f&#225;cil, mas fazer o <emph>download</emph> de v&#225;rios registros de uma vez - uma necessidade cada vez mais frequente para um historiador - &#233; muito mais eficiente usando uma linguagem de programa&#231;&#227;o como o Python. Nesta li&#231;&#227;o, escreveremos um programa que far&#225; o <emph>download</emph> de uma s&#233;rie de registros do <emph><link target="http://www.oldbaileyonline.org/">Old Bailey Online</link></emph> usando crit&#233;rios de investiga&#231;&#227;o personalizados e ir&#225; armazen&#225;-los num diret&#243;rio no nosso computador. Esse processo envolve interpretar e manipular <emph>Query Strings</emph> de URL. Nesse caso, o tutorial buscar&#225; fazer o <emph>download</emph> de fontes que contenham refer&#234;ncias a afrodescendentes que foram publicadas no <emph>Old Bailey Proceedings</emph> entre 1700 e 1750.</p>
<p class="alert alert-warning" style="alert alert-warning">
Os exemplos nessa li&#231;&#227;o incluem linguagem hist&#243;rica racializada que os leitores podem achar ofensiva. O autor n&#227;o tolera o uso dessa linguagem, mas tentou us&#225;-la no seu contexto hist&#243;rico, reconhecendo que, de outra forma, &#233; imposs&#237;vel encontrar os materiais desejados do estudo de caso. Qualquer pessoa que ensine com este material &#233; aconselhada a adotar uma abordagem sens&#237;vel em rela&#231;&#227;o &#224; linguagem e a aplicar as boas pr&#225;ticas ao ensinar sobre ra&#231;a. O autor recomenda os muitos recursos do <link target="https://www.tolerance.org">Teaching Tolerance</link>; Peggy McIntosh, &#8216;White Privilege: Unpacking the Invisible Knapsack&#8217;, <i>Peace and Freedom Magazine</i>, (1989), 10-12; Binyavanga Wainaina, &#8216;How to Write About Africa&#8217;, <i>Granta</i> (92): 2006.
</p>
</div>
      <div type="2"><head>Para Quem isso &#233; &#218;til?</head>
<p>Automatizar o processo de <emph>download</emph> de registros de uma base de dados <emph>online</emph> ser&#225; &#250;til para qualquer um que trabalhe com fontes hist&#243;ricas armazenadas <emph>online</emph> de forma ordenada e acess&#237;vel e que deseje salvar c&#243;pias dessas fontes no seu pr&#243;prio computador. &#201; particularmente &#250;til para algu&#233;m que deseja fazer o <emph>download</emph> de v&#225;rios registros espec&#237;ficos, em vez de apenas um punhado. Caso deseje fazer o <emph>download</emph> de <emph>todos</emph> ou da <emph>maioria</emph> dos registros de uma base de dados em particular, pode achar o tutorial de Ian Milligan sobre <link target="/en/lessons/automated-downloading-with-wget">Automated Downloading with WGET</link> mais adequado.</p>
<p>O presente tutorial permitir&#225; que fa&#231;a <emph>download</emph> de forma isolada e discriminada de registros espec&#237;ficos que atendam &#224;s suas necessidades. Fazer o <emph>download</emph> de m&#250;ltiplas fontes de forma autom&#225;tica economiza um tempo consider&#225;vel. O que faz com as fontes baixadas depende dos seus objetivos de investiga&#231;&#227;o. Pode desejar criar visualiza&#231;&#245;es ou realizar uma s&#233;rie de m&#233;todos de an&#225;lise de dados, ou simplesmente reformat&#225;-las para facilitar a navega&#231;&#227;o. Ou pode desejar apenas manter uma c&#243;pia de <emph>backup</emph> para poder acess&#225;-las sem acesso &#224; internet.</p>
<p>Essa li&#231;&#227;o &#233; voltada para usu&#225;rios de Python com n&#237;vel intermedi&#225;rio. Caso ainda n&#227;o tenha tentado as li&#231;&#245;es do <link target="/pt/licoes/introducao-instalacao-python">B&#225;sico de Programa&#231;&#227;o em Python</link>, pode ach&#225;-las um ponto de partida &#250;til.</p>
</div>
      <div type="2"><head>Aplicando nosso Conhecimento Hist&#243;rico</head>
<p>Nesta li&#231;&#227;o, estamos tentando criar o nosso pr&#243;prio corpus de casos relacionados com pessoas afrodescendentes. A partir do <link target="http://www.oldbaileyonline.org/browse.jsp?id=t17800628-33&amp;div=t17800628-33">caso de Benjamin Bowsey</link> no <emph>Old Bailey</emph> em 1780, podemos notar que "<emph>black</emph>" pode ser uma palavra-chave &#250;til para usarmos para localizar outros casos envolvendo r&#233;us de ascend&#234;ncia africana. No entanto, quando buscamos por <emph>black</emph> no <emph>website</emph> do <emph>Old Bailey</emph>, percebemos que esta palavra &#224;s vezes se refere a outros usos: <emph>black horses</emph> ou <emph>black cloth</emph>. A tarefa de desambiguar esse uso da linguagem ter&#225; que esperar por outra li&#231;&#227;o. Por enquanto, vamos nos voltar para casos mais f&#225;ceis. Como historiadores, provavelmente, podemos pensar em palavras-chave de termos historicamente racializados relacionados com afrodescendentes as quais valeria a pena buscar. A infame "<emph>n-word</emph>", &#233; claro, n&#227;o &#233; &#250;til, j&#225; que esse termo n&#227;o era comumente utilizado at&#233; meados do s&#233;culo XIX. Outras express&#245;es racializadas como "<emph>negro</emph>" e "<emph>mulatto</emph>" s&#227;o, por&#233;m, muito mais relevantes para o in&#237;cio do s&#233;culo XVIII. Essas palavras-chave s&#227;o menos amb&#237;guas do que "<emph>black</emph>" e s&#227;o muito mais propensas a serem refer&#234;ncias imediatas a pessoas no nosso p&#250;blico-alvo. Se testarmos esses dois termos em buscas separadas simples no <emph>Old Bailey website</emph>, temos resultados como nessa captura de tela:</p>
<figure><desc>Resultados de investiga&#231;&#227;o para 'negro' no *Old Bailey Online*</desc><graphic url="SearchResultsNegro.png"/></figure>
<figure><desc>Resultados de investiga&#231;&#227;o para 'mulatto' no *Old Bailey Online*</desc><graphic url="SearchResultsMulatto.png"/></figure>
<p>Depois de examinar estes resultados de busca, parece evidente que s&#227;o refer&#234;ncias a pessoas e n&#227;o a cavalos, panos ou qualquer outra coisa que seja preta. Desejamos fazer o <emph>download</emph> de todas para usar na nossa an&#225;lise. Poder&#237;amos, &#233; claro, fazer o <emph>download</emph> de uma por uma manualmente. Mas vamos encontrar uma maneira program&#225;tica de automatizar essa tarefa.</p>
</div>
      <div type="2"><head>A Investiga&#231;&#227;o Avan&#231;ada no OBO</head>
<p>As ferramentas de pesquisa de cada <emph>site</emph> funcionam de maneira diferente. Embora as pesquisas funcionem de forma semelhante, as complexidades das pesquisas numa base de dados podem n&#227;o ser totalmente &#243;bvias. Portanto, &#233; importante pensar criticamente sobre as op&#231;&#245;es de busca de uma base de dados e, quando dispon&#237;vel, ler a documenta&#231;&#227;o fornecida pelo <emph>website</emph>. Investigadores de hist&#243;ria prudentes sempre interrogam suas fontes; os procedimentos por tr&#225;s das suas caixas de pesquisa devem receber a mesma aten&#231;&#227;o. O <link target="http://www.oldbaileyonline.org/forms/formMain.jsp">formul&#225;rio de busca avan&#231;ada</link> do <emph>Old Bailey Online</emph> permite refinar as suas buscas com base em dez campos diferentes, incluindo palavras-chave simples, um intervalo de datas e um tipo de crime. Como as ferramentas de busca de cada <emph>website</emph> s&#227;o diferentes, vale sempre a pena reservar um momento ou dois para testar e ler a respeito das op&#231;&#245;es de investiga&#231;&#227;o dispon&#237;veis. Uma vez que j&#225; fizemos buscas simples por "<emph>negro</emph>" e "<emph>mulatto</emph>", sabemos que haver&#225; resultados. No entanto, vamos usar a busca avan&#231;ada para limitar os nossos resultados aos registros publicados no <emph>Old Bailey Proceedings</emph> que dizem respeito a julgamentos apenas de 1700 at&#233; 1750. &#201; claro que pode alter&#225;-lo para o que desejar, mas isso tornar&#225; o exemplo mais simples de ser acompanhado. Fa&#231;a a busca mostrada na imagem abaixo. Certifique-se de que marcou o bot&#227;o "<emph>Advanced</emph>" e incluiu as <emph>wildcards</emph> <code type="inline">*</code> para incluir entradas pluralizadas ou com um "e" extra no final.</p>
<figure><desc>Exemplo de Busca Avan&#231;ada no *Old Bailey*</desc><graphic url="AdvancedSearchExample.png"/></figure>
<p>Execute a busca e depois clique no <emph>link</emph> "<emph>Calculate Total</emph>" para ver quantas entradas existem. Agora temos 13 resultados (caso tenha um n&#250;mero diferente, volte e certifique-se de que copiou o exemplo acima da forma exata). O que queremos fazer neste ponto &#233; o <emph>download</emph> de todos esses ficheiros de julgamento e analiz&#225;-los mais profundamente. Mais uma vez, para apenas 13 registros, tamb&#233;m pode fazer o <emph>download</emph> de cada registro manualmente. Mas &#224; medida que mais e mais dados s&#227;o disponibilizados <emph>online</emph>, torna-se mais comum a necessidade de baixar 1.300 ou at&#233; 130.000 registros, caso no qual o <emph>download</emph> individual dos registros se torna impratic&#225;vel e entender como automatizar o processo se torna muito valioso. Para automatizar o processo, precisamos de dar um passo atr&#225;s e lembrar como as URLs de busca s&#227;o criadas no <emph>Old Bailey website</emph>, um m&#233;todo comum para muitas bases de dados <emph>online</emph> e <emph>websites</emph>.</p>
</div>
      <div type="2"><head>Entendendo <emph>Queries</emph> de URL</head>
<p>Observe a URL produzida com a &#250;ltima p&#225;gina de resultado de busca. Ela deve se parecer com isso:</p>
<pre><code xml:id="code_download-multiplos-registros-query-strings_0" type="block" corresp="code_download-multiplos-registros-query-strings_0.txt"/></pre>
<p>Vimos sobre URLs em <link target="/pt/licoes/nocoes-basicas-paginas-web-html">No&#231;&#245;es b&#225;sicas de p&#225;ginas web e HTML</link>, mas isso parece muito mais complexo. Ainda que mais longo, <emph>n&#227;o</emph> &#233; verdadeiramente muito mais complexo. Mas &#233; mais f&#225;cil de entender observando como os nossos crit&#233;rios de busca s&#227;o representados na URL.</p>
<pre><code xml:id="code_download-multiplos-registros-query-strings_1" type="block" corresp="code_download-multiplos-registros-query-strings_1.txt"/></pre>
<p>Nessa vis&#227;o, vemos com mais clareza as 12 informa&#231;&#245;es importantes que precisamos para realizar a nossa busca (uma por linha). Na primeira h&#225; a URL base do <emph>Old Bailey website</emph>, seguida por uma query "?" (n&#227;o se preocupe com o <emph>bit</emph> <code type="inline">gen=1</code>; os desenvolvedores do <emph>Old Bailey Online</emph> dizem que ele n&#227;o faz nada) e uma s&#233;rie de 10 pares <emph>nome/valor</emph> unidos por caracteres <code type="inline">&amp;</code>. Juntos, esses 10 pares de nome/valor comp&#245;em a <emph>query string</emph> (express&#227;o de busca), que informa ao mecanismo de busca quais vari&#225;veis usar em etapas espec&#237;ficas da investiga&#231;&#227;o. Observe que cada par nome/valor cont&#233;m um nome de vari&#225;vel: <code type="inline">toYear</code> e, em seguida, atribui a essa vari&#225;vel um valor: <code type="inline">1750</code>. Isso funciona exatamente da mesma forma que os <emph>Argumentos de Fun&#231;&#227;o</emph>, passando certas informa&#231;&#245;es para vari&#225;veis espec&#237;ficas. Nesse caso, a vari&#225;vel mais importante &#233; <code type="inline">_divs_fulltext=</code>, para a qual foi dado o valor:</p>
<pre><code xml:id="code_download-multiplos-registros-query-strings_2" type="block" corresp="code_download-multiplos-registros-query-strings_2.txt"/></pre>
<p>Esta cont&#233;m o termo que digitamos na caixa de busca. O programa adicionou automaticamente um sinal de soma <code type="inline">+</code> no lugar de um espa&#231;o em branco (URLs n&#227;o podem conter espa&#231;amentos); dito de outro modo, isso &#233; exatamente o que pedimos que o <emph>site</emph> do <emph>Old Bailey</emph> encontrasse. As outras vari&#225;veis carregam valores que n&#243;s tamb&#233;m definimos. <code type="inline">fromYear</code> e <code type="inline">toYear</code> cont&#233;m o nosso intervalo de datas. J&#225; que nenhum ano possui 99 meses, como sugerido na vari&#225;vel <code type="inline">toMonth</code>, podemos assumir que esse seja o modo atrav&#233;s do qual o algoritmo garante que todos os registros daquele ano s&#227;o inclu&#237;dos. N&#227;o h&#225; regras dif&#237;ceis ou r&#225;pidas para descobrir o que cada vari&#225;vel faz, porque a pessoa que criou o site as nomeou. Muitas vezes pode fazer uma suposi&#231;&#227;o razo&#225;vel. Todos os campos de busca poss&#237;veis na p&#225;gina de busca avan&#231;ada possuem os seus pr&#243;prios pares nome/valor. Caso deseje descobrir o nome da vari&#225;vel de modo a que possa utiliz&#225;-la, fa&#231;a uma nova busca e certifique-se de colocar um valor no campo no qual est&#225; interessado. Ap&#243;s submeter a sua busca, ver&#225; o seu valor e o nome associado a ele como parte da URL da p&#225;gina dos resultados de busca. Com o <emph>Old Bailey Online</emph>, assim como com noutros <emph>websites</emph>, o formul&#225;rio de busca (avan&#231;ada ou n&#227;o) ajuda, essencialmente, a construir URLs que informam &#224; base de dados o que est&#225; buscando. Se puder entender como os campos de busca est&#227;o representados no URL - o que geralmente &#233; algo bem direto -, ent&#227;o torna-se relativamente simples construir esses URLs programaticamente e automatizar o processo de <emph>download</emph> de registros.</p>
<p>Agora tente alterar o <code type="inline">start=0</code> para <code type="inline">start=10</code> e pressione <code type="inline">enter</code>. Deve agora ter os resultados 11-13. A vari&#225;vel <code type="inline">start</code> informa ao <emph>website</emph> qual a entrada que deve ser mostrada no in&#237;cio da lista de resultados de busca. N&#243;s devemos ser capazes de utilizar esse conhecimento para criar uma s&#233;rie de URLs que nos permitir&#227;o fazer o <emph>download</emph> de todos os 13 ficheiros. Vamos nos voltar para isso agora.</p>
</div>
      <div type="2"><head>Fazendo o <emph>Download</emph> de Ficheiros Sistematicamente</head>
<p>Na li&#231;&#227;o <link target="/pt/licoes/download-paginas-web-python">Download de P&#225;ginas Web com Python</link>, aprendemos que o Python pode fazer o <emph>download</emph> de uma p&#225;gina web desde que tenhamos a URL. Naquela li&#231;&#227;o, usamos a URL para fazer o <emph>download</emph> da transcri&#231;&#227;o do julgamento de Benjamin Bowsey. Nesse caso, estamos tentando fazer o <emph>download</emph> de m&#250;ltiplas transcri&#231;&#245;es de julgamentos que atendem aos crit&#233;rios de busca descritos acima sem precisar executar o programa repetidamente. Ao inv&#233;s disso, queremos um programa que fa&#231;a o <emph>download</emph> de tudo de uma vez. Neste ponto, temos a URL para a p&#225;gina de resultados de busca que cont&#233;m as 10 primeiras entradas na nossa investiga&#231;&#227;o. Tamb&#233;m sabemos que ao mudarmos o valor de <code type="inline">start</code> na URL, podemos sequencialmente chamar cada uma das p&#225;ginas de resultados de busca e finalmente recuperar todos os ficheiros de julgamento que elas possuem. &#201; claro que os resultados de busca n&#227;o nos oferecem os ficheiros do julgamento em si, mas apenas <emph>links</emph> para eles. Ent&#227;o precisamos de extrair esses <emph>links</emph> para os registros subjacentes dos resultados de busca. No <emph>Old Bailey Online website</emph>, as URLs para os registros individuais (os ficheiros de transcri&#231;&#227;o de julgamento) podem ser encontrados como <emph>links</emph> na p&#225;gina de resultados de busca. Sabemos que todas as transcri&#231;&#245;es de julgamento possuem um id de julgamento que assume a forma: "t" seguido por, pelo menos, 8 n&#250;meros (ex.: t17800628-33). Ao buscar <emph>links</emph> que contenham esse padr&#227;o, podemos identificar URLs de transcri&#231;&#227;o de julgamento. Como em li&#231;&#245;es anteriores, vamos desenvolver um algoritmo de modo a que possamos come&#231;ar a enfrentar esse problema de uma maneira que o computador possa lidar. Parece que a tarefa pode ser realizada em 4 passos. Precisaremos:</p>
<ul>
<li>Gerar as URLs para cada p&#225;gina de resultados de busca incrementando a vari&#225;vel <code type="inline">start</code> numa quantidade fixa um n&#250;mero apropriado de vezes.</li>
<li>Fazer o <emph>download</emph> de cada p&#225;gina de resultados de busca como um ficheiro HTML.</li>
<li>Extrair os URLs de cada transcri&#231;&#227;o de julgamento (usando o ID do julgamento como descrito acima) de cada ficheiro HTML de resultados de busca. </li>
<li>Percorrer essas URLs extra&#237;das para baixar cada transcri&#231;&#227;o de avalia&#231;&#227;o e salv&#225;-las num diret&#243;rio no nosso computador.</li>
</ul>
<p>Perceber&#225; que isso &#233; razoavelmente similiar &#224;s tarefas que realizamos em <link target="/pt/licoes/download-paginas-web-python">Download de P&#225;ginas Web com Python</link> e <link target="/pt/licoes/HTML-lista-palavras-2">De HTML para Lista de Palavras (parte 2)</link>. Primeiro, fazemos o <emph>download</emph> e, ent&#227;o, analisamos as informa&#231;&#245;es que procuramos. E, nesse caso, fazemos mais alguns <emph>downloads</emph>.</p>
</div>
      <div type="2"><head>Fazendo o <emph>Download</emph> das P&#225;ginas de Resultados de Busca</head>
<p>Primeiro, precisamos de gerar as URLs para fazer o download de cada p&#225;gina de resultados de busca. J&#225; temos a primeira usando a forma do pr&#243;prio <emph>website</emph>.</p>
<pre><code xml:id="code_download-multiplos-registros-query-strings_3" type="block" corresp="code_download-multiplos-registros-query-strings_3.txt"/></pre>
<p>Poder&#237;amos escrever essa URL duas vezes e alterar a vari&#225;vel <code type="inline">start</code> para obter todas as 13 entradas, mas vamos escrever um programa que funcionaria independentemente de quantas p&#225;ginas de resultados de busca ou registros precis&#225;ssemos de fazer <emph>download</emph>, n&#227;o importando o que decid&#237;ssemos investigar. Estude esse c&#243;digo e, depois, adicione essa fun&#231;&#227;o ao seu m&#243;dulo chamado <code type="inline">obo.py</code> (crie um ficheiro com esse nome e armazene-o no diret&#243;rio onde deseja trabalhar). Os coment&#225;rios no c&#243;digo destinam-se a ajud&#225;-lo a decifrar as v&#225;rias partes.</p>
<pre><code class="language-python" xml:id="code_download-multiplos-registros-query-strings_4" type="block" corresp="code_download-multiplos-registros-query-strings_4.txt"/></pre>
<p>Nessa fun&#231;&#227;o, separamos os v&#225;rios componentes da <emph>Query String</emph> e usamos Argumentos de Fun&#231;&#227;o para que a fun&#231;&#227;o possa ser reutilizada al&#233;m dos nossos objetivos espec&#237;ficos atuais. Quando chamarmos por essa fun&#231;&#227;o, substituiremos os argumentos pelos valores que desejamos buscar. Depois, fazemos o <emph>download</emph> das p&#225;ginas dos resultados de busca de maneira similiar a como foi feito em <link target="/pt/licoes/download-paginas-web-python">Download de P&#225;ginas Web com Python</link>. Agora, crie um novo ficheiro: <code type="inline">download-searches.py</code> e copie o c&#243;digo a seguir dentro dele. Observe: os valores que passamos como argumentos s&#227;o exatamente os mesmos dos utilizados no exemplo acima. Sinta-se livre para test&#225;-los para receber resultados diferentes ou ver como funcionam.</p>
<pre><code class="language-python" xml:id="code_download-multiplos-registros-query-strings_5" type="block" corresp="code_download-multiplos-registros-query-strings_5.txt"/></pre>
<p>Quando executar esse c&#243;digo, deve encontrar um novo ficheiro: <code type="inline">search-result.html</code> no seu <code type="inline">diret&#243;rio programming-historian</code> contendo a primeira p&#225;gina dos resultados de busca da sua investiga&#231;&#227;o. Certifique-se de que o <emph>download</emph> foi realizado apropriadamente e apague o ficheiro. Vamos adaptar o nosso programa para fazer o <emph>download</emph> da outra p&#225;gina contendo as outras 3 entradas ao mesmo tempo, assim queremos ter certeza que obteremos as duas. Vamos refinar a nossa fun&#231;&#227;o <code type="inline">getSearchResults</code> adicionando outro argumento de fun&#231;&#227;o chamado <code type="inline">entries</code>, de modo a que possamos dizer ao programa quantas p&#225;ginas de resultados de busca precisamos fazer o <emph>download</emph>. Usaremos o valor das entradas e matem&#225;tica simples para determinar quantas p&#225;ginas de resultado de busca existem. Isso &#233; algo bastante direto uma vez que sabemos que h&#225; dez transcri&#231;&#245;es de julgamento listadas por p&#225;gina. Podemos calcular o n&#250;mero de p&#225;ginas de resultados de busca dividindo o valor das entradas por 10. Armazenaremos esse resultado na vari&#225;vel chamada <code type="inline">pageCount</code>. Ela se parecer&#225; com isso:</p>
<pre><code class="language-python" xml:id="code_download-multiplos-registros-query-strings_6" type="block" corresp="code_download-multiplos-registros-query-strings_6.txt"/></pre>
<p>No entanto, em casos em que o n&#250;mero de entradas n&#227;o &#233; um m&#250;ltiplo de 10, isso resultar&#225; num n&#250;mero decimal. Pode test&#225;-lo executando esse c&#243;digo no seu Terminal (Mac &amp; Linux) / Linha de Comandos Python (Windows) e exibindo o valor mantido em <code type="inline">pageCount</code>. (Observe que, daqui em diante, usaremos a palavra Terminal para referir esse programa).</p>
<pre><code class="language-python" xml:id="code_download-multiplos-registros-query-strings_7" type="block" corresp="code_download-multiplos-registros-query-strings_7.txt"/></pre>
<p>Sabemos que a contagem do n&#250;mero de p&#225;gina deve ser 2 (uma p&#225;gina contendo as entradas 1-10 e uma p&#225;gina contendo as entradas 11-13). Uma vez que sempre queremos o maior inteiro mais pr&#243;ximo, podemos arredondar o resultado da divis&#227;o.</p>
<pre><code class="language-python" xml:id="code_download-multiplos-registros-query-strings_8" type="block" corresp="code_download-multiplos-registros-query-strings_8.txt"/></pre>
<p>Se adicionarmos isso &#224; nossa fun&#231;&#227;o <code type="inline">getSearchResults</code> abaixo da linha <code type="inline">startValue=0</code>, agora o c&#243;digo &#233; capaz de calcular o n&#250;mero de p&#225;ginas cujo <emph>download</emph> precisa de ser realizado. No entanto, nesta etapa ele ir&#225; fazer somente o <emph>download</emph> da primeira p&#225;gina, j&#225; que informamos &#224; se&#231;&#227;o de <emph>download</emph> da fun&#231;&#227;o para executar somente uma vez. Para corrigir isso, podemos adicionar o c&#243;digo de <emph>download</emph> a um <code type="inline">for</code> <emph>loop</emph> que far&#225; o <emph>download</emph> uma vez para cada n&#250;mero na vari&#225;vel <code type="inline">pageCount</code>. Caso ele leia 1, far&#225; o <emph>download</emph> uma vez; caso ele leia 5, far&#225; o <emph>download</emph> cinco vezes e assim por diante. Imediatamente ap&#243;s o <code type="inline">if</code> <emph>statement</emph> que acabou de escrever, adicione a linha a seguir e indente tudo antes de <code type="inline">f.close</code> com um espa&#231;amento adicional de modo que tudo fique dentro do <code type="inline">for</code> <emph>loop</emph>:  </p>
<pre><code class="language-python" xml:id="code_download-multiplos-registros-query-strings_9" type="block" corresp="code_download-multiplos-registros-query-strings_9.txt"/></pre>
<p>Uma vez que isso &#233; um <code type="inline">for</code> <emph>loop</emph>, todo o c&#243;digo que desejamos executar repetidamente tamb&#233;m precisa de ser planejado. Pode-se certificar de que fez isso corretamente verificando o c&#243;digo finalizado no exemplo abaixo. Esse <emph>loop</emph> aproveita a fun&#231;&#227;o <link target="https://docs.python.org/3/tutorial/controlflow.html#the-range-function">range</link> do Python. Para entender esse <code type="inline">for</code> <emph>loop</emph> &#233; melhor, provavelmente, pensar em <code type="inline">pageCount</code> igual a 2 como no exemplo. Portanto, essas duas linhas de c&#243;digo significam: comece a executar com um valor de <emph>loop</emph> inicial 1 e, a cada vez que executar, adicione uma unidade a esse valor. Quando o valor do <emph>loop</emph> &#233; o mesmo de <code type="inline">pageCount</code>, executa mais uma vez e para. Isso &#233; particularmente valioso porque significa que podemos dizer ao nosso programa para executar exatamente uma vez para cada p&#225;gina de resultados de busca e oferece uma nova habilidade flex&#237;vel para controlar quantas vezes um <code type="inline">for</code> <emph>loop</emph> &#233; executado. Caso deseje praticar essa nova e poderosa maneira de escrever <emph>loops</emph>, pode abrir o seu Terminal e brincar.</p>
<pre><code class="language-python" xml:id="code_download-multiplos-registros-query-strings_10" type="block" corresp="code_download-multiplos-registros-query-strings_10.txt"/></pre>
<p>Antes de adicionar todo esse c&#243;digo &#224; nossa fun&#231;&#227;o <code type="inline">getSearchResults</code>, temos que fazer dois ajustes finais. No final do <code type="inline">for</code> <emph>loop</emph> (mas ainda dentro do <emph>loop</emph>) e depois que o nosso c&#243;digo de <emph>download</emph> for executado, precisamos de mudar nossa vari&#225;vel <code type="inline">startValue</code>, que &#233; usada na constru&#231;&#227;o da URL da p&#225;gina que desejamos fazer o <emph>download</emph>. Se nos esquecermos de fazer isso, o nosso programa far&#225; repetidamente o <emph>download</emph> da primeira p&#225;gina de resultados de busca, j&#225; que n&#227;o estamos verdadeiramente mudando nada na URL inicial. A vari&#225;vel <code type="inline">startValue</code>, como discutido acima, &#233; o que controla em que p&#225;gina de resultados de busca desejamos fazer o <emph>download</emph>. Portanto, podemos solicitar a pr&#243;xima p&#225;gina de resultados de busca incrementando o valor de <code type="inline">startvalue</code> em 10 unidades depois que o <emph>download</emph> inicial for conclu&#237;do. Caso n&#227;o tenha certeza de onde adicionar essa linha, pode espiar adiante o c&#243;digo finalizado no exemplo abaixo.</p>
<p>Finalmente, queremos garantir que os nomes do ficheiros que fizemos o <emph>download</emph> s&#227;o diferentes entre si. De outro modo, cada <emph>download</emph> ser&#225; armazenado em cima do <emph>download</emph> anterior, deixando apenas um &#250;nico ficheiro de resultados de busca. Para resolver isso, podemos ajustar os conte&#250;dos da vari&#225;vel <code type="inline">filename</code> para incluir o valor armazenado em <code type="inline">startValue</code> de modo que a cada vez que fizermos o <emph>download</emph> de uma nova p&#225;gina, ela recebe um nome diferente. J&#225; que a vari&#225;vel <code type="inline">startValue</code> &#233; um inteiro, precisaremos de convert&#234;-la para uma string antes de adicion&#225;-la &#224; vari&#225;vel <code type="inline">filename</code>. Ajuste a linha no seu programa que pertence &#224; vari&#225;vel <code type="inline">filename</code> para ficar assim:</p>
<pre><code class="language-python" xml:id="code_download-multiplos-registros-query-strings_11" type="block" corresp="code_download-multiplos-registros-query-strings_11.txt"/></pre>
<p>Agora deve ser capaz de adicionar essas novas linhas de c&#243;digo &#224; sua fun&#231;&#227;o <code type="inline">getSearchResults</code>. Lembre-se de que fizemos as adi&#231;&#245;es a seguir:</p>
<ul>
<li>Adicionar <code type="inline">entries</code> como um argumento de fun&#231;&#227;o adicional logo depois de <code type="inline">toMonth</code></li>
<li>Calcular o n&#250;mero de p&#225;ginas de resultados de pesquisa e adicionar isso imediatamente ap&#243;s a linha que come&#231;a com <code type="inline">startValue = 0</code> (antes de construirmos a URL e come&#231;armos o <emph>download</emph>)</li>
<li>Imediatamente ap&#243;s isso, adicione um <code type="inline">for</code> <emph>loop</emph> que informar&#225; ao programa para executar uma vez para cada p&#225;gina de resultados de busca, e indentar o resto do c&#243;digo de modo a que ele esteja dentro do novo <emph>loop</emph></li>
<li>A &#250;ltima linha no <code type="inline">for</code> <emph>loop</emph> deve agora incrementar o valor da vari&#225;vel <code type="inline">startValue</code> a cada vez que o <emph>loop</emph> &#233; executado</li>
<li>Ajustar a vari&#225;vel <code type="inline">filename</code> existente de modo que a cada vez que for feito o <emph>download</emph> de uma p&#225;gina de resultados de busca ela forne&#231;a um nome &#250;nico ao ficheiro.</li>
</ul>
<p>A fun&#231;&#227;o finalizada no seu ficheiro <code type="inline">obo.py</code> deve-se parecer com isso:</p>
<pre><code class="language-python" xml:id="code_download-multiplos-registros-query-strings_12" type="block" corresp="code_download-multiplos-registros-query-strings_12.txt"/></pre>
<p>Para executar essa nova fun&#231;&#227;o, adicione o argumento extra ao <code type="inline">download-searches.py</code> e execute o programa novamente:</p>
<pre><code class="language-python" xml:id="code_download-multiplos-registros-query-strings_13" type="block" corresp="code_download-multiplos-registros-query-strings_13.txt"/></pre>
<p>&#211;timo! Agora temos as duas p&#225;ginas de resultados de busca, chamadas <code type="inline">search-result0.html</code> e <code type="inline">search-result10.html</code>. Mas antes de seguirmos para o pr&#243;ximo passo do algoritmo, vamos cuidar de algumas "tarefas de organiza&#231;&#227;o". O nosso diret&#243;rio <code type="inline">programming-historian</code> rapidamente se tornar&#225; dif&#237;cil de controlar se fizermos o <emph>download</emph> de m&#250;ltiplas p&#225;ginas de resultados de busca e transcri&#231;&#245;es de julgamento. Vamos fazer com que o Python crie um novo diret&#243;rio nomeado a partir dos nossos termos de busca. </p>
<p>Desejamos adicionar essa nova funcionalidade em <code type="inline">getSearchResults</code>, de modo que os <emph>downloads</emph> das nossas p&#225;ginas de resultados de busca sejam direcionadas a diret&#243;rios com o mesmo nome da nossa <emph>query</emph> de busca. Isso manter&#225; o nosso diret&#243;rio <code type="inline">programming-historian</code> mais organizado. Para faz&#234;-lo, criaremos um novo diret&#243;rio usando a biblioteca <code type="inline">os</code>, abrevia&#231;&#227;o de "<emph>operating system</emph>" (sistema operacional). Essa biblioteca cont&#233;m uma fun&#231;&#227;o chamada <code type="inline">makedirs</code> que, n&#227;o surpreendentemente, cria um novo diret&#243;rio. Pode testar usando o Terminal:</p>
<pre><code class="language-python" xml:id="code_download-multiplos-registros-query-strings_14" type="block" corresp="code_download-multiplos-registros-query-strings_14.txt"/></pre>
<p>Esse programa ir&#225; verificar se o seu computador j&#225; possui um diret&#243;rio com esse nome. Caso n&#227;o possua, agora deve possuir um diret&#243;rio chamado <code type="inline">meuNovoDiret&#243;rio</code> no seu computador. Num Mac provavelmente est&#225; localizado no seu diret&#243;rio <code type="inline">/Users/username/</code>, e no Windows deve ser capaz de encontr&#225;-lo no diret&#243;rio <code type="inline">Python</code> no seu computador, o mesmo no qual abriu o programa da linha de comandos. Se isso funcionou, pode deletar o diret&#243;rio do seu disco r&#237;gido, j&#225; que isso foi s&#243; uma pr&#225;tica. Uma vez que desejamos criar um novo diret&#243;rio nomeado a partir da <emph>query</emph> que inserimos no <emph>Old Bailey Online website</emph>, vamos usar diretamente esse argumento de fun&#231;&#227;o <code type="inline">query</code> da fun&#231;&#227;o <code type="inline">getSearchResults</code>. Para fazer isso, importe a biblioteca <code type="inline">os</code> ap&#243;s as outras e, depois, adicione o c&#243;digo que acabou de escrever imediatamente abaixo. A sua fun&#231;&#227;o <code type="inline">getSearchResults</code> deve agora se parecer com isso:</p>
<pre><code class="language-python" xml:id="code_download-multiplos-registros-query-strings_15" type="block" corresp="code_download-multiplos-registros-query-strings_15.txt"/></pre>
<p>O &#250;ltimo passo para essa fun&#231;&#227;o &#233; garantir que, quando salvarmos as nossas p&#225;ginas de resultados de busca, as armazenaremos nesse novo diret&#243;rio. Para fazer isso, podemos fazer um pequeno ajuste &#224; vari&#225;vel <code type="inline">filename</code> de modo a que o ficheiro termine no lugar certo. H&#225; muitas formas de o fazer e a mais f&#225;cil &#233; simplesmente adicionar o nome do novo diret&#243;rio mais uma barra no nome do ficheiro:</p>
<pre><code class="language-python" xml:id="code_download-multiplos-registros-query-strings_16" type="block" corresp="code_download-multiplos-registros-query-strings_16.txt"/></pre>
<p>Caso o seu computador esteja executando o Windows, precisar&#225; de uma barra invertida em vez da barra do exemplo acima. Adicione a linha acima &#224; sua fun&#231;&#227;o <code type="inline">getSearchResults</code> no lugar da descri&#231;&#227;o atual do <code type="inline">filename</code>.</p>
<p>Se estiver executando o Windows, &#233; prov&#225;vel que o seu programa <code type="inline">downloadSearches.py</code> falhe quando o executar porque est&#225; tentando criar um diret&#243;rio com um * nele. O Windows n&#227;o gosta disso. Para resolver esse problema podemos usar <link target="https://docs.python.org/3/library/re.html">express&#245;es regulares</link> para remover qualquer caractere n&#227;o compat&#237;vel com o Windows. Usamos express&#245;es regulares anteriormente em <link target="/pt/licoes/contar-frequencias-palavras-python">Contagem de Frequ&#234;ncias de Palavras com Python</link>. Para remover caracteres n&#227;o-alfanum&#233;ricos da <emph>query</emph>, primeiro importe a biblioteca de express&#245;es regulares imediatamente ap&#243;s importar a biblioteca <code type="inline">os</code> e, depois, use a fun&#231;&#227;o <code type="inline">re.sub()</code> para criar uma nova string chamada <code type="inline">cleanQuery</code> que cont&#233;m apenas caracteres alfanum&#233;ricos. Depois precisar&#225; de substituir <code type="inline">cleanQuery</code> como a vari&#225;vel usada nas declara&#231;&#245;es de <code type="inline">os.path.exists()</code>, <code type="inline">os.makedirs()</code> e <code type="inline">filename</code>.</p>
<pre><code class="language-python" xml:id="code_download-multiplos-registros-query-strings_17" type="block" corresp="code_download-multiplos-registros-query-strings_17.txt"/></pre>
<p>A vers&#227;o final da sua fun&#231;&#227;o deve-se parecer com isso:</p>
<pre><code class="language-python" xml:id="code_download-multiplos-registros-query-strings_18" type="block" corresp="code_download-multiplos-registros-query-strings_18.txt"/></pre>
<p>Dessa vez dizemos ao programa para fazer o <emph>download</emph> dos julgamentos e armazen&#225;-los num novo diret&#243;rio ao inv&#233;s do nosso diret&#243;rio <code type="inline">programming-historian</code>. Execute o programa <code type="inline">download-searches.py</code> mais uma vez para se certificar de que ele funcionou e que entendeu como armazenar os ficheiros num diret&#243;rio particular usando Python.</p>
<div type="3"><head>Fazendo o <emph>Download</emph> das Entradas de Julgamento Individuais</head>
<p>A este ponto, criamos uma fun&#231;&#227;o que &#233; capaz de fazer o <emph>download</emph> de todos os ficheiros HTML de resultados de busca a partir do website <emph>Old Bailey Online</emph> para uma busca avan&#231;ada que definimos e desenvolvemos de forma program&#225;tica. Agora o pr&#243;ximo passo do algoritmo: extrair as URLs de cada transcri&#231;&#227;o de julgamento dos ficheiros HTML de resultados de busca. Nas li&#231;&#245;es que precedem esta (ex.: <link target="/pt/licoes/download-paginas-web-python">Download de P&#225;ginas Web com Python</link>), trabalhamos com as vers&#245;es para exibi&#231;&#227;o das transcri&#231;&#245;es dos julgamentos e continuaremos a fazer isso. Sabemos que a vers&#227;o de exibi&#231;&#227;o do julgamento de Benjamin Bowsey est&#225; localizada na URL:</p>
<pre><code xml:id="code_download-multiplos-registros-query-strings_19" type="block" corresp="code_download-multiplos-registros-query-strings_19.txt"/></pre>
<p>Da mesma forma que alterar as <emph>query strings</emph> nas URLs gera resultados de busca diferentes, alterar a URL dos registros de julgamento - no caso, substituir um ID de julgamento por outro - nos far&#225; obter a transcri&#231;&#227;o para aquele novo julgamento. Isso significa que, para encontrar e fazer o <emph>download</emph> dos 13 ficheiros que buscamos, tudo o que precisamos s&#227;o esses IDs de julgamento. Uma vez que sabemos que essas p&#225;ginas de resultados de busca geralmente cont&#233;m um <emph>link</emph> para as p&#225;ginas descritas, h&#225; uma boa chance de que consigamos encontrar esses <emph>links</emph> integrados ao c&#243;digo HTML. Se formos capazes de raspar essa informa&#231;&#227;o das p&#225;ginas de resultados de busca em que fizemos <emph>download</emph>, podemos ent&#227;o usar essa informa&#231;&#227;o para gerar uma URL que nos permitir&#225; fazer o <emph>download</emph> de cada transcri&#231;&#227;o de julgamento. Essa &#233; uma t&#233;cnica que ir&#225; utilizar para a maioria das p&#225;ginas de resultados de busca, n&#227;o s&#243; o <emph>Old Bailey Online</emph>! Para fazer isso, primeiro precisamos encontrar onde os IDs de julgamento est&#227;o no c&#243;digo HTML dos ficheiros que fizemos o <emph>download</emph> e, depois, determinar uma maneira de isol&#225;-los consistentemente usando c&#243;digo de modo a que, independentemente de qual p&#225;gina de resultado de busca fizermos o <emph>download</emph>, sejamos capazes de encontrar as transcri&#231;&#245;es de julgamento. Primeiro, abra <code type="inline">search-results0.html</code> no Komodo Edit e d&#234; uma olhada na lista de julgamentos. A primeira entrada come&#231;a com "Anne Smith", ent&#227;o pode usar o recurso <code type="inline">find</code> no Komodo Edit para pular imediatamente para o lugar certo. Observe que o nome de Anne faz parte de um <emph>link</emph>:</p>
<pre><code xml:id="code_download-multiplos-registros-query-strings_20" type="block" corresp="code_download-multiplos-registros-query-strings_20.txt"/></pre>
<p>Perfeito, o <emph>link</emph> cont&#233;m o ID do julgamento! Percorra as entradas restantes e ver&#225; que isso &#233; verdade em todos os casos. Para nossa sorte, o <emph>site</emph> &#233; bem formatado e parece que cada <emph>link</emph> come&#231;a com <code type="inline">browse.jsp?id=</code> seguido pelo ID do julgamento e termina com um <code type="inline">&amp;</code>, no caso de Anne: <code type="inline">browse.jsp?id=t17160113-18&amp;</code>. Podemos escrever algumas linhas de c&#243;digo que sejam capazes de isolar esses IDs. Veja a fun&#231;&#227;o a seguir. Essa fun&#231;&#227;o tamb&#233;m usa a biblioteca <code type="inline">os</code>, nesse caso para listar todos os ficheiros localizados no diret&#243;rio criado na se&#231;&#227;o anterior. A biblioteca <code type="inline">os</code> possui uma gama de fun&#231;&#245;es &#250;teis que imitam os tipos de tarefas que esperaria ser capaz de fazer com o seu mouse no Mac Finder ou Windows, como abrir, fechar, criar, deletar e mover ficheiros e diret&#243;rios, e &#233; uma boa biblioteca a ser masterizada - ou pelo menos para se familiarizar.</p>
<pre><code class="language-python" xml:id="code_download-multiplos-registros-query-strings_21" type="block" corresp="code_download-multiplos-registros-query-strings_21.txt"/></pre>
<p>Crie e execute um novo programa chamado <code type="inline">extract-trials-ids.py</code> com o c&#243;digo a seguir. Certifique-se de inserir o mesmo valor nos argumentos da <emph>query</emph> como fez no exemplo anterior:</p>
<pre><code class="language-python" xml:id="code_download-multiplos-registros-query-strings_22" type="block" corresp="code_download-multiplos-registros-query-strings_22.txt"/></pre>
<p>Se tudo correu bem, deve ver uma lista contendo o nome de todos os ficheiros no seu novo diret&#243;rio <code type="inline">mulatto*+negro*</code>, que a essa altura devem ser as duas p&#225;ginas de resultados de busca. Certifique-se de que isso funcionou antes de prosseguir. Uma vez que armazenamos todas as p&#225;ginas de resultados de busca com um nome de ficheiro que inclui <code type="inline">search-results</code>, agora desejamos abrir todos os ficheiros cujo nome contenha <code type="inline">search-results</code> e extrair todos os IDs de julgamento encontrados neles. Nesse caso sabemos que temos 2, mas desejamos que o nosso c&#243;digo seja o mais reutiliz&#225;vel poss&#237;vel (com raz&#227;o, &#233; claro!). Restringir essa a&#231;&#227;o a ficheiros denominados <code type="inline">search-results</code> significar&#225; que este programa funcionar&#225; como pretendido, mesmo que o diret&#243;rio contenha muitos outros ficheiros n&#227;o relacionados, j&#225; que o programa ignorar&#225; qualquer coisa com nome diferente.</p>
<p>Adicione o c&#243;digo a seguir &#224; sua fun&#231;&#227;o <code type="inline">getIndivTrials()</code>, que verificar&#225; se cada ficheiro cont&#233;m <code type="inline">search-results</code> no seu nome. Em caso verdadeiro, o ficheiro ser&#225; aberto e o conte&#250;do ser&#225; salvo na vari&#225;vel chamada <code type="inline">text</code>. Essa vari&#225;vel <code type="inline">text</code> ser&#225; analisada na busca por um ID de julgamento, que sabemos que sempre segue <code type="inline">browse.jsp?id=</code>. Se e quando o ID de julgamento for encontrado, ele ser&#225; armazenado numa lista e exibido na Sa&#237;da de Comando, que nos deixa com todas as informa&#231;&#245;es que precisamos para ent&#227;o escrever o programa que far&#225; o <emph>download</emph> dos julgamentos desejados.</p>
<pre><code class="language-python" xml:id="code_download-multiplos-registros-query-strings_23" type="block" corresp="code_download-multiplos-registros-query-strings_23.txt"/></pre>
<p>Essa &#250;ltima linha do <code type="inline">for</code> <emph>loop</emph> pode parecer confusa, mas certifique-se de que entendeu antes de seguir em frente. A vari&#225;vel <code type="inline">words</code> &#233; verificada para saber se cont&#233;m os caracteres <code type="inline">id=</code> (sem aspas), que obviamente se referem a um ID espec&#237;fico de transcri&#231;&#227;o de julgamento. Caso contenha, usamos o m&#233;todo de string <code type="inline">slice</code> para capturar apenas o trecho entre <code type="inline">id=</code> e <code type="inline">&amp;</code> e o adicionamos &#224; lista de url. Se soub&#233;ssemos as posi&#231;&#245;es exatas dos &#237;ndices dessa substring, poder&#237;amos ter usado esses valores num&#233;ricos no lugar. No entanto, ao utilizar o m&#233;todo de string <code type="inline">find()</code>, criamos um programa muito mais flex&#237;vel. O c&#243;digo a seguir faz exatamente a mesma coisa que essa &#250;ltima linha, mas de maneira menos condensada:</p>
<pre><code class="language-python" xml:id="code_download-multiplos-registros-query-strings_24" type="block" corresp="code_download-multiplos-registros-query-strings_24.txt"/></pre>
<p>Ao executar novamente o programa <code type="inline">extract-trial-ids.py</code>, deve ver uma lista de todos os IDs de julgamento. Podemos adicionar algumas linhas extra para transform&#225;-los em URLs propriamente ditos e fazer o <emph>download</emph> de toda a lista para o nosso novo diret&#243;rio. Tamb&#233;m vamos usar a biblioteca <code type="inline">time</code> para pausar o nosso programa por 3 segundos entre cada <emph>download</emph> - uma t&#233;cnica chamada <emph>throttling</emph> (em portugu&#234;s, estrangulamento). &#201; considerada uma boa forma de n&#227;o sobrecarregar o servidor de algu&#233;m com muitas solicita&#231;&#245;es por segundo; e o pequeno retardamento torna mais f&#225;cil que todos esses ficheiros sejam, de fato, baixados ao inv&#233;s de ocorrer um <link target="https://en.wikipedia.org/wiki/Timeout_(computing)">time out</link>. Adicione o c&#243;digo a seguir ao final da sua fun&#231;&#227;o <code type="inline">getIndivTrials()</code>. Esse c&#243;digo vai gerar uma URL para cada p&#225;gina individualmente, far&#225; o <emph>download</emph> da p&#225;gina no seu computador, ir&#225; coloc&#225;-lo no seu diret&#243;rio, armazenar o ficheiro e pausar por 3 segundos antes de continuar para o pr&#243;ximo julgamento. Todo esse trabalho est&#225; contido num <code type="inline">for</code> <emph>loop</emph> e ser&#225; executado uma vez para cada julgamento na sua lista de urls.</p>
<pre><code class="language-python" xml:id="code_download-multiplos-registros-query-strings_25" type="block" corresp="code_download-multiplos-registros-query-strings_25.txt"/></pre>
<p>Se unirmos tudo numa &#250;nica fun&#231;&#227;o, ela deve-se parecer com isso (note que adicionamos todas as chamadas por <code type="inline">import</code> no in&#237;cio para manter as coisas claras):</p>
<pre><code class="language-python" xml:id="code_download-multiplos-registros-query-strings_26" type="block" corresp="code_download-multiplos-registros-query-strings_26.txt"/></pre>
<p>Vamos adicionar a mesma pausa de tr&#234;s segundos &#224; nossa fun&#231;&#227;o <code type="inline">getSearchResults</code> para ser amig&#225;vel aos <emph>servers</emph> do <emph>Old Bailey Online</emph>:</p>
<pre><code class="language-python" xml:id="code_download-multiplos-registros-query-strings_27" type="block" corresp="code_download-multiplos-registros-query-strings_27.txt"/></pre>
<p>Finalmente, chame a fun&#231;&#227;o no programa <code type="inline">download-searches.py</code>:</p>
<pre><code class="language-python" xml:id="code_download-multiplos-registros-query-strings_28" type="block" corresp="code_download-multiplos-registros-query-strings_28.txt"/></pre>
<p>Agora criou um programa que &#233; capaz de fazer a solicita&#231;&#227;o e o <emph>download</emph> de ficheiros do <emph>Old Bailey website</emph>, baseado em par&#226;metros de busca que definiu, tudo sem visitar o <emph>site</emph>!</p>
</div><div type="3"><head>No Caso de um Ficheiro N&#227;o Ser Baixado</head>
<p>Verifique se o <emph>download</emph> dos treze ficheiros foi realizado corretamente. Se esse for o caso, &#243;timo! No entanto, h&#225; a possibilidade de que esse programa tenha parado no meio do caminho. Isso porque o nosso programa, ao ser executado na nossa m&#225;quina, depende de dois fatores al&#233;m do nosso controle imediato: a velocidade da internet e a o tempo de resposta do <emph>server</emph> do <emph>Old Bailey Online</emph> naquele momento. Uma coisa &#233; pedir que o Python fa&#231;a o <emph>download</emph> de um &#250;nico ficheiro, mas quando come&#231;amos a solicitar um ficheiro a cada tr&#234;s segundos, h&#225; grandes chances de ocorrer um <emph>time out</emph> no <emph>server</emph> ou que ele falhe em nos enviar o ficheiro que estamos buscando.</p>
<p>Se estivermos usando um navegador <emph>web</emph> para fazer essas solicita&#231;&#245;es, eventualmente receber&#237;amos uma mensagem de que "a conex&#227;o expirou" ou algo do tipo. Todos n&#243;s vemos isso de tempos em tempos. No entanto, o nosso programa n&#227;o foi desenvolvido para lidar ou retransmitir essas mensagens de erro, ent&#227;o s&#243; perceber&#225; o problema quando o programa n&#227;o tiver retornado o n&#250;mero esperado de ficheiros ou simplesmente n&#227;o fizer nada. Para evitar frustra&#231;&#245;es e incertezas, queremos um sistema &#224; prova de falha no nosso programa, que tentar&#225; baixar cada julgamento. Se por alguma raz&#227;o ele falhar, apontaremos o problema e passaremos para o pr&#243;ximo julgamento.</p>
<p>Para fazer isso, utilizaremos os mecanismos para lidar com erros do Python, <link target="http://docs.python.org/tutorial/errors.html">try / except</link>, bem como uma nova biblioteca: <code type="inline">socket</code>. <code type="inline">Try</code> e <code type="inline">Except</code> s&#227;o muito parecidos com um <code type="inline">if / else</code> <emph>statement</emph>. Quando solicita que o Python <code type="inline">try</code> (em portugu&#234;s, tente) algo, ele tentar&#225; executar o c&#243;digo; caso o c&#243;digo falhe em alcan&#231;ar o que definiu, ele executar&#225; o  c&#243;digo em <code type="inline">except</code> (em portugu&#234;s, exce&#231;&#227;o).  Isso &#233; frequentemente usado ao lidar com erros, conhecido como &#8220;error handling&#8221;. Podemos us&#225;-lo a nosso favor dizendo ao programa para tentar fazer o <emph>download</emph> de uma p&#225;gina. Caso o programa falhe, solicitaremos que ele nos informe qual ficheiro falhou e depois prossiga. Para fazer isso precisamos de usar a biblioteca <code type="inline">socket</code>, que nos permitir&#225; definir um limite de tempo para um <emph>download</emph> antes de seguir em frente. Isso envolve alterar a fun&#231;&#227;o <code type="inline">getIndivTrials</code>.</p>
<p>Primeiro, precisamos de carregar a biblioteca <code type="inline">socket</code>, o que deve ser feito da mesma forma que todos as outras importa&#231;&#245;es de biblioteca. Depois, precisamos de importar a biblioteca <code type="inline">urllib.error</code>, que nos permite lidar com erros de <emph>download</emph>. Tamb&#233;m precisamos de definir o tamanho do <emph>timeout</emph> padr&#227;o do <emph>socket</emph> - por quanto tempo desejamos tentar fazer o <emph>download</emph> de uma p&#225;gina antes de desistirmos. Isso deve entrar imediatamente ap&#243;s o coment&#225;rio que come&#231;a com <code type="inline"># faz o download da p&#225;gina</code>:</p>
<pre><code class="language-python" xml:id="code_download-multiplos-registros-query-strings_29" type="block" corresp="code_download-multiplos-registros-query-strings_29.txt"/></pre>
<p>Ent&#227;o, precisamos de uma nova lista de Python que armazenar&#225; todas as urls cujo <emph>download</emph> falhou. Vamos cham&#225;-la de <code type="inline">failedAttempts</code> e pode inser&#237;-la imediatamente ap&#243;s as instru&#231;&#245;es de importa&#231;&#227;o:</p>
<pre><code class="language-python" xml:id="code_download-multiplos-registros-query-strings_30" type="block" corresp="code_download-multiplos-registros-query-strings_30.txt"/></pre>
<p>Finalmente, podemos adicionar o <code type="inline">try / except</code> <emph>statement</emph> de forma muito similar a como um <code type="inline">if / else</code> <emph>statement</emph> seria adicionado. Nesse caso, vamos colocar todo o c&#243;digo desenvolvido para fazer o <emph>download</emph> e armazenar os julgamentos no <code type="inline">try</code> <emph>statement</emph>, e no <code type="inline">except</code> <emph>statement</emph> vamos dizer ao programa o que desejamos que ele fa&#231;a caso falhe. Aqui, vamos adicionar a url cujo <emph>download</emph> falhou &#224; nossa nova lista, <code type="inline">failedAttempts</code>:</p>
<pre><code class="language-python" xml:id="code_download-multiplos-registros-query-strings_31" type="block" corresp="code_download-multiplos-registros-query-strings_31.txt"/></pre>
<p>Finalmente, diremos ao programa para exibir os conte&#250;dos da lista na Sa&#237;da de Comando de modo que saibamos quais ficheiros falharam no <emph>download</emph>. Isso deve ser adicionado nas linhas finais da fun&#231;&#227;o:</p>
<pre><code class="language-python" xml:id="code_download-multiplos-registros-query-strings_32" type="block" corresp="code_download-multiplos-registros-query-strings_32.txt"/></pre>
<p>Agora ao executarmos o programa, caso haja algum problema no <emph>download</emph> de um ficheiro espec&#237;fico, receber&#225; uma mensagem na janela de Sa&#237;da de Comando do Komodo Edit. Essa mensagem ir&#225; conter quaisquer URLs dos ficheiros que falharam no <emph>download</emph>. Caso haja apenas um ou dois, provavelmente &#233; mais f&#225;cil simplesmente visitar as p&#225;ginas manualmente e usar o recurso de "Salvar Como" do seu navegador. Caso se esteja sentindo aventureiro, poderia modificar o programa para automaticamente fazer o <emph>download</emph> dos ficheiros faltantes. A vers&#227;o final das suas fun&#231;&#245;es <code type="inline">getSearchResults()</code> e <code type="inline">getIndivTrials()</code> deve-se parecer com isso:</p>
<pre><code class="language-python" xml:id="code_download-multiplos-registros-query-strings_33" type="block" corresp="code_download-multiplos-registros-query-strings_33.txt"/></pre>
</div></div>
      <div type="2"><head>Leituras Adicionais</head>
<p>Para usu&#225;rios mais avan&#231;ados, ou para se tornar um usu&#225;rio mais avan&#231;ado, pode achar que vale a pena ler sobre como alcan&#231;ar esse mesmo processo usando Interfaces de Programa&#231;&#227;o de Aplica&#231;&#245;es (API). Geralmente, um <emph>website</emph> com uma API d&#225; instru&#231;&#245;es de como solicitar certos documentos. &#201; um processo bastante similar ao que acabamos de fazer interpretando a <emph>Query String</emph> de URL, mas sem o trabalho de investiga&#231;&#227;o adicional necess&#225;rio para decifrar o que cada vari&#225;vel faz. Caso esteja interessado no <emph>Old Bailey Online</emph>, recentemente liberaram uma API e a documenta&#231;&#227;o pode ajudar bastante:</p>
<ul>
<li>Old Bailey Online API (<link target="http://www.oldbaileyonline.org/static/DocAPI.jsp">http://www.oldbaileyonline.org/static/DocAPI.jsp</link>)</li>
<li>Melhor maneira de criar um diret&#243;rio para grava&#231;&#227;o de ficheiros, se ele n&#227;o existir, usando Python? (<link target="http://stackoverflow.com/questions/273192/python-best-way-to-create-directory-if-it-doesnt-exist-for-file-write">http://stackoverflow.com/questions/273192/python-best-way-to-create-directory-if-it-doesnt-exist-for-file-write</link>)</li>
</ul>
</div>
    </body>
  </text>
</TEI>
