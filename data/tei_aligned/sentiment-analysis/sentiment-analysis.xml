<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xi="http://www.w3.org/2001/XInclude" xml:id="sentiment-analysis" type="original" xml:base="sentiment-analysis/sentiment-analysis.xml">
    <teiHeader>
        <fileDesc>
            <titleStmt>
                <title>Sentiment Analysis for Exploratory Data Analysis
</title>
                <author role="original_author">Zo&amp;#235; Wilkinson Salda&amp;#241;a</author>
                <editor role="reviewers">
                    <persName>Anandi Silva Knuppel</persName>
                    <persName>Puteri Zarina Megat Khalid</persName>
                </editor>
                <editor role="editors">Adam Crymble</editor>
            </titleStmt>
            <publicationStmt>
                <distributor>Programming Historian</distributor>
                <idno type="doi">10.46430/phen0079</idno>
                <date type="published">01/15/2018</date>
            </publicationStmt>
            <sourceDesc>
                <p>Born digital, in a markdown format. This lesson is original. Available translations are the following:<ref type="translations" target="#analise-sentimento-exploracao-dados"/>
                </p>
            </sourceDesc>
        </fileDesc>
        <profileDesc>
            <abstract>
                <p>In this lesson you will learn to conduct 'sentiment analysis' on texts and to interpret the results. This is a form of exploratory data analysis based on natural language processing. You will learn to install all appropriate software and to build a reusable program that can be applied to your own texts.</p>
            </abstract>
            <textClass>
                <keywords>
                    <term xml:lang="en">distant-reading</term>
                </keywords>
            </textClass>
        </profileDesc>
    </teiHeader>
    <text xml:lang="en">
        <body>
            <div type="2" n="1">
                <head>Lesson Goals</head>
                <p>This lesson uses <ref target="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</ref> as the basis for an <ref target="https://en.wikipedia.org/wiki/Exploratory_data_analysis">exploratory data analysis</ref> of a large textual corpus. It is appropriate for readers with some basic prior experience programming with <ref target="https://www.python.org/">Python</ref>. If you have no experience with Python or computer programming, the author recommends working through the first few lessons in the <ref target="/lessons/introduction-and-installation">Introduction to Python series</ref>. By the end of this lesson, you will be able to:</p>
                <list type="unordered">
                    <item>Devise appropriate research questions that use <ref target="https://en.wikipedia.org/wiki/Natural_language_processing">Natural Language Processing</ref> (NLP) on a textual corpus.</item>
                    <item>Use Python and the <ref target="http://www.nltk.org/">Natural Language Processing Toolkit</ref> (NLTK) to generate sentiment scores for a text.</item>
                    <item>Critically evaluate the sentiment analysis scores and adjust <ref target="https://en.wikipedia.org/wiki/Parameter">parameters</ref> and methodology as appropriate.</item>
                    <item>Identify next steps to continue learning about exploratory data analysis and programmatic approaches to qualitative data.</item>
                </list>
                <div type="3" n="1.1">
                    <head>What is Exploratory Data Analysis?</head>
                    <p>
                        <ref target="https://en.wikipedia.org/wiki/Exploratory_data_analysis">Exploratory data analyses</ref> are strategies that summarize or otherwise reveal features of interest within a dataset which are not likely visible through traditional <ref target="https://en.wikipedia.org/wiki/Close_reading">close reading</ref>. With the insights of exploratory data analysis at hand, researchers can make more informed decisions when selecting a method or approach for tackling their research question, and it may help to identify new research questions altogether.</p>
                    <p>In 1977, mathematician <ref target="https://en.wikipedia.org/wiki/John_Tukey">John Tukey</ref> described exploratory data analysis as a form of detective work without which scholars would too frequently miss out on interesting but less obvious findings:</p>
                    <quote>
                        <p>"Unless the detective finds the clues, judge or jury has nothing to consider. Unless exploratory data analysis uncovers indications, usually quantitative ones, there is likely to be nothing for confirmation data analysis to consider." (Tukey 1977:3)</p>
                    </quote>
                </div>
                <div type="3" n="1.2">
                    <head>Exploring Text with Sentiment Analysis</head>
                    <p>When confronted with a promising yet large corpus, how can one go about determining the features and subsets of data that might lead to the most interesting research findings?</p>
                    <p>
                        <ref target="https://en.wikipedia.org/wiki/Natural_language_processing">Natural Language Processing</ref> (NLP) covers a broad range of techniques that apply computational analytical methods to textual content, which provide means of categorizing and quantifying text. These NLP approaches, which include sentiment analysis, can help researchers explore their textual data. In the words of Tukey, it can help the researcher to find "clues" about their texts and "indications" that something might be worth investigating further.</p>
                    <p>In this lesson, we will focus on one tool in the NLP toolkit: <ref target="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</ref>. Sentiment analysis seeks to quantify the emotional intensity of words and phrases within a text. Some sentiment analysis tools can also factor in the emotional weight of other features of language such as punctuation or <ref target="https://en.wikipedia.org/wiki/Emoji">emojis</ref>. Sentiment analysis tools generally process a unit of text (a sentence, paragraph, book, etc) and output quantitative scores or classifications to indicate whether the algorithm considers that text to convey <emph>positive</emph> or <emph>negative</emph> emotion. Some tools can also quantify the <emph>degree of positivity</emph> or <emph>degree of negativity</emph> within a text. Combined with other NLP methods like <ref target="/lessons/topic-modeling-and-mallet">topic modeling</ref>, sentiment analysis provides a means of characterising the emotions expressed about different topics of conversation. When used in conjunction with <ref target="/lessons/correspondence-analysis-in-R">network analysis</ref> it could shed light on the ways that individuals interact with one another. A researcher interested in attitudes towards a political event might use sentiment analysis to characterize how individuals describe that event on social media. Given the right data to input into the tool, it could be possible to make regional comparisons, or to understand how different demographics viewed the event differently. Because the tool can process lots of data sequentially, it is even possible to analyse the sentiment in hundreds of thousands or even millions of speech events.</p>
                    <p>To get you started, this lesson provides an introduction to sentiment analysis that is both practical and critical. Like any computational tool, sentiment analysis has a number of limitations and biases that researchers should take into account. Researchers should be especially cautious about making empirical claims based on the results of sentiment analysis. You may be better served using sentiment analysis in provisional and exploratory situations, as a means for guiding the research process. When wielding these tools both skeptically and effectively, one can accomplish some pretty remarkable detective work.</p>
                </div>
            </div>
            <div type="2" n="2">
                <head>Analysis of Large Textual Correspondence Collections</head>
                <p>Written correspondences such as letters, e-mails, chat logs, tweets, and text message histories can provide researchers with invaluable insight into their authors. Texts are often rich with emotions and information not disclosed elsewhere. A researcher may learn about the opinions that their subjects held on various topics or about certain events. It could also be possible to learn about the relationships that individuals developed and maintained within complex organizations or networks.</p>
                <p>While methodologies such as <ref target="https://en.wikipedia.org/wiki/Ethnography">ethnography</ref>, close reading, and <ref target="https://en.wikipedia.org/wiki/Discourse_analysis">discourse analysis</ref> all help researchers analyze historical correspondence, these methods face significant challenges when the number of texts grows from dozens or hundreds to thousands or millions. Computational textual analysis provides a set of methods for making visible trends, dynamics, and relationships that may be hidden to the human reader by problems of scale. Furthermore, many computation methods produce findings that can be expressed quantitatively, and that may subsequently allow the researcher to conduct <ref target="https://en.wikipedia.org/wiki/Statistical_model">statistical modeling</ref>, information visualization, and <ref target="https://en.wikipedia.org/wiki/Machine_learning">machine learning</ref> to make further discoveries.</p>
                <div type="3" n="2.1">
                    <head>A Case Study: the Enron E-mail Corpus</head>
                    <p>This tutorial uses the e-mail correspondence of bankrupt American energy company Enron. Enron concealed a wide variety of illegal accounting practices until a federal investigation in 2001 forced it into bankruptcy. At the time, the <ref target="https://en.wikipedia.org/wiki/Enron_scandal">Enron Scandal</ref> was the largest collapse of a publicly traded company in history. In 2001, the company started showing signs of financial strain that didn't align with the company's financial disclosures to that point. The publicly traded Enron stocks dropped from their mid-2000 high of $90.75 to less than a dollar in November 2001, which led stockholders to sue the company. A subsequent U.S. Securities and Exchange Commission (SEC) investigation revealed that Enron executives committed fraud and accounting malpractice on a massive scale. Enron declared bankruptcy in December of that year. In the years that followed, several executives faced criminial convictions for their role in the scandal.</p>
                    <p>For researchers, the Enron Scandal resulted in the creation of one of the largest (and most infamous) correspondence text corpora ever collected:</p>
                    <quote>
                        <p>"One of the most infamous corporate scandals of the past few decades curiously left in its wake one of the most valuable publicly available datasets. In late 2001, the Enron Corporation's accounting obfuscation and fraud led to the bankruptcy of the large energy company. The Federal Energy Regulatory Commission subpoenaed all of Enron's e-mail records as part of the ensuing investigation. Over the following two years, the commission released, unreleased, and re-released the e-mail corpus to the public after deleting e-mails that contained personal information like social security numbers. The Enron corpus contains e-mails whose subjects range from weekend vacation planning to political strategy talking points, and it remains the only large example of real world e-mail datasets available for research." (Hardin, Sarkis, and Urc, 2015)</p>
                    </quote>
                    <p>When the organized and redacted <ref target="https://www.cs.cmu.edu/~./enron/">Enron E-mail Dataset</ref> was released in 2004, researchers discovered an unprecedented opportunity: direct access to the spontaneous, largely uncensored way employees in a doomed corporation communicated with one another. Suddenly, researchers had access to how people communicated at work at an unprecedented scale. This mattered for researchers interested in the special case of the Enron scandal and collapse, but also for researchers interested in a wide spectrum of questions about everyday communication at work.</p>
                    <p>In the following decade, hundreds of new studies sprouted up from the e-mails pursuing questions as diverse as <ref target="https://en.wikipedia.org/wiki/Social_network">social network theory</ref>, community and <ref target="https://en.wikipedia.org/wiki/Anomaly_detection">anomaly detection</ref>, gender and communication within organizations, behavioral change during an organizational crisis, and insularity and community formation. The use of social network theory in the humanities proposes some <ref target="http://journals.sagepub.com/doi/abs/10.1177/1749975514542486">fascinating possibilities</ref>, but is not without <ref target="http://www.emeraldinsight.com/doi/abs/10.1108/S0733-558X%282014%290000040001">significant debate</ref>.</p>
                    <p>In addition to the sheer quantity of messages included (the corpus contains over 600,000 messages), the Enron E-mail Corpus also includes the metadata necessary for researchers to pursue a number of research questions. Just as the presence of envelopes with legible sender and recipient addresses would be a wonderful asset for researchers of historic letter correspondences, the presence of sender and recipient e-mail addresses allows researchers to associate e-mails with particular known individuals within the corporation. As some individuals had multiple e-mail addresses, or more than one individual may have shared the same address, the metadata is not fool proof, but it is incredibly insightful. The rest of the tutorial will go through how to apply and interpret sentiment analysis of e-mails in this corpus.</p>
                </div>
            </div>
            <div type="2" n="3">
                <head>Using Python with the Natural Language Toolkit (NLTK)</head>
                <p style="alert alert-warning">
First time coding? This lesson is intended for beginners, but you may find it helpful to <ref target="/lessons/?topic=python">review other Python lessons at Programming Historian</ref>. However, please note that while many lessons at the <emph>Programming Historian</emph> use Python version 2, this lesson requires <ref target="https://www.python.org/download/releases/3.0/">Python version 3</ref>. Python 3 installation instructions are linked to below.
</p>
                <p>In this tutorial, you will be using <ref target="https://www.python.org/">Python</ref> along with a few tools from the Natural Language Toolkit (NLTK) to generate sentiment scores from e-mail transcripts. To do this, you will first learn how to load the textual data into Python, select the appropriate NLP tools for sentiment analysis, and write an <ref target="https://en.wikipedia.org/wiki/Algorithm">algorithm</ref> that calculates sentiment scores for a given selection of text. We'll also explore how to adjust your algorithm to best fit your research question. Finally, you will package your problem-solving algorithm as a self-contained bundle of code known as a <emph>function</emph> that you can reuse and repurpose (including in part 2 of this tutorial)</p>
                <div type="3" n="3.1">
                    <head>Installation</head>
                    <p>To complete the example below, you will need to install the following:</p>
                    <list type="unordered">
                        <item>Python 3 (ideally 3.5 or higher) - <ref target="https://wiki.python.org/moin/BeginnersGuide/Download">Download &amp; install instructions from the Python wiki</ref>
                        </item>
                        <item>NLTK (3.2.5 or higher) - <ref target="http://www.nltk.org/install.html">Download &amp; install instructions from NLTK.org</ref>
                        </item>
                    </list>
                </div>
                <div type="3" n="3.2">
                    <head>Getting Started with NLTK</head>
                    <p>The Natural Language Toolkit (NLTK) is a collection of reusable Python tools (also known as a Python <ref target="https://en.wikipedia.org/wiki/Library_(computing)">library</ref> that help researchers apply a set of computational methods to texts. The tools range from methods of breaking up text into smaller pieces, to identifying whether a word belongs in a given language, to sample texts that researchers can use for training and development purposes (such as the complete text of <emph>Moby Dick</emph>).</p>
                    <p>If you need any help downloading and installing the module for <ref target="https://www.python.org/download/releases/3.0/">Python 3</ref>, take a look at the <ref target="/lessons/installing-python-modules-pip">Installing Python Modules with pip lesson</ref> by Fred Gibbs.</p>
                    <p>In our case, we will be using two NLTK tools in particular:</p>
                    <list type="unordered">
                        <item>The '<ref target="http://www.nltk.org/_modules/nltk/sentiment/vader.html">VADER Sentiment Analysis</ref>' tool (generates positive, negative, and neutral sentiment scores for a given input)</item>
                        <item>The 'word_tokenize' tokenizer tool (splits a large text into a sequence of smaller units, like sentences or words)</item>
                    </list>
                    <p>To use VADER and word_tokenize, we first need to download and install a little extra data for NLTK. NLTK is a very large toolkit, and several of its tools actually require a second download step to gather the necessary collection of data (often coded lexicons) to function correctly.</p>
                    <p>To install the sentiment analysis and word tokenizer we will use for this tutorial, write a new Python script with the following three lines:</p>
                    <ab>
                        <code xml:id="code_sentiment-analysis_0" corresp="code_sentiment-analysis_0.txt" rend="block"/>
                    </ab>
                    <p>You can save this file as "<code rend="inline">installation.py</code>". If you are unsure how to save and run Python scripts, please review the appropriate tutorial on setting up an 'Integrated Development Environment' using Python, replacing the command '%(python) %f' with '%(python3) %f' when you reach that point in the tutorial.</p>
                    <list type="ordered">
                        <item>Setting Up an Integrated Development Environment for Python <ref target="/lessons/windows-installation">Windows</ref>.</item>
                        <item>Setting Up an Integrated Development Environment for Python <ref target="/lessons/mac-installation">Mac</ref>.</item>
                        <item>Setting Up an Integrated Development Environment for Python <ref target="/lessons/linux-installation">Linux</ref>.</item>
                    </list>
                    <p>If you do know how to run Python scripts, run the file using Python 3.</p>
                    <p>
                        <ref target="http://www.nltk.org/_modules/nltk/sentiment/vader.html">
                            <emph>VADER</emph>
                        </ref> (Valence Aware Dictionary and sEntiment Reasoner) is a sentiment intensity tool added to NLTK in 2014. Unlike other techniques that require training on related text before use, <emph>VADER</emph> is ready to go for analysis without any special setup. <emph>VADER</emph> is unique in that it makes fine-tuned distinctions between varying degrees of positivity and negativity. For example, <emph>VADER</emph> scores "comfort" moderately positively and "euphoria" extremely positively. It also attempts to capture and score textual features common in informal online text such as capitalizations, exclamation points, and emoticons, as shown in the table below:</p>
                    <figure>
                        <desc>Vader captures slight gradations in enthusiasm. (Hutto and Gilbert, 2014)</desc>
                        <graphic url="sentiment-analysis1.png"/>
                    </figure>
                    <p>Like any text analysis tool, <emph>VADER</emph> should be evaluated critically and in the context of the assumptions it makes about communication. <emph>VADER</emph> was developed in the mid-2010s primarily to analyse English language microblogging and social media sites (especially Twitter). This context is likely much more informal than professional e-mail, and contains language and feature usage patterns that differ from 1999-2002 patterns when the Enron e-mails were written. However, <emph>VADER</emph> was also developed as a general purpose sentiment analyzer, and the authors' initial study shows it compares favorably against tools that have been trained for specific domains, use specialized lexicons, or resource-heavy machine learning techniques (Hutto and Gilbert, 2014). Its sensitivity towards degrees of affect may be well-suited to describe the subtle displays of emotion within professional e-mail - as researchers, we may be especially interested in capturing the moments where emotion surfaces in otherwise formal text. However, sentiment analysis continues to struggle to capture complex sentiments like irony, sarcasm, and mockery, when the average reader would be able to make the distinction between the literal text and its intended meaning.</p>
                    <p>While <emph>VADER</emph> is a good general purpose tool for both contemporary and historical English texts, <emph>VADER</emph> only provides partial native support for non-English texts (it detects emojis/capitalization/etc., but not word choice). However, the developers encourage users to use automatic translation to pre-process non-English texts and then input the results into <emph>VADER</emph>. The "VADER demo" includes code to automatically submit input text to the web service 'My Memory Translation Service', (which advanced readers can review <ref target="https://github.com/cjhutto/vaderSentiment/blob/master/vaderSentiment/vaderSentiment.py">on Github</ref> starting at line 554 - at the time of writing). Implementation of this translation method is probably best reserved for intermediate Python users. You can learn more about the general state of multilingual sentiment analysis (which unfortunately almost always requires a translation step) in <ref target="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4981629/">'Multilingual Sentiment Analysis: State of the Art and Independent Comparison of Techniques'</ref> by Kia Dashtipour, et al (2016).</p>
                </div>
                <div type="3" n="3.3">
                    <head>Calculate Sentiment for a Paragraph</head>
                    <p>Consider the following passage:</p>
                    <quote>
                        <p>"Like you, I am getting very frustrated with this process. I am genuinely trying to be as reasonable as possible. I am not trying to "hold up" the deal at the last minute. I'm afraid that I am being asked to take a fairly large leap of faith after this company (I don't mean the two of you -- I mean Enron) has screwed me and the people who work for me."</p>
                    </quote>
                    <p>This is the opening paragraph from January 2012 e-mail from Timothy Belden to Louise Kitchen and John Lavorato regarding the "Employment Contracts Deal". Belden directed Enron's Energy Services, and would later be convicted of conspiracy to drive up energy costs in California that led to a statewide energy crisis.</p>
                    <p>Despite the feeling of frustration and anxiety you may glean from the paragraph as a whole, notice the ambivalence of the specific phrases within the paragraph. Some appear to express good faith efforts, e.g.  "not trying to 'hold up' the deal" and "genuinely trying". And yet, there are even stronger negative statements about "getting frustrated", "I am afraid", and "this company... has screwed me and the people who work for me."</p>
                    <p>Let's calculate the sentiment scores for this e-mail using <emph>VADER</emph> to get a sense for what the tool can do. To start, create a new working directory (folder) on your computer called "<code rend="inline">sentiment</code>" somewhere that you can find it. Within that folder, create a new text file and save it as "<code rend="inline">sentiment.py</code>". This will be where we write the code for this task.</p>
                    <p>First, we have to tell Python where the NLTK code for <emph>VADER</emph> sentiment analysis is located. At the top of our file, we will import the code for <emph>VADER</emph>:</p>
                    <ab>
                        <code xml:id="code_sentiment-analysis_1" corresp="code_sentiment-analysis_1.txt" rend="block"/>
                    </ab>
                    <p>We also must enable Python to use this code with our particular set of code. Even though we have all the instructions we need in the NLTK library, Python likes to bundle these instructions into a single <ref target="https://en.wikipedia.org/wiki/Object-oriented_programming">
                            <code rend="inline">object</code>
                        </ref> (our Sentiment Analyzer tool) that our program can access. <emph>SentimentIntensityAnalyzer</emph> is a <ref target="https://docs.python.org/3/tutorial/classes.html">
                            <code rend="inline">class</code>
                        </ref>, which is a blueprint that instructs Python to build an <code rend="inline">object</code> with a special set of <code rend="inline">functions</code> and <code rend="inline">variables</code>. In our case, we want to build a single <code rend="inline">object</code>: our sentiment analyzer, that follows this blueprint. To do so, we run <emph>SentimentIntensityAnalyzer()</emph> and assign the output - our brand-new sentiment analyzer - to a variable, which we will name '<emph>sid</emph>'.</p>
                    <ab>
                        <code xml:id="code_sentiment-analysis_2" corresp="code_sentiment-analysis_2.txt" rend="block"/>
                    </ab>
                    <p>By doing this we have given our new variable <emph>sid</emph> all of the features of the <emph>VADER</emph> sentiment analysis code. It has become our sentiment analysis tool, but by a shorter name.</p>
                    <p>Next, we need to store the text we want to analyze in a place <emph>sid</emph> can access. In Python, we can store a single sequence of text as a <ref target="https://en.wikipedia.org/wiki/String_(computer_science)">string</ref> variable.</p>
                    <ab>
                        <code xml:id="code_sentiment-analysis_3" corresp="code_sentiment-analysis_3.txt" rend="block"/>
                    </ab>
                    <p>As this text includes both quotation marks and apostrophes, it is necessary to surround the whole text with three quotation marks (""" or '''). This means that any quotation marks and apostrophes in the text will be recognised as such. This approach also retains any spacing our text already includes.</p>
                    <p>Now you are ready to process the text.</p>
                    <p>To do this, the text (<emph>message_text</emph>) must be input into the tool (<emph>sid</emph>) and the programme must be run. We are interested in the 'polarity score' of the sentiment analyzer, which gives us a score that is either positive or negative. This feature is built into <emph>VADER</emph> and can be requested on demand.</p>
                    <p>We want to make sure to capture the output of sid.polarity_scores() by assigning it to a variable that we will call <emph>scores</emph> - short for 'sentiment score' or 'polarity score':</p>
                    <ab>
                        <code xml:id="code_sentiment-analysis_4" corresp="code_sentiment-analysis_4.txt" rend="block"/>
                    </ab>
                    <p>When you run this code, the results of the sentiment analysis is now stored in the <emph>scores</emph>
                        <ref target="https://docs.python.org/2/tutorial/datastructures.html">
                            <code rend="inline">dictionary</code>
                        </ref>. A dictionary, much like the type you use to look up the definition of words, is a variable that stores information known as 'values' which are accessible by giving the programme the 'key' to the entry you want to read. This means a dictionary like <emph>scores</emph> can store many <ref target="https://en.wikipedia.org/wiki/Attribute%E2%80%93value_pair">key-value pairs</ref>. To request the data, you just need to know the <code rend="inline">keys</code>. But we don't know the <code rend="inline">keys</code>. Fortunately, Python will give us a list of all <code rend="inline">keys</code>, sorted alphabetically, if we use the function <emph>sorted(scores)</emph>.</p>
                    <p>To print out each <code rend="inline">key</code> and <code rend="inline">value</code> stored in the dictionary, we need a <ref target="https://en.wikipedia.org/wiki/For_loop">
                            <code rend="inline">for loop</code>
                        </ref>, which applies the same code sequentially to every <code rend="inline">key</code> in the dictionary.</p>
                    <p>Here is the code to print out every <code rend="inline">key-value</code> pair within the <emph>scores</emph> variable:</p>
                    <ab>
                        <code xml:id="code_sentiment-analysis_5" corresp="code_sentiment-analysis_5.txt" rend="block"/>
                    </ab>
                    <p>Here's all the code together in a single program:</p>
                    <ab>
                        <code xml:id="code_sentiment-analysis_6" corresp="code_sentiment-analysis_6.txt" rend="block"/>
                    </ab>
                    <p>Save your Python file. Now we're ready to execute the code. Using your preferred method (either your Integrated Development Environment, or the command line), run your Python file, <code rend="inline">sentiment.py</code>.</p>
                    <p>The output should look like this:</p>
                    <ab>
                        <code xml:id="code_sentiment-analysis_7" corresp="code_sentiment-analysis_7.txt" rend="block"/>
                    </ab>
                    <p style="alert alert-warning"> Be careful to use three single quotes to wrap the <emph>message_text</emph> string above. If you use double quotes, the string will end early due to the quotation marks within the text</p>
                    <p>
                        <emph>VADER</emph> collects and scores negative, neutral, and positive words and features (and accounts for factors like negation along the way). The "neg", "neu", and "pos" values describe the fraction of weighted scores that fall into each category. <emph>VADER</emph> also sums all weighted scores to calculate a "compound" value normalized between -1 and 1; this value attempts to describe the overall affect of the entire text from strongly negative (-1) to strongly positive (1). In this case, the <emph>VADER</emph> analysis describes the passage as slightly-to-moderately negative (-0.3804). We can think of this value as estimating the overall impression of an average reader when considering the e-mail as a whole, despite some ambiguity and ambivalence along the way.</p>
                    <p>Reading the text, I would be inclined to agree with this overall assessment. The output value of -0.3804 is negative but not very strongly negative. Researchers may wish to set a minimum threshold for positivity or negativity before they declare a text definitively positive or negative -- for instance, the official <emph>VADER</emph> documentation suggests a threshold of -0.5 and 0.5, which this particular excerpt would fail to meet (in other words, this text is negative, but not definitively negative).</p>
                    <p>What does this imply, to you, about the way that sentiment might be expressed within a professional e-mail context? How might you define your threshold values when the text expresses emotion in a more subtle or courteous manner? Do you think that sentiment analysis is an appropriate tool for our exploratory data analysis?</p>
                    <p>Challenge Task: Try replacing the contents of <emph>message_text</emph> with the following strings and re-running the program. Don't forget to surround each text with three single quotation marks when assigning it to the <emph>message_text</emph> variable (as in: <emph>message_text = '''some words'''</emph>). Before running the program, guess what you think the sentiment analysis outcome will be: positive, or negative? How strongly positive or negative?</p>
                    <ab>
                        <code xml:id="code_sentiment-analysis_8" corresp="code_sentiment-analysis_8.txt" rend="block"/>
                    </ab>
                    <ab>
                        <code xml:id="code_sentiment-analysis_9" corresp="code_sentiment-analysis_9.txt" rend="block"/>
                    </ab>
                    <p>Try it a third time with some text from one of your own research sources. What results did you get for each? Do you agree with the outcomes?</p>
                </div>
            </div>
            <div type="2" n="4">
                <head>Determine Appropriate Scope for E-mail</head>
                <p>When analyzed via the <emph>VADER</emph> sentiment analysis tool, text yields a set of positive, neutral, and negative scores, which are then aggregated and scaled as a 'compound score'. While this is helpful to know in theory, how can this method be applied to the data in the Enron example - namely, a collection of e-mail data and metadata? And what can this tell us about the emotions, relationships, and changes over time of employees at Enron?</p>
                <p>In this section, we will introduce you to the process of selecting the scope of analysis for our sentiment analysis tool. Consider the following raw data belonging to an October 3rd, 2000 e-mail written written by Jeffrey Shankman, then President of Global Markets at Enron (Quinn, 2006):</p>
                <ab>
                    <code xml:id="code_sentiment-analysis_10" corresp="code_sentiment-analysis_10.txt" rend="block"/>
                </ab>
                <p>In the message text of the e-mail, Shankman outlines a corporate strategy for moving forward in what he perceives as an ambiguous geopolitical context. The message describes a number of difficult situations, as well as exasperation ("The morning meetings are not inspiring") and uncertainty ("I don't have a real feel for everyone's passion"). At the same time, Shankman outlines a set of action steps along with polite requests ("I'd like to ask...") and expressions of gratitude ("Thanks").</p>
                <p>Before we proceed, take a minute to reflect on the message. How do you feel like a typical reader would describe the emotional intensity of this e-mail? Given what you now know about <emph>VADER</emph>, what ratio of positivity, negativity, and neutrality do you expect the sentiment analysis tool to find in the message? Finally, what do you think the compound score will suggest about the overall affect in the message?</p>
                <p>As we discussed above, sentiment analysis does not provide an objective output so much as guiding indicators that reflect our choice and calibration of analytical tools. Perhaps the most important element of calibration is selecting the <hi rend="bold">scope</hi> of the text being analyzed, meaning how much of a message we feed into the tool at once. In our case, we can determine the scope of analysis by deciding between analyzing the entire message as a single unit, or instead by breaking the message into smaller units like sentences and analyzing each separately.</p>
                <p>First, let's consider a <emph>message-level approach</emph>, in which we analyze the message as a single block:</p>
                <ab>
                    <code xml:id="code_sentiment-analysis_11" corresp="code_sentiment-analysis_11.txt" rend="block"/>
                </ab>
                <p>Replace <code rend="inline">sentiment.py</code> with the above code, save it, and run it. The output should look like this:</p>
                <ab>
                    <code xml:id="code_sentiment-analysis_12" corresp="code_sentiment-analysis_12.txt" rend="block"/>
                </ab>
                <p>Here you can see that, when analyzing the e-mail as a whole, <emph>VADER</emph> returns values that suggest the message is mostly neural (neu: 0.765) but that more features appear to be positive (pos: 0.14) rather than negative (0.096). <emph>VADER</emph> computes an overall sentiment score of <hi rend="bold">0.889</hi> for the message (on a scale of -1 to 1) which suggests a strongly positive affect for the message as a whole.</p>
                <p>Did this meet your expectation? If not, why do you think <emph>VADER</emph> found more positive than negative features?</p>
                <p>At the message-entity-level, there is no way to single out particularly positive or negative sentiments in the message. This loss of detail may be irrelevant, or it may be vital when conducting exploratory analysis. This depends upon the research needs of your study. For instance, identifying negative sentences in otherwise congenial e-mails may be especially important when looking for emotional outbursts or abusive exchanges that may occur very infrequently, but reveal something essential about the nature of a relationship. If we want to capture this level of nuance, we need a method for moving from message-level to sentiment-level analysis.</p>
                <p>Fortunately, NLTK provides a collection of tools for breaking up text into smaller components. <emph>Tokenizers</emph> split up strings of text into smaller pieces like sentences. Some can even further break out a sentence into particular parts of speech, such as the noun participle, adjective, and so on. In our case, we will use NLTK's <emph>english.pickle</emph> tokenizer to break up paragraphs into sentences.</p>
                <p>We can now rewrite the sentiment analysis script to analyze each sentence separately:</p>
                <ab>
                    <code xml:id="code_sentiment-analysis_13" corresp="code_sentiment-analysis_13.txt" rend="block"/>
                </ab>
                <p>The output should look like this:</p>
                <ab>
                    <code xml:id="code_sentiment-analysis_14" corresp="code_sentiment-analysis_14.txt" rend="block"/>
                </ab>
                <p>Here you'll note a much more detailed picture of the sentiment in this e-mail. <emph>VADER</emph> successfully identifies moderate to strongly negative sentences in the e-mail, especially the leading description of crises. Sentence-level analysis allows you to identify specific sentences and topics at the extremes of sentiment, which may be helpful later.</p>
                <p>But even at this level, <emph>VADER</emph> also runs into a number of errors. The sentence beginning with "The morning meetings are not inspiring" outputs a surprisingly positive score -- perhaps because of a misreading of the terms "passion" and "respect". Also note that the question mark at the beginning of the e-mail and the period of Mon near the end cause <emph>english.pickle</emph> tokenizer to mistakenly break up sentences. This is a constant risk from informal and complex punctuation in text.</p>
                <p>What do you notice about the distribution of scores? How can you imagine collecting them in a manner that would help you better understand your data and its relationships to the research questions you care about? (Feel free to experiment with different kinds of text in the <emph>message_text</emph> variable to see how the tool responds to different types of language constructions). The code you have just written can be repurposed for any text.</p>
            </div>
            <div type="2" n="5">
                <head>Acknowledgments</head>
                <p>My sincere thanks to Justin Joque, Visualization Librarian at the University of Michigan Library and the <ref target="https://clarkdatalabs.github.io">Digital Projects Studio</ref> for support in formulating the ideas and approach behind this lesson.</p>
                <p>Many thanks as well to Adam Crymble, who provided extensive insight and support throughout the editorial process. And thank you to Anandi Silva Knuppel and Puteri Zarina Megat Khalid for their thoughtful comments.</p>
            </div>
            <div type="2" n="6">
                <head>Works Cited</head>
                <p>Barton, D., &amp; Hall, N. (Eds.). (2000). Letter writing as a social practice (Vol. 9). John Benjamins Publishing.</p>
                <p>Hardin, J., Sarkis, G., &amp; Urc, P. C. (2015). Network Analysis with the Enron Email Corpus. Journal of Statistics Education, 23:2. <ref target="https://doi.org/10.1080/10691898.2015.11889734">https://doi.org/10.1080/10691898.2015.11889734</ref>
                </p>
                <p>Hutto, C.J. &amp; Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for
Sentiment Analysis of Social Media Text. Eighth International Conference on
Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014. <ref target="https://www.aaai.org/ocs/index.php/ICWSM/ICWSM14/paper/viewPaper/8109">https://www.aaai.org/ocs/index.php/ICWSM/ICWSM14/paper/viewPaper/8109</ref>
                </p>
                <p>Klimt, B., &amp; Yang, Y. (2004, July). Introducing the Enron Corpus. In CEAS. <ref target="https://bklimt.com/papers/2004_klimt_ceas.pdf">https://bklimt.com/papers/2004_klimt_ceas.pdf</ref>
                </p>
                <p>Klimt, B., &amp; Yang, Y. (2004). The Enron corpus: A new dataset for email classification research. Machine learning: ECML 2004, 217-226. <ref target="https://bklimt.com/papers/2004_klimt_ecml.pdf">https://bklimt.com/papers/2004_klimt_ecml.pdf</ref>
                </p>
                <p>Tukey, J.W. (1977). <emph>Exploratory Data Analysis</emph>. Addison-Wesley Publishing Company</p>
                <p>Quinn, J. (2006, November 14). Ex-Enron man goes back into energy. Retrieved January 10, 2018, from <ref target="http://www.telegraph.co.uk/finance/2950645/Ex-Enron-man-goes-back-into-energy.html">http://www.telegraph.co.uk/finance/2950645/Ex-Enron-man-goes-back-into-energy.html</ref>
                </p>
            </div>
        </body>
    </text>
</TEI>
