<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xi="http://www.w3.org/2001/XInclude" xml:id="download-multiplos-registros-query-strings" xml:base="download-multiplos-registros-query-strings/download-multiplos-registros-query-strings.xml">
    <teiHeader>
        <fileDesc>
            <titleStmt>
                <title>Download de Múltiplos Registros usando Query Strings</title>
                <author role="original_author">Adam Crymble</author>
                <editor role="reviewers">
                    <persName>Luke Bergmann</persName>
                    <persName>Sharon Howard</persName>
                    <persName>Frederik Elwert</persName>
                </editor>
                <author role="translators">Felipe Lamarca</author>
                <editor role="translation-reviewers">
                    <persName>André Salvo</persName>
                    <persName>Aracele Torres</persName>
                </editor>
                <editor role="editors">Fred Gibbs</editor>
            </titleStmt>
            <publicationStmt>
                <distributor>Programming Historian</distributor>
                <date type="translated">11/25/2022</date>
                <idno type="doi">10.46430/phpt0034</idno>
                <date type="published">11/11/2012</date>
            </publicationStmt>
            <sourceDesc>
                <p>Born digital, in a markdown format. Original file: <ref type="original_file" target="#downloading-multiple-records-using-query-strings"/>.</p>
                <p>There are other translations: <ref target="#descarga-multiples-registros-usando-cadenas-de-consulta"/>
                </p>
            </sourceDesc>
        </fileDesc>
        <profileDesc>
            <abstract>
                <p>Fazer o download de um único registro de um website é fácil, mas fazer o download de vários registros de uma vez - uma necessidade cada vez mais frequente para um historiador - é muito mais eficiente usando uma linguagem de programação como o Python. Nessa lição, escreveremos um programa que fará o download de uma série de registros do Old Bailey Online usando critérios de busca personalizados e irá armazená-los num diretório no nosso computador.</p>
            </abstract>
            <textClass>
                <keywords>
                    <term xml:lang="en">web-scraping</term>
                </keywords>
            </textClass>
        </profileDesc>
    </teiHeader>
    <text xml:lang="pt">
        <body>
            <div type="2" n="1">
                <head>Objetivos do Módulo</head>
                <p>Fazer o <emph>download</emph> de um único registro de um website é fácil, mas fazer o <emph>download</emph> de vários registros de uma vez - uma necessidade cada vez mais frequente para um historiador - é muito mais eficiente usando uma linguagem de programação como o Python. Nesta lição, escreveremos um programa que fará o <emph>download</emph> de uma série de registros do <emph>
                        <ref target="http://www.oldbaileyonline.org/">Old Bailey Online</ref>
                    </emph> usando critérios de investigação personalizados e irá armazená-los num diretório no nosso computador. Esse processo envolve interpretar e manipular <emph>Query Strings</emph> de URL. Nesse caso, o tutorial buscará fazer o <emph>download</emph> de fontes que contenham referências a afrodescendentes que foram publicadas no <emph>Old Bailey Proceedings</emph> entre 1700 e 1750.</p>
                <p style="alert alert-warning">
Os exemplos nessa lição incluem linguagem histórica racializada que os leitores podem achar ofensiva. O autor não tolera o uso dessa linguagem, mas tentou usá-la no seu contexto histórico, reconhecendo que, de outra forma, é impossível encontrar os materiais desejados do estudo de caso. Qualquer pessoa que ensine com este material é aconselhada a adotar uma abordagem sensível em relação à linguagem e a aplicar as boas práticas ao ensinar sobre raça. O autor recomenda os muitos recursos do <ref target="https://www.tolerance.org">Teaching Tolerance</ref>; Peggy McIntosh, ‘White Privilege: Unpacking the Invisible Knapsack’, <emph>Peace and Freedom Magazine</emph>, (1989), 10-12; Binyavanga Wainaina, ‘How to Write About Africa’, <emph>Granta</emph> (92): 2006.
</p>
            </div>
            <div type="2" n="2">
                <head>Para Quem isso é Útil?</head>
                <p>Automatizar o processo de <emph>download</emph> de registros de uma base de dados <emph>online</emph> será útil para qualquer um que trabalhe com fontes históricas armazenadas <emph>online</emph> de forma ordenada e acessível e que deseje salvar cópias dessas fontes no seu próprio computador. É particularmente útil para alguém que deseja fazer o <emph>download</emph> de vários registros específicos, em vez de apenas um punhado. Caso deseje fazer o <emph>download</emph> de <emph>todos</emph> ou da <emph>maioria</emph> dos registros de uma base de dados em particular, pode achar o tutorial de Ian Milligan sobre <ref target="/en/lessons/automated-downloading-with-wget">Automated Downloading with WGET</ref> mais adequado.</p>
                <p>O presente tutorial permitirá que faça <emph>download</emph> de forma isolada e discriminada de registros específicos que atendam às suas necessidades. Fazer o <emph>download</emph> de múltiplas fontes de forma automática economiza um tempo considerável. O que faz com as fontes baixadas depende dos seus objetivos de investigação. Pode desejar criar visualizações ou realizar uma série de métodos de análise de dados, ou simplesmente reformatá-las para facilitar a navegação. Ou pode desejar apenas manter uma cópia de <emph>backup</emph> para poder acessá-las sem acesso à internet.</p>
                <p>Essa lição é voltada para usuários de Python com nível intermediário. Caso ainda não tenha tentado as lições do <ref target="/pt/licoes/introducao-instalacao-python">Básico de Programação em Python</ref>, pode achá-las um ponto de partida útil.</p>
            </div>
            <div type="2" n="3">
                <head>Aplicando nosso Conhecimento Histórico</head>
                <p>Nesta lição, estamos tentando criar o nosso próprio corpus de casos relacionados com pessoas afrodescendentes. A partir do <ref target="http://www.oldbaileyonline.org/browse.jsp?id=t17800628-33&amp;div=t17800628-33">caso de Benjamin Bowsey</ref> no <emph>Old Bailey</emph> em 1780, podemos notar que "<emph>black</emph>" pode ser uma palavra-chave útil para usarmos para localizar outros casos envolvendo réus de ascendência africana. No entanto, quando buscamos por <emph>black</emph> no <emph>website</emph> do <emph>Old Bailey</emph>, percebemos que esta palavra às vezes se refere a outros usos: <emph>black horses</emph> ou <emph>black cloth</emph>. A tarefa de desambiguar esse uso da linguagem terá que esperar por outra lição. Por enquanto, vamos nos voltar para casos mais fáceis. Como historiadores, provavelmente, podemos pensar em palavras-chave de termos historicamente racializados relacionados com afrodescendentes as quais valeria a pena buscar. A infame "<emph>n-word</emph>", é claro, não é útil, já que esse termo não era comumente utilizado até meados do século XIX. Outras expressões racializadas como "<emph>negro</emph>" e "<emph>mulatto</emph>" são, porém, muito mais relevantes para o início do século XVIII. Essas palavras-chave são menos ambíguas do que "<emph>black</emph>" e são muito mais propensas a serem referências imediatas a pessoas no nosso público-alvo. Se testarmos esses dois termos em buscas separadas simples no <emph>Old Bailey website</emph>, temos resultados como nessa captura de tela:</p>
                <figure>
                    <desc>Resultados de investigação para 'negro' no *Old Bailey Online*</desc>
                    <graphic url="SearchResultsNegro.png"/>
                </figure>
                <figure>
                    <desc>Resultados de investigação para 'mulatto' no *Old Bailey Online*</desc>
                    <graphic url="SearchResultsMulatto.png"/>
                </figure>
                <p>Depois de examinar estes resultados de busca, parece evidente que são referências a pessoas e não a cavalos, panos ou qualquer outra coisa que seja preta. Desejamos fazer o <emph>download</emph> de todas para usar na nossa análise. Poderíamos, é claro, fazer o <emph>download</emph> de uma por uma manualmente. Mas vamos encontrar uma maneira programática de automatizar essa tarefa.</p>
            </div>
            <div type="2" n="4">
                <head>A Investigação Avançada no OBO</head>
                <p>As ferramentas de pesquisa de cada <emph>site</emph> funcionam de maneira diferente. Embora as pesquisas funcionem de forma semelhante, as complexidades das pesquisas numa base de dados podem não ser totalmente óbvias. Portanto, é importante pensar criticamente sobre as opções de busca de uma base de dados e, quando disponível, ler a documentação fornecida pelo <emph>website</emph>. Investigadores de história prudentes sempre interrogam suas fontes; os procedimentos por trás das suas caixas de pesquisa devem receber a mesma atenção. O <ref target="http://www.oldbaileyonline.org/forms/formMain.jsp">formulário de busca avançada</ref> do <emph>Old Bailey Online</emph> permite refinar as suas buscas com base em dez campos diferentes, incluindo palavras-chave simples, um intervalo de datas e um tipo de crime. Como as ferramentas de busca de cada <emph>website</emph> são diferentes, vale sempre a pena reservar um momento ou dois para testar e ler a respeito das opções de investigação disponíveis. Uma vez que já fizemos buscas simples por "<emph>negro</emph>" e "<emph>mulatto</emph>", sabemos que haverá resultados. No entanto, vamos usar a busca avançada para limitar os nossos resultados aos registros publicados no <emph>Old Bailey Proceedings</emph> que dizem respeito a julgamentos apenas de 1700 até 1750. É claro que pode alterá-lo para o que desejar, mas isso tornará o exemplo mais simples de ser acompanhado. Faça a busca mostrada na imagem abaixo. Certifique-se de que marcou o botão "<emph>Advanced</emph>" e incluiu as <emph>wildcards</emph>
                    <code rend="inline">*</code> para incluir entradas pluralizadas ou com um "e" extra no final.</p>
                <figure>
                    <desc>Exemplo de Busca Avançada no *Old Bailey*</desc>
                    <graphic url="AdvancedSearchExample.png"/>
                </figure>
                <p>Execute a busca e depois clique no <emph>link</emph> "<emph>Calculate Total</emph>" para ver quantas entradas existem. Agora temos 13 resultados (caso tenha um número diferente, volte e certifique-se de que copiou o exemplo acima da forma exata). O que queremos fazer neste ponto é o <emph>download</emph> de todos esses ficheiros de julgamento e analizá-los mais profundamente. Mais uma vez, para apenas 13 registros, também pode fazer o <emph>download</emph> de cada registro manualmente. Mas à medida que mais e mais dados são disponibilizados <emph>online</emph>, torna-se mais comum a necessidade de baixar 1.300 ou até 130.000 registros, caso no qual o <emph>download</emph> individual dos registros se torna impraticável e entender como automatizar o processo se torna muito valioso. Para automatizar o processo, precisamos de dar um passo atrás e lembrar como as URLs de busca são criadas no <emph>Old Bailey website</emph>, um método comum para muitas bases de dados <emph>online</emph> e <emph>websites</emph>.</p>
            </div>
            <div type="2" n="5">
                <head>Entendendo <emph>Queries</emph> de URL</head>
                <p>Observe a URL produzida com a última página de resultado de busca. Ela deve se parecer com isso:</p>
                <ab>
                    <code xml:id="code_download-multiplos-registros-query-strings_0" corresp="code_download-multiplos-registros-query-strings_0.txt" rend="block"/>
                </ab>
                <p>Vimos sobre URLs em <ref target="/pt/licoes/nocoes-basicas-paginas-web-html">Noções básicas de páginas web e HTML</ref>, mas isso parece muito mais complexo. Ainda que mais longo, <emph>não</emph> é verdadeiramente muito mais complexo. Mas é mais fácil de entender observando como os nossos critérios de busca são representados na URL.</p>
                <ab>
                    <code xml:id="code_download-multiplos-registros-query-strings_1" corresp="code_download-multiplos-registros-query-strings_1.txt" rend="block"/>
                </ab>
                <p>Nessa visão, vemos com mais clareza as 12 informações importantes que precisamos para realizar a nossa busca (uma por linha). Na primeira há a URL base do <emph>Old Bailey website</emph>, seguida por uma query "?" (não se preocupe com o <emph>bit</emph>
                    <code rend="inline">gen=1</code>; os desenvolvedores do <emph>Old Bailey Online</emph> dizem que ele não faz nada) e uma série de 10 pares <emph>nome/valor</emph> unidos por caracteres <code rend="inline">&amp;</code>. Juntos, esses 10 pares de nome/valor compõem a <emph>query string</emph> (expressão de busca), que informa ao mecanismo de busca quais variáveis usar em etapas específicas da investigação. Observe que cada par nome/valor contém um nome de variável: <code rend="inline">toYear</code> e, em seguida, atribui a essa variável um valor: <code rend="inline">1750</code>. Isso funciona exatamente da mesma forma que os <emph>Argumentos de Função</emph>, passando certas informações para variáveis específicas. Nesse caso, a variável mais importante é <code rend="inline">_divs_fulltext=</code>, para a qual foi dado o valor:</p>
                <ab>
                    <code xml:id="code_download-multiplos-registros-query-strings_2" corresp="code_download-multiplos-registros-query-strings_2.txt" rend="block"/>
                </ab>
                <p>Esta contém o termo que digitamos na caixa de busca. O programa adicionou automaticamente um sinal de soma <code rend="inline">+</code> no lugar de um espaço em branco (URLs não podem conter espaçamentos); dito de outro modo, isso é exatamente o que pedimos que o <emph>site</emph> do <emph>Old Bailey</emph> encontrasse. As outras variáveis carregam valores que nós também definimos. <code rend="inline">fromYear</code> e <code rend="inline">toYear</code> contém o nosso intervalo de datas. Já que nenhum ano possui 99 meses, como sugerido na variável <code rend="inline">toMonth</code>, podemos assumir que esse seja o modo através do qual o algoritmo garante que todos os registros daquele ano são incluídos. Não há regras difíceis ou rápidas para descobrir o que cada variável faz, porque a pessoa que criou o site as nomeou. Muitas vezes pode fazer uma suposição razoável. Todos os campos de busca possíveis na página de busca avançada possuem os seus próprios pares nome/valor. Caso deseje descobrir o nome da variável de modo a que possa utilizá-la, faça uma nova busca e certifique-se de colocar um valor no campo no qual está interessado. Após submeter a sua busca, verá o seu valor e o nome associado a ele como parte da URL da página dos resultados de busca. Com o <emph>Old Bailey Online</emph>, assim como com noutros <emph>websites</emph>, o formulário de busca (avançada ou não) ajuda, essencialmente, a construir URLs que informam à base de dados o que está buscando. Se puder entender como os campos de busca estão representados no URL - o que geralmente é algo bem direto -, então torna-se relativamente simples construir esses URLs programaticamente e automatizar o processo de <emph>download</emph> de registros.</p>
                <p>Agora tente alterar o <code rend="inline">start=0</code> para <code rend="inline">start=10</code> e pressione <code rend="inline">enter</code>. Deve agora ter os resultados 11-13. A variável <code rend="inline">start</code> informa ao <emph>website</emph> qual a entrada que deve ser mostrada no início da lista de resultados de busca. Nós devemos ser capazes de utilizar esse conhecimento para criar uma série de URLs que nos permitirão fazer o <emph>download</emph> de todos os 13 ficheiros. Vamos nos voltar para isso agora.</p>
            </div>
            <div type="2" n="6">
                <head>Fazendo o <emph>Download</emph> de Ficheiros Sistematicamente</head>
                <p>Na lição <ref target="/pt/licoes/download-paginas-web-python">Download de Páginas Web com Python</ref>, aprendemos que o Python pode fazer o <emph>download</emph> de uma página web desde que tenhamos a URL. Naquela lição, usamos a URL para fazer o <emph>download</emph> da transcrição do julgamento de Benjamin Bowsey. Nesse caso, estamos tentando fazer o <emph>download</emph> de múltiplas transcrições de julgamentos que atendem aos critérios de busca descritos acima sem precisar executar o programa repetidamente. Ao invés disso, queremos um programa que faça o <emph>download</emph> de tudo de uma vez. Neste ponto, temos a URL para a página de resultados de busca que contém as 10 primeiras entradas na nossa investigação. Também sabemos que ao mudarmos o valor de <code rend="inline">start</code> na URL, podemos sequencialmente chamar cada uma das páginas de resultados de busca e finalmente recuperar todos os ficheiros de julgamento que elas possuem. É claro que os resultados de busca não nos oferecem os ficheiros do julgamento em si, mas apenas <emph>links</emph> para eles. Então precisamos de extrair esses <emph>links</emph> para os registros subjacentes dos resultados de busca. No <emph>Old Bailey Online website</emph>, as URLs para os registros individuais (os ficheiros de transcrição de julgamento) podem ser encontrados como <emph>links</emph> na página de resultados de busca. Sabemos que todas as transcrições de julgamento possuem um id de julgamento que assume a forma: "t" seguido por, pelo menos, 8 números (ex.: t17800628-33). Ao buscar <emph>links</emph> que contenham esse padrão, podemos identificar URLs de transcrição de julgamento. Como em lições anteriores, vamos desenvolver um algoritmo de modo a que possamos começar a enfrentar esse problema de uma maneira que o computador possa lidar. Parece que a tarefa pode ser realizada em 4 passos. Precisaremos:</p>
                <list type="unordered">
                    <item>Gerar as URLs para cada página de resultados de busca incrementando a variável <code rend="inline">start</code> numa quantidade fixa um número apropriado de vezes.</item>
                    <item>Fazer o <emph>download</emph> de cada página de resultados de busca como um ficheiro HTML.</item>
                    <item>Extrair os URLs de cada transcrição de julgamento (usando o ID do julgamento como descrito acima) de cada ficheiro HTML de resultados de busca. </item>
                    <item>Percorrer essas URLs extraídas para baixar cada transcrição de avaliação e salvá-las num diretório no nosso computador.</item>
                </list>
                <p>Perceberá que isso é razoavelmente similiar às tarefas que realizamos em <ref target="/pt/licoes/download-paginas-web-python">Download de Páginas Web com Python</ref> e <ref target="/pt/licoes/HTML-lista-palavras-2">De HTML para Lista de Palavras (parte 2)</ref>. Primeiro, fazemos o <emph>download</emph> e, então, analisamos as informações que procuramos. E, nesse caso, fazemos mais alguns <emph>downloads</emph>.</p>
            </div>
            <div type="2" n="7">
                <head>Fazendo o <emph>Download</emph> das Páginas de Resultados de Busca</head>
                <p>Primeiro, precisamos de gerar as URLs para fazer o download de cada página de resultados de busca. Já temos a primeira usando a forma do próprio <emph>website</emph>.</p>
                <ab>
                    <code xml:id="code_download-multiplos-registros-query-strings_3" corresp="code_download-multiplos-registros-query-strings_3.txt" rend="block"/>
                </ab>
                <p>Poderíamos escrever essa URL duas vezes e alterar a variável <code rend="inline">start</code> para obter todas as 13 entradas, mas vamos escrever um programa que funcionaria independentemente de quantas páginas de resultados de busca ou registros precisássemos de fazer <emph>download</emph>, não importando o que decidíssemos investigar. Estude esse código e, depois, adicione essa função ao seu módulo chamado <code rend="inline">obo.py</code> (crie um ficheiro com esse nome e armazene-o no diretório onde deseja trabalhar). Os comentários no código destinam-se a ajudá-lo a decifrar as várias partes.</p>
                <ab>
                    <code lang="language-python" xml:id="code_download-multiplos-registros-query-strings_4" corresp="code_download-multiplos-registros-query-strings_4.txt" rend="block"/>
                </ab>
                <p>Nessa função, separamos os vários componentes da <emph>Query String</emph> e usamos Argumentos de Função para que a função possa ser reutilizada além dos nossos objetivos específicos atuais. Quando chamarmos por essa função, substituiremos os argumentos pelos valores que desejamos buscar. Depois, fazemos o <emph>download</emph> das páginas dos resultados de busca de maneira similiar a como foi feito em <ref target="/pt/licoes/download-paginas-web-python">Download de Páginas Web com Python</ref>. Agora, crie um novo ficheiro: <code rend="inline">download-searches.py</code> e copie o código a seguir dentro dele. Observe: os valores que passamos como argumentos são exatamente os mesmos dos utilizados no exemplo acima. Sinta-se livre para testá-los para receber resultados diferentes ou ver como funcionam.</p>
                <ab>
                    <code lang="language-python" xml:id="code_download-multiplos-registros-query-strings_5" corresp="code_download-multiplos-registros-query-strings_5.txt" rend="block"/>
                </ab>
                <p>Quando executar esse código, deve encontrar um novo ficheiro: <code rend="inline">search-result.html</code> no seu <code rend="inline">diretório programming-historian</code> contendo a primeira página dos resultados de busca da sua investigação. Certifique-se de que o <emph>download</emph> foi realizado apropriadamente e apague o ficheiro. Vamos adaptar o nosso programa para fazer o <emph>download</emph> da outra página contendo as outras 3 entradas ao mesmo tempo, assim queremos ter certeza que obteremos as duas. Vamos refinar a nossa função <code rend="inline">getSearchResults</code> adicionando outro argumento de função chamado <code rend="inline">entries</code>, de modo a que possamos dizer ao programa quantas páginas de resultados de busca precisamos fazer o <emph>download</emph>. Usaremos o valor das entradas e matemática simples para determinar quantas páginas de resultado de busca existem. Isso é algo bastante direto uma vez que sabemos que há dez transcrições de julgamento listadas por página. Podemos calcular o número de páginas de resultados de busca dividindo o valor das entradas por 10. Armazenaremos esse resultado na variável chamada <code rend="inline">pageCount</code>. Ela se parecerá com isso:</p>
                <ab>
                    <code lang="language-python" xml:id="code_download-multiplos-registros-query-strings_6" corresp="code_download-multiplos-registros-query-strings_6.txt" rend="block"/>
                </ab>
                <p>No entanto, em casos em que o número de entradas não é um múltiplo de 10, isso resultará num número decimal. Pode testá-lo executando esse código no seu Terminal (Mac &amp; Linux) / Linha de Comandos Python (Windows) e exibindo o valor mantido em <code rend="inline">pageCount</code>. (Observe que, daqui em diante, usaremos a palavra Terminal para referir esse programa).</p>
                <ab>
                    <code lang="language-python" xml:id="code_download-multiplos-registros-query-strings_7" corresp="code_download-multiplos-registros-query-strings_7.txt" rend="block"/>
                </ab>
                <p>Sabemos que a contagem do número de página deve ser 2 (uma página contendo as entradas 1-10 e uma página contendo as entradas 11-13). Uma vez que sempre queremos o maior inteiro mais próximo, podemos arredondar o resultado da divisão.</p>
                <ab>
                    <code lang="language-python" xml:id="code_download-multiplos-registros-query-strings_8" corresp="code_download-multiplos-registros-query-strings_8.txt" rend="block"/>
                </ab>
                <p>Se adicionarmos isso à nossa função <code rend="inline">getSearchResults</code> abaixo da linha <code rend="inline">startValue=0</code>, agora o código é capaz de calcular o número de páginas cujo <emph>download</emph> precisa de ser realizado. No entanto, nesta etapa ele irá fazer somente o <emph>download</emph> da primeira página, já que informamos à seção de <emph>download</emph> da função para executar somente uma vez. Para corrigir isso, podemos adicionar o código de <emph>download</emph> a um <code rend="inline">for</code>
                    <emph>loop</emph> que fará o <emph>download</emph> uma vez para cada número na variável <code rend="inline">pageCount</code>. Caso ele leia 1, fará o <emph>download</emph> uma vez; caso ele leia 5, fará o <emph>download</emph> cinco vezes e assim por diante. Imediatamente após o <code rend="inline">if</code>
                    <emph>statement</emph> que acabou de escrever, adicione a linha a seguir e indente tudo antes de <code rend="inline">f.close</code> com um espaçamento adicional de modo que tudo fique dentro do <code rend="inline">for</code>
                    <emph>loop</emph>:  </p>
                <ab>
                    <code lang="language-python" xml:id="code_download-multiplos-registros-query-strings_9" corresp="code_download-multiplos-registros-query-strings_9.txt" rend="block"/>
                </ab>
                <p>Uma vez que isso é um <code rend="inline">for</code>
                    <emph>loop</emph>, todo o código que desejamos executar repetidamente também precisa de ser planejado. Pode-se certificar de que fez isso corretamente verificando o código finalizado no exemplo abaixo. Esse <emph>loop</emph> aproveita a função <ref target="https://docs.python.org/3/tutorial/controlflow.html#the-range-function">range</ref> do Python. Para entender esse <code rend="inline">for</code>
                    <emph>loop</emph> é melhor, provavelmente, pensar em <code rend="inline">pageCount</code> igual a 2 como no exemplo. Portanto, essas duas linhas de código significam: comece a executar com um valor de <emph>loop</emph> inicial 1 e, a cada vez que executar, adicione uma unidade a esse valor. Quando o valor do <emph>loop</emph> é o mesmo de <code rend="inline">pageCount</code>, executa mais uma vez e para. Isso é particularmente valioso porque significa que podemos dizer ao nosso programa para executar exatamente uma vez para cada página de resultados de busca e oferece uma nova habilidade flexível para controlar quantas vezes um <code rend="inline">for</code>
                    <emph>loop</emph> é executado. Caso deseje praticar essa nova e poderosa maneira de escrever <emph>loops</emph>, pode abrir o seu Terminal e brincar.</p>
                <ab>
                    <code lang="language-python" xml:id="code_download-multiplos-registros-query-strings_10" corresp="code_download-multiplos-registros-query-strings_10.txt" rend="block"/>
                </ab>
                <p>Antes de adicionar todo esse código à nossa função <code rend="inline">getSearchResults</code>, temos que fazer dois ajustes finais. No final do <code rend="inline">for</code>
                    <emph>loop</emph> (mas ainda dentro do <emph>loop</emph>) e depois que o nosso código de <emph>download</emph> for executado, precisamos de mudar nossa variável <code rend="inline">startValue</code>, que é usada na construção da URL da página que desejamos fazer o <emph>download</emph>. Se nos esquecermos de fazer isso, o nosso programa fará repetidamente o <emph>download</emph> da primeira página de resultados de busca, já que não estamos verdadeiramente mudando nada na URL inicial. A variável <code rend="inline">startValue</code>, como discutido acima, é o que controla em que página de resultados de busca desejamos fazer o <emph>download</emph>. Portanto, podemos solicitar a próxima página de resultados de busca incrementando o valor de <code rend="inline">startvalue</code> em 10 unidades depois que o <emph>download</emph> inicial for concluído. Caso não tenha certeza de onde adicionar essa linha, pode espiar adiante o código finalizado no exemplo abaixo.</p>
                <p>Finalmente, queremos garantir que os nomes do ficheiros que fizemos o <emph>download</emph> são diferentes entre si. De outro modo, cada <emph>download</emph> será armazenado em cima do <emph>download</emph> anterior, deixando apenas um único ficheiro de resultados de busca. Para resolver isso, podemos ajustar os conteúdos da variável <code rend="inline">filename</code> para incluir o valor armazenado em <code rend="inline">startValue</code> de modo que a cada vez que fizermos o <emph>download</emph> de uma nova página, ela recebe um nome diferente. Já que a variável <code rend="inline">startValue</code> é um inteiro, precisaremos de convertê-la para uma string antes de adicioná-la à variável <code rend="inline">filename</code>. Ajuste a linha no seu programa que pertence à variável <code rend="inline">filename</code> para ficar assim:</p>
                <ab>
                    <code lang="language-python" xml:id="code_download-multiplos-registros-query-strings_11" corresp="code_download-multiplos-registros-query-strings_11.txt" rend="block"/>
                </ab>
                <p>Agora deve ser capaz de adicionar essas novas linhas de código à sua função <code rend="inline">getSearchResults</code>. Lembre-se de que fizemos as adições a seguir:</p>
                <list type="unordered">
                    <item>Adicionar <code rend="inline">entries</code> como um argumento de função adicional logo depois de <code rend="inline">toMonth</code>
                    </item>
                    <item>Calcular o número de páginas de resultados de pesquisa e adicionar isso imediatamente após a linha que começa com <code rend="inline">startValue = 0</code> (antes de construirmos a URL e começarmos o <emph>download</emph>)</item>
                    <item>Imediatamente após isso, adicione um <code rend="inline">for</code>
                        <emph>loop</emph> que informará ao programa para executar uma vez para cada página de resultados de busca, e indentar o resto do código de modo a que ele esteja dentro do novo <emph>loop</emph>
                    </item>
                    <item>A última linha no <code rend="inline">for</code>
                        <emph>loop</emph> deve agora incrementar o valor da variável <code rend="inline">startValue</code> a cada vez que o <emph>loop</emph> é executado</item>
                    <item>Ajustar a variável <code rend="inline">filename</code> existente de modo que a cada vez que for feito o <emph>download</emph> de uma página de resultados de busca ela forneça um nome único ao ficheiro.</item>
                </list>
                <p>A função finalizada no seu ficheiro <code rend="inline">obo.py</code> deve-se parecer com isso:</p>
                <ab>
                    <code lang="language-python" xml:id="code_download-multiplos-registros-query-strings_12" corresp="code_download-multiplos-registros-query-strings_12.txt" rend="block"/>
                </ab>
                <p>Para executar essa nova função, adicione o argumento extra ao <code rend="inline">download-searches.py</code> e execute o programa novamente:</p>
                <ab>
                    <code lang="language-python" xml:id="code_download-multiplos-registros-query-strings_13" corresp="code_download-multiplos-registros-query-strings_13.txt" rend="block"/>
                </ab>
                <p>Ótimo! Agora temos as duas páginas de resultados de busca, chamadas <code rend="inline">search-result0.html</code> e <code rend="inline">search-result10.html</code>. Mas antes de seguirmos para o próximo passo do algoritmo, vamos cuidar de algumas "tarefas de organização". O nosso diretório <code rend="inline">programming-historian</code> rapidamente se tornará difícil de controlar se fizermos o <emph>download</emph> de múltiplas páginas de resultados de busca e transcrições de julgamento. Vamos fazer com que o Python crie um novo diretório nomeado a partir dos nossos termos de busca. </p>
                <p>Desejamos adicionar essa nova funcionalidade em <code rend="inline">getSearchResults</code>, de modo que os <emph>downloads</emph> das nossas páginas de resultados de busca sejam direcionadas a diretórios com o mesmo nome da nossa <emph>query</emph> de busca. Isso manterá o nosso diretório <code rend="inline">programming-historian</code> mais organizado. Para fazê-lo, criaremos um novo diretório usando a biblioteca <code rend="inline">os</code>, abreviação de "<emph>operating system</emph>" (sistema operacional). Essa biblioteca contém uma função chamada <code rend="inline">makedirs</code> que, não surpreendentemente, cria um novo diretório. Pode testar usando o Terminal:</p>
                <ab>
                    <code lang="language-python" xml:id="code_download-multiplos-registros-query-strings_14" corresp="code_download-multiplos-registros-query-strings_14.txt" rend="block"/>
                </ab>
                <p>Esse programa irá verificar se o seu computador já possui um diretório com esse nome. Caso não possua, agora deve possuir um diretório chamado <code rend="inline">meuNovoDiretório</code> no seu computador. Num Mac provavelmente está localizado no seu diretório <code rend="inline">/Users/username/</code>, e no Windows deve ser capaz de encontrá-lo no diretório <code rend="inline">Python</code> no seu computador, o mesmo no qual abriu o programa da linha de comandos. Se isso funcionou, pode deletar o diretório do seu disco rígido, já que isso foi só uma prática. Uma vez que desejamos criar um novo diretório nomeado a partir da <emph>query</emph> que inserimos no <emph>Old Bailey Online website</emph>, vamos usar diretamente esse argumento de função <code rend="inline">query</code> da função <code rend="inline">getSearchResults</code>. Para fazer isso, importe a biblioteca <code rend="inline">os</code> após as outras e, depois, adicione o código que acabou de escrever imediatamente abaixo. A sua função <code rend="inline">getSearchResults</code> deve agora se parecer com isso:</p>
                <ab>
                    <code lang="language-python" xml:id="code_download-multiplos-registros-query-strings_15" corresp="code_download-multiplos-registros-query-strings_15.txt" rend="block"/>
                </ab>
                <p>O último passo para essa função é garantir que, quando salvarmos as nossas páginas de resultados de busca, as armazenaremos nesse novo diretório. Para fazer isso, podemos fazer um pequeno ajuste à variável <code rend="inline">filename</code> de modo a que o ficheiro termine no lugar certo. Há muitas formas de o fazer e a mais fácil é simplesmente adicionar o nome do novo diretório mais uma barra no nome do ficheiro:</p>
                <ab>
                    <code lang="language-python" xml:id="code_download-multiplos-registros-query-strings_16" corresp="code_download-multiplos-registros-query-strings_16.txt" rend="block"/>
                </ab>
                <p>Caso o seu computador esteja executando o Windows, precisará de uma barra invertida em vez da barra do exemplo acima. Adicione a linha acima à sua função <code rend="inline">getSearchResults</code> no lugar da descrição atual do <code rend="inline">filename</code>.</p>
                <p>Se estiver executando o Windows, é provável que o seu programa <code rend="inline">downloadSearches.py</code> falhe quando o executar porque está tentando criar um diretório com um * nele. O Windows não gosta disso. Para resolver esse problema podemos usar <ref target="https://docs.python.org/3/library/re.html">expressões regulares</ref> para remover qualquer caractere não compatível com o Windows. Usamos expressões regulares anteriormente em <ref target="/pt/licoes/contar-frequencias-palavras-python">Contagem de Frequências de Palavras com Python</ref>. Para remover caracteres não-alfanuméricos da <emph>query</emph>, primeiro importe a biblioteca de expressões regulares imediatamente após importar a biblioteca <code rend="inline">os</code> e, depois, use a função <code rend="inline">re.sub()</code> para criar uma nova string chamada <code rend="inline">cleanQuery</code> que contém apenas caracteres alfanuméricos. Depois precisará de substituir <code rend="inline">cleanQuery</code> como a variável usada nas declarações de <code rend="inline">os.path.exists()</code>, <code rend="inline">os.makedirs()</code> e <code rend="inline">filename</code>.</p>
                <ab>
                    <code lang="language-python" xml:id="code_download-multiplos-registros-query-strings_17" corresp="code_download-multiplos-registros-query-strings_17.txt" rend="block"/>
                </ab>
                <p>A versão final da sua função deve-se parecer com isso:</p>
                <ab>
                    <code lang="language-python" xml:id="code_download-multiplos-registros-query-strings_18" corresp="code_download-multiplos-registros-query-strings_18.txt" rend="block"/>
                </ab>
                <p>Dessa vez dizemos ao programa para fazer o <emph>download</emph> dos julgamentos e armazená-los num novo diretório ao invés do nosso diretório <code rend="inline">programming-historian</code>. Execute o programa <code rend="inline">download-searches.py</code> mais uma vez para se certificar de que ele funcionou e que entendeu como armazenar os ficheiros num diretório particular usando Python.</p>
                <div type="3" n="7.1">
                    <head>Fazendo o <emph>Download</emph> das Entradas de Julgamento Individuais</head>
                    <p>A este ponto, criamos uma função que é capaz de fazer o <emph>download</emph> de todos os ficheiros HTML de resultados de busca a partir do website <emph>Old Bailey Online</emph> para uma busca avançada que definimos e desenvolvemos de forma programática. Agora o próximo passo do algoritmo: extrair as URLs de cada transcrição de julgamento dos ficheiros HTML de resultados de busca. Nas lições que precedem esta (ex.: <ref target="/pt/licoes/download-paginas-web-python">Download de Páginas Web com Python</ref>), trabalhamos com as versões para exibição das transcrições dos julgamentos e continuaremos a fazer isso. Sabemos que a versão de exibição do julgamento de Benjamin Bowsey está localizada na URL:</p>
                    <ab>
                        <code xml:id="code_download-multiplos-registros-query-strings_19" corresp="code_download-multiplos-registros-query-strings_19.txt" rend="block"/>
                    </ab>
                    <p>Da mesma forma que alterar as <emph>query strings</emph> nas URLs gera resultados de busca diferentes, alterar a URL dos registros de julgamento - no caso, substituir um ID de julgamento por outro - nos fará obter a transcrição para aquele novo julgamento. Isso significa que, para encontrar e fazer o <emph>download</emph> dos 13 ficheiros que buscamos, tudo o que precisamos são esses IDs de julgamento. Uma vez que sabemos que essas páginas de resultados de busca geralmente contém um <emph>link</emph> para as páginas descritas, há uma boa chance de que consigamos encontrar esses <emph>links</emph> integrados ao código HTML. Se formos capazes de raspar essa informação das páginas de resultados de busca em que fizemos <emph>download</emph>, podemos então usar essa informação para gerar uma URL que nos permitirá fazer o <emph>download</emph> de cada transcrição de julgamento. Essa é uma técnica que irá utilizar para a maioria das páginas de resultados de busca, não só o <emph>Old Bailey Online</emph>! Para fazer isso, primeiro precisamos encontrar onde os IDs de julgamento estão no código HTML dos ficheiros que fizemos o <emph>download</emph> e, depois, determinar uma maneira de isolá-los consistentemente usando código de modo a que, independentemente de qual página de resultado de busca fizermos o <emph>download</emph>, sejamos capazes de encontrar as transcrições de julgamento. Primeiro, abra <code rend="inline">search-results0.html</code> no Komodo Edit e dê uma olhada na lista de julgamentos. A primeira entrada começa com "Anne Smith", então pode usar o recurso <code rend="inline">find</code> no Komodo Edit para pular imediatamente para o lugar certo. Observe que o nome de Anne faz parte de um <emph>link</emph>:</p>
                    <ab>
                        <code xml:id="code_download-multiplos-registros-query-strings_20" corresp="code_download-multiplos-registros-query-strings_20.txt" rend="block"/>
                    </ab>
                    <p>Perfeito, o <emph>link</emph> contém o ID do julgamento! Percorra as entradas restantes e verá que isso é verdade em todos os casos. Para nossa sorte, o <emph>site</emph> é bem formatado e parece que cada <emph>link</emph> começa com <code rend="inline">browse.jsp?id=</code> seguido pelo ID do julgamento e termina com um <code rend="inline">&amp;</code>, no caso de Anne: <code rend="inline">browse.jsp?id=t17160113-18&amp;</code>. Podemos escrever algumas linhas de código que sejam capazes de isolar esses IDs. Veja a função a seguir. Essa função também usa a biblioteca <code rend="inline">os</code>, nesse caso para listar todos os ficheiros localizados no diretório criado na seção anterior. A biblioteca <code rend="inline">os</code> possui uma gama de funções úteis que imitam os tipos de tarefas que esperaria ser capaz de fazer com o seu mouse no Mac Finder ou Windows, como abrir, fechar, criar, deletar e mover ficheiros e diretórios, e é uma boa biblioteca a ser masterizada - ou pelo menos para se familiarizar.</p>
                    <ab>
                        <code lang="language-python" xml:id="code_download-multiplos-registros-query-strings_21" corresp="code_download-multiplos-registros-query-strings_21.txt" rend="block"/>
                    </ab>
                    <p>Crie e execute um novo programa chamado <code rend="inline">extract-trials-ids.py</code> com o código a seguir. Certifique-se de inserir o mesmo valor nos argumentos da <emph>query</emph> como fez no exemplo anterior:</p>
                    <ab>
                        <code lang="language-python" xml:id="code_download-multiplos-registros-query-strings_22" corresp="code_download-multiplos-registros-query-strings_22.txt" rend="block"/>
                    </ab>
                    <p>Se tudo correu bem, deve ver uma lista contendo o nome de todos os ficheiros no seu novo diretório <code rend="inline">mulatto*+negro*</code>, que a essa altura devem ser as duas páginas de resultados de busca. Certifique-se de que isso funcionou antes de prosseguir. Uma vez que armazenamos todas as páginas de resultados de busca com um nome de ficheiro que inclui <code rend="inline">search-results</code>, agora desejamos abrir todos os ficheiros cujo nome contenha <code rend="inline">search-results</code> e extrair todos os IDs de julgamento encontrados neles. Nesse caso sabemos que temos 2, mas desejamos que o nosso código seja o mais reutilizável possível (com razão, é claro!). Restringir essa ação a ficheiros denominados <code rend="inline">search-results</code> significará que este programa funcionará como pretendido, mesmo que o diretório contenha muitos outros ficheiros não relacionados, já que o programa ignorará qualquer coisa com nome diferente.</p>
                    <p>Adicione o código a seguir à sua função <code rend="inline">getIndivTrials()</code>, que verificará se cada ficheiro contém <code rend="inline">search-results</code> no seu nome. Em caso verdadeiro, o ficheiro será aberto e o conteúdo será salvo na variável chamada <code rend="inline">text</code>. Essa variável <code rend="inline">text</code> será analisada na busca por um ID de julgamento, que sabemos que sempre segue <code rend="inline">browse.jsp?id=</code>. Se e quando o ID de julgamento for encontrado, ele será armazenado numa lista e exibido na Saída de Comando, que nos deixa com todas as informações que precisamos para então escrever o programa que fará o <emph>download</emph> dos julgamentos desejados.</p>
                    <ab>
                        <code lang="language-python" xml:id="code_download-multiplos-registros-query-strings_23" corresp="code_download-multiplos-registros-query-strings_23.txt" rend="block"/>
                    </ab>
                    <p>Essa última linha do <code rend="inline">for</code>
                        <emph>loop</emph> pode parecer confusa, mas certifique-se de que entendeu antes de seguir em frente. A variável <code rend="inline">words</code> é verificada para saber se contém os caracteres <code rend="inline">id=</code> (sem aspas), que obviamente se referem a um ID específico de transcrição de julgamento. Caso contenha, usamos o método de string <code rend="inline">slice</code> para capturar apenas o trecho entre <code rend="inline">id=</code> e <code rend="inline">&amp;</code> e o adicionamos à lista de url. Se soubéssemos as posições exatas dos índices dessa substring, poderíamos ter usado esses valores numéricos no lugar. No entanto, ao utilizar o método de string <code rend="inline">find()</code>, criamos um programa muito mais flexível. O código a seguir faz exatamente a mesma coisa que essa última linha, mas de maneira menos condensada:</p>
                    <ab>
                        <code lang="language-python" xml:id="code_download-multiplos-registros-query-strings_24" corresp="code_download-multiplos-registros-query-strings_24.txt" rend="block"/>
                    </ab>
                    <p>Ao executar novamente o programa <code rend="inline">extract-trial-ids.py</code>, deve ver uma lista de todos os IDs de julgamento. Podemos adicionar algumas linhas extra para transformá-los em URLs propriamente ditos e fazer o <emph>download</emph> de toda a lista para o nosso novo diretório. Também vamos usar a biblioteca <code rend="inline">time</code> para pausar o nosso programa por 3 segundos entre cada <emph>download</emph> - uma técnica chamada <emph>throttling</emph> (em português, estrangulamento). É considerada uma boa forma de não sobrecarregar o servidor de alguém com muitas solicitações por segundo; e o pequeno retardamento torna mais fácil que todos esses ficheiros sejam, de fato, baixados ao invés de ocorrer um <ref target="https://en.wikipedia.org/wiki/Timeout_(computing)">time out</ref>. Adicione o código a seguir ao final da sua função <code rend="inline">getIndivTrials()</code>. Esse código vai gerar uma URL para cada página individualmente, fará o <emph>download</emph> da página no seu computador, irá colocá-lo no seu diretório, armazenar o ficheiro e pausar por 3 segundos antes de continuar para o próximo julgamento. Todo esse trabalho está contido num <code rend="inline">for</code>
                        <emph>loop</emph> e será executado uma vez para cada julgamento na sua lista de urls.</p>
                    <ab>
                        <code lang="language-python" xml:id="code_download-multiplos-registros-query-strings_25" corresp="code_download-multiplos-registros-query-strings_25.txt" rend="block"/>
                    </ab>
                    <p>Se unirmos tudo numa única função, ela deve-se parecer com isso (note que adicionamos todas as chamadas por <code rend="inline">import</code> no início para manter as coisas claras):</p>
                    <ab>
                        <code lang="language-python" xml:id="code_download-multiplos-registros-query-strings_26" corresp="code_download-multiplos-registros-query-strings_26.txt" rend="block"/>
                    </ab>
                    <p>Vamos adicionar a mesma pausa de três segundos à nossa função <code rend="inline">getSearchResults</code> para ser amigável aos <emph>servers</emph> do <emph>Old Bailey Online</emph>:</p>
                    <ab>
                        <code lang="language-python" xml:id="code_download-multiplos-registros-query-strings_27" corresp="code_download-multiplos-registros-query-strings_27.txt" rend="block"/>
                    </ab>
                    <p>Finalmente, chame a função no programa <code rend="inline">download-searches.py</code>:</p>
                    <ab>
                        <code lang="language-python" xml:id="code_download-multiplos-registros-query-strings_28" corresp="code_download-multiplos-registros-query-strings_28.txt" rend="block"/>
                    </ab>
                    <p>Agora criou um programa que é capaz de fazer a solicitação e o <emph>download</emph> de ficheiros do <emph>Old Bailey website</emph>, baseado em parâmetros de busca que definiu, tudo sem visitar o <emph>site</emph>!</p>
                </div>
                <div type="3" n="7.2">
                    <head>No Caso de um Ficheiro Não Ser Baixado</head>
                    <p>Verifique se o <emph>download</emph> dos treze ficheiros foi realizado corretamente. Se esse for o caso, ótimo! No entanto, há a possibilidade de que esse programa tenha parado no meio do caminho. Isso porque o nosso programa, ao ser executado na nossa máquina, depende de dois fatores além do nosso controle imediato: a velocidade da internet e a o tempo de resposta do <emph>server</emph> do <emph>Old Bailey Online</emph> naquele momento. Uma coisa é pedir que o Python faça o <emph>download</emph> de um único ficheiro, mas quando começamos a solicitar um ficheiro a cada três segundos, há grandes chances de ocorrer um <emph>time out</emph> no <emph>server</emph> ou que ele falhe em nos enviar o ficheiro que estamos buscando.</p>
                    <p>Se estivermos usando um navegador <emph>web</emph> para fazer essas solicitações, eventualmente receberíamos uma mensagem de que "a conexão expirou" ou algo do tipo. Todos nós vemos isso de tempos em tempos. No entanto, o nosso programa não foi desenvolvido para lidar ou retransmitir essas mensagens de erro, então só perceberá o problema quando o programa não tiver retornado o número esperado de ficheiros ou simplesmente não fizer nada. Para evitar frustrações e incertezas, queremos um sistema à prova de falha no nosso programa, que tentará baixar cada julgamento. Se por alguma razão ele falhar, apontaremos o problema e passaremos para o próximo julgamento.</p>
                    <p>Para fazer isso, utilizaremos os mecanismos para lidar com erros do Python, <ref target="http://docs.python.org/tutorial/errors.html">try / except</ref>, bem como uma nova biblioteca: <code rend="inline">socket</code>. <code rend="inline">Try</code> e <code rend="inline">Except</code> são muito parecidos com um <code rend="inline">if / else</code>
                        <emph>statement</emph>. Quando solicita que o Python <code rend="inline">try</code> (em português, tente) algo, ele tentará executar o código; caso o código falhe em alcançar o que definiu, ele executará o  código em <code rend="inline">except</code> (em português, exceção).  Isso é frequentemente usado ao lidar com erros, conhecido como “error handling”. Podemos usá-lo a nosso favor dizendo ao programa para tentar fazer o <emph>download</emph> de uma página. Caso o programa falhe, solicitaremos que ele nos informe qual ficheiro falhou e depois prossiga. Para fazer isso precisamos de usar a biblioteca <code rend="inline">socket</code>, que nos permitirá definir um limite de tempo para um <emph>download</emph> antes de seguir em frente. Isso envolve alterar a função <code rend="inline">getIndivTrials</code>.</p>
                    <p>Primeiro, precisamos de carregar a biblioteca <code rend="inline">socket</code>, o que deve ser feito da mesma forma que todos as outras importações de biblioteca. Depois, precisamos de importar a biblioteca <code rend="inline">urllib.error</code>, que nos permite lidar com erros de <emph>download</emph>. Também precisamos de definir o tamanho do <emph>timeout</emph> padrão do <emph>socket</emph> - por quanto tempo desejamos tentar fazer o <emph>download</emph> de uma página antes de desistirmos. Isso deve entrar imediatamente após o comentário que começa com <code rend="inline"># faz o download da página</code>:</p>
                    <ab>
                        <code lang="language-python" xml:id="code_download-multiplos-registros-query-strings_29" corresp="code_download-multiplos-registros-query-strings_29.txt" rend="block"/>
                    </ab>
                    <p>Então, precisamos de uma nova lista de Python que armazenará todas as urls cujo <emph>download</emph> falhou. Vamos chamá-la de <code rend="inline">failedAttempts</code> e pode inserí-la imediatamente após as instruções de importação:</p>
                    <ab>
                        <code lang="language-python" xml:id="code_download-multiplos-registros-query-strings_30" corresp="code_download-multiplos-registros-query-strings_30.txt" rend="block"/>
                    </ab>
                    <p>Finalmente, podemos adicionar o <code rend="inline">try / except</code>
                        <emph>statement</emph> de forma muito similar a como um <code rend="inline">if / else</code>
                        <emph>statement</emph> seria adicionado. Nesse caso, vamos colocar todo o código desenvolvido para fazer o <emph>download</emph> e armazenar os julgamentos no <code rend="inline">try</code>
                        <emph>statement</emph>, e no <code rend="inline">except</code>
                        <emph>statement</emph> vamos dizer ao programa o que desejamos que ele faça caso falhe. Aqui, vamos adicionar a url cujo <emph>download</emph> falhou à nossa nova lista, <code rend="inline">failedAttempts</code>:</p>
                    <ab>
                        <code lang="language-python" xml:id="code_download-multiplos-registros-query-strings_31" corresp="code_download-multiplos-registros-query-strings_31.txt" rend="block"/>
                    </ab>
                    <p>Finalmente, diremos ao programa para exibir os conteúdos da lista na Saída de Comando de modo que saibamos quais ficheiros falharam no <emph>download</emph>. Isso deve ser adicionado nas linhas finais da função:</p>
                    <ab>
                        <code lang="language-python" xml:id="code_download-multiplos-registros-query-strings_32" corresp="code_download-multiplos-registros-query-strings_32.txt" rend="block"/>
                    </ab>
                    <p>Agora ao executarmos o programa, caso haja algum problema no <emph>download</emph> de um ficheiro específico, receberá uma mensagem na janela de Saída de Comando do Komodo Edit. Essa mensagem irá conter quaisquer URLs dos ficheiros que falharam no <emph>download</emph>. Caso haja apenas um ou dois, provavelmente é mais fácil simplesmente visitar as páginas manualmente e usar o recurso de "Salvar Como" do seu navegador. Caso se esteja sentindo aventureiro, poderia modificar o programa para automaticamente fazer o <emph>download</emph> dos ficheiros faltantes. A versão final das suas funções <code rend="inline">getSearchResults()</code> e <code rend="inline">getIndivTrials()</code> deve-se parecer com isso:</p>
                    <ab>
                        <code lang="language-python" xml:id="code_download-multiplos-registros-query-strings_33" corresp="code_download-multiplos-registros-query-strings_33.txt" rend="block"/>
                    </ab>
                </div>
            </div>
            <div type="2" n="8">
                <head>Leituras Adicionais</head>
                <p>Para usuários mais avançados, ou para se tornar um usuário mais avançado, pode achar que vale a pena ler sobre como alcançar esse mesmo processo usando Interfaces de Programação de Aplicações (API). Geralmente, um <emph>website</emph> com uma API dá instruções de como solicitar certos documentos. É um processo bastante similar ao que acabamos de fazer interpretando a <emph>Query String</emph> de URL, mas sem o trabalho de investigação adicional necessário para decifrar o que cada variável faz. Caso esteja interessado no <emph>Old Bailey Online</emph>, recentemente liberaram uma API e a documentação pode ajudar bastante:</p>
                <list type="unordered">
                    <item>Old Bailey Online API (<ref target="http://www.oldbaileyonline.org/static/DocAPI.jsp">http://www.oldbaileyonline.org/static/DocAPI.jsp</ref>)</item>
                    <item>Melhor maneira de criar um diretório para gravação de ficheiros, se ele não existir, usando Python? (<ref target="http://stackoverflow.com/questions/273192/python-best-way-to-create-directory-if-it-doesnt-exist-for-file-write">http://stackoverflow.com/questions/273192/python-best-way-to-create-directory-if-it-doesnt-exist-for-file-write</ref>)</item>
                </list>
            </div>
        </body>
    </text>
</TEI>
